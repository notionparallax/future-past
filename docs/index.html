<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />

        <title>🤖🤖🤖</title>
    </head>

    <body class="not-ready">
        
<script src="https://unpkg.com/pagedjs/dist/paged.polyfill.js"></script>
<link href="../css/interface-0.1.css" rel="stylesheet" type="text/css" />

<script src="../js/paged/functions.js"></script>
<script src="../js/paged/fnUtilities.js"></script>
<script src="../js/paged/fnLinks.js"></script>
<script src="../js/paged/control.js"></script>
<link href="../css/magazine.css" rel="stylesheet" type="text/css" />

<section class="front-page">
    <h1>The Past and Futures of Digital Cultures</h1>
    <!-- <figure>
        <img
            src="https://www.pngfind.com/pngs/m/271-2718608_smear-smudge-doodle-scribble-squiggle-blue-cyan-water.png"
            class="front-page-image"
        />
        <figcaption>caption</figcaption>
    </figure> -->
</section>

<section class="toc-section">
    <div class="toc">
        <ol>
             
            <li>
                2: 
                <a href="#h_Neuromancer"
                >Neuromancer</a
                >&mdash;William Gibson</li>
            <li>
                2: 
                <a href="#h_The Moment of Wired"
                >The Moment of Wired</a
                >&mdash;Thomas Streeter</li>
            <li>
                3: 
                <a href="#h_Guarding the gatekeepers: Trust, truth and digital platforms"
                >Guarding the gatekeepers: Trust, truth and digital platforms</a
                >&mdash;Terry Flew</li>
            <li>
                3: 
                <a href="#h_The net delusion: How not to liberate the world"
                >The net delusion: How not to liberate the world</a
                >&mdash;Evgeny Morozov</li>
            <li>
                4: 
                <a href="#h_Ada Lovelace, the First Tech Visionary"
                >Ada Lovelace, the First Tech Visionary</a
                >&mdash;Betsy Morais</li>
            <li>
                4: 
                <a href="#h_The Digital Age"
                >The Digital Age</a
                >&mdash;Paul E. Ceruzzi</li>
            <li>
                5: 
                <a href="#h_Early Television"
                >Early Television</a
                >&mdash;Vincent Mosco</li>
            <li>
                6: 
                <a href="#h_How Search Shaped and Was Shaped by the Web"
                >How Search Shaped and Was Shaped by the Web</a
                >&mdash;Alexander Halavais</li>
            <li>
                6: 
                <a href="#h_The Engine"
                >The Engine</a
                >&mdash;Alexander Halavais</li>
            <li>
                7: 
                <a href="#h_Commendary Cultures"
                >Commendary Cultures</a
                >&mdash;Fiona Martin</li>
            <li>
                7: 
                <a href="#h_Platforms Intervene"
                >Platforms Intervene</a
                >&mdash;Tarleton Gillespie</li>
            <li>
                8: 
                <a href="#h_Tweet fast and kill things: digital war"
                >Tweet fast and kill things: digital war</a
                >&mdash;William Merrin & Andrew Hoskins</li>
            <li>
                9: 
                <a href="#h_Big Data, new epistemologies and paradigm shifts"
                >Big Data, new epistemologies and paradigm shifts</a
                >&mdash;Rob Kitchin</li>
            <li>
                10: 
                <a href="#h_Self-branding, ‘micro-celebrity’ and the rise of Social Media Influencers"
                >Self-branding, ‘micro-celebrity’ and the rise of Social Media Influencers</a
                >&mdash;Susie Khamis, Lawrence Ang & Raymond Welling</li>
            <li>
                10: 
                <a href="#h_‘It’s like the gold rush’: the lives and careers of professional video game streamers on Twitch.tv"
                >‘It’s like the gold rush’: the lives and careers of professional video game streamers on Twitch.tv</a
                >&mdash;Mark R. Johnson & Jamie Woodcock</li>
            <li>
                11: 
                <a href="#h_Rise of the Machines: The Future has Lots of Robots, Few Jobs for Humans"
                >Rise of the Machines: The Future has Lots of Robots, Few Jobs for Humans</a
                >&mdash;Marguerite McNeal</li>
            <li>
                11: 
                <a href="#h_A Robot-Human Handshake in Space: Touch and Lively Alterity Relations in Social Robotics"
                >A Robot-Human Handshake in Space: Touch and Lively Alterity Relations in Social Robotics</a
                >&mdash;Chris Chesher & David Silvera-Tawil</li>
            <li>
                12: 
                <a href="#h_City Of Technology: Where The Streets Are Paved With Data"
                >City Of Technology: Where The Streets Are Paved With Data</a
                >&mdash;Vincent Mosco</li>
            <li>
                12: 
                <a href="#h_Smart street furniture in Australia: a public service or surveillance and advertising tool?"
                >Smart street furniture in Australia: a public service or surveillance and advertising tool?</a
                >&mdash;Justine Humphry, Chris Chesher & Sophia Maalsen</li>
            
        </ol>
    </div>
</section>

<div class="the-articles">
    <article><p>💩</p><p>💩</p><p>💩</p><p>💩</p><p>💩</p><p>💩</p></article>
    <article
        class="letter-from-the-editor paper-story"
        id="letter-to-the-editor"
    >
        <h1
            class="article-title"
            id="intro"
            data-article-title="Letter to the editor"
        >
            Readings for this course
        </h1>

        <p>Hi,</p>
        <p>intro text</p>
    </article>

    
     
    <article
id="Neuromancer"
class="paper-story"
data-article-title="Neuromancer"
>

<h1 class="article-title" id="h_Neuromancer">Neuromancer</h1>

<div class="top-meta">William Gibson, 1984-07-1 00:00:00 AEST. for week 2.</div>

<p>Gibson, W. (1984) [excerpt pp 62-83] <a href="https://en.wikipedia.org/wiki/Neuromancer"><em>Neuromancer</em></a>.</p>
<p><a href="https://gist.github.com/m-242/ecb3e130b76a3b12f7ef41b04f486405">Full text of neuromancer</a> as a <a href="https://gist.github.com/discover">Gist</a></p>
<hr>
<p>Lifeless neon spelled out METRO HOLOGRAFIX in dusty capitals of glass tubing. Case picked at a shred of bacon that had lodged between his front teeth. He'd given up asking her where they were going and why; jabs in the ribs and the sign for silence were all he'd gotten in reply. She talked about the season's fashions, about sports, about a political scandal in California he'd never heard of.</p>
<p>He looked around the deserted dead end street. A sheet of newsprint went cart wheeling past the intersection. Freak winds in the East side; something to do with convection, and an overlap in the domes. Case peered through the window at the dead sign. Her Sprawl wasn't his Sprawl? he decided. She'd led him through a dozen bars and clubs he'd never seen before, taking care of business, usually with no more than a nod. Maintaining connections.</p>
<p>Something was moving in the shadows behind METRO HOLOGRAFIX.</p>
<p>The door was a sheet of corrugated roofing. In front of it, Molly's hands flowed through an intricate sequence of jive that he couldn't follow. He caught the sign for <em>cash</em>, a thumb brushing the tip of the forefinger. The door swung inward and she led him into the smell of dust. They stood in a clearing, dense tangles of junk rising on either side to walls lined with shelves of crumbling paperbacks. The junk looked like something that had grown there, a fungus of twisted metal and plastic. He could pick out individual objects, but then they seemed to blur back into the mass: the guts of a television so old it was studded with the glass stumps of vacuum tubes, a crumpled dish antenna, a brown fiber canister stuffed with corroded lengths of alloy tubing. An enormous pile of old magazines had cascaded into the open area, flesh of lost summers staring blindly up as he followed her back through a narrow canyon of impacted scrap. He heard the door close behind them. He didn't look back.</p>
<p>The tunnel ended with an ancient Army blanket tacked across a doorway. White light flooded out as Molly ducked past it.</p>
<p>Four square walls of blank white plastic, ceiling to match, floored with white hospital tile molded in a non slip pattern of small raised disks. In the center stood a square, white-painted wooden table and four white folding chairs.</p>
<p>The man who stood blinking now in the doorway behind them, the blanket draping one shoulder like a cape, seemed to have been designed in a wind tunnel. His ears were very small, plastered flat against his narrow skull, and his large front teeth, revealed in something that wasn't quite a smile, were canted sharply backward. He wore an ancient tweed jacket and held a handgun of some kind in his left hand. He peered at them, blinked, and dropped the gun into a jacket pocket. He gestured to Case, pointed at a slab of white plastic that leaned near the doorway. Case crossed to it and saw that it was a solid sandwich of circuitry, nearly a centimeter thick. He helped the man lift it and position it in the doorway. Quick, nicotine-stained fingers secured it with a white velcro border. A hidden exhaust fan began to purr.</p>
<p>&quot;Time,&quot; the man said, straightening up, &quot;and counting. You know the rate, Moll.&quot;</p>
<p>&quot;We need a scan, Finn. For implants.&quot;</p>
<p>&quot;So get over there between the pylons. Stand on the tape. Straighten up, yeah. Now turn around, gimme a full threesixty.&quot; Case watched her rotate between two fragile-looking stands studded with sensors. The man took a small monitor from his pocket and squinted at it. &quot;Something new in your head, yeah. Silicon. coat of pyrolitic carbons. A clock, right? Your glasses gimme the read they always have, low-temp isotropic carbons. Better biocompatibility with pyrolitics, but that's your business, right? Same with your claws.&quot;</p>
<p>&quot;Get over here, Case.&quot; He saw a scuffed X in black on the white floor. &quot;Turn around. Slow.&quot;</p>
<p>&quot;Guy's a virgin.&quot; The man shrugged. &quot;Some cheap dental work, is all.&quot;</p>
<p>&quot;You read for biologicals?&quot; Molly unzipped her green vest and took off the dark glasses.</p>
<p>&quot;You think this is the Mayo? Climb on the table, kid, we'll run a little biopsy.&quot; He laughed, showing more of his yellow teeth. &quot;Nah. Finn's word, sweetmeat, you got no little bugs, no cortex bombs. You want me to shut the screen down?&quot;</p>
<p>&quot;Just for as long as it takes you to leave, Finn. Then we'll want full screen for as long as we want it.&quot;</p>
<p>&quot;Hey, that's fine by the Finn, Moll. You're only paying by the second.&quot;</p>
<p>They sealed the door behind him and Molly turned one of the white chairs around and sat on it, chin resting on crossed forearms. &quot;We talk now. This is as private as I can afford.&quot;</p>
<p>&quot;What about?&quot;</p>
<p>&quot;What we're doing.&quot;</p>
<p>&quot;What are we doing?&quot;</p>
<p>&quot;Working for Armitage.&quot;</p>
<p>&quot;And you're saying this isn't for his benefit?&quot;</p>
<p>&quot;Yeah. I saw your profile, Case. And I've seen the rest of our shopping list, once. You ever work with the dead?&quot;</p>
<p>&quot;No.&quot; He watched his reflection in her glasses. &quot;I could, I guess. I'm good at what I do.&quot; The present tense made him nervous.</p>
<p>&quot;You know that the Dixie Flat line's dead?&quot; He nodded. &quot;Heart, I heard.&quot;</p>
<p>&quot;You'll be working with his construct.&quot; She smiled. &quot;Taught you the ropes, huh? Him and Ovine. I know Quine, by the way. Real ass hole.&quot;</p>
<p>&quot;Somebody's got a recording of McCoy Pauley? Who?&quot; Now Case sat, and rested his elbows on the table. &quot;I can't see it. He'd never have sat still for it.&quot;</p>
<p>&quot;Sense/Net. Paid him mega, you bet your ass.&quot;</p>
<p>&quot;Ovine dead too?&quot;</p>
<p>&quot;No such luck. He's in Europe. He doesn't come into this.&quot;</p>
<p>&quot;Well, if we can get the Flatline, we're home free. He was the best. You know he died brain death three times?&quot;</p>
<p>She nodded.</p>
<p>&quot;Flat lined on his EEG. Showed me tapes. 'Boy, I was <em>daid</em>.' &quot;</p>
<p>&quot;Look, Case, I been trying to suss out who it is is backing Armitage since I signed on. But it doesn't feel like a zaibatsu, a government, or some Yakuza subsidiary. Armitage gets orders. Like something tells him to go off to Chiba, pick up a pillhead who's making one last wobble throught the burnout belt, and trade a program for the operation that'll fix him up. We could a bought twenty world class cowboys for what the market was ready to pay for that surgical program. You were good, but not <em>that</em> good. . .&quot; She scratched the side of her nose.</p>
<p>&quot;Obviously makes sense to somebody,&quot; he said. &quot;Somebody big.&quot;</p>
<p>&quot;Don't let me hurt your feelings.&quot; She grinned. &quot;We're gonna be pulling one hardcore run, Case, just to get the Flatline's construct. Sense/Net has it locked in a library vault uptown. Tighter than an eel's ass, Case. Now, Sense/Net, they got all their new material for the fall season locked in there too. Steal that and we'd be richer than shit. But no, we gotta get us the Flatline and nothing else. Weird.&quot;</p>
<p>&quot;Yeah, it's all weird. You're weird, this hole's weird, and who's the weird little gopher outside in the hall?&quot;</p>
<p>&quot;Finn's an old connection of mine. Fence, mostly. Software. This privacy biz is a sideline. But I got Armitage to let him be our tech here, so when he shows up later, you never saw him. Got it?&quot;</p>
<p>&quot;So what's Arrnitage got dissolving inside you?&quot;</p>
<p>&quot;I'm an easy make.&quot; She smiled. &quot;Anybody any good at what they do, that's what they <em>are</em>, right? You gotta jack, I gotta tussle.&quot;</p>
<p>He stared at her. &quot;So tell me what you know about Armitage.&quot;</p>
<p>&quot;For starters, nobody named Armitage took part in any Screaming Fist. I checked. But that doesn't mean much. He doesn't look like any of the pics of the guys who got out.&quot; She shrugged. &quot;Big deal. And starters is all I got.&quot; She drummed her nails on the back of the chair. &quot;But you <em>are</em> a cowboy, aren't you? I mean, maybe you could have a little look around.&quot; She smiled.</p>
<p>&quot;He'd kill me.&quot;</p>
<p>&quot;Maybe. Maybe not. I think he needs you, Case, and real bad. Besides, you're a clever john, no? You can winkle him, sure.&quot;</p>
<p>&quot;What else is on that list you mentioned?&quot;</p>
<p>&quot;Toys. Mostly for you. And one certified psychopath name of Peter Riviera. Real ugly customer.&quot;</p>
<p>&quot;Where's he?&quot;</p>
<p>&quot;Dunno. But he's one sick fuck, no lie. I saw his profile.&quot; She made a face. &quot;God awful.&quot; She stood up and stretched, catlike. &quot;So we got an axis going, boy? We're together in this? Partners?&quot;</p>
<p>Case looked at her. &quot;I gotta lotta choice, huh?&quot;</p>
<p>She laughed. &quot;You got it, cowboy.&quot;</p>
<p> </p>
<p>&quot;The matrix has its roots in primitive arcade games,&quot; said the voice-over, &quot;in early graphics programs and military experimentation with cranial jacks.&quot; On the Sony, a two-dimensional space war faded behind a forest of mathematically generated ferns, demonstrating the spacial possibilities of logarithmic spirals- cold blue military footage burned through, lab animals wired into test systems, helmets feeding into fire con. trot circuits of tanks and war planes. &quot;Cyberspace. A con sensual hallucination experienced daily by billions of legitimate operators, in every nation, by children being taught mathematical concepts . . . A graphic representation of data abstracted from the banks of every computer in the human system. Unthinkable complexity. Lines of light ranged in the non space of the mind, clusters and constellations of data. Like city lights, receding. . .&quot;</p>
<p>&quot;What's that?&quot; Molly asked, as he flipped the channel selector.</p>
<p>&quot;Kid's show.&quot; A discontinuous flood of images as the selector cycled. &quot;Off,&quot; he said to the Hosaka.</p>
<p>&quot;You want to try now, Case?&quot;</p>
<p>Wednesday. Eight days from waking in Cheap Hotel with Molly beside him. &quot;You want me to go out, Case? Maybe easier for you, alone. . .&quot; He shook his head.</p>
<p>&quot;No. Stay, doesn't matter.&quot; He settled the black terry sweatband across his forehead, careful not to disturb the flat Sendai dermatrodes. He stared at the deck on his lap, not really seeing it, seeing instead the shop window on Ninsei, the chromed shuriken burning with reflected neon. He glanced up; on the wall, just above the Sony, he'd hung her gift, tacking it there with a yellow-headed drawing pin through the hole at its center. closed his eyes.</p>
<p>Found the ridged face of the power stud.</p>
<p>And in the bloodlit dark behind his eyes, silver phosphenes boiling in from the edge of space, hypnagogic images jerking past like film compiled from random frames. Symbols, figures, faces, a blurred, fragmented mandala of visual information.</p>
<p>Please, he prayed, <em>now</em>—</p>
<p>A gray disk, the color of Chiba sky.</p>
<p><em>Now</em>—</p>
<p>Disk beginning to rotate, faster, becoming a sphere of paler gray. Expanding—</p>
<p>And flowed, flowered for him, fluid neon origami trick, the unfolding of his distance less home, his country, transparent 3D chessboard extending to infinity. Inner eye opening to the stepped scarlet pyramid of the Eastern Seaboard Fission Authority burning beyond the green cubes of Mitsubishi Bank of America, and high and very far away he saw the spiral arms of military systems, forever beyond his reach.</p>
<p>And somewhere he was laughing, in a white-painted loft, distant fingers caressing the deck, tears of release streaking his face.</p>
<p> </p>
<p>Molly was gone when he took the trodes off, and the loft was dark. He checked the time. He'd been in cyberspace for five hours. He carried the Ono-Sendai to one of the new worktables and collapsed across the bedslab, pulling Molly's black silk sleeping bag over his head.</p>
<p>The security package taped to the steel fire door bleeped twice. &quot;Entry requested,&quot; it said. &quot;Subject is cleared per my program.&quot;</p>
<p>&quot;So open it.&quot; Case pulled the silk from his face and sat up as the door opened, expecting to see Molly or Armitage.</p>
<p>&quot;Christ,&quot; said a hoarse voice, &quot;I know that bitch can see in the dark. . .&quot; A squat figure stepped in and closed the door.</p>
<p>&quot;Turn the lights on, okay?&quot; Case scrambled off the slab and found the old-fashioned switch.</p>
<p>&quot;I'm the Finn,&quot; said the Finn, and made a warning face at Case.</p>
<p>&quot;Case.&quot;</p>
<p>&quot;Pleased to meecha, I'm sure. I'm doing some hardware for your boss, it looks like.&quot; The Finn fished a pack of Partagas from a pocket and lit one. The smell of Cuban tobacco filled the room. He crossed to the worktable and glanced at the OnoSendai. &quot;Looks stock. Soon fix that. But here is your problem, kid.&quot; He took a filthy manila envelope from inside his jacket, flicked ash on the floor, and extracted a featureless black rectangle from the envelope. &quot;Goddamn factory prototypes,&quot; he said, tossing the thing down on the table. &quot;Cast 'em into a block of polycarbon, can't get in with a laser without frying the works. Booby-trapped for x-ray, ultrascan, God knows what else. We'll get in, but there's no rest for the wicked, right?&quot; He folded the envelope with great care and tucked it away in an inside pocket.</p>
<p>&quot;What is it?&quot;</p>
<p>&quot;It's a flip flop switch, basically. Wire it into your Sendai here, you can access live or recorded Sims Tim without having to jack out of the matrix.&quot;</p>
<p>&quot;What for?&quot;</p>
<p>&quot;I haven't got a clue. Know I'm fitting Moll for a broadcast rig, though, so it's probably her sensorium you'll access.&quot; The Finn scratched his chin. &quot;So now you get to find out just how tight those jeans really are, huh?&quot;</p>
<h2>4</h2>
<p>Case sat in the loft with the dermatrodes strapped across his forehead, watching motes dance in the diluted sunlight that filtered through the grid overhead. A countdown was in progress in one corner of the monitor screen.</p>
<p>Cowboys didn't get into Simstim, he thought, because it was basically a meat toy. He knew that the trodes he used and the little plastic tiara dangling from a Simstim deck were basically the same, and that the cyberspace matrix was actually a drastic simplification of the human sensorium, at least in terms of presentation, but Simstim itself struck him as a gratuitous multiplication of flesh input. The commercial stuff was edited, of course, so that if Tally Isham got a headache in the course of a segment, you didn't feel it.</p>
<p>The screen bleeped a two-second warning.</p>
<p>The new switch was patched into his Sendai with a thin ribbon of fiber optics.</p>
<p>And one and two and—</p>
<p>Cyberspace slid into existence from the cardinal points. Smooth, he thought, but not smooth enough. Have to work on it. . .</p>
<p>Then he keyed the new switch.</p>
<p>The abrupt jolt into other flesh. Matrix gone, a wave of sound and color. . . She was moving through a crowded street, past stalls vending discount software, prices felt penned on sheets of plastic, fragments of music from countless speakers. Smells of urine, free monomers, perfume, patties of frying krill. For a few frightened seconds he fought helplessly to control her body. Then he willed himself into passivity, became the passenger behind her eyes.</p>
<p>The glasses didn't seem to cut down the sunlight at all. He wondered if the built-in amps compensated automatically. Blue alphanumerics winked the time, low in her left peripheral field. Showing off, he thought.</p>
<p>Her body language was disorienting, her style foreign. She seemed continually on the verge of colliding with someone, but people melted out of her way, stepped sideways, made room.</p>
<p>&quot;How you doing, Case?&quot; He heard the words and felt her form them. She slid a hand into her jacket, a fingertip circling a nipple under warm silk. The sensation made him catch his breath. She laughed. But the link was one-way. He had no way to reply.</p>
<p>Two blocks later, she was threading the outskirts of Memory Lane. Case kept trying to jerk her eyes toward landmarks he would have used to find his way. He began to find the passivity of the situation irritating.</p>
<p>The transition to cyberspace, when he hit the switch, was instantaneous. He punched himself down a wall of primitive ice belonging to the New York Public Library, automatically counting potential windows. Keying back into her sensorium, into the sinuous flow of muscle, senses sharp and bright.</p>
<p>He found himself wondering about the mind he shared these sensations with. What did he know about her? That she was another professional; that she said her being, like his, was the thing she did to make a living. He knew the way she'd moved against him, earlier, when she woke, their mutual grunt of unity when he'd entered her, and that she liked her coffee black, afterward. . .</p>
<p>Her destination was one of the dubious software rental complexes that lined Memory Lane. There was a stillness, a hush.Booths lined a central hall. The clientele were young, few of them out of their teens. They all seemed to have carbon sockets planted behind the left ear, but she didn't focus on them. The counters that fronted the booths displayed hundreds of slivers of microsoft, angular fragments of colored silicon mounted under oblong transparent bubbles on squares of white cardboard. Molly went to the seventh booth along the south wall. Behind the counter a boy with a shaven head stared vacantly into space, a dozen spikes of microsoft protruding from the socket behind his ear.</p>
<p>&quot;Larry, you in, man?&quot; She positioned herself in front of him. The boy's eyes focused. He sat up in his chair and pried a bright magenta splinter from his socket with a dirty thumbnail .</p>
<p>&quot;Hey, Larry.&quot;</p>
<p>&quot;Molly.&quot; He nodded.</p>
<p>&quot;I have some work for some of your friends, Larry.&quot;</p>
<p>Larry took a flat plastic case from the pocket of his red sport shirt and flicked it open, slotting the microsoft beside a dozen others. His hand hovered, selected a glossy black chip that was slightly longer than the rest, and inserted it smoothly into his head. His eyes narrowed.</p>
<p>&quot;Molly's got a rider,&quot; he said, &quot;and Larry doesn't like that.&quot;</p>
<p>&quot;Hey,&quot; she said, &quot;I didn't know you were so . . . sensitive. I'm impressed. Costs a lot, to get that sensitive.&quot;</p>
<p>&quot;I know you, lady?&quot; The blank look returned. &quot;You looking to buy some softs?&quot;</p>
<p>&quot;I'm looking for the Moderns.&quot;</p>
<p>&quot;You got a rider, Molly. This says.&quot; He tapped the black splinter. &quot;Somebody else using your eyes.&quot;</p>
<p>&quot;My partner.&quot;</p>
<p>&quot;Tell your partner to go.&quot;</p>
<p>&quot;Got something for the Panther Moderns, Larry.&quot;</p>
<p>&quot;What are you talking about, lady?&quot;</p>
<p>&quot;Case, you take off,&quot; she said, and he hit the switch, instantly back in the matrix. Ghost impressions of the software complex hung for a few seconds in the buzzing calm of cyberspace.</p>
<p>&quot;Panther Moderns,&quot; he said to the Hosaka, removing the trodes. &quot;Five minute precis.&quot;</p>
<p>&quot;Ready,&quot; the computer said.</p>
<p>It wasn't a name he knew. Something new, something that had come in since he'd been in Chiba. Fads swept the youth of the Sprawl at the speed of light; entire subcultures could rise overnight, thrive for a dozen weeks, and then vanish utterly. &quot;Go,&quot; he said. The Hosaka had accessed its array of libraries, journals, and news services.</p>
<p>The precis began with a long hold on a color still that Case at first assumed was a collage of some kind, a boy's face snipped from another image and glued to a photograph of a paint-scrawled wall. Dark eyes, epicanthic folds obviously the result of surgery, an angry dusting of acne across pale narrow cheeks. The Hosaka released the freeze; the boy moved, flowing with the sinister grace of a mime pretending to be a jungle predator. His body was nearly invisible, an abstract pattern approximating the scribbled brickwork sliding smoothly across his tight one piece. Mimetic polycarbon.</p>
<p>Cut to Dr. Virginia Rambali, Sociology, NYU, her name, faculty, and school pulsing across the screen in pink alphanumerics.</p>
<p>&quot;Given their penchant for these random acts of surreal violence,&quot; someone said, &quot;it may be difficult for our viewers to understand why you continue to insist that this phenomenon isn't a form of terrorism.&quot;</p>
<p>Dr. Rambali smiled. &quot;There is always a point at which the terrorist ceases to manipulate the media gestalt. A point at which the violence may well escalate, but beyond which the terrorist has become symptomatic of the media gestalt itself. Terrorism as we ordinarily understand it is inately media-related. The Panther Moderns differ from other terrorists precisely in their degree of self-consciousness, in their awareness of the extent to which media divorce the act of terrorism from the original sociopolitical intent. . .&quot;</p>
<p>&quot;Skip it,&quot; Case said.</p>
<p> </p>
<p>Case met his first Modern two days after he'd screened the Hosaka's precis. The Moderns, he'd decided, were a contemporary version of the Big Scientists of his own late teens. There was a kind of ghostly teenage DNA at work in the Sprawl, something that carried the coded precepts of various short-lived sub cults and replicated them at odd intervals. The Panther Moderns were a soft head variant on the Scientists. If the technology had been available the Big Scientists would all have had sockets stuffed with microsofts. It was the style that mattered and the style was the same. The Moderns were mercenaries, practical jokers, nihilistic technofetishists.</p>
<p>The one who showed up at the loft door with a box of diskettes from the Finn was a soft-voiced boy called Angelo. His face was a simple graft grown on collagen and shark-cartilage polysaccharides, smooth and hideous. It was one of the nastiest pieces of elective surgery Case had ever seen. When Angelo smiled, revealing the razor-sharp canines of some large animal, Case was actually relieved. Tooth bud transplants. He'd seen that before.</p>
<p>&quot;You can't let the little pricks generation-gap you,&quot; Molly said. Case nodded, absorbed in the patterns of the Sense/Net ice.</p>
<p>This was it. This was what he was, who he was, his being. He forgot to eat. Molly left cartons of rice and foam trays of sushi on the corner of the long table. Sometimes he resented having to leave the deck to use the chemical toilet they'd set up in a corner of the loft. Ice patterns formed and reformed on the screen as he probed for gaps, skirted the most obvious traps, and mapped the route he'd take through Sense/Net's ice. It was good ice. Wonderful ice. Its patterns burned there while he lay with his arm under Molly's shoulders, watching the red dawn through the steel grid of the skylight. Its rainbow pixel maze was the first thing he saw when he woke. He'd go straight to the deck, not bothering to dress, and jack in. He was cutting it. He was working. He lost track of days.</p>
<p>And sometimes, falling asleep, particularly when Molly was off on one of her reconnaissance trips with her rented cadre of Moderns, images of Chiba came flooding back. Faces and Ninsei neon. Once he woke from a confused dream of Linda Lee, unable to recall who she was or what she'd ever meant to him. When he did remember, he jacked in and worked for nine straight hours.</p>
<p>The cutting of Sense/Net's ice took a total of nine days.</p>
<p>&quot;I said a week,&quot; Armitage said, unable to conceal his satisfaction when Case showed him his plan for the run. &quot;You took your own good time.&quot;</p>
<p>&quot;Balls,&quot; Case said, smiling at the screen. &quot;That's good work, Armitage.&quot;</p>
<p>&quot;Yes,&quot; Armitage admitted, &quot;but don't let it go to your head. Compared to what you'll eventually be up against, this is an arcade toy.&quot;</p>
<p> </p>
<p>&quot;Love you, Cat Mother,&quot; whispered the Panther Modern's link man. His voice was modulated static in Case's headset.</p>
<p>&quot;Atlanta, Brood. Looks go. Go, got it?&quot; Molly's voice was slightly clearer.</p>
<p>&quot;To hear is to obey.&quot; The Moderns were using some kind of chicken wire dish in New Jersey to bounce the link man's scrambled signal off a Sons of Christ the King satellite in geosynchronous orbit above Manhattan. They chose to regard the entire operation as an elaborate private joke, and their choice of comsats seemed to have been deliberate. Molly's signals were being beamed up from a one-meter umbrella dish epoxy-ed to the roof of a black glass bank tower nearly as tall as the Sense/Net building.</p>
<p>Atlanta. The recognition code was simple. Atlanta to Boston to Chicago to Denver, five minutes for each city. If anyone managed to intercept Molly's signal, unscramble it, synth her voice, the code would tip the Moderns. If she remained in the building for more than twenty minutes, it was highly unlikely she'd be coming out at all.</p>
<p>Case gulped the last of his coffee, settled the trodes in place, and scratched his chest beneath his black t-shirt. He had only a vague idea of what the Panther Moderns planned as a diversion for the Sense/Net security people. His job was to make sure the intrusion program he'd written would link with the Sense/Net systems when Molly needed it to. He watched the countdown in the corner of the screen. Two. One.</p>
<p>He jacked in and triggered his program. &quot;Mainline,&quot; breathed the link man, his voice the only sound as Case plunged through the glowing strata of Sense/Net ice. Good. Check Molly. He hit the Simstim and flipped into her sensorium.</p>
<p>The scrambler blurred the visual input slightly. She stood before a wall of gold-flecked mirror in the building's vast white lobby, chewing gum, apparently fascinated by her own reflection. Aside from the huge pair of sunglasses concealing her mirrored insets, she managed to look remarkably like she belonged there, another tourist girl hoping for a glimpse of Tally Isham. She wore a pink plastic raincoat, a white mesh top, loose white pants cut in a style that had been fashionable in Tokyo the previous year. She grinned vacantly and popped her gum. Case felt like laughing. He could feel the micro pore tape across her ribcage, feel the flat little units under it: the radio, the Simstim unit, and the scrambler. The throat mike, glued to her neck, looked as much as possible like an analgesic dermadisk. Her hands, in the pockets of the pink coat, were flexing systematically through a series of tension-release exercises. It took him a few seconds to realize that the peculiar sensation at the tips of her fingers was caused by the blades as they were partially extruded, then retracted.</p>
<p>He flipped back. His program had reached the fifth gate. He watched as his icebreaker strobed and shifted in front of him, only faintly aware of his hands playing across the deck, making minor adjustments. Translucent planes of color shuffled like a trick deck. Take a card, he thought, any card.</p>
<p>The gate blurred past. He laughed. The Sense/Net ice had accepted his entry as a routine transfer from the consortium's Los Angeles complex. He was inside. Behind him, viral subprograms peeled off, meshing with the gate' s code fabric, ready to deflect the real Los Angeles data when it arrived.</p>
<p>He flipped again. Molly was strolling past the enormous circular reception desk at the rear of the lobby.</p>
<p>12:01:20 as the readout flared in her optic nerve.</p>
<p>At midnight, synch Ed with the chip behind Molly's eye, the link man in Jersey had given his command. &quot;Mainline.&quot; Nine Moderns, scattered along two hundred miles of the Sprawl, had simultaneously dialed MAX EMERG from pay phones. Each Modern delivered a short set speech, hung up, and drifted out into the night, peeling off surgical gloves. Nine different police departments and public security agencies were absorbing the information that an obscure sub sect of militant Christian fundamentalists had just taken credit for having introduced clinical levels of an outlawed psychoactive agent known as Blue Nine into the ventilation system of the Sense/Net Pyramid. Blue Nine, known in California as Grievous Angel, had been shown to produce acute paranoia and homicidal psychosis in eighty-five percent of experimental subjects.</p>
<p> </p>
<p>Case hit the switch as his program surged through the gates of the subsystem that controlled security for the Sense/Net research library. He found himself stepping into an elevator.</p>
<p>&quot;Excuse me, but are you an employee?&quot; The guard raised his eyebrows. Molly popped her gum. &quot;No,&quot; she said, driving the first two knuckles of her right hand into the man's solar plexus. As he doubled over, clawing for the beeper on his belt she slammed his head sideways, against the wall of the elevator. Chewing a little more rapidly now, she touched CLOSE DOOR and STOP on the illuminated panel. She took a black box from her coat pocket and inserted a lead in the keyhole of the lock that secured the panel's circuitry.</p>
<p> </p>
<p>The Panther Moderns allowed four minutes for their first move to take effect, then injected a second carefully prepared dose of misinformation. This time, they shot it directly into the Sense/Net building's internal video system.</p>
<p>At 12:04:03, every screen in the building strobed for eighteen seconds in a frequency that produced seizures in a susceptible segment of Sense/Net employees. Then something only vaguely like a human face filled the screens, its features stretched across asymmetrical expanses of bone like some obscene Mercator projection. Blue lips parted wetly as the twisted, elongated jaw moved. Something, perhaps a hand, a thing like a reddish clump of gnarled roots, fumbled toward the camera, blurred, and vanished. Subliminally rapid images of contamination: graphics of the building's water supply system, gloved hands manipulating laboratory glassware, something tumbling down into darkness, a pale splash. . . The audio track, its pitch adjusted to run at just less than twice the standard playback speed, was part of a month-old newscast detailing potential military uses of a substance known as HsG, a biochemical governing the human skeletal growth factor. Overdoses of HsG threw certain bone cells into overdrive, accelerating growth by factors as high as one thousand percent.</p>
<p>At 12:05:00, the mirror-sheathed nexus of the Sense/Net consortium held just over three thousand employees. At five minutes after midnight, as the Modems' message ended in a flare of white screen, the Sense/Net Pyramid screamed.</p>
<p>Half a dozen NYPD Tactical hovercraft, responding to the possibility of Blue Nine in the building's ventilation system, were converging on the Sense/Net Pyramid. They were running full riot lights. A BAMA Rapid Deployment helicopter was lifting off from its pad on Riker's.</p>
<p> </p>
<p>Case triggered his second program. A carefully engineered virus attacked the code fabric screening primary custodial commands for the sub-basement that housed the Sense/Net research materials. &quot;Boston,&quot; Molly's voice came across the link, &quot;I'm downstairs.&quot; Case switched and saw the blank wall of the elevator. She was unzipping the white pants. A bulky packet, exactly the shade of her pale ankle, was secured there with micro pore. She knelt and peeled the tape away. Streaks of burgundy flickered across the mimetic polycarbon as she unfolded the Modem suit. She removed the pink raincoat, threw it down beside the white pants, and began to pull the suit on over the white mesh top.</p>
<p>12:06:26.</p>
<p>Case's virus had bored a window through the library's command ice. He punched himself through and found an infinite blue space ranged with color-coded spheres strung on a tight grid of pale blue neon. In the non space of the matrix, the interior of a given data construct possessed unlimited subjective dimension; a child's toy calculator, accessed through Case's Sendai, would have presented limitless gulfs of nothingness hung with a few basic commands. Case began to key the sequence the Finn had purchased from a mid-eschelon sarariman with severe drug problems. He began to glide through the spheres as if he were on invisible tracks.</p>
<p>Here. This one.</p>
<p>Punching his way into the sphere, chill blue neon vault above him starless and smooth as frosted glass, he triggered a subprogram that effected certain alterations in the core custodial commands.</p>
<p>Out now. Reversing smoothly, the virus reknitting the fabric of the window.</p>
<p>Done.</p>
<p> </p>
<p>In the Sense/Net lobby, two Panther Moderns sat alertly behind a low rectangular planter, taping the riot with a video camera. They both wore chameleon suits. &quot;Tacticals are spraying foam barricades now,&quot; one noted, speaking for the benefit of his throat mike. &quot;Rapids are still trying to land their copter.&quot;</p>
<p> </p>
<p>Case hit the Sims Tim switch. And flipped into the agony of broken bone. Molly was braced against the blank gray wall of a long corridor, her breath coming ragged and uneven. Case was back in the matrix instantly, a white-hot line of pain fading in his left thigh.</p>
<p>&quot;What's happening, Brood?&quot; he asked the link man.</p>
<p>&quot;I dunno, Cutter. Mother's not talking. Wait.&quot;</p>
<p>Case's program was cycling. A single hair-fine thread of crimson neon extended from the center of the restored window to the shifting outline of his icebreaker. He didn't have time to wait. Taking a deep breath, he flipped again.</p>
<p>Molly took a single step, trying to support her weight on the corridor wall. In the loft, Case groaned. The second step took her over an outstretched arm. Uniform sleeve bright with fresh blood. Glimpse of a shattered fiberglass shock stave. Her vision seemed to have narrowed to a tunnel. With the third step, Case screamed and found himself back in the matrix.</p>
<p>&quot;Brood? Boston, baby. . .&quot; Her voice tight with pain. She coughed. &quot;Little problem with the natives. Think one of them broke my leg.&quot;</p>
<p>&quot;What you need now, Cat Mother?&quot; The link man's voice was indistinct, nearly lost behind static.</p>
<p>Case forced himself to flip back. She was leaning against the wall, taking all of her weight on her right leg. She fumbled through the contents of the suit's kangaroo pocket and withdrew a sheet of plastic studded with a rainbow of dermadisks. She selected three and thumbed them hard against her left wrist, over the veins. Six thousand micrograms of endorphin analog came down on the pain like a hammer, shattering it. Her back arched convulsively. Pink waves of warmth lapped up her thighs. She sighed and slowly relaxed.</p>
<p>&quot;Okay, Brood. Okay now. But I'll need a medical team when l come out. Tell my people. Cutter, I'm two minutes from target. Can you hold?&quot;</p>
<p>&quot;Tell her I'm in and holding,&quot; Case said.</p>
<p>Molly began to limp down the corridor. When she glanced back, once, Case saw the crumpled bodies of three Sense/Net security guards. One of them seemed to have no eyes.</p>
<p>&quot;Tacticals and Rapids have sealed the ground floor, Cat Mother. Foam barricades. Lobby's getting juicy.&quot;</p>
<p>&quot;Pretty juicy down here,&quot; she said, swinging herself through a pair of gray steel doors. &quot;Almost there, Cutter.&quot;</p>
<p>Case flipped into the matrix and pulled the trodes from his forehead. He was drenched with sweat. He wiped his forehead with a towel, took a quick sip of water from the bicycle bottle beside the Hosaka, and checked the map of the library displayed on the screen. A pulsing red cursor crept through the outline of a doorway. Only millimeters from the green dot that indicated the location of the Dixie Flat line's construct. He wondered what it was doing to her leg, to walk on it that way. With enough endorphin analog, she could walk on a pair of bloody stumps. He tightened the nylon harness that held him in the chair and replaced the trodes.</p>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="The Moment of Wired"
class="paper-story"
data-article-title="The Moment of Wired"
>

<h1 class="article-title" id="h_The Moment of Wired">The Moment of Wired</h1>

<div class="top-meta">Thomas Streeter, 2011-01-01 00:00:00 AEST. for week 2.</div>

<p>Streeter, T. (2011) The Moment of Wired, Chapter 4 in The Net Effect: Romanticism, Capitalism, and the Internet. New York and London: New York University Press.</p>
<p>https://dokumen.pub/the-net-effect-romanticism-capitalism-and-the-internet-0814741169-9780814741160.html</p>
<p><a href="/assets/pdf/The-net-effect-romanticism-capitalism-and-the-internet.pdf">pdf</a></p>
<hr>
<figure>
> When it comes to smashing a paradigm, pleasure is not the most important thing. It is the only thing. [The web browser] Mosaic is not the most direct way to find online information. Nor is it the most powerful. It is merely the most pleasurable way, and in the 18 months since it was released, Mosaic has incited a rush of excitement and commercial energy unprecedented in the history of the Net.
<figcaption>
&mdash;<cite>Wired</cite>, Oct. 1994 (10 months before the Netscape IPO)
</figcaption>
</figure>
<h2>Revelations in the Cubicle: White-collar Computing in the Early 1990s</h2>
<p>Recall—or, if you are young enough, imagine—what it was like to go online in the early 1990s. At the time, desktop computers had recently lost their novelty and become a routine part of office life. Word processing had, in the preceding five years, become a standard secretarial skill, and a new desktop computer was a standard part of an academic job offer. The desktop computer had become just another part of office routine, like the photocopier.</p>
<p>In most offices, however, people who used email were still a small minority, and web browsing was unknown. Those who had experimented with email a bit had done so typically within specific, confined worlds like CompuServe, Prodigy, local bulletin boards, or one of several restricted academic or corporate networks. Going online at the time was thus technically possible with the computers that were on the desks of journalists, academics, and other professionals, but it was a little out of the ordinary. If you weren’t a computer professional, it was something you did out of curiosity; it took a substantial amount of time and was unlikely to yield much in the way of immediate practical value. For the vast majority, communications that mattered still happened exclusively on paper or on the phone. If you went online you knew that most people around you did not.</p>
<p>Going online typically required purchasing and plugging in a roughly paperback-sized modem (computers did not routinely come equipped with them). The modem had a bank of mysterious flashing red lights, and using it involved installing, configuring, and then running a terminal program, typing commands, listening to the squealing modem, and typing in another cryptic series of commands and passwords. There was no pointing and clicking yet in the online world. Just getting it all going was at least a forty-five-minute time investment. And then figuring out what to do once signed on was a further challenge. Gateways between computer networks were still being constructed. As a result, to send, say, an email from the BITNET network—then common at less technical universities— across the still limited internet, the email addresses had to be sandwiched between quote marks and prefaced by IN%—thusly: IN%”T_STREETER@uvmvax.uvm.edu”—and this technical detail was not easy to find out.</p>
<p>But, once you mastered such arcana, you could then enter into a secret world.</p>
<p>This was the context in which a message appeared on a number of discussion lists in February 1993, prefaced with the following:</p>
<pre><code>From:IN%”TNC@GITVM1.BITNET” “’TECHNOCULTURE’ discussion
list” 22-FEB-1993 11:48:56.39
    To:IN%”T_STREETER@uvmvax.uvm.edu” “Thomas Streeter”
    Subject: John Perry Barlow meets the spooks
    Folks,
    This lovely missive came from SURFPUNKs (subscription info below). The
    idea of JPB giving an invited address on technology to the intelligence (sic) community
    is just soooo sweet. And it’s a good speech, too.
    Larry Hunter
</code></pre>
<p>The bulk of the message was the text of an address given a few months before, in December 1992, by Electronic Frontier Foundation (EFF) cofounder John Perry Barlow to a conference on National Security outside of Washington, DC.<sup>1</sup> As the message made clear, many members of the U.S. intelligence community (that is, the CIA, NSA, FBI) were present. Barlow’s agenda as EFF representative was to educate this community about the value of protecting free speech and privacy in the digital realm.</p>
<p>Ordinarily, when speaking to a skeptical audience, most of us are likely to adopt a careful, formal, conformist rhetorical strategy. We would downplay our disagreements and differences and represent ourselves as having deep respect for the audience members. Barlow, however, began his talk this way:</p>
<blockquote>
<p>I can’t tell you the sense of strangeness that comes over someone who earns his living writing Grateful Dead songs, addressing people who earn their livings as many of you do, especially after hearing the last speaker. If you don’t appreciate the irony of our appearing in succession, you have no sense of irony at all. . . . .</p>
<p>The reason I am here has absolutely nothing to do with the Grateful Dead. I’m here because I met a fellow named Mitch Kapor in 1989. Despite obvious differences, I felt as if we’d both been up in the same saucer or something . . . . that we shared a sense of computers being more than just better adding machines or a better typewriters. We saw that computers, connected together, had the capacity to create an environment which human beings could and did inhabit. . . . . The people who share this awareness are natives of the future. People who have a hard time with it may always be immigrants.</p>
<p>When Mitch and I saw that computers had created a place, we started asking some questions about what kind of place it was. . . . . We decided to name it Cyberspace, after Bill Gibson’s description of a futuristic place rather like it which we found in his novel Neuromancer.<sup>2</sup></p>
</blockquote>
<p>Here is a central example of some habits of talk and thought that would soon be moving into the mainstream with enormous impact. Barlow was the key figure in importing the term cyberspace from the world of science-fiction fan programmers into middlebrow discourse; hereafter, the internet could be envisioned, not just as a tool or set of devices with predictable potentials, but as an unknown space to be explored and thus available for any number of collective projections, particularly the frontier metaphor—made explicit in the name of Barlow’s foundation. But this particular refiguring of the frontier metaphor was also heavily inflected with tropes from the 1960s counterculture; Barlow’s missive featured a studied informality (“we’d both been up in the same saucer or something,” “Mitch,” “Bill”); a pleasure in iconoclasm (“if you don’t appreciate the irony”); and a flamboyant individualism (in the EFF’s relentless focus on personal privacy and liberties). But this bit of computer counterculturalism also had an association with power (the CIA!). And, crucially, in a classic countercultural maneuver, instead of flattering his audience or downplaying his differences from them, Barlow offers them a choice between being one who gets it and one who doesn’t. Accept his rhetorical universe, and you are a “native of the future.” Reject it, however, and you are threatened with always being an immigrant there.</p>
<p>At the time, reading a missive like this on a monochrome screen, perhaps during a slow day at the office or perhaps late at night at home, had an arresting effect. Barlow’s email suggested to the lone cubicle dweller who had mastered email that a new sense of energy was emerging in the online world. The incongruous juxtaposition of a Grateful Dead lyricist with CIA officials was funny, of course, but also enticing; how many people get invitations to talk to CIA officials, much less go on to tweak the officials’ noses and get away with it? Here was someone whose tax bracket and espionage experience were probably comparable to yours, yet he was boldly preaching to an established, powerful, and sometimes violent institution. The situation suggested a new opening, a new avenue towards power. As a white-collar reader of this text in early 1993, you felt uniquely privy to this intriguing opening because you were among the elite few who had mastered the arcane art of online access. The relative obscurity of the procedures needed to get the message only added to the aura of being part of a special group. You, who both got the joke and technically could get access to it, were invited to be one of the vanguard, one of Barlow’s “natives of the future.” It gave you a new sense of what it meant to be sitting in one’s office typing, a new, hipper, less ordinary, sense of self.</p>
<p>The effect was indeed delicious.</p>
<p>In the early 1990s, growing numbers of professionals and white-collar workers were being surprised by this kind of experience on their desktop computers. As the number of people with some variety of online access increased from month to month, more and more people had an experience of stumbling upon something striking; it could be a surprising exchange on an email discussion list, involving a tidbit of insider information from afar. Or it could be a titillating personal revelation; this was the moment when stories of email romances began to circulate in popular folklore. It could be a new form of access to something or someone, like the personal MTV gopher created as a hobby by MTV vee-jay Adam Curry; accessing his gopher gave one a kind of personal access to a media figure, to someone ordinarily shielded behind the glossy professionalism of the television screen. (Fans of this gopher were treated to a Barlow-like iconoclastic moment in April 1994 when Curry, with a 1960s flourish of rebellion, announced his resignation from MTV on air. He was resigning in order to pursue his digital activities full time, on the then-astonishing theory that the digital world was the wave of the future, and television was obsolete.)3 Something out of the ordinary, it seemed, was afoot.</p>
<p>By the early 1990s in the United States, the microcomputer industry had triumphed, but it was no longer enchanting. Microcomputers so far were turning out to be office machines, and most of the computers in the home turned out to be mostly ways to do office work after hours. Most of the 1980s efforts to sell computers specifically for the home market—for example, the Sinclair, the Commodore 64, the Atari, the IBM PCJr—had gradually disappeared. The little computers did not seem quite so personal anymore. Not only had the desktop computer become a commonplace of office life, with all its associations with bureaucracy, but the companies that made microcomputers no longer seemed like the boisterous garage start-ups of popular capitalist mythology; by 1990, Microsoft had pushed aside the grey, arrogant, predictable monopoly of IBM—and replaced it with another grey, arrogant, predictable monopoly.</p>
<p>And, as Barlow’s message was circulating in email discussion lists and newsgroups, the first issue of <em>Wired</em> had just hit the newsstands; within a year it would have a circulation of over 100,000 and a curious readership several times that.<sup>4</sup></p>
<h2>From “Information Superhighway” to “Cyberspace” and the <em>Habitus</em> of Knowledge Workers</h2>
<p>The internet enthusiasms of the 1990s have frequently been described as utopian, but it was really the information superhighway scenario that was utopian, in the sense of offering a blueprint for a better future. Cyberspace, by contrast, was made famous in the precedent-setting novel of cyberpunk fiction, Gibson’s <em>Neuromancer</em>, which depicts a near-future world of technological violence, cruelty, manipulation, and cynical disaffection—a world that is distinctly dystopian. The appeal of <em>Neuromancer</em> is less utopian than romantic. Its tale of a “console cowboy” is a narrative of an outcast hero on a desperate quest initiated by a search, not for wealth, but for inner transformation—for love, comradeship, and meaning, but also, as if to make the inner transformation point vivid, an internal physical reprogramming so as to allow for better net traveling.</p>
<p>To the computer-operating white-collar worker in the early 1990s, <em>Neuromancer</em> provided a story line that redefined the act of sitting at a keyboard entering commands from one of white-collar drudgery into an act of exploration and adventure. Cyberspace, by defining the internet as a space, a territory for adventure, rather than as merely a highway, a means towards the end of accessing already organized information, suggested a new potential self-definition for knowledge workers. <em>Information superhighway</em> sounds clean, obedient, and orderly. The connotations of <em>cyberspace</em> are darker, less regimented, more scary—but thereby more thrilling. Late at night, alone in one’s cubicle, <em>cyberspace</em> had a much more alluring ring. Cyberspace did not offer a utopia, a perfected world; it offered a taste of rebel-hero selfhood.</p>
<p>We like to think that romances and revolutions come from nowhere, as if they are their own explanation and driving force. But of course there’s generally a context like a mid-life crisis or a frustrated and underemployed middle class that sets the conditions for the change. The same is true of the spread of online computing in the early 1990s.</p>
<p>To understand why <em>cyberspace</em> outlived <em>information superhighway</em> in popular usage, it helps to consider exactly what kinds of people were getting online access in the early 1990s. Typical discussions of social class and computer use focus on a haves versus have-nots continuum, where the concern is extending the benefits of computer use lower down on the class ladder. But it is also illuminating to look upwards on the ladder as well: Both Bill Gates and the janitor that empties your office trash bin can get along fine without desktop computers in the day-to-day of their work lives. Computers have become a central feature of the work lives specifically of the knowledge or professional classes, a group that includes middle managers, engineers, mid-level government bureaucrats, academics, and journalists— white-collar knowledge workers.</p>
<p>Crucial to the character of the early 1990s, then, was the fact that online access came first among those who <em>did their own word processing</em> and thus had the necessary equipment and experience readily at hand. Graduate students and assistant professors were online before university presidents and provosts. Middle managers, technicians, and engineers were online before vice presidents and CEOs. Mid-level journalists were online before editors and managers. This is a relatively unusual pattern of technological diffusion; networking entered social life through the same portal as the photocopy machine rather than through the top-down diffusion patterns of the telephone or the consumer-distribution patterns of television. This pattern thus meant that the sense of something important happening in networking would hit the middle ranks of the knowledge class before it hit their superiors.</p>
<p>The information superhighway, and the corporate liberal technology policy for which it stood, may have been reasonable, forward looking, and economically rational. But it lacked a sense of enchantment. Developing government-business partnerships that would encourage investment in wide-area computer networking for purposes of information exchange may have been a good idea, but, for the typical cubicle dweller, it did not generate much fire in the belly.</p>
<p>In the years leading up to 1995, the stage was thus set for the middle ranks to be treated to a drama of obliviousness from above, an object lesson in highlevel bewilderment. It was the people who typed their own memos, reports, term papers, and journal articles who sensed the importance of the internet first and then watched the higher-ups struggle to catch up with them. <em>Cyberspace</em>, with its romantic hint of a rebellious self image, better captured the sense of pleasure and open-ended possibility they felt in watching their secret world trump the staid world of their superiors.</p>
<h2>Tropes from the Counterculture: “They Just Don’t Get It”</h2>
<p>Louis Rossetto, cofounder of <em>Wired</em>, had experienced both the original 1960s counterculture and its emerging computer-culture variant, the former as a college student, the latter as the editor of a small journal about desktop computer publishing, <em>Electric Word</em>.<sup>5</sup> He has said he modeled <em>Wired</em> on the early <em>Rolling Stone</em>—the sincere, preironic, early 1970s <em>Rolling Stone</em>, when it was based in San Francisco and celebrated rock stars as oracles of a revolution in human consciousness.<sup>6</sup> Rossetto frequently dismissed mainstream media’s technology coverage with the phrase, “they just don’t get it.”<sup>7</sup> The phrase is part of the rhetorical foundation of outlets like the hacker website Slashdot or <em>Wired</em>; in the constant cavalier dismissal of vaguely defined, “old” institutions and points of view (for example, Microsoft, television networks, government bureaucracies, Keynesianism) these media are flattering readers by implicitly including them in the knowledgeable avant-garde. As John Perry Barlow was fond of implying, You are one of us, the mammals, and those powerful people are the dinosaurs.</p>
<p>When a marginal social movement accurately anticipates in the public eye a significant historical failure of judgment on the part of leadership, the effect can be powerful. Being right about something when the powers that be were wrong, for example, was a central collective experience of the 1960s counterculture; by 1969, the world had watched the television networks, the <em>New York Times</em>, and many members of the political establishment change their position on the Vietnam War. In the mid-1990s, it would be the failure to anticipate the importance of the internet, and, in the late 1990s the value of open software. And part of the power of such moments is that they open the door to iconoclasm and to new currents of thought; if the authorities are wrong about that one thing, what else might they have missed?</p>
<p>At the same time, this kind of collective experience establishes the conditions for a less clearly beneficial drawing of boundaries between those who knew and those who didn’t. What this phrase does is tell the listener that he or she and the speaker are part of the elite group who get it. The ones who don’t could be the Pentagon, the media, or your parents; in any case, there’s a thrill in the implication that you and I stand apart from despised others in the world.</p>
<p>If being right about some central event like Vietnam or the internet gives the rhetoric of getting it force, accuracy in general is not necessary or even a precondition for the rhetoric to work. The internet was only discussed in passing in <em>Wired’s</em> first issue; Rossetto had to catch up to the centrality of the internet like everyone else in the media. And, more importantly, once the rhetorical ground is established by whatever means, a powerful trope for shutting down inquiry is made available. In the interview mentioned above, when Rossetto was asked if he’s religious, he replied “no.” When asked if he’s an atheist, he also replied “no,” and then continued: “It’s not worth thinking about. . . . . I mean, I’ve gone beyond it.”8 The rhetoric of “they just don’t get it” can create conditions that make this kind of shutting down of inquiry sound wise. The reader or hearer is made automatically wary of voicing any criticism, questioning, or complexity, even to themselves. Express doubts, and you risk being worse than wrong, you risk revealing yourself to be a dinosaur and thus no longer part of the privileged club; you just don’t get it.</p>
<h2>The Moment of Mosaic: The Pleasure of Anticipation</h2>
<p>By mid-1993, then, a growing crowd of mid-rank white-collar computer users was quietly gaining access to networked computing; and a growing portion of these were learning about and using the nonprofit, nonproprietary internet. These experiences were becoming increasingly inflected with countercultural habits and iconoclasm, and the higher ranks of leadership, the CEOs and politicians, were largely oblivious to it all. This context proved extremely fertile ground for a new, freely distributed computer program called Mosaic, the first successful graphical web browser. Mosaic 1.0 for the Macintosh and PC was released in August 1993 and spread like wildfire through the fall of that year. The program created an almost instant wow effect, motivating ordinarily bored or preoccupied cubicle dwellers to call a colleague and tell them, “you gotta try this thing.” This was where it all started. This was the moment of take-off in the internet frenzy of the 1990s.</p>
<p>Mosaic, it needs be said, was neither the first web browser nor even the first graphical web browser.<sup>9</sup> When two employees of the University of Illinois’s National Center for Supercomputing Applications (NCSA), Eric Beena and undergraduate Marc Andreessen, decided to program a better browser near the end of 1992, they were simply making their own contribution to an ongoing networking software evolution based on ideas that were already very much in the air. Their main technical contribution in the first version of Mosaic for Unix was the ability to display images within the page and a slicker, more inviting interface. Another important contribution was the production of PC and Macintosh versions of the browser released in August 1993. These versions, programmed by a larger team of mostly undergraduate programmers, made the browsing experience more widely available.</p>
<p>Technically speaking, then, Mosaic was a useful but modest contribution, arguably not as important as, say, SMTP, the WWW protocol itself, or the SLIP and PPP protocols that enabled connection to the internet via a modem. And Mosaic was clearly not as important a technical contribution as the underlying TCP/IP packet switching protocol and all the software that had been written to implement it on a wide variety of computers. Mosaic did not make it possible to connect to the internet. Other programs and protocols did that. And Mosaic did not make the internet friendly; it simply made it somewhat friendlier. And it is safe to say that it was not a question of efficiency; Mosaic was a slow and cumbersome way to get information, particularly on the graphics-impaired computers of the first years. Mosaic was a fine program, but it was not a revolutionary work of genius by any definition.</p>
<p>So why did Mosaic become the killer app of the internet? Why did its direct successor Netscape launch the “internet economy” of the 1990s? Part of it was simply the cumulative critical mass of people and technologies, what some economists call network effects; enough computers were becoming graphics-capable, enough of those computers were becoming connected to LANs, and enough of those LANs were being connected to the internet, that being on the internet was becoming more and more valuable.</p>
<p>But it’s crucial that Mosaic wasn’t so much efficient as it was pleasurable; using Mosaic was one of the first really compelling, fun experiences available on the internet. Some computer professionals tried to downplay it for that very reason: “Mostly, people use Mosaic to show off the money they spent on their PCs,” observed one software executive, “you can call somebody over and say, ‘Look at this.’ It has got that kind of whiz-bang appeal. . . . . It’s like the first time you go through the library: It’s fun to wander through the stacks, pulling down books. But that does wear off.”<sup>10</sup> But of course we now know in retrospect that the fun of web browsing was not about to wear off any time soon.</p>
<p>What kind of pleasure did Mosaic offer? Mosaic did not satisfy desire, it provoked it. Colin Campbell has described what he calls “modern autonomous imaginative hedonism,” a distinctly modern structure of pleasure in which the anticipation of pleasure becomes part of the pleasure itself and which is characteristic of the consumer culture and romanticism generally.<sup>11</sup> What one wants in this peculiarly modern form of pleasure, Campbell argues, is not the satiation of desire but desire itself; it is the desire to desire. Mosaic did not so much show someone something they wanted or needed to see as it stimulated one to imagine what one <em>might</em> see. One of the early classic ways to demonstrate the web was to click onto the website for the Louvre, to watch grainy images of paintings slowly appear on the screen. This was not pleasurable so much in what it actually delivered—better versions of the same images generally could be found in any number of art books—but in how the experience inspired the viewer to imagine <em>what else might be</em> delivered. Mosaic enacted a kind of hope; it did not deliver new things so much as a sense of the <em>possibility</em> of new things. Surfing the web using Mosaic in the early days shared certain features with the early stages of a romantic affair or the first phases of a revolutionary movement; pointing, clicking, and watching images slowly appear generated a sense of anticipation, of possibility. To engage in the dreamlike, compulsive quality of web surfing in the early days was an immersion in an endless what’s next?</p>
<h2>The Genesis of Irrational Exuberance: Romanticizing the Market</h2>
<p>By May 1993, white-collar workers scattered in cubicles and offices across the land were quietly discovering the thrills of going online, as Andreessen and others worked on the code for Mosaic, as the likes of John Perry Barlow and the editorial staff of <em>Wired</em> were spreading the tropes of the computer counterculture to the middle ranks. But the mainstream was still thinking other things. That month, <em>U.S. News and World Report</em> published a “technology report” about the coming future of networked computing. The article, clearly a response to the enthusiasm surrounding Vice President Al Gore’s information superhighway initiatives, had no mention of the internet. It began,</p>
<blockquote>
<p>The melding of the telephone, television and personal computer today has unleashed a dynamic digital revolution that promises to radically alter the way people live, work and play around the world. What new products and services can we expect from this technological upheaval? How big a market, exactly, are we talking about? And what, if anything, should the Clinton administration do to help foster these emerging technologies in America?<sup>12</sup></p>
</blockquote>
<p>This was the conventional way of understanding things at the time—in the business terminology of products, services, and markets. From there the article went on to seek answers from “seven titans of technology”: Bill Gates, shopping-channel pioneer Barry Diller, AT&amp;T Chair Robert Allen, cable TV tycoon John Malone, IBM board vice chairman Jack Kuehler, cell phone magnate Craig McCaw, and Motorola chair George Fisher. The article was thus organized around the assumption that, whatever happened, it would be shaped primarily by corporate leadership and corporate concerns, perhaps in interactions with government regulators spurred on by initiatives coming from the White House. Gates predicted a wallet-sized personal PC interconnected with home appliances. Others forecast a lucrative cornucopia of online shopping, ubiquitous multimedia communication for business executives, movies-on-demand, distance education via cable TV, and growing wireless data services. All expressed an ambivalence about government’s role, expressing appreciation for the excitement generated by Gore and the Clinton White House but cautioning government regulators to stay out of the way of corporate initiatives. This was a view from the top.</p>
<p>Three months later, as Andreessen and his colleagues were quietly releasing the first version of Mosaic for the Macintosh and the PC, the August issue of <em>Scientific American</em> appeared with a similar overview article.<sup>13</sup> In keeping with its more sophisticated readership, the article contained much more technical detail, comparing the bandwidth and cost of various transmission technologies like fiber optic cable and ISDN, for example, and its interviewees were generally further from the boardroom and closer to the research lab. But the basic organizing assumptions of the article were the same as the recent <em>US News</em> piece; the bulk of the article focused on various corporations and their technologically linked interests, comparing and contrasting the schemes of various cable, phone, and media companies, interspersed with various inside-the-beltway regulatory concerns, such as common carrier principles. The list of possible applications of the coming technology leaned a little more towards information and education than shopping: a cut-out box contained descriptions of school children communicating by email with a researcher in Antarctica, a broadcast engineer who helped diagnose his daughter’s rare disease using online databases and email, an experiment with sending dental X-rays across the Atlantic, and a group of New Jersey schoolchildren communicating with teachers in Russia.<sup>14</sup> The World Wide Web was not mentioned.</p>
<p>This article, however, <em>does</em> mention the internet. It opens with an anecdote about Internet Society President Vinton Cerf preparing for a Congressional hearing by contacting thousands of enthusiasts over the internet, pointing to the rapidly growing activity on the internet as a potential “seed” of Gore’s “National Information Infrastructure.”<sup>15</sup> And the article is titled “Domesticating Cyberspace” and closes with a Congressional Representative echoing Barlow’s metaphorical construction of the online world as a frontier: “Anything is a danger in cyberspace. . . . . There are no rules. It’s the Wild West.”<sup>16</sup> The Barlow-inspired metaphorical constructs of its title and opening and closing paragraphs—a vision of a wild, expansive, exciting space in the internet—would prove to resonate more profoundly than the content about corporate struggles, educational applications, and competing delivery technologies. Perhaps <em>Scientific American</em>’s readership is specialized, but that readership includes politicians, executives, and, most importantly at this moment in history, reporters—reporters being among the category of people who do their own word processing.</p>
<p>This was the moment that the internet hit the media radar. As summer turned to fall in 1993, the internet rather suddenly became an object of media fascination. Scott Bradner, a long-time internet insider,<sup>17</sup> observed with some bewilderment that “the Internet is suddenly popular. . . . . For reasons best known to the media gods, articles about the Internet seem to be the thing to do these days.” He pointed out that during the fall of 1993, a time when only a miniscule number of people actually had internet access, 170 articles appeared in major U.S. publications mentioning the internet, as compared to 22 articles in the same period a year before.<sup>18</sup> He continued,</p>
<blockquote>
<p>All this attention is flattering to those of us who have been proselytizing this technology for years. The problem is that I don’t see any logical reason for the current attention. The Internet has been around and growing for more than a decade. Sure, it’s big (almost 2 million interconnected computers world wide) and growing fast (more than 7% a month), but it’s been big and growing fast for quite a while now. It was certainly growing at least at this rate when <em>Time &amp; Newsweek</em> were forecasting national video parlors for the kiddies instead of international on-line, real time, interactive current affairs in the schools. . . . . Last month, I even found an article on the Internet in an airline flight magazine.<sup>19</sup></p>
</blockquote>
<p>As the excitement around the internet gathered in the media, as <em>Wired</em> and John Perry Barlow framed computer networking in breathless countercultural terms, as Mosaic circulated onto the increasing number of internet-connected LANs, members of the business world began to take note. In part, with their attention already directed towards networking by the information superhighway rhetoric, it might be unsurprising that those looking for business opportunities might follow the media towards the internet. But another key factor was the Microsoft monopoly, which played a dual role. On the one hand, Microsoft’s dominance in operating systems represented the uninspiring end of the garage start-up days in microcomputing, thus motivating romantic entrepreneurs to look for something new. On the other, it was well known that Bill Gates had just become one of the richest men in the world and that those who had heavily invested in Microsoft in the late 1980s were beginning to reap fabulous rewards. Microsoft was thus both a reviled corporate monolith and an object lesson: might something overthrow Microsoft just as Microsoft had overthrown IBM? Might that something have to do with the internet? And might there be similar rewards to be reaped by those who accurately guessed what the next best thing would be?</p>
<p>Enter Netscape. Jim Clark, student of Lynn Conway and founder of graphics workstation company Silicon Graphics (SGI), was by that time an executive who did not need to do his own word processing. But sometime in the late fall of 1993, just as the internet craze and Mosaic were entering mainstream attention, Clark stumbled upon Mosaic when, in search of a new direction in technology, he was introduced to the web browser by an underling at SGI. Clark resigned from SGI in February 1994, flew to the NCSA in Champaign-Urbana, Illinois, found Marc Andreessen, and founded a company to commercialize the program in spring 1994.<sup>20</sup> With unprecedented haste, he launched the Netscape IPO just over a year later. This became the most successful IPO in history to that point and the model for many subsequent IPOs, setting off the internet stock craze. The largest party that capitalism has ever thrown had begun.</p>
<p>So why did Netscape get all this swooning attention? In part, Netscape grabbed the headlines because it was in Silicon Valley, in part because of Jim Clark’s previous track record with SGI, and in part because Netscape hired Andreessen and many of the other original programmers of Mosaic. And Netscape’s first browser was a good one, particularly as it channeled its start-up funds heavily into rapidly improving the program, releasing frequent free updates over the internet and quickly becoming the most popular browser. Yet it needs to be remembered that at the time of the IPO the company had no profit and almost no revenues. It was giving its principle product away for free and had no crucial patents or other dramatic advantage in the browser market: Netscape was just one of about ten companies trying to commercialize Mosaic.<sup>21</sup></p>
<p>To a very significant degree, Netscape gained so much attention because it followed a deliberate strategy of creating a media narrative heavily centered on a romanticized, heroic construction of the computer counterculture, which proved very popular with the media itself. Netscape depicted itself as enchanting. Very early on, Clark hired a publicist, Rosanne Siino from SGI, and told her to present Andreessen as the rock star of the company.<sup>22</sup> Siino then developed a strategy that carefully cultivated media attention framed in terms of geek chic, deliberately taking reporters into the back rooms to show the chaos of the programmers’ cubicles, programmers sleeping under their desks, and so forth.<sup>23</sup> And she successfully turned Andreessen into a celebrity; in 1995, Andreessen appeared on the cover of <em>Forbes</em> ASAP with the blurb: “This Kid Can Topple Bill Gates.”<sup>24</sup> Andreessen would soon be featured in <em>People</em> magazine and appear on the cover of <em>Time</em> in his bare feet.<sup>25</sup></p>
<p>Arguably, none of this would have worked without <em>Wired</em> magazine. <em>Wired</em> was barely more than a year old when Clark hired Andreessen, and in that year it had been full of adolescent hyperbole (Rossetto claimed that computer technology was creating “social changes so profound their only parallel is probably the discovery of fire”),<sup>26</sup> and inaccurate predictions (besides mentioning the internet only in passing in the first issue, the second implied that Richard Stallman’s Free Software project was outmoded and doomed).<sup>27</sup> And its eye-catching Day-Glo graphics and layout were sometimes unreadable. <em>Wired</em> did not, furthermore, invent the idea that Mosaic was the killer app of the internet.<sup>28</sup></p>
<p>But it popularized the idea and did so in a particular way. <em>Wired</em> published its first substantial piece on the Mosaic phenomenon in October 1994, when the web was well known to internet aficionados but just beginning to attract the attention of the wider world.<sup>29</sup> Titled “The (Second Phase of the) Revolution Has Begun,” the article, by Gary Wolf, didn’t just target a good investment or new technology as a normal trade magazine piece might have. Instead, it used colloquial language and emphasized revolutionary change, pleasure, and personal expression. “When it comes to smashing a paradigm,” the article began, “pleasure is not the most important thing. It is the only thing.” In a section titled, “Why I Dig Mosaic,” Wolf observed that “Mosaic functions lurchingly, with many gasps and wheezes,” and described an experience of setting off to find technical information on the nascent web and getting distracted by the process of clicking from link to link, eventually ending up on a physicist’s personal page. But while a standard review of computer software might point to these as problems, Wolf did not. “The whole experience,” Wolf wrote, “gave an intense illusion, not of information, but of personality.” Now that personal computers had revealed themselves to be just office machines and therefore not all that personal, Wolf was locating personality in the act of web surfing.</p>
<p>And, as if to give substance to the rather thin idea of the personality of the web, Wolf crafts an image of the personality of Mark Andreessen. Another journalist might have interviewed the senior partner of the company, but Wolf focused on the twenty-something junior partner and notes personal details. “A little way into the interview,” Wolf notes, “Andreessen removes his dress shirt and answers the rest of my questions in a white T-shirt. This gesture leaves the impression of a man doing battle against the businesslike backdrop” of Netscape’s headquarters. And Wolf focuses on Andreessen’s dragon-slaying attitude; working for Netscape, Wolf notes, “offers [Andreessen] a chance to keep him free from the grip of a company he sees as one of the forces of darkness—Microsoft.”</p>
<p>By zeroing in on Netscape and Andreessen, this <em>Wired</em> profile, not only amplified the belief that <em>Mosaic</em> was the killer app of the internet and that Netscape would be its primary beneficiary, but also offered a romantic lens through which to see the phenomenon. As the Clinton White House and Congress took the information superhighway rhetoric off into dry committees, spouting inside-the-beltway acronyms, businessmen could increasingly be seen thumbing through copies of <em>Wired</em> on airplanes, and terms like <em>cyberspace</em> and frontier metaphors began cropping up in newspaper articles and politicians’ sound bites. Without <em>Wired</em>, it’s not obvious that this libertarian-flavored countercultural framing of computer networking would have taken hold in the mainstream.</p>
<p>In the ensuing years, as we all know, take hold it did. Being part of the knowledgeable vanguard was a central part of the ethos at the time. Mary Meeker, who later would be dubbed “the girl in the bubble,” was a stock analyst at Morgan Stanley and key player in the Netscape IPO and many subsequent dot com IPOs. She said, “I remember that in 1995 I would speak with Marc Andreessen and we would try to count up how many people understood this stuff. We thought it was about four hundred.”<sup>30</sup> Soon after the Netscape IPO, a young visionary called Jeffrey Skilling began leading a rising corporation called Enron into new territory based on the speculative trading of energy and internet-related activities; of skeptics of his strategy, Skilling is reported to have scoffed, Rossetto-like, “there were two kinds of people in the world: those who got it and those who didn’t.”<sup>31</sup> And it left its mark in politics; in the summer of 1994, conservative pundit George Gilder teamed up with futurologist Alvin Toffler and others to release a rousing document called “Cyberspace and the American Dream: A Magna Carta for the Knowledge Age”; the document declared a new era in which free markets and technology would make governments obsolete, a set of themes that would soon be picked up by then-Congressman Newt Gingrich.</p>
<p>After a point, it does little good to scoff at these patterns with a smug “I told you so.” Many thoughtful observers knew the stock prices of the late 1990s were irrational, and many of them said so. The evidence and arguments were there, but the bubble kept expanding nonetheless. It is worth ferreting out those who took advantage of the heady atmosphere to engage in various degrees of outright fraud. But one cannot blame the heady atmosphere itself only on occasional instances of exaggerated reporting, conflicts of interest, or dishonesty.</p>
<p>This overheated atmosphere was precisely a fusion of the desire for wealth with romantic dreams of freedom, self-expression, and the dramatic overthrow of the powers that be. Without the romantic visions of freedom and revolution, there would have been nothing to get excited about; there was no gold in this gold rush, no valuable raw material, just castles in the air made of projections onto immaterial digital bits; something had to make those projections seem valuable. Yet without the hope of getting rich, the enthusiasm would never have had the energy it needed to spread. Change the world, overthrow hierarchy, express yourself, <em>and</em> get rich; it was precisely the heady mix of all of these hopes that had such a galvanizing effect.</p>
<h2>The Role of Romanticism in the Internet Surprise</h2>
<p>The development and character of capitalism sometimes tends to be imagined in terms of things in the guns, germs, and steel category, things like technologies, resources, and geography. Economic development, we like to assume, is about the efficiency with which the prosaic fundamentals of human life are produced and distributed or about things that change how much we have to eat or how long we live. Yet this way of thinking, for all its insight, can make us forget just how frivolous the development of capitalism has been at times. Think of the role of gold, spices, tea, tobacco, and beaver pelts in the development of mercantile systems and the early phases of the European colonization of the Americas. These were all trivial commodities, of no major practical value, whose popularity largely reflected the whims of European upper-class fashion. Yet the basic systems of accounting and trade that laid the foundations for early modern capitalism, some would say for capitalism and the world system itself, were created around them.</p>
<p>The internet of the 1990s may have been less like the steam engine or the radio and more like spices and beaver pelts. What the internet offered, however, was not so much fashions for decorating our bodies or our food as fashions for clothing the self.</p>
<p>In a few short years, between 1992 and 1996, the internet went from being a quiet experiment to a global institution whose name seemed to be on everyone’s lips and whose existence and importance was taken for granted. By 1995, the remaining consumer computer communication systems from the 1980s like Compuserve and Prodigy were all selling themselves as means of access to the internet rather than the other way around, the Congress was revising the structure of its communications law for the first time in more than half a century, major corporations from the phone companies to Microsoft to the television networks were radically revamping core strategies, television ads for Coke and Pepsi routinely displayed URLs, and the stock bubble was underway.</p>
<p>In the history of media, this is an extraordinarily rapid shift. In comparison, the early histories of most other media suggest something well coordinated and planned. For example, the general outlines of the TV industry in the United States—the major corporate players, the advertising system, networks providing programming to affiliate stations, even much of the programming like soap operas and variety shows—were clearly mapped out by the mid- to late-1930s, more than a decade before its full-scale introduction around 1950. (RCA/NBC made television a central part of its plans for the future by 1932, just as the networked/ advertising-supported radio broadcast system was becoming consolidated.)<sup>32</sup> For all the complexities and struggles associated with their development, film, television, and VCRs were disseminated in a context in which industry leaders, government regulators, and manufacturers all shared similar broad general outlines of what the new industries were going to be about, and disputes were limited to fine points of technical standards (for example, Betamax versus VHS), revenue distribution (for example, cable and videotape copyright issues), and the like. Historians of technology are correct to scoff at hyperbolic claims about the internet (for example, that the internet is the biggest invention since the book). But one of its striking features is just how much, for a period in the 1990s, it took people by surprise. Arguably, the only communication system of the twentieth century that came with similar unexpectedness was radio broadcasting (which also played a significant role in that other stock bubble in the 1920s).<sup>33</sup></p>
<p>Many might ask: Did not the internet triumph because it offered new efficiencies, new flexibilities, and a new ease of access to information and knowledge creation, which together were really the driving force of the internet itself and its contribution to the new market dynamism, globalization, and the flattening of economic relations? Could that much money and effort really be driven by something as ephemeral and irrational as a particular kind of romantic self-concept?</p>
<p>Other factors mattered, of course. But it seems likely that the romantic entrepreneurial self-concept was a necessary if not sufficient component of the internet explosion of the 1990s. It helps to remember the order of events. Everything changed <em>before</em> significant numbers of individuals were successfully making a profit selling via the internet and even before internet access was widely available. It was not as if people started using the internet to make money and then the business world at large responded; in 1995, there <em>was</em> no appreciable nonmetaphorical market yet, no substantial population of individuals competitively buying and selling things over the internet. There were, by and large, only experimenters, speculators, and enthusiasts, people who expected a market to emerge where one did not yet exist. (Yes, there were those graphs showing skyrocketing numbers of internet nodes and users, forming almost perfect triangles as the lines headed for the upper right corner. But one could produce similar graphs for the sales of the latest new pop rock sensation, and the internet had been growing at a similar rate long before 1993.) Understood as a practical technology, the internet could not have caused these changes because the internet was not practical yet. Many of the more important changes that set the stage for the explosion of the internet and the internet economy, then, happened <em>before</em> the technology itself had a chance to have much concrete effect at all.</p>
<p>The fact is, the internet that appeared in the 1993–95 period wasn’t just a technology; it was the enactment of a hope. The changes of 1993–95 were very much <em>anticipatory</em>, changes based on what people imagined could happen, not what had already happened. In the early 1990s, the internet did not so much cause new things to happen as it served to inspire people to imagine that new things would happen. The shared embodied experience of an immersion in an endless what’s next? that Mosaic unleashed, coupled to the enormous awe accorded new technology and the opportunity to step into the role of the romantic entrepreneur, enabled new behaviors on the part of significant segments of the population. People behaved differently, not just because the internet enabled them to do different things, but because its presence inspired people to imagine how things might change, how things might be transformed. Many of the things said and done in the name of the internet in the 1990s we now know to be misjudgments, some of them colossal ones; those misjudgments, however, were not random. They were part of a pattern of shared collective vision, and that vision had an impact even if it was based on some shaky foundations.</p>
<h2>The Internet and the Revival of Neoliberalism</h2>
<p>That impact, moreover, was not fleeting. The internet enthusiasm was not just a Tulip mania, a mediocre idea that eventually washed away in lost fortunes. On the one hand, the internet bubble unleashed a flood of money into the telecommunications infrastructure, effectively making TCP/IP the standard for the foreseeable future and resulting in a build-out of high-bandwidth lines that remained important even after the bubble burst. On the other hand, less concretely but perhaps more profoundly, the internet surprise helped revived neoliberalism. As we have noted, neoliberalism looked like it might be in serious decline at the time of Bill Clinton’s election in 1992; both corporate leadership and government were moving back towards a more classic corporate liberal point of view involving coordinated private/public partnerships. But somewhere between the collapse of the Soviet Union and the internet bubble, the blind faith in markets was given new energy. The internet, because it took the establishment by surprise, because it occasioned a confluence of the counterculture with spectacularly speculative capitalism, created an opening for big ideas.</p>
<p>Given the political alignments of the early 1990s, the first intellectual bloc to jump into that opening were the libertarians, and they successfully fostered an equation of the romantic individualist vision of the internet with a free market vision of the internet. Esther Dyson—a business consultant with a background in journalism, a door-opening last name, and libertarian leanings (she told Reason magazine that what she likes about the market economy is “number one, that it works. Number two, that it’s moral”)<sup>34</sup>—noticed the emerging internet as an opportunity and made it the core of her career. Republican speech writer George Gilder, previously famous for books attacking feminism and welfare, turned to technology with a book on the end of television in 1990; the book proved not to be all that accurate in its predictions but its enthusiastic reception at the time taught Gilder the power of technological prognostication as a route to an audience. Libertarian journalist Declan McCullough started an online website devoted to the internet and politics in 1994 and soon became a regular contributor to <em>Wired</em>. This group was able to take the framework laid out by de Sola Pool’s Technologies of Freedom, in which free markets are equated with free speech and government regulation is construed as the enemy of both, and apply it to the exploding activity around the internet.</p>
<p>To see how this feat of rhetorical association worked, consider a 1995 essay about the internet in The Economist. Author (and eventually, <em>Wired</em> editor) Christopher Anderson wrote, “the Internet revolution has challenged the corporatetitan model of the information superhighway. The growth of the Net is not a fluke or a fad, but the consequence of unleashing the power of individual creativity. If it were an economy, it would be the triumph of the free market over central planning. In music, jazz over Bach. Democracy over dictatorship.”<sup>35</sup> This vision of individual creativity unleashed (and the associated rhetorical flourishes) was orthodox romantic individualism. But this was in The Economist, not <em>Wired</em>, and what readers of the magazine first saw when they opened the issue added a telling twist. A nameless editor at The Economist compressed Anderson’s romantic passage into a pull quote that graced the first page of the printed version of the article: “The explosive growth of the internet is not just a fad or a fluke, but the result of a digital free market unleashed.”<sup>36</sup> Readers of The Economist were subtly invited to leap from “if it were an economy” to it is a “digital free market.” This associative leap from market metaphor to actual market, repeated over and over again in the culture at the time, allowed a technological system based on nonproprietary standards and with roots in a mix of private and government funding to become a powerful archetype of both the free market and free expression in the broad public mind. The iconoclastic rhythms by which the internet appeared in the cubicles of America were thus harnessed to a Lockean market projection. The illogical leaps inherent in all this were swept aside by the speed of events and by the constant threat of being labeled as a dinosaur by <em>Wired</em>-style countercultural rhetoric.</p>
<p>These events, occurring in the wake of the astonishing collapse of the Soviet Union and the quick triumph of the United States in the 1991 Persian Gulf war, created a context in which neoliberalism was given new life. In law, politics, and business management, most of the talk of industrial policy and related corporate liberal terms disappeared into the background, and the faith in markets as the source of all innovation (and of freedom itself ) was revived as forcefully as ever. In 1994, just as Netscape was plotting its IPO, the New York Times transferred a Middle East foreign correspondent named Thomas Friedman to covering the White House and economics. The following year, as the stock bubble began its climb, Friedman became a regular op-ed writer, and he cultivated an avuncular, anecdotally driven, free market fundamentalism that over time he coupled to a subtle nationalist triumphalism. In the face of all this, those who initially raised doubts about specific neoliberal decisions, such as economist Jeffrey Sachs’s belief in shock therapy for the former Soviet Union to drive it into a market economy— with results that even Sachs admits were mixed, and many would argue were disastrous—were largely rendered mute throughout the 1990s, cowed by the apparent irrefutability of the market vision, buoyed as it was by the flood of events, the energy around the internet, and the associated meteoric rise of the stock markets. Thanks to the way the internet was embraced by the culture, Margaret Thatcher’s 1980s claim that “there is no alternative” to neoliberalism on the world stage was given new life.</p>
<hr>
<h2>Notes</h2>
<div class="notes-and-refs">
<ol>
<li>See Dave Farber, “Remarks of John Perry Barlow to the First International Symposium on National Security and National Competitiveness,” 21 Feb. 1993, textfiles.tonytee.nl/magazines/SURFPUNK/surf0059.txt.</li>
<li>Ibid.</li>
<li>See David Toop, “MTV Gets Tangled in the Net,” The Times (London), 28 May 1994, 16.</li>
<li>See Connie Koenenn, “E-Mail’s Mouthpiece: In Just a Year, <em>Wired</em> Magazine Has Become the Guide Down the Information Superhighway,” Los Angeles Times, 30 Mar. 1994, E1.</li>
<li>See Wolf, Wired–A Romance, 18–21.</li>
<li>See Paul Keegan, “Reality Distortion Field,” Upside.com, 1 Feb. 1997, www.upside.com/texis/mvm/story.</li>
<li>Quoted in ibid.</li>
<li>Quoted in ibid.</li>
<li>It needs be said because of the seriousness with which investors took statements like that of Netscape founder, Jim Clark: “If the invention at the heart of my first start-up was an internal combustion engine, Mosaic was fire itself ” ( Jim Clark, Netscape Time: The Making of the Billion-Dollar Start-Up That Took on Microsoft [St. Martin’s Griffin, 2000], 228). But in fact there were other web browsers before Mosaic. In 1992, for example, the X-Windows-based Viola web browser had scrollbars, back and forward buttons in the upper-left corner, a globe icon in the upper right, a URL display, variegated fonts, and of course the ability to move to underlined links through the click of a mouse—just like Mosaic, Netscape, and Internet Explorer. See Ed Krol, The Whole Internet (O’Reilly &amp; Associates, 1992), 227–33.</li>
<li>Josh Hyatt, “Hyperspace Map: Mosaic Helps Lead Users through Maze of Internet,” Boston
Globe, 29 Mar. 1994, 1.</li>
<li>Campbell, The Romantic Ethic and the Spirit of Modern Consumerism, 77.</li>
<li>Jim Impoco, “Technology Titans Sound off on the Digital Future,” U.S. News and World Report, 3 May 1993, 62.</li>
<li>See Gary Stix, “<a href="https://www.jstor.org/stable/24941584">Domesticating Cyberspace,</a>” Scientific American, Aug. 1993, 100–110.</li>
<li>See ibid., 105.</li>
<li>Ibid., 101.</li>
<li>Ibid., 110.</li>
<li>In the late 1980s, Bradner had been a founder and administrator of NEARNET, a regional TCP/IP network for New England universities, including his employer, Harvard, which had been a participant in the national internet.</li>
<li>See Scott Bradner, “Why Now?” Network World, 27 Sept. 1993, <a href="https://www.sobco.com/nww/1993/bradner-1993-09-27.html">www.sobco.com/nww/1993/bradner-1993-09-27.html</a>.</li>
<li>Ibid.</li>
<li>The company was originally called Mosaic Communications but then changed its name to Netscape after complaints from the NCSA about trademark issues. To avoid confusion, the company is referred to here as simply Netscape.</li>
<li>In July 1994, at least ten companies had licensed Mosaic from the University of Illinois for commercial development, including the well-connected Spyglass and Spry. See Elizabeth Corcoran, “Mosaic Gives Guided Tour of Internet,” Washington Post, July 11, 1994, F19.</li>
<li>See Clark, Netscape Time, 99.</li>
<li>See ibid., 100.</li>
<li>See ibid., 106.</li>
<li>See ibid., 194.</li>
<li>Quoted in Keegan, “Reality Distortion Field.”</li>
<li>See Simson L. Garfinkel, <a href="https://www.wired.com/1993/01/stallman/">“Is Stallman Stalled? One of the Greatest Programmers Alive Saw a Future Where All Software Was Free. Then Reality Set In.,”</a> <em>Wired</em> 1 (Apr. 1993): 102.</li>
<li>That distinction may belong to Robert Metcalfe, 3Com founder who in June 1994 published a column which began, “Mosaic is doing for the Internet right now what Visicalc, the proverbial killer application, did for the personal computer around 1980” (Bob Metcalfe, “Thanks, NCSA, for Graduating a Few of Your Mosaic Cyberstars,” InfoWorld, 6 June 1994, 50).</li>
<li>See Wolf, “The (Second Phase of the) Revolution Has Begun: Don’t Look Now, But Prodigy, AOL, and CompuServe Are All Suddenly Obsolete—and Mosaic Is Well on Its Way to Becoming the World’s Standard Interface,” <em>Wired</em> (Oct. 1994).</li>
<li>John Cassidy, Dot.con: How America Lost Its Mind and Money in the Internet Era (Harper Perennial, 2003), 96. Also see Cassidy, “The Woman in the Bubble,” The New Yorker, 26 Apr. 1999, 48.</li>
<li>Quoted in Wendy Zellner and Stephanie Anderson Forest, “The Fall of Enron: How Ex-CEO Jeff Skilling’s Strategy Grew So Complex That Even His Boss Couldn’t Get a Handle on It,” Business Week, 17 Dec. 2001, 30.</li>
<li>See Erik Barnouw, A Tower of Babel, vol. 1 of A History of Broadcasting in the United States(Oxford University Press, 1966), 232.</li>
<li>In 1918, the corporate world imagined radio as a tool exclusively for strategic, point-to-point uses like ship-to-shore and military communication, and it took the radio amateur community (the original hackers of the twentieth century) to discover the pleasures of broadcasting and using radio for entertainment in the 1906–1919 period. When radio became a popular craze in 1920, the corporate world was taken off guard, and it took major strategic reorientations, a new relationship to Madison avenue, and a new regulatory agency and legal constructs to bring things under control again. It was a key moment in the consolidation of Fordism. See Streeter, Selling the Air, 84–91.</li>
<li>Virginia Postrel, “On the Frontier: From the Wild East of Russian Capitalism to the Evolving Forms of Cyberspace, Esther Dyson Likes the Promise of Unsettled Territory—and the Challenge of Civilizing It,” Reason Magazine, Oct. 1996, www.reason.com/news/show/30021.html.</li>
<li>Christopher Anderson, “The Accidental Superhighway (The Internet Survey),” The Economist (US), 1 July 1995, 4.</li>
<li>Ibid., 3.</li>
</ol>
</div>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="Guarding the gatekeepers: Trust, truth and digital platforms"
class="paper-story"
data-article-title="Guarding the gatekeepers: Trust, truth and digital platforms"
>

<h1 class="article-title" id="h_Guarding the gatekeepers: Trust, truth and digital platforms">Guarding the gatekeepers: Trust, truth and digital platforms</h1>

<div class="top-meta">Terry Flew, 2019-01-01 00:00:00 AEST. for week 3.</div>

<p>by <a href="https://www.griffithreview.com/contributors/terry-flew/">Terry Flew</a></p>
<p>WARS OFTEN RAGE behind the estimated ten million Wikipedia pages: edit wars, where editors repeatedly override each other’s contributions to a page and cannot reach consensus about what the final content should be. This can extend to many thousands of edits. While some of the most famous edit wars have been about classically nerdy topics – whether Anakin Skywalker and Darth Vader should be considered the same character in <em>Star Wars: Episode III – Revenge of the Sith</em>; whether the tiger is in fact ‘the world’s most powerful living cat’. Factual matters have also been under debate, such as whether Europe is a continent or not, or whether Freddie Mercury’s ancestry was Iranian, Indian, Farsi or Azeri. But increasingly these wars are about the politics of definition. The Wikipedia entries for figures such as US President Donald Trump, the television star Roseanne Barr, the former San Francisco 49ers quarterback Colin Kaepernick, US Supreme Court judge Brett Kavanaugh, or the Sudanese-Australian writer Yassmin Abdel-Magied, become the sites for seemingly endless edit wars. As all of these figures are politically contentious, their Wikipedia entries become online proxies for larger culture wars.</p>
<p>Agonistic exchanges around politics, news and culture on digital platforms are now part of the rich texture of everyday life online. But the case of Wikipedia is important as it has become the most enduring success symbol of what we called the web 2.0 era, where open, easy-to-use digital platforms could become spaces where a multitude of users could come together and create new forms of culture and information. It has become the <em>de facto</em> first source of information for billions of people around the world, not least students drafting essays and assignments. It speaks to what was known as the ‘wisdom of crowds’, where content co-creation and the willingness of people to give up their free time and expertise – what the author and consultant Clay Shirky termed their ‘cognitive surplus’<a href="#_edn1" name="_ednref1">[i]</a> – led to knowledge sharing for the common good. The phenomenal growth of Wikipedia saw it expand from 17,000 entries in 2001 to over a million in 2006.</p>
<p> </p>
<p>THESE ARE NOT optimistic times for how we understand the internet. After more than two decades of a mostly benign and optimistic take on where the enabling possibilities of digital technologies and social networks would take us, the late 2010s have been characterised by foreboding and dystopian visions. David Karpf has noted how the changing nature of the San Francisco-based <em>WIRED</em> magazine captures this shift well.<a href="#_edn2" name="_ednref2">[ii]</a> For much of its twenty-five-year history, <em>WIRED</em> was the go-to place for identifying the next big thing of the Digital Revolution (it used caps to describe it), whether it be the ‘new economy’, the death of advertising, DIY journalism, self-publishing, and much more besides. <em>WIRED</em> got some predictions right, such as the use of smartphones to capture police brutality, or peer-to-peer renting of houses and cars. Some it got wrong, such as the demise of advertising or the disappearance of paid journalism. Underpinning all of these predictions, however, was the assumption that the internet was making us – or at least the ‘us’ that would read <em>WIRED</em> – smarter, more rational, more tolerant of diversity, more prepared to innovate, but also more prepared to commit to projects with a shared civic purpose. The idea that it may make us less rational and more dogmatic, or that it would be the harbinger of greater economic inequalities, job losses, a collapse of civic discourse, or environmental crises, was reserved for a small, high-profile, but well quarantined group of professional naysayers. Authors such as Nicholas Carr, whose 2010 book <em>The Shallows</em> (WW Norton) argued that internet communication was adversely affecting our brain capacity, and Andrew Keen, who has been a long-time critic of Silicon Valley culture, were accepted as doubting Thomases, whose opinions would be welcomed up to a point, but largely in order to demonstrate a degree of plurality in an otherwise highly optimistic narrative around the impact of digital technologies.</p>
<p>It now seems that everyone is a critic of digital platforms. Talk is rife of fake news, filter bubbles, misinformation, doxxing, trolls, electoral manipulation and the online alt-right. Getting your news from Twitter or Facebook, once a sign that you were part of the zeitgeist, now sounds like a sign of potential gullibility. David Karpf can publish in <em>WIRED</em> about the hubris of the publication, while publications that are certainly not anti-capitalist, such as <em>The Economist</em>, warn of the ‘global techlash’ and the dangers of digital monopolies.<a href="#_edn3" name="_ednref3" >[iii]</a> Television series such as HBO’s comedy <em>Silicon Valley</em> portray the IT sector as havens for the socially dysfunctional, highly prone to often obscure trends and cults, and deeply mercenary in their dealings with others.</p>
<p>Tech leaders such as Mark Zuckerberg now seem to be stuck on an endless loop of parliamentary hearings, public inquiries and apologies for content hosted on their site: manifestos, interviews and public <em>mea culpas</em> that fail to stem the tide of negativity towards them. Twitter’s Jack Dorsey, Facebook’s Sheryl Sandberg, Tim Cook at Apple, Jeff Bezos at Amazon, and Tesla’s Elon Musk: these corporate titans, who were once the poster children for the new economy, are now often portrayed as the robber barons of a rapacious digital capitalism. Indeed, they may be worse than the oil, media and financial barons of yore. Their access to your personal data, and their capacity to sell that back to you as targeted digital content and advertising, suggests they can know you better than you know yourself.</p>
<p>Tech companies once enjoyed a very positive public image. Hollywood films such as <em>The Social Network</em> (2010), with its ‘creation myth’ around Mark Zuckerberg and Facebook, and <em>The Internship</em> (2013), a comedy where Owen Wilson and Vince Vaughn successfully apply to work at Google, presented these companies as being at the forefront of unconventional problem-solving and ‘out-of-the-box’ thinking. But a very sharp turn occurred in March 2018 when <em>Guardian</em> journalist Carole Cadwalladr and an investigative report by Channel 4 in the UK revealed information about the accessing of Facebook user data by the political consultancy firm Cambridge Analytica, and its on-selling to Donald Trump’s presidential campaign and the Vote Leave campaign in the 2016 Brexit referendum in the UK. These revelations, provided by whistleblower and former research director of Cambridge Analytica Christopher Wylie, brought out into the open the extent to which Facebook’s seemingly random mix of quizzes, personal profile exercises (‘What ’60s pop star are you?’), ‘likes’ and other ephemera could form the basis for detailed psychographic profiling based on revealed preferences, which could then be used to micro-target individuals with messages designed to elicit a response. What had long been suspected was now well and truly out in the open. It came on top of allegations of Russian interference in the 2016 US presidential election on Trump’s behalf, and the exposé of a plethora of ‘fake news’ sites that provided information of dubious veracity that was targeted to the preferences (and prejudices) of particular online readerships, most notably – but not exclusively – Trump voters.<a href="#_edn4" name="_ednref4">[iv]</a></p>
<p>In retrospect, the anger here was less about Cambridge Analytica – who hadn’t wondered why all of these quizzes were suddenly appearing on social media? – and more about the election of Trump and the Brexit referendum. These political outcomes revealed both massive social and political fault lines, and the extent of the breakdown of a common culture with shared values and commitment to an ethic of truth-telling. ‘Post-truth’ was the Oxford Dictionaries’ Word of the Year for 2016, joining ‘fake news’, which was the Macquarie Dictionary’s 2016 Word of the Year.</p>
<p>The literature on the rise of populism is now voluminous. But these events had a particular resonance in technology communities since, with the exception of a few outspoken individuals such as PayPal co-founder Peter Theil, these tend to be bastions of social liberalism, cosmopolitan identities and centre-left politics. The liberalism of Silicon Valley was such that <em>The San Francisco Examiner</em> could describe the area as ‘the most staunchly pro-Hillary Clinton, anti-Trump political hot spot in the entire country’, going so far as to be able to map where in the city the 37,000 people who voted for the Trump-Pence ticket were located.<a href="#_edn5" name="_ednref5">[v]</a> They concluded that less than 3 per cent of the voting-age population of the city voted for Trump. In the 2016 Brexit referendum, 60 per cent of Londoners voted for Remain, and only five of the city’s thirty-three council areas had a majority Leave vote, all of which were located on the outskirts of the city.</p>
<p>Those working in the digital-platform industries have thus found themselves in the position of the sorcerer’s apprentice, no longer able to control that which they have created. The platforms appear to have been increasingly appropriated by those whose ideas and values are almost 180-degrees away from their own. To say that the platforms have struggled to deal with the consequences would be to understate the extent of the ensuing chaos.</p>
<p> </p>
<p>THE TWO MOST public manifestations of the crisis have been public apologies and appearances before parliamentary hearings. Mark Zuckerberg issued a 6,000-word manifesto after the 2016 US presidential election, where he proposed to clarify guidelines about acceptable or unacceptable content, tackle the fake-news problem and refocus Facebook around the building of community. But the latter had a sting in the tail, as it saw third-party news content deprioritised in its personalised news algorithm. This adversely affected those news publishers who had been basing their business models around social news consumers who accessed news primarily through Facebook.</p>
<p>With the question of alleged Russian interference on Trump’s behalf in the 2016 elections still raw, US Democrat Senator Dianne Feinstein responded to the no-show of the CEOs of the major digital platform companies to the November 2017 Congressional hearings by saying that ‘I don’t think you get it… You created these platforms, and they are being misused. And you have to be the ones to do something about it – or we will.’<a href="#_edn6" name="_ednref6">[vi]</a> After the 2018 Cambridge Analytica scandal, all patience had gone and apologies were no longer enough. Mark Zuckerberg appeared before the US Senate in April 2018 and then, in May, before the European Parliament. At the first of these hearings, the Republican Senator Lindsey Graham opined that ‘continued self-regulation is not the right answer when it comes to dealing with the abuses we have seen on Facebook’. And Zuckerberg himself conceded that ‘the real question, as the internet becomes more important in people’s lives, is what is the right regulation, not whether there should be or not’.<a href="#_edn7" name="_ednref7">[vii]</a></p>
<p>What have derisorily become known as the ‘Zuckerberg apology tours’ now deliver diminishing returns. Zeynep Tufekci, a proiminent analyst of the ways big data and social media have been reshaping politics, has noted that Zuckerberg has made fifteen public apologies on behalf of Facebook for the misuse of the personal data of its users since the company was established in 2003.<a href="#_edn8" name="_ednref8">[viii]</a></p>
<p>Six months after Zuckerberg said that Facebook would change, it was revealed by <em>The New York Times</em> that the company had hired political lobbyists to discredit its critics. Bizarrely, one tactic involved linking critics with the billionaire liberal philanthropist and <em>bête noire</em> of right-wing populists, George Soros, who had indeed criticised the power of digital monopolists at the World Economic Forum in January 2018. Obviously other companies employ political consultants and image managers in times of trouble, but the net effect is to strengthen the case for regulation. It reveals the extent to which companies such as Google, Facebook, Twitter and others are essentially large corporations prepared to use monopoly power for rent-seeking ends. This is at odds with the image of the digital giants as harbingers of a new form of ‘global community’ along the lines of Marshall McLuhan’s mythical ‘global village’ that Zuckerberg alluded to in his January 2017 manifesto.</p>
<p>The trend towards public enquiries into the operations of digital platforms shows every sign of continuing. Along with the US Congressional hearings have come the UK House of Commons inquiries into hate crime – following the murder of Labour MP Jo Cox by white supremacist Thomas Mair – and disinformation and fake news. In Australia, the Australian Competition and Consumer Commission (ACCC) released its digital platforms inquiry preliminary report in December 2018. The ACCC was highly critical of the market power of Google and Facebook, and how it believed this had been misused with adverse consequences for news media, journalism and advertising markets. The ACCC also noted the regulatory disparity between traditional news and media content providers and the digital platforms, wondering whether this could continue to be justified around claims that the digital communication giants were mere carriers of other people’s content and not publishers in their own right. A number of countries have passed new legislation to deal with online racism, hate speech and harassment, fake news and the impact of digital platforms on media markets. Germany requires social media companies to remove offensive speech content within twenty-four hours of its appearance, under the threat of heavy fines. Brazil has laws requiring digital platforms to take down content that may be injurious to candidates in the run-up to elections. In September 2018, the European Parliament passed legislation granting publications copyright protection over online content sharing, which is known as the ‘link tax’, which means news aggregation sites such as Google News and Reddit need to pay news publishers for aggregating their stories. The impact of such laws remains to be seen: when similar laws were passed in Germany and Spain, Google responded in Germany by only carrying ‘snippets’ from publishers who agreed to waive all fees, and in Spain by withdrawing Google News completely.</p>
<p>The executives of digital platform companies should expect to make a lot of public appearances before parliamentary committees over the next few years. The mood of legislators is captured by this statement by Axel Voss, the European Parliament member who proposed the new copyright directives: ‘I’m very glad that, despite the very strong lobbying campaign by the internet giants, there is now a majority in the full house backing the need to protect the principle of fair pay for European creatives.’<a href="#_edn9" name="_ednref9">[ix]</a> In Australia, the ACCC has raised the question of whether the lack of transparency surrounding the algorithmic sorting of media content inhibits creators from being able to monetise their content online through attracting advertising revenue.</p>
<p>But public enquiries are a mixed blessing in terms of serving the public interest. They are often used as occasions for moral grandstanding by parliamentarians, who know they will get public exposure for strong statements made at hearings that receive a lot of media coverage. Ironically, given the extent to which digital platforms amplify such media exposure, they are most likely to get this coverage through YouTube videos, Facebook videos and Twitter posts. In this, they follow the path pioneered by British comedian Russell Brand, whose feisty anti-establishment statements on the BBC’s <em>Newsnight</em> program were subsequently viewed by over ten million YouTube viewers, making the star of <em>Forgetting Sarah Marshall</em> and <em>Get Him to the Greek</em> an unexpected champion of the global digital left.</p>
<p>Even with the best of intentions, public hearings are difficult fora in which to effectively engage digital platforms. Part of the issue is that these companies are typically far better resourced for such inquiries than those who challenge them. Any public inquiry into digital platforms is highly reliant upon data provided by the platforms themselves, as there are few reliable third-party equivalents to the Audit Bureau of Circulation that services the publishing industry or the ratings agencies for broadcasting. Another issue is the lack of consensus as to what is seen as appropriate public interest regulation of digital platforms. There is considerable consensus on what is not wanted: hate speech, fake news, disinformation, online harassment and so on. But less clear is what is the appropriate balance between self-regulation and oversight by agencies such as the Australian Communications and Media Authority (ACMA), Ofcom in the UK, the US Federal Communications Commission (FCC) and other national regulators. In Australia, there is a disconnect between regulatory arrangements for print and publishing, broadcasting, online services, advertising and telecommunciations, and there are renewed calls to move from media regulations based on what are increasingly blurring industry silos towards ‘platform-neutral’ regulation, which focuses primarily on the public-interest goal of regulation rather than upon the means of carriage. There is the issue of disconnected national rules and laws creating what is known as the ‘splinternet’, where disparate arrangements between nation-states mean that user experiences of the internet change from one jurisdiction to another, thereby fragmenting the global internet and reducing the benefits of seamless global networking.</p>
<p>There also remains a strong suspicion of the state as an agent of control over what content or statements can appear online. This is in part a legacy of the internet’s libertarian past that is adhered to not only by libertarians but by many social critics who nonetheless have a highly attuned antenna for any perceived threat to online civil liberties. One manifestation of these debates is whether digital platform companies can be considered publishers or media companies, as distinct from simply being the conduits for information and entertainment content circulated by their user communities. The spectre of authoritarian statism also hangs over any proposals to restrict online speech, as well as the related question of who decides what is restricted.</p>
<p>The ground has, however, shifted substantially around these debates over the past five years. One factor in this is a growing weariness about the periodic ‘public shocks’ that arise on digital platforms, and the sense that the responses to these by the companies themselves are largely cosmetic. It also reflects what is known as the ‘platformisation of the internet’, as online life is increasingly mediated through the likes of Google and Facebook. A clear issue is the regulatory disparity between digital platforms and media companies. As the ACCC notes in its preliminary report, no existing Australian laws relating to print media, broadcasting, online publishing or advertising are deemed to apply to digital platforms, even though they have a significant presence in all of these markets. Libertarians themselves may be crab-walking away from the internet,
championing seemingly greener pastures such as blockchain and cryptocurrencies, as the initial attractiveness of the internet as a technology of freedom gives way to more and more demands for regulation of online spaces.</p>
<p> </p>
<p>INTERNET REGULATION WORLDWIDE now seems to be in what may be termed the ‘Newton Minow moment’. Minow was the Chair of the Federal Communications Commission under the John F Kennedy administration in the US in the early 1960s. What renders him more than an historical footnote is his famous observation that US network television of the time resembled a ‘vast wasteland’. The ‘vast wasteland’ speech, delivered to the National Association of Broadcasters in May 1961, profoundly shaped the push for public interest regulation of broadcasting for the next twenty years, from greater provision for children’s programming to the establishment of the Public Broadcasting Service. Similar statements were articulated in public enquiries elsewhere, such as the Pilkington Committee review of UK television in 1962, and the Vincent Report in Australia in 1963. Just as the 1960s were the decade of questioning the entertainment media as a product of consumer capitalism, so too have the 2010s become a decade for critical reflections on the costs and downsides of the digital revolution. While it is unlikely that companies such as Google and Facebook will be considered to be fully fledged media companies, their critical role in enabling and curating public conversations will see growing expectations that they demonstrate social responsibility commensurate with market power.</p>
<p>It is highly likely that the various public enquiries into digital platforms will begin to coalesce into a shared understanding of what constitutes appropriate public-interest regulation of digital platforms.<a href="#_edn10" name="_ednref10">[x]</a> Whether it will translate into policy and legislative change will be very much in the hands of governments, and it is very hard to gainsay their preparedness to act around such principles. Twitter established a Trust and Safety Council in 2016 to address concerns about online harassment and cyberbullying, but it remains difficult for those outside the organisation to know what it actually does and how effective its role has been. At the end of the day, whether policy changes can address public concerns about digital platforms and how they are used or misused will come down to questions of trust.</p>
<p>In his September 2018 appearance before the US House Energy and Commerce Committee, Twitter CEO Jack Dorsey asked ‘How do we earn more trust from the people using our service?’<a href="#_edn11" name="_ednref11" >[xi]</a> For Dorsey, perhaps not surprisingly, this need to earn user trust came down to the need for greater transparency about Twitter algorithms. In a similar vein, Mark Zuckerberg has argued that Facebook should not be the ‘arbiter of truth’ in society. He is right up to a point: it is not the role of digital platforms, or any form of media, to dictate truth to citizens. But as influential brokers of public communication, they can be seen to have responsibilities towards the pursuit of greater truth in the public realm, in order to enhance the quality of civic discourse.</p>
<p>A growing number of voices worldwide are now saying that it is time for digital platforms to address the ethical dimensions of their mission and their social role, and that proposing greater transparency is necessary but not sufficient. The digital platforms have come – partly by accident and partly by design – to shape public conversations that can both facilitate and destroy trust among citizens in public institutions, the political process and, ultimately, trust in one another. The struggle to renew public trust will be at the core of any new measures to address the agenda-setting influence of these digital giants.</p>
<h3>References</h3>
<div class="notes-and-refs">
<ul>
<li><a href="#_ednref1" name="_edn1">[i]</a> Shirky, Clay (2010). <em>Cognitive Surplus: Creativity and Generosity in a Connected Age</em>. New York: Penguin.</li>
<li><a href="#_ednref2" name="_edn2">[ii]</a> Karpf, David (2018). 25 Years of WIRED Predictions: Why the Future Never Arrives’, <em>WIRED</em>, 18 September. Retrieved form  <a href="https://www.wired.com/story/wired25-david-karpf-issues-tech-predictions/"> https://www.wired.com/story/wired25-david-karpf-issues-tech-predictions/</a>.</li>
<li><a href="#_ednref3" name="_edn3">[iii]</a> <em>The Economist</em> (2018). How to tame the tech titans. 18 January. Retrieved from <a href="https://www.economist.com/news/leaders/21735021-dominance-google-facebook-and-amazon-bad-consumers-and-competition-how-tame"> https://www.economist.com/news/leaders/21735021-dominance-google-facebook-and-amazon-bad-consumers-and-competition-how-tame</a>.</li>
<li><a href="#_ednref4" name="_edn4">[iv]</a> Subramanian, Samanth (2017). Meet the Macedonian Teens Who Mastered Fake News and Corrupted the US Election. <em>WIRED</em>, 15 February. Retrieved from <a href="https://www.wired.com/2017/02/veles-macedonia-fake-news/"> https://www.wired.com/2017/02/veles-macedonia-fake-news/</a>.</li>
<li><a href="#_ednref5" name="_edn5">[v]</a> Brinklow, Adam (2016), ‘Final result: how San Francisco neighborhoods voted’, <em>SF Examiner</em>, 2 December. Retrieved from <a href="https://sf.curbed.com/2016/12/2/13820078/final-sf-voting-results-trump-neighborhoods-clinton-sanders"> https://sf.curbed.com/2016/12/2/13820078/final-sf-voting-results-trump-neighborhoods-clinton-sanders</a> .</li>
<li><a href="#_ednref6" name="_edn6">[vi]</a> Samuels, Brett (2017). Feinstein to tech execs: 'I don't think you get it'. <em>The Hill</em>, November 1. Retrieved from <a href="https://thehill.com/business-a-lobbying/358232-feinstein-to-tech-cos-i-dont-think-you-get-it"> https://thehill.com/business-a-lobbying/358232-feinstein-to-tech-cos-i-dont-think-you-get-it</a>.</li>
<li><a href="#_ednref7" name="_edn7">[vii]</a> Watson, Chloe (2018). The key moments from Mark Zuckerberg's testimony to Congress. <em>The Giardian</em>, April 11. Retrieved from <a href="https://www.theguardian.com/technology/2018/apr/11/mark-zuckerbergs-testimony-to-congress-the-key-moments"> https://www.theguardian.com/technology/2018/apr/11/mark-zuckerbergs-testimony-to-congress-the-key-moments</a>.</li>
<li><a href="#_ednref8" name="_edn8">[viii]</a> Tufecki, Zeynep (2018). Why Mark Zuckerberg’s 14 Year Apology Tour Hasn’t Fixed Facebook’, WIRED, April 18. Retrieved from <a href="https://www.wired.com/story/why-zuckerberg-15-year-apology-tour-hasnt-fixed-facebook/"> https://www.wired.com/story/why-zuckerberg-15-year-apology-tour-hasnt-fixed-facebook/</a>.</li>
<li><a href="#_ednref9" name="_edn9">[ix]</a> Vaughan-Nichols, Stephen (2018). EU smacks internet in the face with link tax and upload filter laws. <em>ZDNet</em>, September 12. Retrieved from <a href="https://www.zdnet.com/article/eu-smacks-internet-in-the-face-with-link-tax-and-upload-filter-laws/"> https://www.zdnet.com/article/eu-smacks-internet-in-the-face-with-link-tax-and-upload-filter-laws/</a> .</li>
<li><a href="#_ednref10" name="_edn10">[x]</a> For a broad sketch of what such public interest principles would look like, see Robert Picard and Vincent Pickard (2017), <em>Essential Principles for Contemporary Media and Communications Policymaking</em>, Oxford: University of Oxford</li>
<li><a href="#_ednref11" name="_edn11">[xi]</a> Nieva, Richard (2018). Jack Dorsey defends Twitter from charges of bias against conservatives. <em>C/Net</em>, 5 September. Retrieved from <a href="https://www.cnet.com/news/jack-dorsey-defends-twitter-against-conservative-bias-at-house-hearing/">https://www.cnet.com/news/jack-dorsey-defends-twitter-against-conservative-bias-at-house-hearing/</a> .</li>
</ul>
</div>
<p>From Griffith Review Edition 64: The New Disruptors © Copyright Griffith University &amp; the author.</p>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="The net delusion: How not to liberate the world"
class="paper-story"
data-article-title="The net delusion: How not to liberate the world"
>

<h1 class="article-title" id="h_The net delusion: How not to liberate the world">The net delusion: How not to liberate the world</h1>

<div class="top-meta">Evgeny Morozov, 2021. for week 3.</div>

<p>Morozov, E. (2011). Introduction in <em>The net delusion: How not to liberate the world</em>. Penguin UK.</p>
<hr>
<h1>INTRODUCTION</h1>
<p>For anyone who wants to see democracy prevail in the most hostile and unlikely environments, the first decade of the new millennium was marked by a sense of bitter disappointment, if not utter disillusionment. The seemingly inexorable march of freedom that began in the late 1980s has not only come to a halt but may have reversed its course.</p>
<p>Expressions like “freedom recession” have begun to break out of the think-tank circuit and enter the public conversation. In a state of quiet desperation, a growing number of Western policymakers began to concede that the Washington Consensus—that set of dubious policies that once promised a neoliberal paradise at deep discounts—has been superseded by the Beijing Consensus, which boasts of delivering quick-and-dirty prosperity without having to bother with those pesky institutions of democracy.</p>
<p>The West has been slow to discover that the fight for democracy wasn’t won back in 1989. For two decades it has been resting on its laurels, expecting that Starbucks, MTV, and Google will do the rest just fine. Such a laissez-faire approach to democratization has proved rather toothless against resurgent authoritarianism, which has masterfully adapted to this new, highly globalized world. Today’s authoritarianism is of the hedonism- and consumerism-friendly variety, with Steve Jobs and Ashton Kutcher commanding far more respect than Mao or Che Guevara. No wonder the West appears at a loss. While the Soviets could be liberated by waving the magic wand of blue jeans, exquisite coffee machines, and cheap bubble gum, one can’t pull the same trick on China. After all, this is where all those Western goods come from.</p>
<p>Many of the signs that promised further democratization just a few years ago never quite materialized. The so-called color revolutions that swept the former Soviet Union in the last decade produced rather ambiguous results. Ironically, it’s the most authoritarian of the former Soviet republics—Russia, Azerbaijan, Kazakhstan—that found those revolutions most useful, having discovered and patched their own vulnerabilities. My own birthplace, Belarus, once singled out by Condoleezza Rice as the last outpost of tyranny in Europe, is perhaps the shrewdest of the lot; it continues its slide into a weird form of authoritarianism, where the glorification of the Soviet past by its despotic ruler is fused with a growing appreciation of fast cars, expensive holidays, and exotic cocktails by its largely carefree populace.</p>
<p>The wars in Iraq and Afghanistan, which were started, if anything, to spread the gospel of freedom and democracy, have lost much of their initial emancipatory potential as well, further blurring the line between “regime change” and “democracy promotion.” Coupled with Washington’s unnecessary abuses of human rights and rather frivolous interpretations of international law, these two wars gave democracy promotion such a bad name that anyone eager to defend it is considered a Dick Cheney acolyte, an insane idealist, or both.</p>
<p>It is thus easy to forget, if only for therapeutic purposes, that the West still has an obligation to stand up for democratic values, speak up about violations of human rights, and reprimand those who abuse their office and their citizens. Luckily, by the twenty-first century the case for promoting democracy no longer needs to be made; even the hardest skeptics agree that a world where Russia, China, and Iran adhere to democratic norms is a safer world.</p>
<p>That said, there is still very little agreement on the kind of methods and policies the West needs to pursue to be most effective in promoting democracy. As the last few decades have so aptly illustrated, good intentions are hardly enough. Even the most noble attempts may easily backfire, entrenching authoritarianism as a result. The images of horrific prisoner abuse at Abu Ghraib were the result, if only indirectly, of one particular approach to promoting democracy. It did not exactly work as advertised.</p>
<p>Unfortunately, as the neoconservative vision for democratizing the world got discredited, nothing viable has come to fill the vacuum. While George Bush certainly overdid it with his excessive freedom-worshiping rhetoric, his successor seems to have abandoned the rhetoric, the spirit, as well as any desire to articulate what a post-Bush “freedom agenda” might look like.</p>
<p>But there is more to Obama’s silence than just his reasonable attempt to present himself as anti-Bush. Most likely his silence is a sign of an extremely troubling bipartisan malaise: the growing Western fatigue with the project of promoting democracy. The project suffers not just from bad publicity but also from a deeply rooted intellectual crisis. The resilience of authoritarianism in places like Belarus, China, and Iran is not for lack of trying by their Western “partners” to stir things up with an expectation of a democratic revolution. Alas, most such Western initiatives flop, boosting the appeal of many existing dictators, who excel at playing up the threat of foreign mingling in their own affairs. To say that there is no good blueprint for dealing with modern authoritarianism would be a severe understatement.</p>
<p>Lost in their own strategizing, Western leaders are pining for something that has guaranteed effectiveness. Many of them look back to the most impressive and most unambiguous triumph of democracy in the last few decades: the peaceful dissolution of the Soviet Union. Not surprisingly—and who can blame them for seeking to bolster their own self-confidence?—they tend to exaggerate their own role in precipitating its demise. As a result, many of the Western strategies tried back then, like smuggling in photocopiers and fax machines, facilitating the flow of samizdat, and supporting radio broadcasts by Radio Free Europe and the Voice of America, are given much more credit than they deserve.</p>
<p>Such belated Cold War triumphalism results in an egregious logical fallacy. Since the Soviet Union eventually fell, those strategies are presumed to have been extremely effective—in fact, crucial to the whole endeavor. The implications of such a view for the future of democracy promotion are tremendous, for they suggest that large doses of information and communications technology are lethal to the most repressive of regimes.</p>
<p>Much of the present excitement about the Internet, particularly the high hopes that are pinned on it in terms of opening up closed societies, stems from such selective and, at times, incorrect readings of history, rewritten to glorify the genius of Ronald Reagan and minimize the role of structural conditions and the inherent contradictions of the Soviet system.</p>
<p>It’s for these chiefly historical reasons that the Internet excites so many seasoned and sophisticated decision makers who should really know better. Viewing it through the prism of the Cold War, they endow the Internet with nearly magical qualities; for them, it’s the ultimate cheat sheet that could help the West finally defeat its authoritarian adversaries. Given that it’s the only ray of light in an otherwise dark intellectual tunnel of democracy promotion, the Internet’s prominence in future policy planning is assured.</p>
<p>And at first sight it seems like a brilliant idea. It’s like Radio Free Europe on steroids. And it’s cheap, too: no need to pay for expensive programming, broadcasting, and, if everything else fails, propaganda. After all, Internet users can discover the truth about the horrors of their regimes, about the secret charms of democracy, and about the irresistible appeal of universal human rights on their own, by turning to search engines like Google and by following their more politically savvy friends on social networking sites like Facebook. In other words, let them tweet, and they will tweet their way to freedom. By this logic, authoritarianism becomes unsustainable once the barriers to the free flow of information are removed. If the Soviet Union couldn’t survive a platoon of pamphleteers, how can China survive an army of bloggers?</p>
<p>It’s hardly surprising, then, that the only place where the West (especially the United States) is still unabashedly eager to promote democracy is in cyberspace. The Freedom Agenda is out; the Twitter Agenda is in. It’s deeply symbolic that the only major speech about freedom given by a senior member of the Obama administration was Hillary Clinton’s speech on Internet freedom in January 2010. It looks like a safe bet: Even if the Internet won’t bring democracy to China or Iran, it can still make the Obama administration appear to have the most technologically savvy foreign policy team in history. The best and the brightest are now also the geekiest. The Google Doctrine—the enthusiastic belief in the liberating power of technology accompanied by the irresistible urge to enlist Silicon Valley start-ups in the global fight for freedom—is of growing appeal to many policymakers. In fact, many of them are as upbeat about the revolutionary potential of the Internet as their colleagues in the corporate sector were in the late 1990s. What could possibly go wrong here?</p>
<p>As it turns out, quite a lot. Once burst, stock bubbles have few lethal consequences; democracy bubbles, on the other hand, could easily lead to carnage. The idea that the Internet favors the oppressed rather than the oppressor is marred by what I call cyber-utopianism: a naïve belief in the emancipatory nature of online communication that rests on a stubborn refusal to acknowledge its downside. It stems from the starry-eyed digital fervor of the 1990s, when former hippies, by this time ensconced in some of the most prestigious universities in the world, went on an argumentative spree to prove that the Internet could deliver what the 1960s couldn’t: boost democratic participation, trigger a renaissance of moribund communities, strengthen associational life, and serve as a bridge from bowling alone to blogging together. And if it works in Seattle, it must also work in Shanghai.</p>
<p>Cyber-utopians ambitiously set out to build a new and improved United Nations, only to end up with a digital Cirque du Soleil. Even if true—and that’s a gigantic “if”—their theories proved difficult to adapt to non-Western and particularly nondemocratic contexts. Democratically elected governments in North America and Western Europe may, indeed, see an Internet-driven revitalization of their public spheres as a good thing; logically, they would prefer to keep out of the digital sandbox—at least as long as nothing illegal takes place. Authoritarian governments, on the other hand, have invested so much effort into suppressing any form of free expression and free assembly that they would never behave in such a civilized fashion. The early theorists of the Internet’s influence on politics failed to make any space for the state, let alone a brutal authoritarian state with no tolerance for the rule of law or dissenting opinions. Whatever book lay on the cyber-utopian bedside table in the early 1990s, it was surely not Hobbes’s <em>Leviathan</em>.</p>
<p>Failing to anticipate how authoritarian governments would respond to the Internet, cyber-utopians did not predict how useful it would prove for propaganda purposes, how masterfully dictators would learn to use it for surveillance, and how sophisticated modern systems of Internet censorship would become. Instead most cyber-utopians stuck to a populist account of how technology empowers the <em>people</em>, who, oppressed by years of authoritarian rule, will inevitably rebel, mobilizing themselves through text messages, Facebook, Twitter, and whatever new tool comes along next year. (The <em>people</em>, it must be noted, really liked to hear such theories.) Paradoxically, in their refusal to see the downside of the new digital environment, cyber-utopians ended up belittling the role of the Internet, refusing to see that it penetrates and reshapes all walks of political life, not just the ones conducive to democratization.</p>
<p>I myself was intoxicated with cyber-utopianism until recently. This book is an attempt to come to terms with this ideology as well as a warning against the pernicious influence that it has had and is likely to continue to have on democracy promotion. My own story is fairly typical of idealistic young people who think they are onto something that could change the world. Having watched the deterioration of democratic freedoms in my native Belarus, I was drawn to a Western NGO that sought to promote democracy and media reform in the former Soviet bloc with the help of the Internet. Blogs, social networks, wikis: We had an arsenal of weapons that seemed far more potent than police batons, surveillance cameras, and handcuffs.</p>
<p>Nevertheless, after I spent a few busy years circling the former Soviet region and meeting with activists and bloggers, I lost my enthusiasm. Not only were our strategies failing, but we also noticed a significant push back from the governments we sought to challenge. They were beginning to experiment with censorship, and some went so far as to start aggressively engaging with new media themselves, paying bloggers to spread propaganda and troll social networking sites looking for new information on those in the opposition. In the meantime, the Western obsession with the Internet and the monetary support it guaranteed created numerous hazards typical of such ambitious development projects. Quite predictably, many of the talented bloggers and new media entrepreneurs preferred to work for the extremely well-paid but largely ineffective Western-funded projects instead of trying to create more nimble, sustainable, and, above all, effective projects of their own. Thus, everything we did—with generous funding from Washington and Brussels—seemed to have produced the results that were the exact opposite of what my cyber-utopian self wanted.</p>
<p>It was tempting to throw my hands up in despair and give up on the Internet altogether. But this would have been the wrong lesson to draw from these disappointing experiences. Similarly, it would be wrong for Western policymakers to simply dismiss the Internet as a lost cause and move on to bigger, more important issues. Such digital defeatism would only play into the hands of authoritarian governments, who would be extremely happy to continue using it as both a carrot (keeping their populace entertained) and a stick (punishing those who dare to challenge the official line). Rather, the lesson to be drawn is that the Internet is here to stay, it will continue growing in importance, and those concerned with democracy promotion need not only grapple with it but also come up with mechanisms and procedures to ensure that another tragic blunder on the scale of Abu Ghraib will never happen in cyberspace. This is not a far-fetched scenario. How hard is it to imagine a site like Facebook inadvertently disclosing the private information of activists in Iran or China, tipping off governments to secret connections between the activists and their Western funders?</p>
<p>To be truly effective, the West needs to do more than just cleanse itself of cyber-utopian bias and adopt a more realist posture. When it comes to concrete steps to promote democracy, cyber-utopian convictions often give rise to an equally flawed approach that I dub “Internet-centrism.” Unlike cyber-utopianism, Internet-centrism is not a set of beliefs; rather, it’s a philosophy of action that informs how decisions, including those that deal with democracy promotion, are made and how long-term strategies are crafted. While cyber-utopianism stipulates <em>what</em> has to be done, Internet-centrism stipulates <em>how</em> it should be done. Internet-centrists like to answer every question about democratic change by first reframing it in terms of the Internet rather than the context in which that change is to occur. They are often completely oblivious to the highly political nature of technology, especially the Internet, and like to come up with strategies that assume that the logic of the Internet, which, in most cases, they are the only ones to perceive, will shape every environment than it penetrates rather than vice versa.</p>
<p>While most utopians are Internet-centrists, the latter are not necessarily utopians. In fact, many of them like to think of themselves as pragmatic individuals who have abandoned grand theorizing about utopia in the name of achieving tangible results. Sometimes, they are even eager to acknowledge that it takes more than bytes to foster, install, and consolidate a healthy democratic regime.</p>
<p>Their realistic convictions, however, rarely make up for their flawed methodology, which prioritizes the tool over the environment, and, as such, is deaf to the social, cultural, and political subtleties and indeterminacies. Internet-centrism is a highly disorienting drug; it ignores context and entraps policymakers into believing that they have a useful and powerful ally on their side. Pushed to its extreme, it leads to hubris, arrogance, and a false sense of confidence, all bolstered by the dangerous illusion of having established effective command of the Internet. All too often, its practitioners fashion themselves as possessing full mastery of their favorite tool, treating it as a stable and finalized technology, oblivious to the numerous forces that are constantly reshaping the Internet— not all of them for the better. Treating the Internet as a constant, they fail to see their own responsibility in preserving its freedom and reining in the ever-powerful intermediaries, companies like Google and Facebook.</p>
<p>As the Internet takes on an even greater role in the politics of both authoritarian and democratic states, the pressure to forget the context and start with what the Internet allows will only grow. All by itself, however, the Internet provides nothing certain. In fact, as has become obvious in too many contexts, it empowers the strong and disempowers the weak. It is impossible to place the Internet at the heart of the enterprise of democracy promotion without risking the success of that very enterprise.</p>
<p>The premise of this book is thus very simple: To salvage the Internet’s promise to aid the fight against authoritarianism, those of us in the West who still care about the future of democracy will need to ditch both cyber-utopianism and Internet-centrism. Currently, we start with a flawed set of assumptions (cyber-utopianism) and act on them using a flawed, even crippled, methodology (Internet-centrism). The result is what I call the Net Delusion. Pushed to the extreme, such logic is poised to have significant global consequences that may risk undermining the very project of promoting democracy. It’s a folly that the West could do without.</p>
<p>Instead, we’ll need to opt for policies informed by a realistic assessment of the risks and dangers posed by the Internet, matched by a highly scrupulous and unbiased assessment of its promises, and a theory of action that is highly sensitive to the local context, that is cognizant of the complex connections between the Internet and the rest of foreign policymaking, and that originates not in what technology allows but in what a certain geopolitical environment requires.</p>
<p>In a sense, giving in to cyber-utopianism and Internet-centrism is akin to agreeing to box blindfolded. Sure, every now and then we may still strike some powerful blows against our authoritarian adversaries, but in general this is a poor strategy if we want to win. The struggle against authoritarianism is too important of a battle to fight with a voluntary intellectual handicap, even if that handicap allows us to play with the latest fancy gadgets.</p>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="Ada Lovelace, the First Tech Visionary"
class="paper-story"
data-article-title="Ada Lovelace, the First Tech Visionary"
>

<h1 class="article-title" id="h_Ada Lovelace, the First Tech Visionary">Ada Lovelace, the First Tech Visionary</h1>

<div class="top-meta">Betsy Morais, 2013-10-15 00:00:00 AEST. for week 4.</div>

<p>Morais, B. (2013). <a href="https://www.newyorker.com/tech/annals-of-technology/ada-lovelace-the-first-tech-visionary">Ada Lovelace, the first tech visionary</a>. <em>The New Yorker</em>.</p>
<p><img src="https://media.newyorker.com/photos/590952556552fa0be682c157/master/w_1920,c_limit/ada-lovelace-290.jpeg" alt=""></p>
<p>By <a href="https://www.newyorker.com/contributors/betsy-morais">Betsy Morai</a> October 15, 2013</p>
<p>When Ada Lovelace was twelve years old, she wanted to fly. She approached the problem methodically, examining birds and investigating various materials that could serve as wings—feathers, paper, silk. In the course of her research, which began in February, 1828, according to her biographer Betty Alexandra Toole, Ada wrote and illustrated a guide called “Flyology,” to record her findings. She toiled away on this project until her mother reprimanded her for neglecting her studies, which were meant to set her on a rational course, not a fanciful one.</p>
<p>Ada’s mother, Annabella Byron, was the straight-laced counterpoint to her father, Lord Byron, the Romantic poet, who called his wife the “Princess of Parallelograms.” A month after Ada’s birth, Annabella Byron moved their daughter out of their London house, and away from Lord Byron’s influence. When, shortly before his death, he wrote asking about Ada’s upbringing, Annabella had this to report: “Not devoid of imagination, but is chiefly exercised in connection with her mechanical ingenuity.” This was the best she could hope for, having drilled into Ada a discipline for arithmetic, music, and French, according to the biography “<a href="http://www.amazon.com/Female-Genius-Lovelace-Computer-ebook/dp/B00F49M154/ref=tmm_kin_swatch_0?ots=1&amp;slotNum=0&amp;imprToken=90bd732d-79da-708c-426&amp;tag=thneyo0f-20&amp;linkCode=w50&amp;_encoding=UTF8&amp;sr=&amp;qid=">A Female Genius</a>,” by James Essinger, which comes out today. Essinger writes that Lady Byron wished to suppress her daughter’s imagination, which she thought to be “dangerous and potentially destructive and coming from the Byrons.”</p>
<p>But Lovelace reconciled the competing poles of her parents’ influence. On January 5, 1841, she asked, “What is Imagination?” Two things, she thought. First, “the combining faculty,” which “seizes points in common, between subjects having no apparent connection,” and then, she wrote, “Imagination is the Discovering Faculty, pre-eminently. It is that which penetrates into the unseen worlds around us, the worlds of Science.”</p>
<p>Augusta Ada Lovelace is known as the first computer programmer, and, since 2009, she has been recognized annually on October 15th to highlight the often overlooked contributions of women to math and science. The main event is being held today at Imperial College London, with the début of an anthology of essays, “<a href="http://findingada.com/book/">A Passion for Science: Stories of Discovery and Invention</a>.” “I started to think that one of the biggest parts of the problem was that women in tech are often invisible,” Suw Charman-Anderson, the founder of Ada Lovelace Day, told me. After reading a study in 2006 by the psychologist Penelope Lockwood, who researched the dearth of female role models in the sciences, Charman-Anderson thought that a fête for Lovelace could raise awareness of her noteworthy successors. This year, dozens of celebrations will be thrown around the world, including an “Ada Lovelace Edit-a-thon” at Brown University, where volunteers will ramp up Wikipedia entries for female scientists.</p>
<p>Looming in the background of these festivities are findings, announced last month by the Census Bureau, that the share of women working in <em class="small">STEM</em> (science, technology, engineering, and math) has decreased over the past couple of decades; this is due largely to the fact that women account for a smaller proportion of those employed in computing. In 1990, women held thirty-four per cent of <em class="small">STEM</em> jobs; in 2011, it was twenty-seven per cent. Valerie Aurora, the executive director of the Ada Initiative, a nonprofit organization that arranges conferences and training programs to elevate women working in math and science, is participating in the first ever <a href="https://www.stevens.edu/calconference/">Ada Lovelace conference</a> this week, at Stevens Institute of Technology in Hoboken. “Lovelace is an unusual example of a woman for her time because she was not only allowed to learn mathematics but encouraged to learn mathematics,” Aurora said. “She shows what women can do when given a chance.”</p>
<p>Lovelace’s opportunity came when she met Charles Babbage, the renowned mathematician who would become her friend and mentor. On June 5, 1833, she attended a flamboyant party brimming with London socialites, to whom she was making her début at the age of seventeen. There was Babbage, a widower in his forties, who spoke excitedly of an invention he called the “Difference Machine,” a tower of numbered wheels that could make reliable calculations with the turn of a handle. A few days later, Lady Byron took Ada to his home at 1 Dorset Street to see him demonstrate the device in his drawing room. Ada, intrigued by the incomplete prototype, struck up a correspondence with Babbage about its potential, and her own mathematical studies. The letters between them span from June 10, 1835, to August 12, 1852; he told her about his plans, and she wrote to him of her ambition. “I think your taste for mathematics is so decided that it ought not to be checked,” Babbage wrote to her in 1839.</p>
<p>When Babbage began devising a new project, the “Analytical Engine”—sketched out as a hulking machine with thousands of cogwheels that could perform more functions with greater accuracy—Lovelace served as its key interpreter. On a trip to Turin to promote his work, which required considerable financial support, Babbage met a mathematician named Luigi Federico Menabrea, who agreed to write a paper on the machine. It was published in a Swiss academic journal in October, 1842, at about eight thousand words. Lovelace translated it from the French, and added her own notes. Her version came in at twenty thousand words. “The notes of the Countess of Lovelace extend to about three times the length of the original memoir,” Babbage wrote later. “Their author has entered fully into almost all the very difficult and abstract questions connected with the subject.”</p>
<p>Her translation, along with her notes, was published in 1843, and represent her greatest contribution to computer science: she described with clarity how Babbage’s device would work, illuminating its foundations in the <a href="http://en.wikipedia.org/wiki/Jacquard_loom">Jacquard loom</a>. Just as Joseph-Marie Jacquard’s silk-weaving machine could automatically create images using a chain of punched cards, so too could Babbage’s system—the engine, Lovelace explained, weaved algebraic patterns. She also wrote how it might perform a particular calculation: Note G, as it is known, set out a detailed plan for the punched cards to weave a long sequence of <a href="http://www.princeton.edu/~achaney/tmve/wiki100k/docs/Bernoulli_number.html">Bernoulli numbers</a>, and is considered to be the first computer program. “The science of operations, as derived from mathematics more especially, is a science of itself, and has its own abstract truth and value,” Lovelace wrote. Essinger interprets this line in his biography, writing, “Ada is here seeking to do nothing less than invent the science of computing, and separate it from the science of mathematics. What she calls ‘the science of operations’ is indeed in effect computing.”</p>
<p>Beyond that, Lovelace articulated, as not even Babbage could, the poetic significance of his machine. She wrote:</p>
<blockquote>
<p>This science constitutes the language through which alone we can adequately express the great facts of the natural world, and those unceasing changes of mutual relationship which, visibly or invisibly, consciously or unconsciously to our immediate physical perceptions, are interminably going on in the agencies of the creation we live amidst.</p>
</blockquote>
<p>She continues:</p>
<blockquote>
<p>A new, a vast, and a powerful language is developed for the future use of analysis, in which to wield its truths so that these may become of more speedy and accurate practical application for the purposes of mankind than the means hitherto in our possession have rendered possible. Thus not only the mental and the material, but the theoretical and the practical in the mathematical world, are brought into more intimate and effective connection with each other.</p>
</blockquote>
<p>Years later, scholars would dispute that Lovelace actually wrote the notes. The Babbage historian Bruce Collier argued that her contribution had been greatly overstated, and “it is no exaggeration to say that she was a manic depressive with the most amazing delusions about her own talents, and a rather shallow understanding of Charles Babbage and the Analytical Engine.” But Essinger, Toole, and others reject this interpretation. “As people realized how important computer programming was, there was a greater backlash and an attempt to reclaim it as a male activity,” Aurora told me. “In order to keep that wealth and power in a man’s hands, there’s a backlash to try to redefine it as something a woman didn’t do, and shouldn’t do, and couldn’t do.”</p>
<p>Suw Charman-Anderson said that Lovelace’s story resonates “because there are still people who seek to discredit her achievements. It is something that many women working in tech are only too familiar with. We can look at Ada and recognize that our own challenges are similar to hers, and her achievements are the sorts of things that we strive towards.”</p>
<p>In the late seventies, the Department of Defense developed a software language called Ada—one that brought together a number of different programming languages. It’s fitting for Lovelace—a woman who rode horses and played the harp and studied poetry—to tie seemingly disparate elements together. As Aurora told me, “Computer programming has so many interactions with the rest of the world.” While Babbage possessed technical ingenuity, Aurora said, Lovelace propelled his invention into the nascent days of computing: “She was the first person to see the true potential.”
For this, Babbage called her “Lady Fairy.”</p>
<p><em>Illustration: SSPL/Getty.</em></p>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="The Digital Age"
class="paper-story"
data-article-title="The Digital Age"
>

<h1 class="article-title" id="h_The Digital Age">The Digital Age</h1>

<div class="top-meta">Paul E. Ceruzzi, 2012-06-15 00:00:00 AEST. for week 4.</div>

<h1>The Digital Age</h1>
<p>In the spring of 1942, as World War II was raging, the U.S. National Defense Research Committee convened a meeting of scientists and engineers to consider devices to aim and fire anti-aircraft guns. The <em>Blitzkrieg</em>, a brilliant military tactic based on rapid attacks by German dive bombers, made the matter urgent. The committee examined a number of designs, which they noticed fell into two broad categories. One directed antiaircraft fire by constructing a mechanical or electrical analog of the mathematical equations of fire control, for example, by machining a camshaft whose profile followed an equation of motion. The other solved the equations numerically—as with an ordinary calculating machine, only with fast electrical pulses instead of mechanical counters. One member of the committee, Bell Telephone Laboratories mathematician George Stibitz, felt that the term <em>pulse</em> was not quite right. He suggested another term that he felt was more descriptive: <em>digital</em>. The word referred to the method of counting on one’s fingers, or digits. It has since become the adjective that defines social, economic, and political life in the twenty-first century.<sup>1</sup></p>
<p>It took more than just the coining of a term to create the digital age, but that age does have its origins in secret projects initiated or conducted during World War II. Most histories of computing, which purport to cover the full range of the topic, do not explain how such an invention, intended as a high-speed replacement for calculators during the war, could have led to such a far-reaching social impact.</p>
<p>Nor do those wartime developments, as significant as they were, explain the adoption of digital techniques for communications. That took place not during World War II but two decades later, when an agency of the U.S. Defense Department initiated a program to interconnect defense computers across the United States. That combination of computing and communications unleashed a flood of social change, in the midst of which we currently live.</p>
<p>Telecommunications, like computing, has a long and well-documented history, beginning with the Morse and Wheatstone electric telegraphs of the mid-nineteenth century, followed by the invention and spread of the telephone by Alexander Graham Bell, Elisha Gray, Thomas Edison, and others later that century. What was different about the 1960s computer networks? Nearly every social and business phenomenon we associate with the Internet was anticipated by similar uses of the telegraph a century earlier.<sup>2</sup> The telegraph, combined with the undersea cable, did transform society, yet the transformation effected by the more recent application of a digital paradigm seems to be many times greater.</p>
<p>It is dangerous to apply modern terms to events of the past, but one may violate this rule briefly to note that the electric telegraph, as refined by Samuel Morse in the 1840s, was a proto “digital”device. It used pulses, not continuous current, and it employed a code that allowed it to send messages rapidly and accurately over long distances with a minimum number of wires or apparatus. Typesetters had long known that certain letters (e.g., e, t, a) were used more frequently than others, and on that basis the codes chosen for those letters were shorter than the others. A century later mathematicians placed this ad hoc understanding of telecommunications on a theoretical basis. What came to be called information theory emerged at the same time as, and independent of, the first digital computers in the 1930s and 1940s. Binary (base-2) arithmetic, bits, and bytes (8-bit coded characters) are familiar at least in name to modern users of digital devices. The roots of that theory are less well known, but those roots made the modern digital age possible.</p>
<p>Many histories of computing begin with Charles Babbage, the Englishman who tried, and failed, to build an “Analytical Engine”in the mid-nineteenth century—the same time as Morse was developing the telegraph.<sup>3</sup> The reason is that Babbage’s design—what we now call the architecture of his machine—was remarkably modern. It embodied the basic elements that were finally realized in the computers built during World War II. We now see, however, that to begin with Babbage is to make certain assumptions. What exactly is a “computer”? And what is its relation to the digital age that we are living in today?</p>
<h2>The Components of Computing</h2>
<p>Computing represents a convergence of operations that had been mechanized to varying degrees in the past. Mechanical aids to calculation are found in antiquity, when cultures developed aids to counting and figuring such as pebbles (Latin <em>calculi</em>, from which comes the term <em>calculate</em>), counting boards (from which comes the modern term <em>countertop</em>), and the abacus—all of which survive into this century. Although it may seem arbitrary, the true mechanization of calculation began when inventors devised ways not only to record numbers but to add them, in particular to automatically carry a digit form one column to the next when necessary, especially for carries like 999 + 1. That began with Pascal’s adding machine of 1642, or with a device invented by Wilhelm Schickard in 1623. Leibniz extended Pascal’s invention by developing a machine, a few decades later, that could multiply as well as add. The mechanisms by which these devices operated lay dormant until the nineteenth century, when advancing commerce and business created a demand that commercial manufacturers sought to fill. Toward the end of that century, mechanical calculators of intricate design appeared in Europe and in the United States. The Felt Comptometer, invented in the 1880s, was one of the first successful calculators, owing to its simplicity, speed, and reliable operation. The Burroughs adding machine, invented by William S. Burroughs around the same time, also was a commercial success. Burroughs survived as a supplier of electronic computers into the 1980s and is the ancestor of today’s Unisys. In Europe, machines supplied by companies including Brunsviga and Odhner were also widely sold. On these machines, the user set numbers on a set of wheels rather than press keys, but they worked on similar principles.</p>
<p>As significant as calculation were two additional functions: the automatic storage and retrieval of information in coded form and the automatic execution of a sequence of operations. That is the reason historians began with the Analytical Engine that Charles Babbage attempted to build in the nineteenth century. Babbage never completed that machine, for reasons that only in part had to do with the state of mechanical engineering at the time. In the 1830s, when Babbage was sketching out ideas for such an engine, neither he nor anyone else could draw on electrical technology to implement his ideas; everything had to be done mechanically. Given the necessary level of complexity that a computer must have, a mechanical computer of decent power was not practical then, and not today either. The recent successful reconstruction, at great expense, of Babbage’s other project, the Difference Engine, proves this point.<sup>4</sup> It works, but the Difference Engine’s capabilities are nowhere near those of the Analytical Engine. An analogy might be to compare Babbage’s vision with Leonardo’s sketches for a flying machine: Leonardo’s vision was sound, but heavier-than-air flight had to await the invention of the gasoline engine to provide sufficient power in a lightweight package.</p>
<p>By this measure, one might begin the history of computing in the late nineteenth century, when the American inventor Herman Hollerith developed, for the 1890 U.S. Census, a method of storing information coded as holes punched into cards. Hollerith developed not just the punched card but a suite of machines that used cards to sort, retrieve, count, and perform simple calculations on data punched onto cards. The devices he developed combined complex mechanisms with electromagnets and motors to perform operations. The use of electricity was not required. A rival inventor, James Powers, produced pure mechanical punched card equipment to avoid infringing on Hollerith’s parents, but in practice the flexibility that Hollerith’s use of electricity gave his machines was an advantage as the machinery was called on to perform ever more complex operations. By the time of World War II, electrical circuits took on an even greater significance, not just as a carrier of information but also as a way of performing computing operations at high speeds—a property that in theory is not required of a true computer but in practice is paramount.</p>
<p>The inherent flexibility of Hollerith’s system of machines built around the punched card led to many applications beyond that of the U.S. Census. Hollerith founded the Tabulating Machine Company to market his inventions; it was later combined with other companies to form the Computing-Tabulating-Recording Company (C-T-R), and in 1924, the new head of C-T-R, Thomas Watson, changed the name to the International Business Machines Corporation, today’s IBM. In 1927 the Remington Rand Corporation acquired the rival Powers Accounting Machine Company, and these two would dominate business accounting for the next four decades.</p>
<p>It is not known where Hollerith got the idea of storing information in the form of holes punched onto card stock, but the concept was not original with him. Babbage proposed using punched cards to control his Analytical Engine, an idea he borrowed from the looms invented by the Frenchman Joseph-Marie Jacquard (1752–1834), who in the nineteenth century used punched cards to control the weaving of cloth by selectively lifting threads according to a predetermined pattern (Jacquard cloth is still woven to this day). Jacquard looms were common in Hollerith’s day, so he was probably familiar with the way punched cards controlled them. However, there is a crucial difference between Jacquard’s and Hollerith’s systems: Jacquard used cards for control, whereas Hollerith used them for storage of data. Eventually IBM’s punched card installations would also use the cards for control. It is fundamental to the digital paradigm that information stored in digital form can be used for storage, control, or calculation, but an understanding of that would not come until decades later. Before World War II, the control function of a punched card installation was carried out by people: they carried decks of cards from one device to another, setting switches or plugging wires on the devices to perform specific calculations, and then collecting the results.</p>
<p>The concept of automatic control, the ancestor of what we now call software, is a third component of computing, and it too has a history that can be traced back to antiquity. Jacquard’s invention was an inside-out version of a device that had been used to control machinery for centuries: a cylinder on which were mounted pegs, which tripped levers as it rotated. These had been used in medieval clocks that executed complex movements at the sounding of each hour; they are also found in wind-up toys, including music boxes. Babbage’s Analytical Engine was to contain a number of such cylinders to carry more detailed sequences of operations as directed by the punched cards; today we might call this the computer’s microprogramming, or read-only memory (ROM). Continuous control of many machines, including classic automobile engines, is effected by cams, which direct the movement of other parts of the machine in a precisely determined way. Unlike cylinders or camshafts, punched cards can be stacked in an arbitrarily long sequence. It is also easy to substitute a short sequence of cards in the stack to tailor the machine for a specific problem, but Jacquard looms used cards that were tied to one another, making any modification to the control difficult.</p>
<p>Control, storage, calculation, the use of electrical or electronic circuits: these attributes, when combined, make a computer. To them we add one more: communication—the transfer of coded information by electrical or electronic means across geographical distances. This fifth attribute was lacking in the early electronic computers built in the 1930s and 1940s. It was the Defense Department’s Advanced Research Projects Agency (ARPA)’s mission, beginning in the 1960s, to reorient the digital computer to be a device that was inherently networked, for which communication was as important to it as calculation, storage, or control.</p>
<p>The origins of the electric telegraph and telephone are well known, but their relationship to computing is complex. In 1876, Alexander Graham Bell publicly demonstrated a telephone: a device that transmitted the human voice over wires. The telephone's relationship to the invention of the computer was indirect. Computers today operate by electrical circuits that allow only one of two states: in modem terms they are both digital, as described above, and binary: they count in base 2. The telephone operated by inducing a continuous variation of current based on the variations of the sound of a person's voice: in today's terms, it was an analog device. Like <em>digital</em>, that term was also unknown before the late 1930s, and therefore not entirely proper to use here. Devices that compute by analogy were once common. The slide rule, for example, was in common use into the 1970s, when it was driven out by the pocket calculator. During the first decades of electronic digital computing, the 1940s and 1950s, there were debates over the two approaches, with analog devices fading into obscurity. Nature is in a fundamental sense continuous, as in the infinite variations of the human voice or the sounds of a musical instrument. But the digital paradigm has prevailed, even in telephony. During World War II, Bell Telephone Laboratories developed a machine that translated voice signals into discrete pulses, encoded them, and reconstituted the voice at the other end-this was to enable Franklin D. Roosevelt and Winston Churchill to speak to each other securely.<sup>5</sup> That was a one-time development, although eventually all phone calls were encoded this way, in what is now called pulse code modulation. The technique is used not so much for secrecy (although that can be done when necessary), but to exploit of the inherent advantages of digital electronics.</p>
<p>Bell's successful defense of his patent, and the subsequent establishment of a wealthy, regulated monopoly to provide telephone service in the United States, led to generous funding for the Bell Telephone Laboratories, which conducted fundamental research in the transmission of information, broadly defined. The role of one Bell Labs mathematician, George Stibitz, has already been mentioned. It was a team of Bell Labs researchers who invented the transistor in the 1940s; two decades later, another Bell Labs team developed the Unix operating system, to mention only the most visible fruits of Bell Laboratories' research. And it was at Bell Labs where much of the theory of information coding, transmission, and storage was developed.</p>
<p>Once again: the modem computer is a convergence of separate streams of information handling, each with its own rich tradition of technological history. Each of the streams described thus far played a major role. One could add other antecedents such as the development of radio, motion pictures, and photography. The line of mechanical calculators seems to be at the forefront, yet it was the Hollerith system of punched cards, centered around a machine called the tabulator, that had a greater influence. Besides the tabulator, two other critical devices were employed: a key punch, by which a human operator keyed in data, and a sorter, which sorted cards based on the presence or absence of a hole in a desired column. In the early decades of the twentieth century, other devices were added to a typical installation, but these were the main ones.</p>
<h2>From Tabulator to Computer, 1890-1945</h2>
<p>The tabulator kept a record of how many cards had a hole punched in each of its columns. The early tabulators recorded the numbers on a dial that resembled a clock face; later a more familiar counter was used. Although it is hard to imagine that such a basic function could be so important, it was not until the 1920s that other arithmetic functions were provided. What made the tabulator so important was the flexible way it could be used, based on the information punched into different columns, and the way its use could be combined with the other devices, especially the sorter, to perform what we would now call sophisticated data processing. Information, once it was punched onto a card, could be used and reused in many ways. That roomful of equipment was what the early electronic computers replicated; its &quot;program&quot; was carried out by human beings carrying decks of cards from one machine to another and changing the settings on the various machines as the cards were run through them.</p>
<p>Communications, within and outside that room, was also present, in an ad hoc fashion. Human beings carried data from one machine to another as decks of cards. The electric telegraph carried information to and from the installation. Among the first, outside the government, to adopt punched card accounting in the United States were railroads. And railroads were early adopters of the telegraph as well, because they were the first significant business whose managers had to coordinate operations over wide geographical areas. The railroad rights of way became a natural corridor for the erection of wires across the continent, to an extent that people assume the two technologies could not have existed without each other. That is an exaggeration but not far from the truth. Although times have changed, modern overland Internet traffic is carried on fiber-optic lines, which are often laid underground (not on poles) along railroad rights of way.</p>
<p>If the telegraph apparatus did not physically have a presence in the punched card installation, its information was incorporated into the data processed in that room. Railroad operators were proficient at using the Morse code and were proud of their ability to send and receive the dots and dashes accurately and quickly. Their counterparts in early commercial and military aviation did the same, using the &quot;wireless&quot; telegraph, as radio was called. What worked for railroads and aircraft was less satisfactory for other businesses, however. Among the many inventions credited to Thomas Edison was a device that printed stock market data sent by telegraph on a ''ticker tape,&quot; so named because of the sound it made. The physical ticker tape has been replaced by electronic displays, but the terse symbols for the stocks and the &quot;crawling&quot; data have been carried over into the electronic era.<sup>6</sup> Around 1914, Edward E. Kleinschmidt, a German immigrant to the United States, developed a series of machines that combined the keyboard and printing capabilities of a typewriter with the ability to transmit messages over wires.<sup>7</sup> In 1928 the company he founded changed its name to the Teletype Corporation, which AT&amp;T purchased two years later. AT&amp;T, the telephone monopoly, now became a supplier of equipment that transmitted text as well as voice (see figure 1.1).</p>
<figure>
<p><img src="/assets/bell_labs.jpg" alt="(a) H. L. Marvin operating a Bell Labs specialized calculator using a modified Teletype, 1940. (b) Control panel for a Bell Labs computer used for fire control, circa 1950."></p>
<figcaption>
Figure 1.1 Computing at Bell Laboratories designed by George Stibitz and using modified telephone switching equipment. (a) H. L. Marvin operating a Bell Labs specialized calculator using a modified Teletype, 1940. (b) Control panel for a Bell Labs computer used for fire control, circa 1950. (Source: Lucent/ Alcatel Bell Laboratories)
</figcaption>
</figure>
<p>The Teletype (the name referred to the machine as well as to the company that manufactured it) was primitive by today's standards: slow, noisy, and with few symbols other than the uppercase letters of the alphabet and the digits O through 9. But it found a large market, providing the communications component to the information processing ensemble described above. The machine took its place alongside other information handling equipment in offices, the government, and the military. It also entered our culture. Radio newscasters liked to have a Teletype chattering in the background as they read the news, implying that what they were reading was &quot;ripped from the wires.&quot; Jack Kerouac did not type the manuscript for his Beat novel, <em>On the Road</em>, on a continuous reel of Teletype paper, but that is the legend. In the 1970s manufacturers of small computers modified the Teletype to provide an inexpensive terminal for their equipment. Bill Gates and Paul Allen, the founders of Microsoft, marketed their first software products on rolls of teletype tape. Among those few extra symbols on a Teletype keyboard was the @ sign, which in 1972 was adopted as the marker dividing a person's e-mail address from the computer system the person was using. Thus, we owe the symbol of the Internet age to the Teletype (see figure 1.2).</p>
<h2>The Advent of Electronic Computing</h2>
<p>In the worlds of U.S. commerce and government, these systems reached a pinnacle of sophistication in the 1930s, ironically at a time of economic depression. Besides IBM and Remington Rand supplying punched card equipment, companies like National Cash Register (later NCR), Burroughs, Victor Adding Machine (later Victor Comptometer), and others supplied mechanical equipment: adding machines, cash registers, accounting machines, time clocks, &quot;computing&quot; scales (which priced items by weight), duplicating machines, and electric typewriters. Supplementing these were systems that used little mechanization but were crucial to controlling the flow of information: card filing systems, standardized forms in multiple copies with carbon paper, bound or loose-leaf ledgers, and more.<sup>8</sup> The digital computer upended this world, but it did not happen overnight. Many of the firms noted here entered the commercial computer industry, with IBM, Remington Rand, and Burroughs among the top U.S. computer manufacturers through the 1960s.<sup>9</sup></p>
<figure>
<p><img src="/assets/teletype.jpg" alt="The Teletype ASR-33. The Teletype had only uppercase letters, numbers, and a few special characters."></p>
<p><img src="/assets/punch_roll.jpg" alt="Teletypes were used as the main input-output device for the early personal computers, until inexpensive video terminals became available. This piece of Teletype tape contains an interpreter for the BASIC programming language, Microsoft's first product"></p>
<figcaption>
Figure 1.2 (left) The Teletype ASR-33. The Teletype had only uppercase letters, numbers, and a few special characters. In 1972 Ray Tomlinson, an engineer at Bolt Beranek and Newman in Cambridge, Massachusetts, chose the @ sign (shift-p) to separate the recipient of an e-mail message from the host machine to which that message was addressed; it has since become the symbol of the Internet age. (Source: Digital Equipment Corporation, now Hewlett-Packard) (above) Teletypes were used as the main input-output device for the early personal computers, until inexpensive video terminals became available. This piece of Teletype tape contains an interpreter for the BASIC programming language, Microsoft's first product. (Credit: Smithsonian Institution)
</figcaption>
</figure>
<p>As is so often the case in the history of technology, at the precise moment when this system was functioning at its peak of efficiency, digital computing emerged to replace it. The most intense period of innovation was during World War II, but as early as the mid-1930s, the first indications of a shift were apparent. In hindsight, the reasons were clear. The systems in place by the 1930s were out of balance. The versatility of the punched card, which stored data that could be used and reused in a variety of ways, required that human beings first of all make a plan for the work that was to be done and then carry out that plan by operating the machines at a detailed level. Human beings had to serve as the interface with the adding machines, accounting machines, and other equipment, and with the nonmechanized patterns of paper flow that corporations and government agencies had established. For example, an eighty-column card, in spite of its great flexibility, was ill suited to store or print a person's mailing address. Thus, a company that periodically sent out bills required another machine, such as the American Addressograph: a metal plate on which the person's name and address were embossed, from which mailing labels were printed. A human being had to coordinate the operation of these two technologies.<sup>10</sup></p>
<p>For many problems, especially those in science or engineering, a person operating a simple Comptometer or calculator could perform arithmetic quite rapidly, but she (and such persons typically were women) would be asked to carry out one sequence if interim results were positive, a different one if negative. The plan for her work would be specified in detail in advance and given to her on paper. Punched card equipment also had stops built into their operation, signaling to the operator to remove a deck of cards and proceed in a different direction depending on the state of the machine. The human beings who worked in some of these places-for example, astronomical observatories where data from telescope observations were reduced-had the job title &quot;computer&quot;: a definition that was listed as late as the 1970 edition of <em>Webster's New World Dictionary</em>. From the human computers, who alone had the ability to direct a sequence of operations as they worked, the term <em>computer</em> came to describe a machine.</p>
<p>A second reason that the systems of the 1930s fell short emerged during World War II: a need for high speed. The systems of the 1930s used electricity to route signals and transfer information from one part of a device to another and to communicate over long distances. Communication over the telegraph proceeded at high speed, but calculations were done at mechanical speeds, limited by Newton's laws that relate speed to the amount of energy required to move a piece of metal. As the complexity of problems increased, the need for high-speed operation came to the fore, especially in wartime applications like breaking an enemy code or computing the trajectory of a shell. High speeds could be achieved only by modifying another early twentieth-century invention, the vacuum tube, which had been developed for radio and telephone applications. Those modifications would not be easy, and substituting tubes for mechanical parts introduced a host of new problems, but with electronics, the calculations would not be bound not by Newton's laws, thus allowing calculating as well as computing to approach the speed of light.</p>
<p>These limiting factors, of automatic control and of electronic speeds, were &quot;reverse salients,&quot; in Thomas Hughes's term: impediments that prevented the smooth advance of information handling on a broad front (the term comes from World War I military strategy).<sup>11</sup> Solutions emerged simultaneously in several places beginning around 1936. The work continued during World War II at a faster pace, although under a curtain of secrecy, which in some respects mitigated the advantages of having funds and human resources made available to the computer's inventors.</p>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="Early Television"
class="paper-story"
data-article-title="Early Television"
>

<h1 class="article-title" id="h_Early Television">Early Television</h1>

<div class="top-meta">Vincent Mosco, 2021. for week 5.</div>

<p>Chambers, D. (2016). Chapter 2 Early Television. Changing media, homes and households: Cultures, technologies and meanings. London; New York: Routledge.</p>
<hr>
<h1>EARLY TELEVISION</h1>
<h2>Introduction</h2>
<p>From the beginning of broadcasting’s history, media have been a platform for public concerns and debates about the meanings and values associated with home, domesticity and family life. Powerful discourses about home, family and domestic culture accompanied the launch of broadcasting in the US and Europe during the early twenty-first century. Public and popular debates surrounding the emergence of broadcasting for home use were underscored by severe wartime disruption. Television’s (TV) development from the 1930s was interrupted across Europe by the Second World War and resumed thereafter, to become a routine part of domestic life by the 1950s. Early ideas about TV broadcasting were, then, marked by severe social and physical upheavals. This period of social turbulence brought into sharp focus changing meanings and values associated with family life, private and public spheres of society, the roles of women, and the nature of community and nation. Post-war initiatives to recover a sense of national and domestic stability shaped social responses to radio and TV, provoking public concerns about home, family and nation.</p>
<p>These social concerns about the effects of media on families and domestic life were articulated through and corresponded with utopian and dystopian media imaginaries about TV as a technology and cultural form. Traditional ideals of home and family projected an intrinsically white, middle-class nuclear unit structured by hierarchal gendered and generational relations. Home and households were conceived as domestic spaces and cultures through a web of economic and popular cultural discursive processes involved in the imagining and promotion of media technologies for the home. Utopian media imaginaries envisaged TV as a medium capable of fostering traditional, domestic ideals of family togetherness while dystopian visions of the technology stressed the medium’s power to fragment family relations and breach the boundaries between public and private spheres of life. As the following chapters indicate, these contradictory imaginaries have, to this day, remained central to debates about the roles and meanings of media technologies in the home.</p>
<p>This chapter explores how these public concerns and wider popular discourses about ‘home’ and ‘family’ values influenced the TV’s arrival into and colonisation of the home. Media technologies go through a process of enculturation or domestic ‘appropriation’ after entering the home, comprising micro-social processes which are focused on in Chapter 3. The cultural acceptance of early TV depended initially on its desirability to ensure its household adoption. Attempts to generate widespread consumer demand for this new, expensive and unfamiliar technology immediately after the war at a time of austerity posed a challenge for broadcasters, manufacturers and the government. Ensuring that families would welcome this bizarre object into the intimate surroundings of the home depended not only on the existing domestic circumstances and lifestyles of families and households. TV’s acceptance also depended on the material design, on commercial marketing and state promotion, and on wider popular meanings attributed to broadcasting before the technology’s entrance into the home.</p>
<p>With a focus on TV, this chapter charts the key ways in which media technology was popularised for home use between the late 1930s and 1970s. It asks how TV became a taken-for-granted homogenising force. The successful entrance of early radio and TV into the home relied on the public fantasies and aspirations projected on to these media technologies to encourage people to buy them as ‘domestic’ artefacts. The concept of ‘media imaginary’ addressed in Chapter 1 is employed in this chapter to cast light on the emergence and negotiations of various social ideals and to explain the processes through which the acceptance of media technology in the home depended. During its inception, TV technology was popularised in the public imagination to ensure its social acceptance, eventually leading to widespread adoption in the home. Powerful public and popular representations of both broadcasting and domestic media appliances were involved in the establishment of the medium. These media imaginaries were centred on the family and domestic life.</p>
<p>As well as media institutions such as the UK’s BBC and commercial broadcasting channels in the US, manufacturers of media technologies, advertisers and the government all had vested interests in the success of TV as a feature of home life. The chapter examines the complex roles played by design, marketing, advertising and popular media discourses at the stages before and during consumption in shaping images, meanings and values associated with radio and TV technology as well as programming. Media imaginaries that underpinned ideas about the home, families, public and private spheres are identified to indicate how they generated the desire for TV. This chapter is informed by and structured around an original study of the material form of the TV receiver between the 1930s and 1960s to show how the cultural process of designing and styling the TV set ensured its appeal to householders. The chapter indicates that TV sets were designed, promoted and publicised to become a part of domestic life yet also rapidly came to embody ideas of technological progress and imaginative mobility.</p>
<h2>The social need for television</h2>
<p>Early broadcasting became a key player in the history of social struggles about the meanings and changing organisation of public and private spheres of society. Critiquing earlier ideas of technology-driven social change, Raymond Williams emphasises that broadcasting technology was not just a symptom that determined wider social change. He argued that technologies are developed and used in direct response to perceived social needs and problems. Radio, and then TV, were media technologies designed to address a growing need for homes and households to be connected to the outside world. Williams (1974) developed the concept of ‘mobile privatisation’ to explain the rise of a social need for TV as a technology and cultural form. The social need for broadcasting emerged through two apparently contradictory yet interrelated trends in modern social life: ‘geographic mobility’, achieved through technologies of communication and transportation; and ‘privatisation’, realised through housing construction, domestic architecture and community planning.</p>
<p>By the 1920s and 1930s, the rise of smaller, nuclear families in western societies coincided with spatially and socially mobile lifestyles. A desire and need for information from beyond the home was generated by the fragmentation of traditional, tight-knit neighbourhoods into smaller, separate households, and the movement of people to housing estates and suburbs comprised of looser social ties. As Williams explains, broadcasting resolved this problem by bringing information from the outside world to this new kind of private home. The social motives for broadcasting in western societies such as the UK and USA evolved, then, as part of attempts to solve an underlying social problem of connectivity prompted by the mobility and privatisation of households. Not only did broadcasting address the practical problem of connecting isolated homesteads to a central communication source. It also solved an ideological problem of connecting the private sphere of home, domesticity and family with the public sphere of politics, the economy and news about national events.</p>
<p>Williams’ concept of ‘mobile privatisation’ also invokes the idea of media as a form of ‘travel’ from the home. Referring to early TV in the US, Lynn Spigel explains: ‘It gives people a sense of travelling to distant places and having access to information and entertainment in the public sphere, even as they receive this in the confines of their own domestic interiors’ (2001: 391). In contrast to the earlier publicly situated mediums of cinema and theatre, radio and TV allowed family households to travel the world from the privacy of their living rooms by linking the outside world to the domestic context of the home. By broadcasting a flow of entertainment and education, the entrance of radio and TV in the home radically changed families’ experiences of domesticity (Spigel 1992; 2001). This sense of travel has been ingrained not only in popular discourses about broadcasting and in programming, but also in the very shape of media equipment for home use.</p>
<p>After the Second World War, opponents of TV regularly drew on gendered discourses in their criticism of the medium. As a ‘window on the world’ beyond the home, TV was thought likely to breach time-honoured boundaries between the domestic and public spheres by offering women a taste and yearning for public life. It was feared that housewives might neglect their domestic duties by becoming distracted or ‘passive viewers’, or even restless seekers of adventure beyond the home (Andrews 2012; Spigel 1992; 2001). Likewise, it was feared that children might generate unruly behaviour in the home as distracted viewers. These cultural tensions coincided with social unease about changes in the relationship between the home and public spheres of life. In the early twentieth century, notions of ‘domesticity’ were underpinned by the ideological distinction between a feminine private sphere and masculine public sphere. Known as the ‘separation of spheres’, this gendered division of social spheres was characterised by the association of men with the public sphere and women with the private sphere. Men were traditionally engaged in paid work, politics and masculine leisure pursuits beyond the home while women were expected to be occupied in the home via housework, childcare, and feminine hobbies and pastimes (Vickery 1993).</p>
<p>Family togetherness and the changing nature of mediated household interaction formed key concerns since the very inception of broadcasting. Women’s new civic status following universal suffrage challenged the traditional values anchored within separate spheres. However, the ensuing pressure placed on patriarchal principles was eased by boosting the Victorian idealisations of women: by locating women in the private sphere and referring to them as ‘wives’, ‘mothers’ and ‘housewives’ (Bailey 2009: 53). The ideological boundaries between public and private spheres were ruptured during the Second World War by the recruitment of women into full-time paid work. An explosion of popular and public discourses surrounded the role of the housewife in the immediate post-war period through broadcast programmes on both TV and radio, within a patriarchal drive to coax women back into the home.</p>
<p>TV was configured by reproducing powerful, traditional ideals of family life based on gendered and generational hierarchies. To combat public anxieties that TV might destabilise gender and generational relations, the emergent medium was promoted as a ‘new hearth’ that would bind the family together. Spigel (1992) emphasises the role of cultural fantasy that steered TV’s integration into everyday family life. Captivating advertisements for TV and images in lifestyle magazines promoted family togetherness, depicting the ‘family circle’ gathered round the TV set, to convey the idea that the medium could reunite traditional families after the upheaval of war. The figure of the housewife and her domestic work in the home was also heavily endorsed in these popular discourses. Significantly, the post-war familial ideal was an image of an exclusively white, middle-class and nuclear model, evoking a traditional middle-class lifestyle that, for women, centred on the home. The design and marketing of the TV set as a domestic item was an important discursive site that presented a particular vision of the media home.</p>
<h2>Designing media for the home</h2>
<p>Against a backdrop of suspicion about TV’s potentially disruptive effects on family life, the technology had to be carefully designed to fit into particular standards of home décor. Even though the medium was acclaimed as a ‘window on the world’ that could generate family togetherness, during the initial years of TV broadcasting TV receivers were regarded as inherently unattractive. While the ‘window on the world’ function was welcomed by many, the intrusion of the ‘one-eyed monster’ in the living room was not. How, then, did this bulky piece of equipment become a routine part of everyday life in the home? Ambivalent public and private responses to TV technology form part of a longer history. Although industrial capitalism was driven by an ability to invent and sell new products, western cultures of consumption showed a resistance to the ‘newness’ of technologies that stretched back to the eighteenth and nineteenth century (Forty 1986: 11). Until the 1920s, the living room was designated an intimate space for formal leisure and entertainment. Machinery such as sewing machines and electric lamps were decoratively styled to embody meanings associated with that sphere. New forms of electrical communications entering the home, such as telephone and radio, were viewed with a mixture of doubt and approval, prompting a questioning and re-evaluation of the private nature of that space (Spigel 1992; Marvin 1988; Susman 1984; Hirsch 1992; Morley 2007). This styling requirement was even more pertinent in the case of TV’s entrance into the intimate space of the living room.</p>
<p>The reception of radio in the home provides a backdrop to the arrival of TV. In the 1920s, radio was initially perceived as a novel medium for technically proficient men who approached the ‘crystal set’ as a ‘gadget’ (Moores 1993). Comprising a rudimentary assortment of resistors, wires and valves, the first wireless sets to enter the home were viewed, particularly by women, as alien objects that looked incongruous in a domestic setting. And, as ‘listening’ required the use of individual headsets, early radio divided rather than united the family in the shared space of the living room. During this early phase, radio generally appealed to men, who viewed the equipment in terms of its technological qualities rather than the media content. As a ‘masculine’ technology involving technical skill to operate it, the wireless was often banned from the living room and consigned to the workshop or shed (see Boddy 2004; Moores 1993). Several technologies such as home cinema (Klinger 2006) and computers (Lally 2002; Ward 2006) have subsequently proceeded through this ‘gadgeteer’ phase before being domesticated. For instance, when the first personal computers (PCs) were bought, usually by men, they were mainly used for programming, motivated by the question: ‘What can this thing do?’ In the case of radio and then TV, the equipment had to be carefully designed for domestic use as a significant preceding stage of domestic adoption.</p>
<p>Keen to sell radios to families for use in the living room, by the late 1920s and early 1930s, manufacturers and broadcasters devised sophisticated solutions to market the product. As new objects, radio and then TV had to be adapted in terms of their physical, visual and audible presence. In the case of early radio, design formed a vital process in its mass acceptance in the home by transforming it from a ‘gadget’ for male enthusiasts to an entertainment unit for the family (Silverstone and Haddon 1996: 47). The cabinet in which the radio was housed took on visual features relating to other domestic objects so that they could look ‘at home’ in the living room by resembling a piece of furniture: a wooden or Bakelite cabinet to replicate antique or contemporary furniture (Forty 1986). By the late 1930s, radio was no longer viewed as an intrusive masculine gadget but as a medium and object that enhanced the attractiveness of a feminised living room. Radio shifted its status from that of an unwelcome visitor to become part of the family through design and via programming aimed at ‘family audiences’ (Moore 1993; Hollows 2008).</p>
<p>During the early years of radio up to the 1950s, the female listener and her perceived interests influenced the nature of broadcasting by dictating the tone and subject matter of the medium (Andrews 2012). This focus on the housewife underpinned the following media preoccupation with domesticity. For example, radio programmes during the 1920s and 1930s were aimed at women as home-makers by promoting and reflecting particular ideas about the female audience and about the domestic setting. Daily domestic advice programmes depicted women as dependent on radio for companionship and domestic guidance. In the UK, programmes such as Common Sense in Household Work (1929), Household Talks (1929), Family Budgets (1931), How I Keep House (1934), Farmhouse Cookery (1935) and Housewives’ Choice (1946) categorised feminine interests with of those of home and family (Andrews 2012).</p>
<p>In the case of TV, the receiver did not pass through a gadgeteer phase. It was conceived, right from the start, as a commodity for mass consumption and domestic use. Broadcasting and domesticity reflected the rising consumerism of the 1950s in the US and UK, despite the continuing poverty and economic hardship experienced in post-war Britain. Fitting neatly into the economic framework of capitalism, it was designed as a ‘mass-produced’ commodity with standardised components for domestic consumption. Although Britain took the lead in TV manufacture in the 1930s, the sale of TV receivers to individual homes was inevitably slow. In 1936, less than 400 sets were available to receive the new service transmitted for only 30 miles from Alexandra Palace. A TV set cost £60, half the price of a small car (Bussey 1980). Limited transmission and the high price held back sales. By the start of the Second World War in 1939, the number of sets in use in Britain grew to around 23,000 (Scrine 1976). This was significantly higher than in the US and Germany, the two main rival countries involved in establishing TV broadcasting at the same time. But the manufacture of TV sets was halted by the British Government during the war. Wireless and TV factories were directed to produce communication machines for the war effort. This allowed the US to take a lead in TV cabinet design and manufacture.</p>
<p>Manufacturers recognised that the acceptance of this novel but unattractive technology in the home meant hiding the bulky valves and cathode ray tube in a cabinet. TV engineers, manufacturers and industrial designers, also known as product stylists in the US, led the process of its pre-domestication. The taming of this troubling yet desirable artefact was achieved by camouflaging the machine as furniture. Earlier radio cabinet makers and industrial designers performed a vital role in the media imagining of the TV’s future place in the home by concealing the monster eye in a crafted wooden cabinet. Some sets even came with closing doors to conceal the gaping eye of the screen when not in use. This visual embellishment of the set as furniture, suited to the standards of décor of the living room, facilitated and stabilised the concept of ‘family’ viewing (Spigel 1992). Starting life as a piece of furniture for home use, the TV set gradually replaced the radio as the living room’s central media apparatus in the post-war period. It even replaced the role of the hearth around which the family gathered. One particular design, the TV console, simulated a conventional hearth with a TV set placed inside a traditional fireplace frame (Chambers 2011).</p>
<p>At the time of writing, today’s homes boast not only wall-mounted TV sets but even interactive wall-sized ‘wallpaper screens’ for what is advertised as a ‘truly immersive experience’. But in the post-war period, manufacturers’ industrial design departments initially served to express the idea of a tamed, domesticated machine to offer consumers a sense of control over what was a novel and alien technological experience. The use of wood to style the console was crucial in signifying aspirational domesticity. In the UK, contrasting surfaces of wood in natural colours and handicraft skills reminiscent of the British Arts and Craft Revival were used. Interior décor, furniture and architecture of early twentieth-century Britain was gradually influenced by the European Modern Movement. Famous and experienced designers were recruited by British manufactures to dress these machines in plastic moulding as well as wood and Bakelite, including Wells Coates for E.K. Cole Ltd., Victor Taylor for Ace Radio Ltd. and Richard D. Russell for Murphy Radio. When the project of modernism finally took hold in Britain in the interwar years, clean lines became synonymous with clean lives (Chambers 2011).</p>
<p>For example, as a pioneer of the Modern Movement in 1930s British architecture and design, Wells Coates worked with the radio manufacturing company, E.K. Cole Ltd. Coates addressed the popular demands for conventional, decorative craft styles in furniture by blending them with the more austere functionalism of the Modern movement through plastic moulding. In America, one of the most influential designers of TV sets was John Vassos who worked on the design of the first mass-produced TV set for RCA Corporation, debuted at the 1939 New York World Fair (Schwartz 2006). He designed RCA’s 12-inch TRK-12 receiver for the Fair and even a ‘phantom’ version housed in a transparent Lucite plastic case. Vassos’ design philosophy was unique in fusing the harsh Bauhaus functionalism and softer style of American streamlining with rich patinas and generous forms of classic case furniture in handcrafted, highly polished wood cabinets. These sets were aimed at the wealthy, inferred by advertisements depicting TV viewers dressed in evening suits and ball gowns. The luxury status of these TV sets was also signified by high prices from US$199.50 to $600 and also by sales in New York’s luxury department stores: Macy’s, Bloomingdale’s and Wanamaker’s (Schwartz 2006).</p>
<p>In the UK, exhibitions such as the 1936 Olympia and 1939 Radiolympia were major spectacles that dramatised and venerated the introduction of TV for home use. At the 1939 Radiolympia exhibition, every major radio manufacturer exhibited TV sets or combined radio and TV sets (On the Air<sup>1</sup>). However, the New York World Fair was staged on an altogether grander scale, reflecting Vassos’ flamboyant designs. While war was waging in Europe, exhibition space for the new medium in the US nearly doubled at the 1940 New York World’s Fair. The display featured Vassos’ ‘Television Suites’, showcasing new models in ten different American home settings including receivers housed in stylish bleached mahogany modular furniture. During this period, major American designers such as Donald Deskey and Russell Wright, as well as Vassos, styled multi-unit display cabinets for the 1940 New York Fair’s ‘America at Home’ pavilion, thereby confirming America’s international lead in TV set manufacture and sales.</p>
<h2>Family, nation and visions of progress</h2>
<p>After a five-year break in TV broadcasting during the Second World War (1939–1945), a TV service was resumed in the UK in 1946. At this stage, less than two-thirds of its adult population had ever laid eyes on a working TV set (Hopkins 1961). It was not until 1952 that the signal could be received by 81 per cent of UK homes. By now, the US posed a serious threat to British TV manufacturing, being five years ahead in domestic product development. American TVs were marketed as multi-console sets with radio, TV and phonographs combined in luxurious and expensive wood cabinets for around $500 and also as cheaper table receivers for less than half that price (Kosareff 2005). Despite being weakened by war, progress in the UK was rapid. More than 93 per cent transmission coverage was achieved by 1957 (Hopkins 1961). At a cultural level, the state rebuilding of Britain’s infrastructure entailed a new, positive vision of nation and family to be promoted through the medium of TV (Scannell 2000; Briggs 2000). TV was conceived as a medium to be consumed by families to be linked to the idea of ‘a nation of families’ (Morley 2002: 108).</p>
<p>For example, at national exhibitions of the early to mid twentieth century, the model home played a major role in promoting the family as the heart of the nation. Audiences were invited to sign up as members of this new nation as consumers of new products (Sparke 2004). In the 1950s, the institutions that promoted ideas about ‘good design’, the ‘ideal home’ and ‘good living’ in the US and UK, presented TV broadcasting and good design as moral vehicles of national improvement, framed within a growing commodity culture. In these ways, the physical presence and domestic design of the TV receiver became a national issue, proffering a moral good by revering the nuclear family home. In the UK, this national vision of good design and good living was fostered through an alliance between manufactures and government-sponsored organisations such as the Council of Industrial Design (COID). The COID’s role was to advance British manufacturing and foster national pride through good design during a critical period of national reconstruction. ‘Good design’ was conceived as a patriotic endeavour (Jones 2003). National broadcasting formed part of domestic media imaginaries, summoning ideas of domestic cultures as family cultures, thereby marginalising and discounting those who were not part of traditional families (Hollows 2008: 108). The establishment of broadcasting helped to domesticate the nation and embrace a nation of families (Morley 2002: 107).</p>
<p>The popular media were paramount in domesticating the TV set, in alliance with industrial design, by associating the medium with middle-class ideals of family leisure and domestic technology innovation. Extensive marketing efforts were made to confirm TV as vital to the family’s gaze. In magazines such as the Readers Digest advertisements promoted TV sets not only as cosy family-centred objects but also as symbols of luxury, leisure and sophistication. Advertisements of couples dressed in ball gowns and tuxedos were, incongruously, depicted in comfortable living rooms gathered round luxurious, quality wooden veneered sets (Chambers 2011). British and American advertisements managed to appeal to traditional family values at the same time as emphasising design features that signified TV as the pinnacle of progress and modernity. Advertisements also invoked the idea of immediate access to the public sphere from home (Morley 2007). For example, the UK’s 1949 Baird Townsman console TV receiver with 12-inch cathode ray tube was dressed in a cabinet of polished walnut, with controls arranged at the sides of the unit. An advertisement for the product comprised a large aerial photograph of London showing the curve of the River Thames with views of the Houses of Parliament, Whitehall and Westminster Abbey displayed next to the TV set’s specifications. The image signified direct communication between home and Parliament, the very heart of the public sphere. In small print, the advertisement claimed:</p>
<figure>
<blockquote>
<p>The Townsman is a console of exceptionally dignified appearance . . . Designed with all the craftsmanship and finish that goes to the making of a piece of quality furniture, the Townsman will make an imposing and dignified addition to any room as well as a superlative example of television technique.<sup>2</sup></p>
</blockquote>
<figcaption>
<p>(Chambers 2011)</p>
</figcaption>
</figure>
<p>Women’s lifestyle magazines of the 1950s conveyed TV as a technology of the hearth: as the focal point of family space (Spigel 1990). Affluent nuclear families were pictured gathered around the console, gazing into the glowing TV set reminiscent of the glowing hearth as an emblem of familial intimacy and harmony. Handbooks on interior décor of the late 1940s and 1950s advised readers how to position the appliance in the home and how to develop TV-viewing conventions. In the UK, the design of the TV set was highlighted in COID publications and in the displays of furnished rooms designed for the ‘Britain Can Make It’ exhibition (Jones 2003; Maguire and Woodham 1997). Thus, on both sides of the Atlantic, the home came to represent a stage on which good taste in design and wholesome family values were played out (Spigel 1992). In time, TV overtook the radio’s commanding position in the living room. It became the ‘must have’ appliance: the commodity that characterised the home. Ethnographies of families’ uses of TV confirm that families negotiated their use of this novel equipment in the home both by incorporating it into domestic life and making home adjustments to suit the new medium (see Morley 2002; Morse 1990; Silverstone 1994; Fachel Leal 1990). By the late 1950s, the act of owning a TV set signified ‘progress’ and ‘modernity’ (O’Sullivan 1991).</p>
<p>Metaphors of ‘home theatre’ and ‘window on the world’ were drawn on by industry, advertisers, policy-makers, artists, critics, social scientists and engineers as well as in popular literature such as women’s magazines to convey the idea of viewers being imaginatively transported across the world. The middle-class home had been imagined as a theatre since Victorian times and was subsequently articulated through modern housing design. US post-war housing design reflected earlier modernist homes that accentuated theatricality and visual features as key organising principles. TV was represented as a socially healthy version of theatre that could be enjoyed within the privacy of the home without the discomfort of mixing with the masses (Spigel 1992).</p>
<p>The theatre became an organising metaphor for the middle-class home, reflecting the performative dynamics of everyday life. Architects, plan-book writers, religious leaders, domestic engineers, women’s magazines and books on interior décor were variously describing the home as a ‘stage’ on which conventional social roles are played out by family members. To avoid the risk of entering potentially infected public spaces outside the home, family audiences could stage this home theatre in an ‘antiseptic electrical space’ (Spigel 1992). While advertisements showing glamorously dressed couples conveyed an imaginary night out in town, the idea of the home theatre and images of families gathered together round the TV ‘hearth’ evoked a reinstatement of leisurely family values. Advertisers managed to imply that TV could reconcile the paired yet contradictory aspirations for engagement in the public and the private world of traditional family life. TV presented imaginary travel to urban spaces at the same time as allowing families to stay together in the safety of the suburban home. However, later sociological studies uncovered the isolation that women often felt in their new suburban TV homes (Freidan 1963).</p>
<p>TV rapidly became the main leisure activity for children who, by the late 1950s, were watching an average of almost two hours of TV a day (Himmelweit et al. 1958). This generated public anxieties that TV was likely to replace cinema going and socialising with friends. Women’s magazines alerted parents about the dangers that TV might present for children in the form of passive addiction or unruly behaviour. In this respect, the idea of the home theatre was tied to both utopian fantasies and dystopian anxieties about the prospects of family life and of gender and generational relationships in the home.</p>
<h2>The domestication of television programming</h2>
<p>TV was not only rendered familiar and habitual through its styling to match the furniture of the home. It was also a receiver of programmes that reflected and reinforced the normality and inevitability of domestic family life and suburban living. Despite opportunities to discover the outside world from the privacy of the living room, TV programming was, like radio before it, preoccupied with everyday domestic life. This medium played a vital role in media imaginaries of domestic space (as well as of travel away from home, addressed below). In the US, TV network advertisements offered women advice on how to juggle TV viewing with housework. Daytime TV was built around the imagined domestic routines and appropriate pastimes of housewives (Spigel 1992). Programmes such as soap operas comprised a series of short segments so that women could watch TV in a distracted manner while going about their household chores. Ideas about women’s interests were promoted via variety and magazine TV programme formats centred on domestic life and providing advice to women about how to perform their housewife roles.</p>
<p>Daytime soap operas were initially introduced on US commercial TV to support and slot in between advertisements for soap. Together with situation comedies, these genres produced narratives involving family life that contributed to the domestication and normalising of TV within domestic routines (Spigel 1992). These programmes included series such as <em>I Love Lucy</em> (1951–1960, CBS), <em>Leave It to Beaver</em> (1957–1963, CBS/ABC), <em>The Adventures of Ozzie and Harriet</em> (1952–1966, ABC) and <em>Father Knows Best</em> (1954–1960, CBS). The scheduling of programmes around domestic daily routines in the home also promoted ideas of a ‘family audience’. Spigel’s reference to the theatricalisation of the home front suggests that, through both the promotion of family TV viewing and TV programmes, families themselves were conceived as a new and desirable spectacle. Hollywood stars were transported from the public movie screen to the sphere of the home through TV. This facilitated the negotiation of Hollywood’s involvement in TV and consolidated its assimilation into the routine, everyday life of the housewife (Mann 1992).</p>
<p>When TV broadcasting was resumed in 1946 after the Second World War in the UK, it consisted only of public service broadcasting via the BBC. Unlike the US, no commercial TV was allowed until 1955. Initially, the BBC offered a series of specialist afternoon magazine programmes for women, with titles focusing on home and family life including <em>Designed for Women</em> (1947), <em>For the Housewife</em> (1948), <em>Leisure and Pleasure</em> (1951), <em>About the Home</em> (1951) and <em>Women’s Viewpoint</em> (1951). These programmes were broadcast in an early-afternoon slot to attract female audiences. The content of these programmes played a major part in circumscribing women’s roles and responsibilities in the home. From the mid twentieth century, national exhibitions were overtaken by TV programmes that influenced the institutions that promoted ideas about ‘good design’, the ‘ideal home’ and ‘good living’. Model homes were now presented to audiences via TV programmes in their living rooms (Sparke 2004). Programmes such as <em>Designed for Women</em> and <em>Leisure and Pleasure</em> were typically located in cosy, feminised TV studio settings set up as comfortable, middle-class living rooms to present a traditional middle-class lifestyle centred on the home (Irwin 2015: 165). In 1953, the BBC appointed a dedicated head of TV programmes ‘for women’ (Irwin 2015; Andrews 2012). Exemplifying media imaginaries of early TV, the normalisation of the housewife role and the universalising of middle-class values as ideal lifestyles was a recurring theme throughout the early history of domestic media.</p>
<p>Women’s magazines corresponded with TV programmes to cultivate domestic and consumer identities. As part of the early process of mediatising the home, TV formed the backcloth for a flood of popular discourses about the home, set within an explicit consumerist framework. In the UK, <em>House and Garden</em> displayed pictures of opulent home interiors while <em>Woman</em> magazine depicted the lifestyles of celebrities including Princess Margaret and famous actors (Irwin 2015: 166). Contrasting with women’s lifestyle magazines of the period, certain TV programmes such as the BBC’s <em>Wednesday Magazine</em> (1958–1963) conceived a female audience as perceptive and discriminating with an interest in the public world of the arts. These programmes addressed their female audiences not only as housewives and consumers but also as citizens and voters (Leman 1987; Irwin 2015). Topics such as architecture were repositioned within a domestic framework to provide cultural signifiers of the ‘ideal’ house and home. For example, Irwin (2015) provides an analysis of a specific episode of the <em>Wednesday Magazine</em> programme on the design and building of the new modernist house, Edritt House, in Mill Hill, North London. The programme moved between the domestic/private and cultural/public divide but, significantly, kept returning the topic to domesticity. Irwin explains that:</p>
<figure>
> This is a transitional stage in the process of establishing a style of cultural television for a female audience. The house offers a look at a very aspirational and affluent lifestyle, especially so in a late 1950s Britain just emerging from a period of scarcity and austerity. 
<figcaption>
(Irwin 2015: 168) 
</figcaption>
</figure>
<p>A whole discourse was created through TV programming to frame domesticity, femininity and aspirational home living, as Irwin (2015) confirms. Today, programmes such as Grand Designs (Channel 4, 1999–) that feature unusual and often elaborate architectural projects and series about house-hunting, such as Location, Location, Location (Channel 4, 2000–), are described as ‘property porn’,3 providing a continuing focus on home to articulate consumerism and aspirational living in contemporary TV (also see Chapter 8).</p>
<p>David Morley (1992) emphasises the power of media texts to bring public life into domestic cultures and to actually shape those domestic cultures as national cultures. In the case of early TV, the experience of a ‘public’ realm was fostered in the context of private, domestic life by conveying a sense of belonging to a nation. For example, in the early 1950s the UK TV industry needed something more than product styling and persuasive magazine features to boost sales. It came in the form of the Coronation of Queen Elizabeth II in 1953, a major public event that won millions of households over to the new medium. Although there were only about two and a half million sets in use in the UK at the time, an estimated 20 million people watched at least part of the Coronation on TV on sets of friends, neighbours and in shop windows (Bussey 1980; Briggs 2000). Through scheduling and by broadcasting national events, the content of media are centrally involved in creating and communicating powerful ideas of the nation, of distant ‘homelands’ and of domestic space, thereby evoking both traditional and new imaginings of ‘home’ (Morley 1992; Hollows 2008; also see Chapter 7).</p>
<p>Benedict Anderson (1991) advanced the influential idea of the modern nation-state as an ‘imagined community’ to explain the need for a common understanding between the citizens in order to engage in a national consciousness. Despite not knowing their fellow citizens, members of a community form an idea of a communion with these strangers through the ritual of newspaper reading, listening to radio and watching TV to generate a sense of collective experience. Explaining that the development of the national newspaper laid the foundations for this imagined nation, Anderson states:</p>
<figure>
<blockquote>
<p>It is imagined because the members of even the smallest nation will never know most of their fellow-members, meet them, or even hear of them, yet in the minds of each lives the image of their communion.</p>
</blockquote>
<figcaption>
(Anderson 1991: 6) 
</figcaption>
</figure>
<p>In the same way, the establishment of a national system of early broadcasting nurtured a sense of collective experience with other anonymous listeners and viewers, evoked through the content of broadcasting and by the weaving of TV schedules into households’ daily routines. The programming of key items such as the news and soap operas at specific times of the day creates a sense of a common nation by collectively structuring the daily schedules of individual households across the country. However, this imagined community represents a particular version of family and nation: mainly white, middle class and heteronormative. Households and social groups that do not conform to these types of families and identities can become marginalised or excluded through these powerful media imaginaries (Hollows 2008). In terms of broadcasting schedules, the term ‘dayliness’ developed by Paddy Scannel (2000) describes how broadcasting contributes to the shaping of everyday routines. Radio and TV schedules slot into and shape daily routines in such a way as to confirm the ordinariness and inevitability of broadcasting and of those domestic routines. These schedules become so natural that audiences come to structure the temporal patterns of the day, week and year in a way that connect these domestic temporal rhythms with practices that traverse the nation (Scannel 2000: 19–21; Gauntlett and Hill 1999). As a feature of the early stages of the mediatisation of the home, this form of assimilation can be identified as a ‘normalisation of social practice’ (Jansson 2013; see Chapter 1).</p>
<h2>Domesticity, progress and portable TV</h2>
<p>TV viewing was gradually integrated into family routines and into the spatial geography of the home, with the TV set rapidly becoming a mundane, ‘tamed’ item (Barthes 1977). But by the end of the 1950s, a new set of metaphors emerged to describe home as a place for travel. During this period of the 1950s and 1960s when TV gradually became a taken-for-granted medium, the TV console began to embody the social tensions associated with two apparently conflicting ideas: domesticity and progress. Spigel (1992) explains that the framework of ‘theatricality’ was connected with and gradually fed into the idea of ‘mobility’. She refers to these new ideas about mediated travel away from home through the term ‘mobile home’ to suggest that watching TV encouraged audiences to cultivate a preoccupation with the potential of space travel and satellite technologies. The idea of TV as ‘travel’ was expressed through programmes about far away places and voyages of adventure and by its new material design as a portable set (Spigel 2001). This preoccupation corresponded with the introduction of cheaper, portable radios and second TV sets from the late 1950s and early 1960s. From an early stage, TV receiver design had signified the contradictions between a craft aesthetic and newly emerging styles associated with mass production, between styles of craftsmanship and the artistic principles of modernism. The arrival of portable TV promised something more exciting. Allowing more flexibility in styling, slimmer TV cabinets offered manufacturers a major opportunity to reconfigure the meanings of the TV set and increase sales through lower prices.</p>
<p>The TV set was liberated from its permanent place in the living room to convey an imaginative mobility. The TV set entered new imaginative territory by moving beyond the living room into kitchens, studies and bedrooms. This new item could now be positioned almost anywhere around the home, leading to the weakening of communal viewing habits. Yet, as Morley (2002: 92) reminds us, in terms of family household dynamics, communal family viewing was never an activity that occurred ‘naturally’. Family-oriented viewing had to be carefully negotiated as part of family life, with evening meals often planned to coincide with regular TV programmes (Gauntlett and Hill 1999). Communal family viewing in the living room was therefore short-lived. Yet this idea has lingered as a powerful fantasy to this day (Morley 2002).</p>
<p>In 1956, a new portable set launched in the UK was advertised in the Wireless and Electrical Trader magazine with a clumsy but intriguing caption: ‘ANNOUNCING CARRY-IT-AROUND TV’.<sup>4</sup> The 9-inch Ekco portable with FM radio sold for 66 guineas. It was placed in a moulded plastic box designed by E.K. Cole Ltd., operated by mains or 12-volt car battery, with built-in collapsible aerial (Chambers 2011). The handle on the top of the console resembled a suitcase handle. A mobile ‘personal TV’ was born, designed to be carried around like a piece of luggage. Recommendations for use were listed to help customers decide what to do with the gadget: ‘IN THE HOME; AS A SECOND SET; IN SICKROOMS OR HOSPITALS; IN THE OFFICE OR BOARDROOM; IN HOTELS OR GUESTHOUSES; ON PICNICS; IN CARAVANS; ON HOLIDAYS AND MOTOR TOURS’. Householders were enticed, through design and lowered prices, to purchase second and third sets for use around the home. Yet the impulse to push the technology outdoors and mobilise it was striking. Two years later, in 1958, a 17-inch Ferguson portable TV set was named ‘Flight 546’ to emphasise its mobility. The advert displayed a picture of a portable TV set with a passenger aeroplane on its screen. Costing 58 guineas, the portable boasted a gold-plated telescopic aerial, and an ‘ELEGANT CABINET, ONLY 14” DEEP OVERALL, COVERED WITH SIMULATED PIGSKIN, WEIGHT 31 ½ lbs ONLY’ (Chambers 2011).</p>
<p>Needless to say, portable TV sets were seldom moved around the house, let alone outside the home. Awkward and heavy, these machines either had to be plugged into the mains or weighed down with heavy batteries. And outdoor reception quality was very poor. Nevertheless, portable TV in the 1960s captured the public imagination by triggering new metaphors of home and travel. The naming of these new portable designs was pure fantasy. In the US, by now the vanguard of portable TV engineering design, Philco launched a transistorised and battery powered portable set called the ‘Safari’ model, evoking images of embarking on an African hunting expedition, accompanied by the portable TV. The naming of these models was as crucial as the styling, capturing the idea of mobility and exotic outdoor adventure. General Electric produced the ‘Adventurer’, Zenith created the ‘Jetliner’ and RCA the ‘Globe Trotter’ with their stress on imaginary travel away from the home. Later, more practical mini portables were advertised in the US, using metaphors of transport. The idea of mobility and adventure associated with TV symbolised positive notions of portable culture (Spigel 2001). Portables designed with sun shields were advertised positioned beside swimming pools and at picnic sites to evoke an indoor–outdoor aesthetic.</p>
<p>During this period, futuristic designs associated with portability were inspired by the dawning of space travel in the US. A mobile notion of domesticity was conveyed via 1960s images that even depicted the home as a rocket. Spigel (2001) argues that the portable TV set expressed a ‘privatised mobility’. The imagery of space-age domesticity signalled a break with the past, corresponding with ideas of the New Frontier promoted by President Kennedy’s emphasis on space travel as a supreme sign of national progress. The high-tech world of telecommunications transformed ideas about private and public space: the metaphor of home as ‘theatre’ was overtaken by the idea of the home launched ‘in orbit’ (Baudrillard 1985; Spigel 2001). Inverting Williams’ (1974) concept of mobile privatisation that described the reconnection of the privatised home with the public sphere, Spigel emphasises the aspirations of progressive family lifestyles and glamour of escape or travel away from the home conveyed in the popular media.</p>
<p>Shifting from feminine to masculine aspirations and identities, portable TVs implied a move away from ideas of home as a decorative feminine space for the pursuit of trivial pastimes in favour of a masculine, scientific space associated with elevated goals of national supremacy and citizenship (Spigel 2001: 390). The TV set now signified technological progress, mobility, modernity and adventure rather than cosy domesticity and family togetherness. The fantasies of portability in both design and in advertisements of the 1960s conveyed, then, an emergent set of gender and generational relations. A masculinisation of the technology was effected via associations with mobility and scientific progress.</p>
<p>In addition to masculine images of mobility and progress, the portable TV signified social class distinctions. In the UK, portable TVs often replaced large-screened sets in middle-class homes. Public debates about the potentially harmful effects of TV viewing in the 1960s, such as Mary Whitehouse’s ‘Clean-up Campaign’,5 coincided with widening accessibility to TV to influence class attitudes to the technology. Kudos was now attached to ‘low’ viewing. The middle classes expressed themselves as ‘selective viewers’. A gradual switch occurred in terms of the relationship between social status, size of set and its prominence as an object in the living room. By the early 1970s, working-class homes were seen to possess the largest sets with the middle classes hiding portables discreetly among bookshelves.</p>
<p>Class distinctions in taste were also found by Ondina Fachel Leal (1995) in her study of the meaning of TV in Brazil. Like the British experience, the TV set in upper-class Brazilian homes was positioned more discretely, away from public view. Among the urban working classes, the TV set was regarded as a treasured possession with the set’s status reflected by its prominent positioning in the lounge to show off the owners’ successful ‘modern life’. The TV set in working-class homes was surrounded by other meaningful ornaments to encourage the ‘watching’ of TV not only by members of the household but also by passers-by on the street, whether the set was switched on or off (Fachel Leal 1995). A contrasting trend was observable in the US, where large-sized sets were universally esteemed in living room settings. And, among large-screened sets in the UK, the concealment of the screen in a wooden cabinet, often with closing doors, persisted as a design theme right up to the 1980s alongside futuristic portable designs. Advertisements mirrored these contradictory images of craft tradition and scientific progress by mixing futuristic ideals of progress with highly sentimental images of home and nature (Kosareff 2005). This brings to mind Bruno Latour’s observation, that ‘modernity’ represents the construction of systems that, incongruently, fuse together technology and nature (Latour 1993).</p>
<h2>From communal to individual viewing</h2>
<p>Portable designs not only reflected ideas about travel and adventure. They also corresponded with new TV-viewing habits during a period when, on both sides of the Atlantic, the home’s ‘aura of sharing and communality’ was wearing thin (Cieraad 2006). As mentioned earlier, the position of receivers in the home branched out from the lounge to kitchens and bedrooms along with the growth in viewing, improvements in programmes, reliability of sets and, importantly, the introduction of domestic central heating. By the early 1960s, open-plan kitchens and living rooms were featuring in modern home architecture and design. The opening up of communal living space allowed housewives to supervise children, chat with husbands and watch TV while preparing meals (Cieraad 2006; Morley 2007). Yet open-plan architecture and family TV viewing began to clash with the individual projects of household members. It sparked domestic tensions about programme preferences and multiple uses of these communal spaces.</p>
<p>The arrival of a range of electronic products in the home from the 1960s onwards fostered home-based but separate, individualised tasks and undermined the ideals of shared use of space (Hirsch 1992; Silverstone 1991). Imaginative media mobilities that embraced the social tensions associated with domesticity and progress corresponded with a shift in emphasis from familialism to individualisation (Giddens 1992; Beck and Beck-Gernsheim 1995). As a feature of individualisation, family members’ understanding of their social position and their interactions with other people is guided less by traditional duties and more by active personal choice and negotiation between individuals. The portable set was gradually designed to signify sole use through the production of more individualised devices with the addition of remote controls, headphones and muting switches. The device was marketed as a remedy for family fights over programme choice (Cieraad 2006). Advances in cable, satellite and video confirmed the demise of family-centred viewing and rise of more private, individualised viewing (Hirsch 1992). By the 1980s, children were regularly watching TV in their bedrooms and parents watched in the living room, with 80 per cent of British household TV viewing becoming dispersed (Gauntlet and Hill 1999). Portability and mobility came to symbolise the contradictions between passive, individualised ‘bedroom viewing’ and active, mobile viewing (see Chapter 4). Following the rise of portable TV, more personalised, communication technologies came to represent the tensions and pressures involved in managing the familiar binaries of personal/private and public/outdoors. This occurred during a period when traditional family values were being re-evaluated in relation to aspirations towards a democratisation of intimacy (Chambers 2012).</p>
<p>Initial representations of TV in advertisements and magazines as a ‘harmonising’ force were gradually overtaken by alternative visions of individuals being entertained separately, as isolated audiences. Families were depicted at home together yet apart: watching their chosen programmes on separate TV sets around the home. Spigel explains that these contradictory discourses about domestic media reflected the ideological tensions of the era. Critics and commentators maintained that TV might pose a danger to family life and did not belong in the family home (Spigel 1992). To promote family togetherness, TV was often conveyed as an ideal form of family leisure and useful medium to draw children into the home and spend more time in the company of the family. Yet, at the same time, children were depicted as potential prey to the power of TV. Such contradictory discourses and anxieties have also been triggered in connection with later technologies such as video games, mobile phones and computer tablets, as indicated in the following chapters.</p>
<h2>Conclusion</h2>
<p>This chapter indicates that early domestic technology broadcasting was propelled by a combination of commercial and idealistic impulses. The chapter has also identified some of the principle ways in which radio and TV are distinguished from other kinds of objects by chronicling the history of the design and styling of the technology for home use in relation to wider popular discourses that comprised media imaginaries of the time. With a focus on TV, the chapter indicates that early twentieth-century domestic media technologies comprised a vital stage of interpretative flexibility during which a range of media imaginaries were generated, deliberated and projected about their uses and adaptation to the home. The TV set’s placement in the home in the 1950s comprised the beginning of the mediatisation of the home as an evolving process (Peil and Röser 2014: 237). TV manufacturers, designers, advertisers and popular media played a vital role alongside programming in this cultural process by presenting early versions of the apparatus as a device for embellishing the décor of the family home, elevating domestic femininity and fostering family togetherness. Characterised by ambivalent social attitudes towards newer media technologies, negative social responses posed challenges for the government, manufactures, designers and advertisers of TV receivers whose aim was to persuade households to embrace the equipment as both a domestic commodity and a moral worth.</p>
<p>The chapter has identified the key ways in which early television was distinguished from other kinds of objects by examining the intersecting roles of industrial design, marketing and programming in shaping the social meanings of TV sets during its early adoption. The expression of post-war national and familial values of good design and good living associated with the advancement of television technology in the UK was signified through a combination of TV content and console design. The medium was venerated via the aesthetic and material symbolism of the TV set, from craft-styled wooden consoles to 1960s’ portable designs and also displays of these products at national exhibitions to promote ‘good design’. Positioned within a domestic framework, British 1950s programmes on architecture and home design endorsed the object’s status by providing cultural signifiers of the ‘ideal’ home and by conflating ideas about ‘audience’, ‘consumer’ and ‘nation’. Portable TV designs invoked a sense of travel and personalised use, undermining notions of family togetherness associated with earlier notions of TV as the family ‘hearth’. Through a focus on the relationship between design, programming and wider popular discourses, the chapter builds on the seminal work of scholars such as Morley, Spigel, Scannel, Moores and Hollows who have advanced understandings of the role of domestic media in communicating powerful ideas of nation, family and ‘home’.</p>
<p>Social concerns about mobile forms of domestic leisure embodied in portable TV are indicative of more recent changes in work and leisure (Spigel 2001). The ideals of mobility, freedom and progress remain central themes in contemporary imaginaries of new digital technologies and domesticity, reflecting anxieties about individualisation and changing family life. Today, these concerns are conveyed through ideas about the movement of information between homes and work, exemplified by the introduction of the computer and then the rise of the digitally connected contemporary home explored in later chapters.</p>
<h2>Notes</h2>
<ol>
<li>
<p><em>On the Air</em>, the online radio and TV history centre, available at: http://www.vintageradio.co.uk/htm/tvhistory.htm, accessed 5 December 2015.</p>
</li>
<li>
<p>Available at: www.thevalvepage.com/tv/baird/townsman/brochure.htm, accessed 25 May 2010.</p>
</li>
<li>
<p>For an example of debates in the press about property porn, see London, B., ‘Property Porn: The UK’s Favourite New Guilty Pleasure’, <em>The Daily Mail</em>, 10 September 2012, available at: http://www.dailymail.co.uk/femail/article-2200949/Property-porn-The-UKs-favourite-new-guilty-pleasure.html, accessed 25 May 2010.</p>
</li>
<li>
<p>Wireless and Electrical Trader 1956, available at http://www.rewindmuseum.com/vintagetv.htm, accessed 15 September 2010.</p>
</li>
<li>
<p>See Thompson (2012) for a study of Mary Whitehouse’s campaigning activities.</p>
</li>
</ol>
<h2>References</h2>
<div class="notes-and-refs">
<ul>
<li>Anderson, B. (1991) <em>Imagined Communities: Reflections on the Origin and Spread of Nationalism</em>, London: Verso.</li>
<li>Andrews, M. (2012) <em>Domesticating the Airwaves: Broadcasting, Domesticity and Femininity</em>, London: Continuum.</li>
<li>Bailey, M. (ed.) (2009) <em>Narrating Media History</em>, London: Routledge.</li>
<li>Barthes, R. (1977) <em>Image-Music-Text</em>, London: Fontana.</li>
<li>Baudrillard, J. (1985) ‘The Ecstasy of Communication’, in Hal Foster (ed.) <em>Postmodern Culture</em>, London: Pluto Press, pp. 126–134.</li>
<li>Beck, U. and Beck-Gernsheim, E. (1995) <em>The Normal Chaos of Love</em>, Cambridge: Polity Press.</li>
<li>Boddy, W. (2004) <em>New Media and Popular Imagination: Launching Radio, Television and Digital Media in the United States</em>, Oxford: Oxford University Press.</li>
<li>Briggs, A. (1979 [2000]) <em>The History of Broadcasting in the United Kingdom, Vol. 4: Sound and Vision</em>, Oxford: Oxford University Press.</li>
<li>Bussey, G. (1980) ‘Vintage Television Receivers’, in <em>The Great Optical Illusion</em>, Science Museum, London (A Philips Industries publication in Conjunction with Thorn Consumer Electronics for the Special Exhibition on Television, March to September).</li>
<li>Chambers, D. (2011) ‘The Material Form of the TV Set: A Cultural History’, <em>Media History</em> 17 (4), pp. 359–375.</li>
<li>Chambers, D. (2012) <em>A Sociology of Family Life: Change and Diversity in Intimate Relations</em>, Cambridge: Polity Press.</li>
<li>Cieraad, I. (2006) ‘Introduction: Anthropology at Home’, in Irene Cieraad (ed.) <em>At Home: An Anthropology of Domestic Space</em>, Syracuse, NY: Syracuse University Press, pp. 1–12.</li>
<li>Fachel Leal, O. (1990) ‘Popular Taste and Erudite Repertoire: The Place and Space of Television in Brazil’, <em>Cultural Studies</em> 4 (1), pp. 19–29.</li>
<li>Friedan, B. (1992 [1963]) <em>The Feminine Mystique</em>, Harmondsworth: Penguin.</li>
<li>Forty, A. (1986) <em>Objects of Desire: Design and Society Since 1750</em>, London: Thames and Hudson.</li>
<li>Gauntlett, D. and Hill, A. (1999) <em>TV Living: Television Culture and Everyday Life</em>, London: Routledge.</li>
<li>Giddens, A. (1992) <em>The Transformation of Intimacy: Sexuality, Love and Eroticism in Modern Societies</em>, Oxford: Polity Press.</li>
<li>Himmelweit, H.T., Oppenheim, A.N. and Vince, P. (1958) <em>Television and the Child: An Empirical Study of the Effect of Television on the Young</em>, London: Published for the Nuffield Foundation by Oxford University Press.</li>
<li>Hirsch, E. (1992) ‘New Technologies and Domestic Consumption’, in Roger Silverstone and Eric Hirsch (eds) <em>Consuming Media Technologies: Media and Information in Domestic Spaces</em>, London: Routledge, pp. 208–226.</li>
<li>Hollows, J. (2008) <em>Domestic Cultures</em>, Maidenhead: Open University Press.</li>
<li>Hopkins, H. (1961) <em>The New Look: A Social History of the Forties and Fifties</em>, London: Secker and Warburg.</li>
<li>Irwin, M. (2015) ‘BBC’s Wednesday Magazine and Arts Televison for Women’, <em>Media History</em> 21 (2), pp. 162–177.</li>
<li>Jansson, A. (2013) ‘Mediatisation and Social Space: Reconstructing Mediatisation for the Transmedia Age’, <em>Communication Theory</em> 23 (3), pp. 279–296.</li>
<li>Jones, M. (2003) ‘Design and the Domestic Persuader: Television and the British Broadcasting Corporation’s Promotion of Post-war “Good Design”’, <em>Design History</em> 16 (4), pp. 307–318.</li>
<li>Klinger, B. (2006) <em>Beyond the Multiplex: Cinema, New Technologies and the Home</em>, Berkeley, CA: University of California Press.</li>
<li>Kosareff, S. (2005) <em>Window to the Future: The Golden Age of Television Marketing and Advertising</em>, San Francisco, CA: Chronicle Books.</li>
<li>Lally, E. (2002) <em>At Home with Computers</em>, Berg: Oxford.</li>
<li>Latour, B. (1993) <em>We Have Never Been Modern</em>, London: Harvester Press.</li>
<li>Leman, J. (1987) ‘Women’s Programmes: Why Not?’, in Helen Baehr and Gillian Dyer (eds) Boxed In: <em>Women and Television</em>, London: Pandora, pp. 84–92.</li>
<li>Maguire, P. and Woodham, J. (1997) <em>Design and Cultural Politics in Post-war Britain: The ‘Britain Can Make It’ Exhibition of 1946</em>, Leicester: Leicester University Press.</li>
<li>Mann, D. (1992) ‘The Spectacularisation of Everyday Life: Recycling Hollywood Stars and Fans in Early Televison Variety Shows’, in Lyn Spigel and Denise Mann (eds) Private Screenings: <em>Television and the Female Consumer</em>, Minneapolis, MN: University of Minnesota Press, pp. 41–70.</li>
<li>Marvin, C. (1988) <em>When Old Technologies Were New: Thinking about Communication Technologies in the Late Nineteenth Century</em>, Oxford: Oxford University Press.</li>
<li>Moores, S. (1993) <em>Interpreting Audiences: The Ethnography of Media Consumption</em>, London: Sage.</li>
<li>Morley, D. (1992) <em>Television, Audiences and Cultural Studies</em>, London: Routledge.</li>
<li>Morley, D. (2002) <em>Home Territories: Media, Mobility and Identity</em>, London: Routledge.</li>
<li>Morley, D. (2007) <em>Media, Modernity and Technology: The Geography of the New</em>, London: Routledge.</li>
<li>Morse, M. (1990) ‘An Ontology of Everyday Distraction: The Freeway, the Mall, and Television’, in Patricia Mellencamp (ed.) <em>The Logics of Television</em>, Bloomington, IN: Indiana University Press, pp. 193–221.</li>
<li>O’Sullivan, T. (1991) ‘Television Memories and Cultures of Viewing 1950–65’, in John Corner (ed.) <em>Popular Television in Britain</em>, London: British Film Institute, pp. 169–174.</li>
<li>Peil, C. and Röser, J. (2014) ‘The Meaning of Home in the Context of Digital Mediatisation, Mobilization and Mediatisation’, in Andreas Hepp and Friedrich Krotz (eds) <em>Mediatised Worlds: Culture and Society in a Media Age</em>, Basingstoke: Palgrave Macmillan, pp. 233–252.</li>
<li>Scannell, P. (2000) ‘For Anyone-as-Someone Structures’, <em>Media, Culture and Society</em> 22 (1), pp. 5–24.</li>
<li>Schwartz, D. (2006) ‘Modernism for the Masses: The Industrial Design of John Vassos’, <em>Archives of American Art Journal</em> 46 (1–2), pp. 4–24.</li>
<li>Scrine, R.C. (1976) ‘Milestones in Television History’, <em>The Technical Journal of Rediffusion Engineering</em> 2 (5), pp. 142–147.</li>
<li>Silverstone, R. (1991) ‘Beneath the Bottom Line: Households and Information and Communication Technologies in the Age of the Consumer’, PICT Policy Research Papers, No.17, Oxford: PICT.</li>
<li>Silverstone, R. (1994) <em>Television and Everyday Life</em>, London: Routledge.</li>
<li>Silverstone, R. and Haddon, L. (1996) ‘Design and the Domestication of Information and Communication Technologies: Technical Change and Everyday Life’, in Roger Silverstone and Robin Mansell (eds) Communication by Design: <em>The Politics of Information and Communication Technologies</em>, Oxford: Oxford University Press, pp. 44–74.</li>
<li>Sparke, P. (2004) ‘Studying the Modern Home’, <em>The Journal of Architecture</em> 9 (4), pp. 413–417.</li>
<li>Spigel, L. (1990) ‘Television in the Family Circle, the Popular Reception of a New Medium’, in Patricia Mellencamp (ed.) <em>Logics of Television: Television, Essays in Cultural Criticism</em>, London: BFI Publishing, pp. 73–97.</li>
<li>Spigel, L. (1992) <em>Make Room for TV: Television and the Family Ideal in Postwar America</em>, Chicago, IL: University of Chicago Press.</li>
<li>Spigel, L. (2001) <em>Welcome to the Dreamhouse: Popular Media and Postwar Suburbia</em>, Durham, NC: Duke University Press. Susman, W. (1984 [1973]) Culture as History: the Transformation of American Society in the Twentieth Century, New York: Pantheon, 1973, reprinted 1984.</li>
<li>Thompson, B. (2012) <em>Ban This Filth!: Letters from the Mary Whitehouse Archive</em>, London: Faber and Faber.</li>
<li>Vickery, A. (1993) ‘Golden Age to Separate Spheres? A Review of the Categories and Chronology of English Women’s History’, <em>The Historical Journal</em> 36 (2), pp. 383–414.</li>
<li>Ward, K. (2006) ‘The Bald Guy Just Ate an Orange: Domestication, Work and Home’, in Thomas Berker, Maren Hartman, Yves Punie and Katie Ward (eds) <em>Domestication of Media and Technology</em>, Maidenhead: Open University Press, pp. 145–164.</li>
<li>Williams, R. (1974) <em>Television: Technology and Cultural Form</em>, London: Fontana.</li>
</ul>
</div>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="How Search Shaped and Was Shaped by the Web"
class="paper-story"
data-article-title="How Search Shaped and Was Shaped by the Web"
>

<h1 class="article-title" id="h_How Search Shaped and Was Shaped by the Web">How Search Shaped and Was Shaped by the Web</h1>

<div class="top-meta">Alexander Halavais, 2017-01-05 00:00:00 AEST. for week 6.</div>

<p>Search engines have long been seen as a set of services somehow
‘bolted on’ to the larger web experience. In this view, search engine technology allowed for an ever-more complete indexing of a rapidly growing new World Wide Web, and as the card catalog provided an index to the library stacks, the search engine was seen as somehow separate from the rest of the web. This is more than a metaphor: the technologies that make up web search trace their lineage directly to library cataloging, among other sources. But for many reasons, the relationship of search engines to the larger web is far messier. The architecture of the web has co-evolved with the development of search engine technologies, and the biases of those technologies have shaped – and continue to shape – the modern web.</p>
<p>This chapter traces the large-scale shift from web surfing to web searching, and what this has meant for the organization of the web over time. The massive reorganization from intentionally chaotic distributed hypertext to</p>
<p>a largely indexed and searchable web marks one part of that shift.
This has been driven not only by the technology of search, but by the commodification of attention online. As the search engine came to be the main gatekeeper of online attention, search became the economic engine and came to be closely tied to online advertising and marketing.</p>
<p>But this is far from unidirectional. While it is true that the technologies of search have had wide-ranging effects on the organization of information, those search engines did not emerge from a vacuum. In many cases, search evolved to meet specific needs brought about by new uses of the growing web. The development of search engines and the web were deeply intertwined and co-evolutionary. This chapter begins by tracing the changes in search over time, from the period before the emergence of the web to the present. It then examines the question of how new markets of attention and online socialization have both affected and been affected by the structures and biases of search engines.</p>
<p>By understanding search, we are better able to understand how the web as a whole works, and how it has changed over time.</p>
<h2>THE LONG HISTORY OF THE SEARCH ENGINE</h2>
<p>The World Wide Web changed the face of the internet, in many ways subsuming it. We still use a number of applications outside of the web, from email to chat to gaming, and video content takes up roughly three-quarters of total internet traffic (Cisco, 2016), but the World Wide Web was the application that took the internet to the masses. Within several years of the first web browser being introduced, there were at least a couple dozen search engines that sought to make sense of the rapidly expanding web (Chu and Rosenthal, 1996). Many of these engines owed their existence to pre-web search technologies. In each of these cases, search answered a need. The information structure was not efficiently browsable; a technology was needed that would make it more effec-
tive for the user.</p>
<p>It is difficult to identify a clear starting point for search engines. The process of indexing large collections of digital text generally comes under the aegis of ‘information retrieval’. While that field has received far more attention and engagement since the early 1990s, it certainly did not begin with the internet – it grew up with digital computing. Some draw a connection to Vannevar Bush’s prophetic ‘As We May Think’ (1945), which described an imagined device (the ‘Memex’) that allowed the researcher to easily query a large collection of text and retrieve the appropriate document. He and his team built prototypes that did this with microfilm in the 1930s, and others similarly indexed systems for punch cards (Sanderson and Croft, 2012). The first examples of purely electronic machines that could do something similar soon followed. By the 1960s the digital computer’s ability to not just crunch numbers but store data was becoming apparent, and it was during this period that many of the models for representing documents and algorithms for searching were developed, especially as part of Gerard Salton’s research groups at Harvard and then Cornell. His measure of document similarity (as the coefficient of the cosine between vectors described by the totality of the terms found in each document) and other ideas developed during the period became the core of early search engine functionality (Salton, 1975).</p>
<p>Early mechanical and digital computing is not the only starting point. The systems eventually used to index digital data had been used to catalog printed and written information for as long as those have existed. For very modest collections, such an index could be held in the head of the owner or librarian. Especially as the collection increased in size, creating an externalized index became an essential task, and the power initially vested in the librarian moved to the technical embodiment of that person: the index (Kaser, 1962). That index, and the metadata that accompanies it, has been a part of what we traditionally think of as libraries for thousands of years.</p>
<p>By the 1980s, traditional printed card catalogs were largely being replicated digitally and displaced by online indexes (Borgman, 1986). And with the growth of the internet during the same decade, a new and rapidly growing source of digital data emerged. With it came the need to search. Applications intended to search through the files of a single computer were expanded to include indexes of other computers on the network. New forms of searching also emerged. The Unix command ‘finger’, for example, provided information about a particular user, including when that user last logged on, and often some personal contact information. Its creator, Les Earnest, designed ‘finger’ in 1971 to aid in social networking at the Stanford Artificial Intelligence Lab (quoted in Shah, 2000):</p>
<blockquote>
<p>People generally worked long hours there, often with unpredictable schedules. When you wanted to meet with some group, it was important to know who was there and when the others would likely reappear. It also was important to be able to locate potential volleyball players when you wanted to play, Chinese food freaks when you wanted to eat, and antisocial computer users when it appeared that something strange was happening on the system.</p>
</blockquote>
<blockquote>
<p>When computers were networked via the internet, it became possible to ‘finger’ individuals from across the country or the world, to find out more about them, and in the days before the web was among the more widely used protocols for searching for information about individuals online.</p>
</blockquote>
<p>The development of the File Transfer Protocol (FTP) led to even more disconnected collections of files. Often public FTP servers allowed individuals to upload or download files anonymously. Since a file name was rarely descriptive enough to be of particular use, these servers often had an index file, updated by hand, that listed the available files and briefly described their contents. This quickly became unsustainable, and as a result, arguably the first search engine appeared in 1990 (Deutsch, 2000). Archie provided a way of searching across FTP servers to find a particular file. After it launched, it grew quickly: ‘From 30 hits a day, we soon went to 30 an hour, then 30 a minute’. Archie’s approach to gathering information from distributed servers and then providing it as a search service became the model for the search engines that followed. This included Veronica, a search engine for Gopher, an intermediate step toward the World Wide Web that made it possible to browse files available on the internet via a menu structure. Like Archie, it searched through the titles of files and indexed them by crawling through the menus of ‘gopherspace’ (Parker, 1994).</p>
<p>In 1989, when Tim Berners-Lee prototyped the ‘WorldWideWeb’, a project that provided distributed access to hypertexts, he already could draw on several years of development around hypermedia. The ACM Hypertext conferences had started two years earlier, and had already examined the question of searching hypertext when the amount of information grew too large to be made sense of through browsing (Frisse, 1987). Indeed, Berners-Lee himself saw the project as a melding of information retrieval and browsable hypertexts. In one of the early announcements of the project (1991) he notes:</p>
<blockquote>
<p>The WWW world consists of documents, and links. Indexes are special documents which, rather than being read, may be searched. The result of such a search is another (‘virtual’)
document containing links to the documents found. A simple protocol (‘HTTP’) is used to allow a browser program to request a keyword search by a remote information server.</p>
</blockquote>
<p>Much of the growth of the web can be attributed to how open ended it was. Adding to the growing web was as simple as making a link.
Exploring this new web of information was as exciting as it was intimidating. But as the web grew exponentially, and particularly as it came to be used commercially, the need to be able to rapidly find what you were looking for became acute. The web needed to be searchable as well as surfable.</p>
<h2>WEB SEARCH BEFORE GOOGLE</h2>
<p>For many people, Google represents the way one accesses the content of the internet. It can be easy to forget that there were a number of popular web search engines during early popularization of the web, and even after Google came to dominate. The earliest search engines had a single challenge: effectively accessing and indexing the rapidly growing web. But as search engines did a better job keeping up with the web, they faced a new challenge: there was a growing effort across the web to become more easily noticed by the search engines.</p>
<p>One of the earliest web search engines was Wandex, developed by Matthew Gray at the Massachusetts Institute of Technology. Gray initially created a crawler, the World</p>
<p>Wide Web Wanderer, in an effort to measure the size of the growing web, but by the end of 1993 the resulting index made the web searchable. Even after initial search engines were made available, the discovery of useful websites was often human-curated through the distribution of ‘what’s new’ emails, shared collections of bookmarks, collaborative ‘webrings’ that linked together like sites (Elmer, 1999), or web catalogs like Yahoo! or DMOZ (Callery, 1996). Carefully organized ‘bookmark files’ with the URLs of interesting or oft-revisited sites (Abrams et al., 1998) could easily be published as pages with webready versions generated by some of the early web browsers. As a result, many personal home pages included a list of favored sites, a practice that eventually dovetailed with ‘blogrolls’ once blogging became popular. Reports of new and interesting sites could be found in a number of places, from magazines like <em>Wired</em> to emailed bulletins.</p>
<p>While bookmark files certainly helped users to ‘refind’ sites –
something search engines are now frequently relied on to provide –
they were of less use in finding specific information. Especially early in the evolution of the web, this is hardly surprising. Today, there is the general expectation that if something (an idea, a company, a person) exists, there is some indicator of it somewhere on the web; it is simply a matter of finding it. In the case of the early web, it was far more likely to be a surprise when something you were interested in had some sort of presence on the web. As a result, the early web was ripe for exploration and discovery.
_Searching _the web only made sense as its size increased. That size increased quickly. The web consisted of just over 600 sites by the end of 1993. That number was over 10,000 by the end of 1994 and crossed the million mark in the first half of 1997 (Zakon, 2017). While surfing through several hundred sites, even at the slow speeds of the early 1993 internet, was entirely possible, visiting a million – and eventually a billion – certainly was not. And with commercialization, the ways in which</p>
<p>people used the web were changing as well. Brian Pinkerton (1994)
indicates this issue as central to the development of one of the first web search engines, WebCrawler:</p>
<blockquote>
<p>Imagine trying to find a book in a library without a card catalog. It is not an easy task! Finding specific documents in a distributed hypertext system like the World-Wide Web can be just as difficult. To get from one document to another users follow links that identify the documents. A user who wants to find a specific document in such a system must choose among the links, each time following links that may take her further from her desired goal. In a small, unchanging environment, it might be possible to design documents that did not have these problems. But the World-Wide Web is decentralized, dynamic, and diverse; navigation is difficult, and finding information can be a challenge. This problem is called the resource discovery problem.</p>
</blockquote>
<p>Wandex largely replicated the functionality of Veronica, with a crawler that was able to find and follow links. But like that predecessor, it also indexed only the titles of pages, not the content. Brian Pinkerton’s WebCrawler and the Repository-Based Software Engineering (RBSE) spider and indexer each extended this to indexing the textual content of the page. By the end of 1994, the WebCrawler had received its millionth query, and had been joined by more than a half-dozen other early search engines. In terms of overall design, these shared very similar architectures, each crawling the web with robots, constructing an index, and providing a front end to handle queries and generate a list of search engine results. Competition was fierce, but largely revolved around coverage: how broadly their robots crawled and how often. As Bharat and Broder noted in 1998, a cottage industry had emerged around comparing the most popular search engines, with scores of articles and a dedicated website. They estimated the coverage and overlapped four of the most popular search engines of the time: HotBot, AltaVista, Excite, and Infoseek. The search engines had different sizes of coverage, but the authors note that their most startling discovery was how very little overlap the search</p>
<p>engines had: ‘less than 1.4% of the total coverage, or about 2.2 million pages appeared to be indexed by all four engines’. Dogpile and other meta-search engines could help a bit here, by aggregating the results across search engines, but there was concern that much of the web was undiscoverable.</p>
<p>Moreover, a clear financial model to provide these resources had yet to emerge. Serving an advertisement for AT&amp;T in 1994, _HotWired _was a pioneer in selling web banner ads, which helped to make their HotBot search engine a profitable venture. They claim (Singel, 2010) that this was the spark that led to the ‘portal war’ and eventually the dot-com bubble. While there is no doubt that search engines played an important part in the commercial development of the web, that may apportion too much of the credit –
and blame – to the role of advertising online. Nonetheless, the ad-supported model would make search one of the few profitable industries on the early web, and drive out other financial models for search, including paid submission, paid inclusion, and paid placement. Directly paying to manipulate search results undermines the value of an engine, at least in a competitive market (see Henshaw, 2001), and eventually it drew the scrutiny of regulators as well. Many search engines, especially a young Google, also provided customized search and enterprise solutions that helped to fund their efforts. Others shifted in this direction as well, including Inktomi, which provided search results for several engines, and Northern Light, which launched a search engine in 1997 that included links results in proprietary databases, and eventually closed down their public search engine to focus on enterprise search.</p>
<p>Because search engines always yielded more potential results than an individual could make use of, all of them provided some form of prioritization; as Schwartz (1998) wryly notes: ‘Although experience with search engines sometimes makes this hard to believe, search results are usually ranked by relevance…’. The disbelief was natural, since</p>
<p>it was often difficult to discern the reasoning behind the ranking.
First, the specific algorithm that determined where in the list a site fell was almost always a closely held secret. Second, without any semantic data, there were limited ways of determining the most
‘important’ pages. These included measuring the frequency and proximity of the query terms on the page, as well as whether pages had been clicked through on earlier searches, or whether it was part of a human-reviewed list of sites (sometimes taken from category-
based sites like DMOZ). Third was an influence that gradually changed the dynamic between search engines and the searchable web: site owners sought any advantage they could in rising in the ranks of relevance.</p>
<p>The formal restrictions on commercial activity on the internet were lifted just as the web was taking off. By the late 1990s the ‘search engine wars’ largely focused on ways of ranking search results, while those who had things to sell online were particularly interested in influencing those rankings. The basic problem of assembling and keeping current an index had been superseded by the question of ‘relevance’ (Introna and Nissenbaum, 2000). For some –
including Tim Berners-Lee (1996), one of the architects of the web
– for it to be useful, the web would need to be coded with semantic data, allowing computers to make sense of it in a more comprehensive fashion:</p>
<blockquote>
<p>To date, the principle [sic] machine analysis of material on the web has been its textual indexing by search engines. Search engines have proven remarkably useful, in that large indexes can be searched very rapidly, and obscure documents found. They have proved to be remarkably useless, in that their searches generally take only vocabulary of documents into account, and have little or no concept of document quality, and so produce a lot of junk. (Berners-Lee, 1996)</p>
</blockquote>
<p>While a number of efforts were made toward the inclusion of semantic data for search, the web at large remained – and remains today –
wildly unstructured. Moreover, the cat-andmouse game between search engines and</p>
<p>marketers continued unabated. Into this fray came a new weapon that would significantly disrupt that ongoing conflict: PageRank.</p>
<h2>THE GOOGLE REVOLUTION</h2>
<p>In early 1996, Stanford University doctoral students Larry Page and Sergey Brin started working on BackRub, which would eventually come to be called Google. The initial advantage of Google over the existing search engines was embodied in the PageRank algorithm, which took a page from academic citation analysis and used the information from hyperlinks as a kind of peer review. Those pages that received the most links from popular pages floated to the top of the ‘relevant’ results. Page and Brin described it not in terms of citation, but, from an intuitive sense, from the perspective of a ‘random surfer’ (Page et al., 1999). A user who randomly surfs links on the web would be more likely to wind up on a page with a high PageRank. PageRank is far from the only reason for Google’s long-term rise to search engine dominance, but there can be little doubt that the algorithm changed the balance of power between search engines and the marketers hoping to gain an advantage through them – at least temporarily. For the first time, web authors had to think not only about how to make the site appealing to the search engine robots that visited it, but how to make its hyperlinked ‘location’ in the web ecosystem more appealing. Much like retailers in the physical world have to think about neighborhoods, foot traffic, and visibility, suddenly it was more important than ever before that others linked to your site.</p>
<p>Naturally, having a large number of inbound hyperlinks (or
‘backlinks’) was always important to website owners. After all, it was not just the theoretical surfer envisioned by PageRank who followed hyperlinks: that is how many people found their way to your website, especially before the</p>
<p>turn of the millennium. If you wanted to be found, you had to be linked. And if you were linked by a particularly influential site –
especially some of the group blogs and news filters like Slashdot and its descendants – you could see your web traffic spike to an extreme degree. These flash crowds were at one point called the
‘Slashdot Effect’, but could be seen as a result of sites that followed the group news approach Slashdot pioneered: Kuro5hin, Fark, Digg, Reddit, and – although it is not an exact analog – now Facebook and Twitter. So, even if backlinks were not important to the process of search, they would be of interest to the web author.
Naturally, these two functions went hand-in-hand, though. Once a site had received traffic from a flash mob, it was likely to receive more links, and higher search rankings – a cumulative process that is common among a number of networked environments (Price, 1976).</p>
<p>While the initial work on what would become Google web search began in 1996, and the search engine was launched by 1998, Google really came into its own at the turn of the millennium, and Search Engine Land (Sullivan, 2010) called what followed ‘The Google Decade’. Much of this had to do with Google’s seemingly incessant march into eve-
rything from ecommerce to social networking. In particular, the basis for Google’s most significant source of income – the AdWords advertising network – was launched in 2000, providing the basis for its steady rise to one of the most profitable businesses on the planet.</p>
<p>Starting with the acquisition of an archive of Usenet messages called Dejanews in 2001, much of Google’s expansion occurred via acquisitions that became products for advertising, blogging, mapping, cloud-based services, artificial intelligence, online sales and coupons, video sharing, ebooks, robotics, social networking, facial recognition, health, telephony, mapping, natural language systems, customer relationship management, and mobile software, among many more. These helped Google to produce a popular email service, a mobile phone operating system,</p>
<p>and a range of other services that seemingly have little to do with search. Just as PageRank shifted the focus to the web ecosystem, Google used the data collected from these services to create a more effective search engine and a more effective advertising network.</p>
<p>If the period before Google represented a war of attrition and attention among search engines seeking to discover a new market, the period since Google’s inception has been marked by consolidation.
Certainly, Google continues to have significant challenges from rivals. In particular, the Chinese search engine Baidu is often the first choice for those seeking materials from China or in Chinese, though it may not have the broader global coverage of Google (Jiang, 2014). And Microsoft’s Bing search engine continues to attract a segment of searchers. And a handful of search engines with names familiar to long-time denizens of the web continue to operate, including Yahoo!, AOL, Excite, and Ask.com (though in several cases these sites deliver search results provided by Google or Bing).
Nonetheless, by most measures, of every five people searching the web, roughly four are likely to be googling (NetMarketShare, 2017).
Though the basic technologies that make up the web as a whole had not changed, the architecture had, moving from a browsable to a searchable space.</p>
<h2>MONETIZING ATTENTION</h2>
<p>By 2006, the Oxford English Dictionary had added ‘to google’, as a synonym for searching the internet. The web come to be a main-
stay in the media diet for a good portion of the world, and as audiences left traditional mass media, advertisers needed to make sense of a new and challenging medium. They naturally focused on the search engine as a technology that acted as a gatekeeper and provided a clear space for influencing users. Google was in a prime position for addressing these new interests. As Siva</p>
<p>Vaidhyanathan (2011) persuasively writes, Google is more than merely an application for searching the web, or an extraordinarily successful internet company. The process of ‘googlization’ reaches into nearly every corner of our information ecosystem, coloring our social interactions, our political processes, and the ways in which we come to know the world. Of course, media have always shaped our experience of the world, setting the agenda of our political debates, or influencing what we see as risks and threats. In some ways, the internet should have reversed the ways in which global media attenuated our sources of information. After all, with broad access to the web, everyone now had their own ‘printing press’.</p>
<p>While the early web might have looked like a distributed conversation, where information could only be found by ‘surfing’
from page to page, search engines changed that, making pages increasingly more findable, but less discoverable. Search engines became a point of control, focusing attention on some parts of the web while ignoring others. On the early web, it was perfectly rea-
sonable to publish something and hope to be ‘discovered’ by people who happened by and were willing to recommend your site to others.
When the recommendations came from a search engine instead, influencing those engines became more important. And as Google gradually became synonymous with search, it also became the central switch for information and knowledge on the internet.</p>
<p>It initially wrested some control over attention that online marketing and search engine optimization (SEO) had begun to accrue, evening out the playing field somewhat. By 1995, the ‘Multi-Media Marketing Group’ had been founded, which produced a popular newsletter with tips for influencing search engines (Knowles, 2017). The SEO industry grew continuously until 2016, when salaries and demand for SEO expertise abated slightly. Especially in the early days, the term ‘spamdexing’ was far more popular (Torok, 1996). Initially, the focus of</p>
<p>SEO practitioners was on ‘keyword stuffing’: determining which keywords were worth targeting in searches and then including as many of them as high on the page as possible. Early on, these might have appeared in the metadata tags for the page, including those that specifically indicated keywords chosen by the author, but once search engines began ignoring such metadata for the purposes of ranking, authors turned to new approaches. These included repeating targeted keywords throughout the text of the page, sometimes with text with the same color as the page background, or otherwise hidden from all but the search engine. This could result in visitors using a search engine and arriving at a page that had absolutely nothing to do with their search terms.</p>
<p>This was particularly true for pornography. During the 1990s, there was significant concern over the availability of pornography online, especially to children. Part of this was because, as Susanna Paasonen describes elsewhere in this volume, pornography was one of the earliest commercially successful ventures on the web. Users often searched for pornographic content, and providers sought buyers who could make an instant purchase. In many ways search engines served as a natural intermediary between those seeking out pornography – often with little interest in paying – and those seeking to provide it at a price. Online pornography providers innovated in a range of areas, from advertising networks to pop-ups to the use of online video and safe online payments. One of those areas of innovation was affiliate networks: developing automated systems that provided rewards for bringing paying customers to a site. Those who created these affiliate sites were single-mindedly interested in drawing searchers’ attention, and one of the most effective ways of doing this was to attract not just their legitimate searches for adult content, but searches on just about any topic.</p>
<p>Naturally, this reduced the effectiveness of the search engine for the user, who was seeking ‘relevant’ results. Those searching</p>
<p>AltaVista or HotBot would often have to wade through a number of pornographic results – including, at times, those illegal in their jurisdiction – regardless of the information sought. During a period in which search engines were in direct competition, those that could avoid misdirecting users had an advantage. Obviously, as the number of pages on the web ballooned, and as the web became even more commercial, the question of not just returning results, but returning the most ‘important’ results became a priority. Search engines responded to spamdexing as quickly as they could, but it rapidly became a game of cat-and-mouse.</p>
<p>It took a bit longer for spamdexers to figure their way around PageRank, and many celebrated Google for bringing some measure of balance back to the web. While spamdexers had developed a repertoire of techniques for manipulating their own websites to achieve high rankings in search engine results pages, they had not needed to think about the broader web ecosystem, and the effect of linkages, before Google came along. As Page et al. (1999) noted, the low ranks of these pages were likely ‘because people do not want to link to pornographic sites from their own webpages’. Google rapidly gained in popularity against the other search engines thanks to its reputation of presenting a view of the web that had been manipulated far less and provided what were sometimes considered more useful results.</p>
<p>But Google was certainly not a one-trick pony. Soon after it gained significant popularity, website owners targeted PageRank. Rather than making changes to their own site, they would create rings of sites that linked to one another, or seek to have links made from other sites. And it was not just the link that mattered: the context of the link could affect how Google interpreted a site. This effect was noted and exploited by some, before it became common knowledge.
In early 2001, Farhad Manjoo noted a strange effect: searching for
‘dumb motherfucker’ on Google presented you with a link for merchandise relating to the US president at the time.</p>
<p>He hypothesized some potential reasons for this, but in the coming years it became clear that including keywords in links to a page could affect how Google’s search engine indexed it. The technique, called a ‘Google bomb’, was used for several years to collectively shape what Google indexed.</p>
<p>While Google bombing represented, largely, an amusing diversion, it also provided a small peek into the ways in which Google continuously changed its technology to prevent manipulation by SEO practitioners and spamdexers. The rise of the Google bomb occurred around the time of the rise of the blogosphere. Thanks to heavy linking and frequently updated pages, blogs came to exert a significant influence on Google. When a collection of bloggers decided to, they could collect this power to create a Google bomb
(Kahn and Kellner, 2004). But more broadly, blogs had natural advantages when it came to achieving high search rankings, and some complained that the blogosphere was taking over Google’s results pages. Others used this to their advantage, either creating their own blog networks or spamming comments on blogs from around the web to provide links to the page they were promoting. (Eventually, the latter was dampened through the ‘nofollow’ tag, which excluded links in comments from providing the ‘googlejuice’ that adds to a site’s prominence in results.)</p>
<p>Today, Google uses dozens of ‘signals’ beyond PageRank in order to provide results and counter attempted manipulation. Nonetheless, it relies heavily on reading the environment around a site, and attempts to manipulate those links in order to gain ranking continue to be used, and are one of the few reasons for Google to execute a ‘manual action’, which is sometimes referred to as a
‘Google death sentence’ (Malaga, 2010). There have been a number of examples of Google’s removal of a site from the web resulting in substantial financial repercussions for the violating site. Even larger companies that have been penalized by Google, including American retailer JC Penney</p>
<p>(Segal, 2011), and BMW’s site in Germany (Blakely and McCormack, 2006), have felt the sting of being shunned. A US court recently decided that Google has the absolute right to delist companies if it so chooses (<em>e-ventures _v. _Google</em>, 2017). Google’s ability to effectively silence voices on the web – not by removing them, but by making them unfindable – is remarkable.</p>
<p>Google advises the creators of websites to simply make their sites usable for human visitors, and they will do the rest. Nonetheless, producers of websites have continuously tried to gain an advantage and Google has continuously adjusted their algorithms to counter this. This process has been called by some the ‘Google Dance’, as pages climb and fall according to new criteria for relevance. There have also been large-scale changes that significantly reorganize the results pages and determine who new winners and losers are.
Sometimes these are explained by the search engine (though rarely in detail), and other times they are noted by keen observers in the SEO community. Sometimes these changes can be quite substantial, with major elements of the ranking or interface systems changed.
For example, in late August of 2013, Google deployed ‘Hummingbird’, which provided for more conversational queries. These changes are often tested with a subset of searches made by unsuspecting visitors before they are used more broadly.</p>
<p>The idea that search is a neutral conduit, a switchboard that allows you to reach your desired page, is part of the mythology of the search engine. It occupies an important space both in terms of the distribution of knowledge, and the flow of commerce. As such, it is difficult to imagine that it would not be subject to substantial efforts to influence its functionality. The primary way this has been achieved is by changing the way web pages appear, and how the web itself is linked together. Despite a design that was intended to be ‘bottom up’, the web has evolved in an effort to reflect the biases of search engines, and particularly the biases of Google.</p>
<h2>THE BIASING ENGINE</h2>
<p>Critics of search often seek to determine whether Google is
‘biased’. This is the wrong question to ask: search is inherently a biasing process, favoring some results over others. This does not mean that Google wishes to present a particular position or idea, necessarily, but rather that any system that acts as a filter must also introduce some form of bias. As one early newspaper article
(Pegoraro, 1999) had it, Google ‘sees the Web as a popularity contest’. In that respect, Google has become more biased over time, as it aims to provide better results. But just as the word ‘biased’
is problematic, so is the word ‘better’. The natural question is: better for whom? Given that Google’s product is its users’ atten-
tion, which it sells to advertisers in order to produce a profit, Google’s aim is to create a bias that attracts users back to Google.
Because</p>
<p>of this, ‘better’ is often better for the user.</p>
<p>But a number of criticisms have suggested that what the user gets from Google is biased in ways that are not necessarily better for society, and some of these critiques find parallels with those of journalism and mass media more broadly. There has long been a concern that Google presents a bias toward, broadly, its advertisers. Others suggests that it commodifies knowledge, presenting it in brief, easily digestible chunks that draw us away from more considered forms of learning and make us collectively more stupid (Carr, 2008). Another concern – especially with search results that since 2009 are influenced by our past searches, our activity on the web, or what our friends look for – is that we may find information that satiates us by playing to our preconceptions
(Pariser, 2011). A search engine created in 2008 as an alternative to this kind of ‘filter bubble’, called DuckDuckGo, has enjoyed some modest success by not tracking its users’ searches, and therefore allowing them to escape from selfreinforcing echo chambers
(Wauters, 2011).</p>
<p>One of the more longstanding challenges to the issue of what Google considers ‘important’</p>
<p>comes from a particular US-centric (or, alternatively, a globalized)
view that might miss important national or cultural nuance. Baidu played directly to that difference in advertising its search engine.
An article in _Computerworld _(Lemon, 2007: 26) described an early ad for the search engine:</p>
<blockquote>
<p>‘I get it’, the Western man says, speaking heavily accented Chinese. Surrounded by beautiful Chinese women in the video advertisement, he grins with self-satisfaction. Nearby, a suave Chinese man dressed in scholar’s robes laughs. ‘You don’t necessarily get it’, he says. As the ad unfolds, the Chinese scholar proceeds to humiliate the Westerner, mocking his poor Chinese-language skills. In the end, the women flock to the scholar’s side, and the Westerner is left confused, alone and humiliated.</p>
</blockquote>
<p>In order to protect its cultural capital – as well as some degree of political control – China has supported the development of alternative search engines like Baidu, through both direct funding and policy that has been at times antagonistic toward Google.</p>
<p>And China is not alone in this regard. In his 2007 book, Jean-Noël Jeanneney suggested, for example, that a Google search is likely to lead to an Anglo-centric view of the French revolution; not necessarily ignoring French sources, but favoring those from the perspective of English observers. The title of his book –
_Quand Google défie l’Europe _– also hints at issues of national control. Driven in part by the concern regarding such con-
trol (Abelson et al., 2008: 159), France and Germany partnered in an attempt to create an alternative to Google with the Quaero project
(2007–13). While other national search engines, including the Swiss Search.ch, continue to attract visitors, none of these have reached anything approaching the traffic of Baidu, let alone Google.</p>
<p>At least for the time being, Google remains a central gateway for ideas and money on the web. While nations can attempt to influence that filter through policy or the courts, the most frequent attempt to change what Google delivers is by reshaping the web. Search</p>
<p>engines began as an attempt to inflict order on the chaotic and dynamic web of interconnected pages that made up the growing World Wide Web. Today, web authors are just as likely to use their own pages in an attempt to inflict a new order on the global search engine. But that centrality is facing a new set of challenges.</p>
<h2>EVOLVING WITH THE SOCIAL WEB</h2>
<p>The term ‘social search’ is a bit of a misnomer; how could search be anything but social? However, over the last decade a sig-
nificant amount of online interaction has moved to platforms that support social participation. Naturally, there has been a ques-
tion about how search engines might shift as internet users’
attention and focus has shifted. One version of the question relates to how search engines might be used to index social media platforms and provide search for and with them. These systems represent a sig-
nificant challenge in terms of the volume and velocity of change: making Twitter and Facebook searchable is no small problem, and requires a more direct connection than is available via the web interface. So it makes sense, for example, that Google might part-
ner directly with Twitter to more easily index their 9,000 tweets per second (Patel, 2015). Likewise, Facebook, Google, Microsoft, and Amazon, among others, have partnered to research how artificial intelligence might make their systems for filtering and finding more effective.</p>
<p>At the same time, these platforms have direct access to their own data and are creating their own, internal search engines to help make sense of it. In 2012, Facebook saw more than a billion queries a day to its search engine, and by 2016 that number was up to two billion and still growing (Constantine, 2016). If Facebook considered itself a search engine, that would make it the second most popular search engine in the world, and the</p>
<p>fastest growing. And like Google, Facebook sees effective search as the gateway to selling advertisements.</p>
<p>Even before the rise of the social media platforms, search engines focused on their forerunners: blogs. Though the blogosphere had its own search engines, the largest of which was Technorati, Google focused on blogs not just because of the currency and interest of their topics, but because their link structure was so essential to finding the ‘important’ sites on the web. It was a bit surprising then that Google initially showed little interest in using signals from social media platforms to aid their search process.
Microsoft’s Bing experimented with ways of directly indicating which results your friends found interesting, and Google did the same for a short time. There is a great deal of speculation as to how important social signals are to prioritizing results on these two search engines today, and while Google continues to indicate that it does not use social signals (Schwartz, 2015), there is some consensus that results rankings correlate to social media attention.</p>
<p>The real impact of ‘social search’ has yet to be felt. Over the last few years news organizations have noticed a trend in the way people end up on their sites. Many still go directly to the websites of trusted news sources, but a significant number arrive not thanks to a search engine results page, but rather via a shared message on Facebook, Twitter, or another social media platform.
Google, which for a time was so ubiquitous it was coming to be seen as the internet itself, is gradually being supplanted by Facebook, and especially by Facebook on mobile devices, a shift that has accelerated rapidly during the 2010s.</p>
<p>This shift away from the search engine interface is something that Google predicted in the earliest days of the company, but it remains unclear what search without visible search engines will become.
Certainly, the collaborative filtering function of Facebook holds part of the key, as do increasingly sophisticated systems for analyzing both the content of the web and the meaning of online messages. The future will continue to require</p>
<p>search, but we may no longer see the search process as clearly, or find the need to identify things called ‘search engines’.</p>
<h2>CO-EVOLVING SEARCH</h2>
<p>Understanding the history of the web requires not just an archive of the pages that were created, but a broad understanding of the context in which audiences encountered those materials. The web, as a broad environment, is far more than its pages, their content, and a collection of hyperlinks. Much of how individuals experience the web has to do with how they find and encounter the information on it. That alone would make it important to understand how search engines have developed over time. But perhaps more importantly, it is impossible to cleanly divide search engines from the larger web; the web makes little sense outside of the context of the search engine. It is not just an essential ‘feature’ of the web, it represents a technology for organizing our social experiences and our collective knowledge. And just as the content and experience of the web is not entirely in the hands of the authors of websites, the nature of search engines is only partially determined by their engineers. The search engine has evolved to meet the needs of users and web authors, and these groups have each contributed signifi-
cantly to the evolution of web search. That back and forth is likely to continue, and so understanding the search engine requires an understanding of how the web has changed, and any hope of understanding the nature of the web relies on a thorough understanding of the search engine.</p>
<h2>REFERENCES</h2>
<div class="notes-and-refs">
<ul>
<li>Abelson, H., Ledeen, K., and Lewis, H.R. (2008) <em>Blown to Bits: Your Life, Liberty, and Happiness After the Digital Explosion</em>. Upper Saddle River, New Jersey: Addison-Wesley.</li>
<li>Abrams, D., Baecker, R., and Chignell, M. (1998) ‘Information Archiving with Bookmarks: Personal Web Space Construction and Organization’, <em>CHI ‘98 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</em>, Los Angeles, California, April 18–23, New York: ACM, pp. 41–8.</li>
<li>Berners-Lee, T. (1991) WorldWideWeb: Summary, Usenet: alt.hypertext, 9 August 1991. Available at: <a href="https://groups.google.com/"     >https://groups.google.com/forum/#!msg/comp.archives/CfsHlSNYPUI/DTs60INnuzcJ</a> [Accessed 15 June 2018].</li>
<li>Berners-Lee, T. (1996) The World Wide Web: Past, Present and Future. Available at: <a href="https://www.w3.org/People/Berners-Lee/1996/ppf.html">https://www.w3.org/People/Berners-Lee/1996/ppf.html</a> [Accessed 15 June 2018].</li>
<li>Bharat, K., and Broder, A. (1998) ‘A Technique for Measuring the Relative Size and Overlap of Public Web Search Engines’, <em>Computer Networks and ISDN Systems</em>, 30(1): 379–88. Blakely, R., and McCormack, H. (2006) ‘Google’s “Death Penalty” for BMW’, <em>The Times</em> <a href="https://www.thetimes.co.uk/article/googles-death-penalty-for-bmw-wpbtz992h8v">, February 6. Available at: https://www.the-times.co.uk/article/googles-death-penalty-for-bmw-wpbtz992h8v</a>[Accessed 15 June 2018].</li>
<li>Borgman, C.L. (1986) ‘The User’s Mental Model of an Information Retrieval System: An Experiment on a Prototype Online Catalog’, <em>International Journal of Man-Machine Studies</em>, 24(1): 47–64.</li>
<li>Bush, V. (1945) ‘As We May Think’, <em>Atlantic Monthly</em>, 176: 101–8.</li>
<li>Callery, A. (1996) ‘Yahoo! Cataloging the Web’, <em>Untangling the Web: Proceedings of the Conference Sponsored by the Librarians Association of the University of California, Santa Barbara, and Friends of the UCSB Library</em><a href="http://files.eric.ed.gov/fulltext/ED403886.pdf">. Available at: http://files.eric.ed.gov/fulltext/ED403886.pdf</a> [Accessed 15 June 2018].</li>
<li>Carr, N. (2008) ‘Is Google Making Us Stupid? What the Internet Is Doing to Our Brains’, <em>The Atlantic</em>, July/August. Available at: <a href="https://www.theatlantic.com/magazine">https://www.theatlantic.com/magazine/archive/2008/07/is-google-making-us-stupid/306868/</a> [Accessed 15 June 2018].</li>
<li>Chu, H., and Rosenthal, M. (1996) ‘Search Engines for the World Wide Web: A Comparative Study and Evaluation Methodology’, <em>Proceedings of the Annual Meeting – American Society for Information Science</em>, 33: 127–35.</li>
<li>Cisco (2016) White Paper: Cisco VNI Forecast and Methodology, 2015–2020. Available at: <a href="http://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/complete-white-paper-c11-481360.html">http://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/complete-white-paper-c11-481360.html</a>.</li>
<li>Constantine, J. (2016) ‘Facebook Sees 2 Billion Searches per Day, But It’s Attacking Twitter, Not Google’, <em>TechCrunch</em>, July 27. Available at:<a href="https://techcrunch.com/2016/07/27/facebook">https://techcrunch.com/2016/07/27/facebookwill-make-you-talk/</a></li>
<li>Deutsch, P. (2000) ‘Archie: A Darwinian Development Process’, <em>IEEE Internet Computing</em>, 4(1): 69–71.</li>
<li>Elmer, G. (1999) ‘Web Rings as ComputerMediated Communication’, <em>CMC Magazine</em>, January. Available at: <a href="http://www.december.com/cmc/mag/1999/jan/elmer.html">http://www.december.com/cmc/mag/1999/jan/elmer.html</a></li>
<li>e-ventures v. Google (2017) Memorandum and Order, US District Court, Middle District of Florida, Fort Meyers Division. Available at: <a href="http://digitalcommons.law.scu.edu/cgi/viewcontent.cgi?article=2410&amp;context=historical">http://digitalcommons.law.scu.edu/cgi/view-content.cgi?article=2410&amp;context=historical</a>.</li>
<li>Frisse, M.E. (1987) ‘Searching for Information in a Hypertext Medical Handbook’, in Stephen Weiss and Mayer Schwartz (eds.), <em>Proceedings of ACM Hypertext 87 Conference</em>, November 13–15, 1987, Chapel Hill, North Carolina, pp. 57–66.</li>
<li>Henshaw, R. (2001) ‘What Next for Internet Journals? Implications of the Trend towards Paid Placement in Search Engines’, <em>First Monday</em>, <a href="http://firstmonday.org/ojs/index.php/fm/article/view/884">6(9). Available at: http://firstmonday.org/ojs/index.php/fm/article/view/884/793</a> [Accessed 15 June 2018].</li>
<li>Introna, L.D., and Nissenbaum, H. (2000) ‘Shaping the Web: Why the Politics of Search Engines Matter’, <em>The Information Society</em>, 16: 169–85.</li>
<li>Jeanneney, J.-N. (2007) <em>Google and the Myth of Universal Knowledge</em>, Teresa Lavender Fagen (trans.). Chicago: University of Chicago Press.</li>
<li>Jiang, M. (2014) ‘The Business and Politics of Search Engines: A Comparative Study of Baidu and Google’s Search Results of Internet Events in China’, <em>New Media &amp; Society</em>, 16(2): 212–33.</li>
<li>Kahn, R., and Kellner, D. (2004) ‘New Media and Internet Activism: From the “Battle of Seattle” to Blogging’, <em>New Media &amp; Society</em>, 6(1): 87–95.</li>
<li>Kaser, D. (1962) ‘In principium Erat Verbum’, Peabody Journal of Education<span class="s6">, 39(5): 258–63.</span></li>
<li>Knowles, M. (2017) The History of SEO. Available at: <a href="http://www.thehistoryofseo.com/">http://www.thehistoryofseo.com</a> [Accessed 15 June 2018].</li>
<li>Lemon, S. (2007) ‘Out-Googling Google: Chinese Search Giant Baidu is Beating Google at Its Own Game in China, But It’s Playing by Different Rules’, <em>Computerworld</em>, April 30, p. 26.</li>
<li>Malaga, R.A. (2010) ‘Search Engine Optimization: Black and White Hat Approaches’, in Marvin V. Zelkowitz (ed.), <em>Advances in Computers: Improving the Web</em>, London: Academic Press, pp. 1–41.</li>
<li>Manjoo, F. (2001) ‘Google Link is Bush League’, <em>Wired News</em>, January 25. Available at: <a href="http://archive.wired.com/science/discoveries/news/2001/01/41401">http://archive.wired.com/science/discoveries/news/2001/01/41401</a> [Accessed 15 June 2018].</li>
<li>NetMarketShare (2017) ‘Desktop Search Engine Market Share, January 2017’. Available at: <a href="http://www.netmarketshare.com/search-engine-market-share.aspx">http://www.netmarketshare.com/search-engine-market-share.aspx</a> [Accessed 15 June 2018].</li>
<li>Page, L., Brin, S., Motwani, R., and Winograd, T. (1999) ‘The PageRank Citation Ranking: Bringing Order to the Web’, Stanford Infolab, 422. Available at: <a href="http://ilpubs.stanford.edu:8090/422/">http://ilpubs.stanford.edu:8090/422/</a> [Accessed 15 June 2018].</li>
<li>Pariser, E. (2011) <em>The Filter Bubble: What the Internet Is Hiding from You</em>. New York: Penguin.</li>
<li>Parker, G. (1994) Internet Guide: Veronica. Available at: <a href="http://www.lib.umich.edu/govdocs/godort/archive/elec/intveron.txt.old">http://web.archive.org/web/20040808093422/http://www.lib.umich.edu/govdocs/godort/archive/elec/intveron.txt.old</a> [Accessed 15 June 2018].</li>
<li>Patel, N. (2015) ‘Everything You Need to Know about the Google-Twitter Partnership’, Search Engine Land, March 20 Available at: <a href="http://searchengineland.com/everything-need-know-google-twitter-partnership-216892">http://searchengineland.com/everything-need-know-google-twitter-partnership-216892</a> [Accessed 15 June 2018].</li>
<li>Pegoraro, R. (1999) ‘Googly Eyes’, <em>The Washington Post</em>, January 22, p. N62.</li>
<li>Pinkerton, B. (1994) ‘Finding What People Want: Experiences with WebCrawler’, presented at the Second World Wide Web Conference, Chicago, October 17–19.</li>
<li>Price, D. De S. (1976) ‘A General Theory of Bibliometric and Other Cumulative Advantage Processes’, <em>Journal of the American Society for Information Science</em>, 27(5): 292–306.</li>
<li>Salton, G. (1975) <em>A Theory of Indexing</em>. Philadelphia: Society for Industrial and Applied Mathematics.</li>
<li>Sanderson, M., and Croft, W.B. (2012) ‘The History of Information Retrieval Research’, <em>Proceedings of the IEEE</em>, _100 _(Special Centennial Issue): 1444–51.</li>
<li>Schwartz, B. (2015) ‘Google: Again, Social Signals Do Not Influence Your Ranking’, Search Engine Roundtable. Available at: <a href="https://www.seroundtable.com/google-social-signals-ranking-20803.html">https://www. seroundtable.com/google-social-signals-ranking-20803.html</a> [Accessed 15 June 2018].</li>
<li>Schwartz, C. (1998) ‘Web Search Engines’, <em>Jounal of the American Society for Information Science</em>, 49(11): 973–82.</li>
<li>Segal, D. (2011) ‘The Dirty Little Secrets of Search’, <em>The New York Times</em>, February 12. Available at: <a href="http://www.nytimes.com/"     >http://www.nytimes.com/2011/02/13/business/13search.html</a> [Accessed 15 June 2018].</li>
<li>Shah, R. (2000) History of the Finger Protocol. Available at: <a href="http://www.rajivshah.com/Case_Studies/Finger/Finger.htm">http://www.rajivshah.com/Case_Studies/Finger/Finger.htm</a> [Accessed 15 June 2018].</li>
<li>Singel, R. (2010) ‘Oct. 27, 1994: Web Gives Birth to Banner Ads’, Wired.com Available at: <a href="https://www.wired.com/2010/10/1027hotwired-banner-ads">https://www.wired.com/2010/10/027hotwired-banner-ads/</a> [Accessed 15 June 2018].</li>
<li>Sullivan, D. (2010) ‘The Google Decade: Search in Review, 2000 to 2009’, Search Engine Land, February 1. Available at: <a href="http://searchengineland.com/the-google-decade-search-in-review-2000-to-2009-34830">http://searchengineland.com/the-google-decade-search-in-review-2000-to-2009-34830</a> [Accessed 15 June 2018].</li>
<li>Torok, A.G. (1996) ‘Internet Search Engines: Are Users Ready?’ in Ahmed H. Helal and Joachim W. Weiss (eds.), <em>Towards a Worldwide Library: A Ten Year Forecast</em>, 19<sup>th</sup> International Essen Symposium, September 23–26, 1996, Essen: Publications of Essen</li>
<li>University Library, 21: 241–53. Vaidhyanathan, S. (2011) <em>The Googlization of</em> Everything (And Why We Should Worry). Berkeley: University of California Press.</li>
<li>Wauters, R. (2011). ‘DuckDuckGo to Google, Bing Users: Escape Them Filter Bubbles!’ <em>Tech Crunch</em><a    href="https://techcrunch.com/2011/06/20/duckduckgo-to-google-bing-users-escape-them-filter-bubbles">, June 20. Available at: https:// techcrunch.com/2011/06/20/duckduckgo-to-google-bing-users-escape-them-filter-bubbles/</a> [Accessed 15 June 2018].</li>
<li>Zakon, R.H. (2017) Hobbes’ Internet Timeline 24. Available at: <a href="https://www.zakon.org/robert/internet/timeline">https://www.zakon.org/robert/internet/timeline/</a> [Accessed 15 June 2018].</li>
</ul>
</div>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="The Engine"
class="paper-story"
data-article-title="The Engine"
>

<h1 class="article-title" id="h_The Engine">The Engine</h1>

<div class="top-meta">Alexander Halavais, 2009-01-01 00:00:00 AEST. for week 6.</div>

<h2>CHAPTER ONE</h2>
<h1>The Engines</h1>
<p>How did we come to mechanize the process of search? How is it that it became something that is increasingly done for us rather than by us? It certainly did not happen all at once. Like most large sociotechnical systems, the process occurred gradually, and was influenced by a combination of technical innovation and the effect of existing structures of economic and political power. And, not surprisingly, it has also reshaped both industrial relationships and political influence in turn. The current state of the search ecosystem is the result of many years of evolution, and layers of encoding of our relationships to each other and to our collective knowledge. Search engines have politics that have been baked in over a long period of time, and that process deserves a deep archeological exploration, peeling back layer by layer.</p>
<p>This chapter cannot reach the depth such a historical treatment requires. It can, however, provide an outline of that history and an indication of the kinds of processes that have been built into search technology. Moreover, it can show how that suite of technologies made its way into the larger media ecosystem, shaping it in turn. It is tempting to treat the search engine as a free-standing technology, an invention that has made it easier to find things located on another independent technology, the World Wide Web. But even a cursory investigation suggests that the search engine, like most other technologies, is not something that can be treated without reference to a larger social context, and to evolutionary social and cultural changes. The search engine, far from being an isolated modern artifact, represents a touchstone of digital culture, and a reflection of the culture in which it exists.</p>
<p>The permanent loss of search engines is now almost unfathomable, but, were it to occur, we would find the way we communicate, learn about the world, and conduct our everyday lives would be changed. And so, we must look beyond the familiar “search box” and understand what it reveals and what it conceals.</p>
<h2>Search engines today</h2>
<p>A basic definition of the search engine might refer to an information retrieval system that allows for “keyword” searches of distributed digital text. That definition often remains our frame of reference, if we have one. If you ask someone what a search engine is, however, they are less likely to provide a definition than they are to indicate one of the handful of popular web search engines that represent some of the most popular sites on the web: Google, Baidu, or Bing, for instance.</p>
<p>And these sites are popular. As of 2012, more than half of Americans said that they used a search engine at least once a day (Purcell, Brenner, &amp; Rainie 2012). Google is easily the most popular search engine today, and the various Google sites, including its search engine, are among the most visited sites on the web (comScore 2016). Google’s dominance was already established a decade ago, and, despite inroads by Bing and Baidu, Google has continued to gain market share (see table 1.1). In 1999, Google was receiving 3.5 million search requests each day (Battelle 2005) and, while the growth has slowed in recent years, Google now receives at least a thousand times that number (Sullivan 2016), from more than a billion people each month. There can be little doubt that visits to search engines make up a large part of internet use, though it can be difficult to discover just how frequent that use is, and for what reasons.</p>
<p>One reason for this difficulty is that people often encounter the large search engines through the façade of another site – that is, without intending to. So a search on a particular website may rely on Google to do the actual searching, or it may draw on an internal search engine. Both of these are a form of search, but may be measured differently by different research firms (Hargittai 2004). Many portal sites are also search engines, so just measuring the visitors, for example, to Yahoo! properties does not provide a useful metric of actual searches. (And even if you did, those Yahoo! searches could just be repackaged Google searches: Sullivan 2015.) Facebook is not usually considered a “search engine” even though it handles a surprisingly large number of search queries on a daily basis. And the traditional search box accessed via the web is itself giving way with the shift to mobile technology as the primary form of access (Schwartz 2016); by 2015, more than half of the queries Google received were from mobile devices (Sterling 2015). As hard as measuring the use of public search engines is, it is nearly impossible to measure search more generally: people searching their company intranet or their hard drive, for example.</p>
<figure>
<figcaption>
Table 1.1 Global search engine use as of September 2016
<p><em>Source:</em> NetMarketShare (2016). ComScore rates Google sites with a slightly lower share.</p>
</figcaption>
<table>
<thead>
<tr>
<th>Search engine</th>
<th style="text-align:right">Global share (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Google</td>
<td style="text-align:right">73.02</td>
</tr>
<tr>
<td>Bing</td>
<td style="text-align:right">9.26</td>
</tr>
<tr>
<td>Baidu</td>
<td style="text-align:right">8.74</td>
</tr>
<tr>
<td>Yahoo!</td>
<td style="text-align:right">7.07</td>
</tr>
</tbody>
</table>
</figure>
<p>Particularly over the last decade, there has been a rise in specialized search engines that seek to index not the entire web, but some constrained portion. This might be referred to as “vertical search,” as opposed to the “horizontal search” of the general-purpose search engines, though this distinction has broken apart as the large search engine companies seek to acquire any novel approaches that might help them to win a share of submarkets. There remain certain areas that are in some sense naturally vertical, often because they index a part of the web that is not easily accessed (the so-called “dark web”) or because they are otherwise defined by linguistic, cultural, or political borders, as in the case of Baidu or Yandex; but it is more accurate to say that search has grown increasingly complex in a number of ways.</p>
<p>Topically constrained search engines seek out only pages within a particular knowledge domain, or of a particular type of content. Some of these vertical search engines are focused on a particular industry. For example, an attorney in the United States might turn to open sources like FindLaw to provide news and information about their practice; to Lawyers. com to find an attorney within a particular practice area; to THOMAS, a search engine maintained by the federal government to track legislation; or to TESS to try to find out whether a proposed trademark is likely to infringe on an existing one – in addition to employing a number of subscription-based search engines for legal information such as those provided by Westlaw and Lexis-Nexis.</p>
<p>The inverse of this may be general search engines designed for particular kinds of users. The most obvious example of this is government surveillance networks. The US National Security Agency draws in massive amounts of digital information from all over the world, “nearly everything a typical user does on the internet,” an estimated 20 trillion transactions in the US alone, and analyzes it using an indexing and query system called XKeyscore (Greenwald 2013). Companies also use sophisticated real-time search and analytics systems that sift through huge amounts of data (in 2010, Raffi Krikorian indicated that Twitter alone handled eight terabytes each day), and then provide that intelligence to private clients. A company called Echosec is one of several that correlate images shared via social media with their geographic location to infer emerging events ranging from military operations to natural disasters. The CEO of the company recently noted that it reminded him of the early days of search engines – a quickly evolving field where the query is more complex than a few keywords (El Akaad 2015).</p>
<p>While less constrained in terms of topic, academic search attempts to seek out a particular kind of document: one that adheres to traditionally scholarly constraints. At the most basic level, these sites are efforts to move databases that have traditionally been found in libraries onto the web. ScienceDirect, for example, provides reference to scientific literature for web users, and Google Scholar offers the utility of a large article and citation index provided by scholarly journals combined with other scholarly (and less scholarly) sources from the web, extending Google’s tentacles into an important space for search. But there are dozens of others that provide access to open (e.g., BASE) or closed (e.g., DeepDyve) collections of academic articles. New ways of discovering this work – including through social networking platforms and large-scale analytics – will mean that this area will continue to evolve rapidly.</p>
<p>Academia is far from the only topically constrained space for doing search. While general-interest search engines like Google can be used to ferret out illicit files, a number of search engines specifically serve this particular niche. Torrentz.eu, which was shut down in 2016 after being in service for 13 years, was a meta-search engine that provided links to torrent files on various torrent trackers. And the “deep web” is partially defined by being those sites obscured from the major search engines, but they often have search engines of their own. For sites available via Tor, a routing system intended to provide a layer of anonymity, there exist more than a dozen search engines, including Ahmia.fi, Grams, and DARPA’s Memex project. And data need not be illicit to be “deep.” SunXDCC provides search for files shared via Internet Relay Chat. Search aggregators exist for things like local Craiglist listings, data to help to assess stocks, game cheats, coupons, and the meta-search engines that allow you to search across multiple engines.</p>
<p>In sum, while the general-purpose search engines provide access to the broadest range of resources, there remains space for search engines that are either deliberately constrained or that reach into areas where Google’s “crawlers” do not dare to tread. Even more specialized forms of search draw together data that would not usually be considered “documents.” Wolfram Alpha is not a web search engine at all, but an attempt to provide answers to questions. It can tell me what my most-liked photo on Facebook is, what the tensile strength of oak is, or what the plot of a mathematical function is. Zanran seeks to aggregate sources of numerical and statistical data from the web, so that a search for “age at death of US presidents” links to sites that provide that information in tabular form. These represent a basic parsing of information beyond keywords. Much of the excitement around the “semantic web” and microformats has dissipated, but the idea that structured information can be extracted and queried from large unstructured collections, like the World Wide Web, remains promising. Those who are trying to be noticed by search engines will frequently include metadata in their pages, including geolocation or indications of contact information. Efforts to develop protein and genetic material search systems go back at least a decade (Liebel, Kindler, &amp; Pepperkok 2005), and a number of companies are now vying to be leaders in genomic search (Ossola 2015).</p>
<p>Thanks in large part to the shift to the mobile web, both searching for geographically constrained results and using geolocated data to constrain search have become vital. “Local search” has largely made local telephone directories a thing of nostalgia, allowing people to not only search for local businesses, but read reviews of those businesses written by their peers. Rather than competing with local search, many of the largest business directories (“yellow pages”) have created their own local search engines, as have local newspapers and television stations. Sometimes, being created within the same locale is enough to make two resources related. The Geo Search Tool (www.geosearchtool.com) or Google Earth can each help you find YouTube videos shot near the same location around the same time, providing a whole new way of thinking about organizing amateur video and other recording. And sometimes it need not be so explicit. Google has long localized results based on the general location of the searcher as revealed by their “IP (Internet Protocol) address.” While it is not clear how Google and other search engines use geographic signals at present, a patent in 2015 by Google (US 20150339397 A1) describes a method for predicting the location of the device used for a search as well as where the searcher is likely to go next.</p>
<p>Sometimes it is not the content area that determines the search, but the type of media. Although large search engines, beginning with AltaVista, generally have had some ability to search for multimedia, it continues to present some of the greatest challenges, as well as opportunities, for those creating new search technologies. Structured “metatags” can be leveraged when present, but it is extracting meaning from the content itself that is more difficult. A number of efforts have been made to extract the content of photographs and videos, often using machine learning. By seeing how humans classify the contents of a large number of photographs, a system may learn to replicate this skill when presented with an unclassified photograph. For this to work well, it generally requires a large number of human-classified examples. One of the reasons Facebook’s facial recognition system does well is that it can draw on a constant stream of human-assigned tags to help train it (Lachance 2016). As we move to devices that monitor the user’s environment, they may be engaged in ongoing image recognition, which represents a kind of continual search (Simonite 2013). Rather than categorizing multimedia, it may be enough to identify items that are in some way similar, as Google’s “search by image” does, or Shazam does when listening to a song in the environment and identifying it. Such similarity structures may prove to open doors to fundamentally different ways of searching and browsing music and video (e.g., the Songrium project: Masahiro, Goto, &amp; Nakano 2014). As we move away from text-based documents and queries, search engines will be called upon to effectively extract information from these less structured forms of media.</p>
<p>As more and more of the world becomes internetworked, both the method of search and the world of searchable things extends beyond the purely digital. It would have been difficult to imagine, even a few years ago, that a search query would consist of the words “Alexa, where are my keys?” spoken while standing in your kitchen (Crist 2016). While the contours of the “Internet of Things (IoT)” are still being sketched out, it seems clear that search will reach beyond digitized documents and draw in real-time data from our devices, our social networks, and other sources, aggregating them into a usable search result. We are only just beginning to see examples of how they might play out. Early IoT-specific search engines, such as Shodan and Thingful, have focused on locating internet-connected appliances, and have found themselves at the center of discussions around privacy and security. And it may end up being the IoT devices themselves doing the searching (Carlton 2016) – what happens when your fridge needs to find the perfect ingredient for tomorrow’s dinner party?</p>
<p>The line between a search engine and what has traditionally been called artificial intelligence is narrowing. In Steven Spielberg’s 2001 film A.I., the search engine is represented as a projected character known as “Dr. Know” (“Ask Dr. Know! There is nothing I don’t.”). A similar role was played by the holographic librarian named “Vox” in the 2002 remake of <em>The Time Machine</em>. Both depictions suggest a cultural recognition of search as a function that requires intelligence, and a feeling that machines can take on a part of that process. That idea is hardly new – for decades before the term “search engine” evolved, there had been interest in the relationship of search (often through structured relationships) to machine intelligence (Thornton &amp; Du Boulay 1992). IBM has focused much of its recent energy on the Watson “cognitive computing” platform, and has sold it in part as a solution for enterprise search, revealing “trends and patterns hidden in unstructured content.” Google is using machine learning to help to interpret user queries, employing an algorithm they call RankBrain to try to triangulate the meaning of a person’s query (Clark 2015).</p>
<p>And it is not just artificial intelligence that can provide answers – some of the answers you need are probably known by another human. Yahoo! Answers was launched in 1995, and while it has lost ground, it still attracts millions of users each month, according to Quantcast. Other Question-and-Answer (Q&amp;A) sites have grown over the last few years, including Quora and Stack Overflow, the latter of which provides answers to programming questions and, as of 2016, reaches 32 million people monthly. We might consider review sites, from restaurant and travel (like Yelp and Tripadvisor) to professional services (Angie’s List and Healthgrades), as serving as a kind of curated search. Of course, these are just some of the explicit Q&amp;A sites; implicitly, certain kinds of queries will be more effectively answered by others on Twitter or Facebook than they will be by a search engine.</p>
<p>At least for those of us who remember the time before search engines, they are defined by the query box on a web page. But search is both much bigger and much more complex than it once was. At one end, machine learning and analytics are drawing on almost unfathomable stores of unstructured data, finding patterns and connections within them that no human ever could. At the other end, individuals need to make sense of their “Personal Networked Spaces,” digital information that relates directly to them and to their lives, right now, right where they are (Michel, Julien, &amp; Payton 2014). Naturally, these tasks have existed before, but the size, extent, and diversity of the content of the web make it the ultimate target for such efforts. As a result, those who would have studied other topics in artificial intelligence, information design, library science, and a host of other fields have set their sights instead on developing better search engines.</p>
<h2>Before the search engine</h2>
<p>Some consider the greatest modern threat to be too much information, a glut of data that obscures what is really valuable. In his book <em>Data smog</em>, David Shenk (1997, p. 43) argues that computers are the “most powerful engines driving the information glut” by constantly drawing more data to our attention. While it is undoubtedly the case that the internet allows for the rapid delivery of ever growing amounts of information, it is also true that new computing devices were often created in order to manage and control increasingly complex environments. What once could be handled by a human, or a collection of individuals, became too time-consuming to result in effective control. So, in 1823, when the British government recognized the need for an effective replacement for human “calculators” to come up with tide tables at their ports, they funded an effort by Charles Babbage to design the first mechanical computer (Campbell-Kelley &amp; Aspray 1996). Likewise, when the United States government found that it would take more than ten years to tabulate the decennial national census in 1890, they turned to Herman Hollerith, who founded the company that later became IBM, to create an automatic tabulating system (Aul 1972). That pattern of turning to information technology when faced with an overwhelming amount of data has occurred over and over: in libraries, in large businesses, and, eventually, on the World Wide Web.</p>
<p>It is natural to think of information technology as digital computing, since so much of contemporary information processing is relegated to networked computers. Computers are only the most of complex collections and flows of information. The obvious example is the library: once a collection of books and papers grows to a significant size, finding the appropriate piece of information in a timely manner becomes the subject of its own techniques, records, and machinery. Collections of documents can be traced back nearly as far as history itself has been recorded; were cave drawings the first libraries? As Kaser (1962) explains, many spiritual traditions conceive of the library as eternal, and the librarian as all-powerful. As early private collections grew larger, librarians emerged to organize and manage these collections. Because libraries were so important to many classical civilizations, the librarian was in a revered and politically powerful position which required special skills in collecting and manipulating information. In some ways, entrusting the organization of library resources to an individual – taking a large collection and making an individual or group of librarians the gateway to that knowledge – represented the first kind of search engine. And, as with later incorporations of that role, gaining control of the resource meant ceding some degree of power to the librarian.</p>
<p>Large libraries have always been a nexus of potential information overload, and so techniques and technologies evolved to help us filter and find information. Sorting and finding items within these collections required the creation and maintenance of information about the collection: metadata. The Babylonian library at Nippur had such records of the collection as early as the twentieth century BCE. The nature of the need was simple enough: the librarian needed to be able to discover which documents addressed a given topic, and then find where that document was physically located so that it could be retrieved for the person requesting information. Given that the subject of a work was often the issue most closely indexed to an informational need, the most popular indexes in the English-speaking world – the Dewey Decimal System and the Library of Congress System – provide a classification that is based on the subject matter of a book, so that books on similar topics are likely to be found in close proximity. Indeed, the role of spatial organization and information structure have been closely tied through most of the history of humanity: information architecture was once simply architecture (Latimer 2011).</p>
<p>Unfortunately, the number of dimensions of indexes that can be represented within spatial organization is limited, and the focus soon shifted from spatial organization to other forms. The use of computing systems in libraries has formed an important basis for how search engines now work. There is a long history of ideas about how to organize knowledge in the library, but the rise of computing in a library setting brought mathematics and linguistics to bear in new ways, and some of the core techniques now used by search engines were first used by library indexes. The field of Information Retrieval (IR) now bridges the closed library index and the wider collection of documents on the web (Salton 1975), and draws from many areas of computing and information science to better understand the information available over computer networks.</p>
<p>Public and private libraries were not the only form of data collections. The industrial revolution led to new forms of social organization, particularly the rise of bureaucracy, which required a flood of new paper files. Records and copies of correspondence were generally kept on paper, and guides emerged for suggesting the best ways to organize these materials, including the best ways to stack papers on a desk. Paper stacking gave way to pigeonholes, and the business titans of the early twentieth century made use of a fabulously expensive piece of office furniture called the “Wooton desk,” which contained hundreds of pigeonholes and could be closed and locked, allowing for the secure storage of and access to personal work documents. The gradual development and innovation that led to vertical filing – a technology, perhaps unsurprisingly, developed by the inventor of the Dewey Decimal System – was a result of a data glut that began a century before anyone uttered the word “internet” (Yates 1982).</p>
<p>While subject-oriented classification made sense for the broad and relatively slowly changing materials of a library, it would have been useless when applied to the office of the last century. First, time was very much of the essence: when a document or file was created, changed, moved, or destroyed was often as important as the document’s subject matter. Likewise, such records were often closely related to the people involved. Clearly this was true of customer records, and large insurance companies – whose very survival rested on increasing the size of their customer base – often drove innovations in business filing, right through to adopting the earliest electronic computers.</p>
<p>The earliest computer systems drew on the ideas of librarians and filing clerks, but were also constrained by the technology itself. While these earlier approaches provided metaphors for digital storage, they failed to consider the hardware constraints posed by the new computing devices and placed limits on the new capabilities of these machines. Computer programmers made use of queues and stacks of data, created new forms of encoding data digitally, and new imaginary structures for holding that data. Not housed in drawers or on shelves, these collections could be rearranged and cross-indexed much more quickly than their physical counterparts. Over time, this evolved into its own art, and database design continues to be a rapidly advancing subfield of computer science. Ironically, as more and more books are digitized, or physical books are stored in closed stacks and their storage and retrieval are automated, the physical library is beginning to look more like a database.</p>
<p>As the internet began its exponential increase in size during the 1990s, driven by the emergence of the World Wide Web, it became apparent that there was more information than could easily be browsed. What began as the equivalent of a personal office, with a small private library and a couple of filing cabinets, grew to rival and exceed the size of the largest libraries in the world. The change was not immediate, and, in the early stages, individuals were able to create guides that listed collections at various institutions, generally consisting of freely available software and a handful of large documents. Especially with the advent of the web, the physical machine where the documents were stored began to matter less and less, and the number of people contributing documents grew quickly. No longer could a person browse the web as if it were a small bookshop, relatively confident that they had visited each and every shelf. Competing metaphors from librarians, organizational communicators, and computer programmers sought out ways of bringing order, but the search engine, in many ways, was a novel solution for this new information environment.</p>
<h2>How a search engine works</h2>
<p>Before outlining the development and commercialization of search over time, it is useful to understand how a basic search engine works. Our interaction with the classic search engine, as users, is fairly uncomplicated. A website presents a box in which we type a few words we presume are relevant, and the engine produces a list of pages that contain that combination of words. In practice, this interface with the person, while important, is only one of three parts of what makes up a search engine. The production of the database queried by the web form requires, first, that information about webpages be gathered from around the web, and, second, that this collection of data be processed in such a way that a page’s “relevance” to a particular set of keywords may be determined. By understanding the basic operation of each of these steps and the challenges they pose, an overall understanding of the basic technology may be reached. Figure 1.1 provides an overview of the process common to most search engines.</p>
<p>The process begins with a system that automatically calls up pages on the web and records them, usually called a crawler, but sometimes referred to as a “spider,” “web robot,” or “bot.” Imagine a person sitting at a computer browsing the web in a methodical way. She begins her process with a list of webpages she plans to visit. She types the URL for the first of these pages into the browser. Once it loads, she saves a copy of the page on her hard drive, noting the time and the date. She then looks through the page for any hyperlinks to other pages. If she finds hyperlinks that are not already on her list, she adds them to the bottom of the list. Following this pattern, she is likely to record a large part of the entire web. Once complete, she would begin again from the top of her list, as there are probably changes to these pages and newly created pages that have been published and linked to since she began.</p>
<figure>
<p><img src="/assets/search_engine.png" alt=""></p>
<figcaption>
Figure 1.1 Conceptual organization of the typical search engine 
</figcaption>
</figure>
<p>If the search engines really relied on individual humans to do this, it would take thousands of years to complete even a single crawl of the web. However, the operation described is not particularly complex, and creating a computer program that can duplicate this behavior is not difficult. Because the crawler is a relatively simple piece of technology, it has not evolved as much as other parts of the search engine. Even the smallest-scale crawlers are usually multi-threaded, making many requests at the same time rather than waiting for each page to be produced before moving on. They generally run not on a single computer, but on a large number of computers working in tandem. Most are careful to distribute their requests across the web, rather than ask for all of the pages from one server at once, since the crush of requests could easily overwhelm a single server, and most are “polite,” taking into account webpage authors’ requests for certain pages to be ignored. Nonetheless, these crawlers can sometimes make up a substantial number of the requests to a less-trafficked website. By one estimate, roughly half the traffic on the web is generated by these non-human visitors (Piejko 2016).</p>
<p>That does not mean that crawlers are all the same. There is an entire menagerie of crawlers out looking for new content on the web. On many pages, visits by web robots outnumber visits by real people. Some of these – going by exotic names like Slurp and Exabot – are gathering information for the largest general-purpose search engines, but others may be run just once by an individual. Small crawlers are built into a number of applications, including plug-ins for browsers and a bot used by Adobe Acrobat to create a PDF from a website. Because of small differences in how they are programmed, they behave slightly differently, following some links and not others, or coming back to re-check more or less frequently. Publishers of websites can exercise some level of control over Google’s bot, through tools provided online, and most crawlers will obey a set of rules presented in a special “robots.txt” file a publisher may place on the server. But beyond these limited restrictions, the bots attempt to capture information from as much of the web as possible, as frequently as possible.</p>
<p>Following hyperlinks may not be enough. Large portions of the web are now generated dynamically, according to various requests from website visitors. Think, for example, of an online site that provides theatre tickets. The calendar, the pages describing available tickets, or even the seating maps may change depending on the show, the location of the person accessing the site, the current date, previous sales, and other variables. The modern webpage is probably not just generated dynamically by the server based on the content of a database, but built with HTML in combination with CSS and Javascript, and it often updates sections of the page on the fly (AJAX), creating a special challenge for the crawler (Mesbah, van Deursen, &amp; Lenselink 2011; Google 2014).</p>
<p>Most crawlers make an archival copy of some or all of a web-page, and extract the links immediately to find more pages to crawl. Some crawlers, like the Heritrix spider employed by the Internet Archive, the “wget” program often distributed with Linux, and web robots built into browsers and other web clients, are pretty much done at this stage. However, most crawlers create an archive that is designed to be parsed and organized in one way or another. Some of this processing (like “scraping” links, or storing metadata) can occur within the crawler itself, but there is usually some form of processing of the text and code of a webpage afterward to try to obtain structural information about it.</p>
<p>The most basic form of processing, common to almost every modern search engine, is extraction of key terms to create a keyword index of the web by an “indexer.” We are all familiar with how the index of a book works: it takes information about which words and ideas appear on any given page and reverses it so that you may learn which pages contain any given word or idea. In retrospect, a full-text index of the web is one of the obvious choices for finding material online, but particularly in the early development of search engines it was not clear what parts should be indexed: the page titles, metadata, hyperlink text, or full text (Yuwono et al. 1995). If indexing the full text of a page, is it possible to determine which words are most important?</p>
<p>In practice, even deciding what constitutes a “word” (or a “term”) can be difficult. For most western languages, it is possible to look for words by finding letters between the spaces and punctuation. This becomes more difficult in languages like Chinese and Japanese, which have no clear markings between terms. In English, contractions and abbreviations cause problems. Some spaces mean more than others; someone looking for information about “York” probably has little use for pages that mention “New York,” for instance. A handful of words like “the” and “my” are often dismissed as “stop words” and not included in the index because they are so common. Further application of “natural language processing” (NLP) is capable of determining the parts of speech of terms, and synonyms can be identified to provide further clues for searching. At the most extreme end of indexing are efforts to allow a computer to in some way understand the genre or topic of a given page by “reading” the text to determine its meaning.<sup>1</sup></p>
<p>An index works well for a book. Even in a fairly lengthy work, it is not difficult to check each occurrence of a keyword or idea, but the same is not true of the web. Generally, an exhaustive examination of each of the pages containing a keyword is impossible, particularly when much of the material is not just unhelpful, but – as in the case of spam – intentionally misleading. This is why results must be ranked according to perceived relevance, and the process by which a particular search engine indexes its content and ranks the results is really a large part of what makes it unique. One of the ways Google leapt ahead of its competitors early on is that it developed an algorithm called “PageRank” that relied on hyperlinks to infer the authority of various pages containing a given keyword. Some of the problems of PageRank will be examined in a later chapter; here, it is enough to note that the process by which an index is established, and the attributes that are tracked, make up a large part of the “secret recipes” of the various search engines.</p>
<p>The crawling of the web and processing of that content happen behind the scenes, and result in a database of indexed material that may then be queried by an individual. The final piece of a search engine is its most visible part: the interface, or “front end,” that accepts a query, processes it, and presents the results. The presentation of an initial request can be, and often is, very simple: the search box found in the corner of a webpage, for example. The sparse home page for the Google search engine epitomizes this simplicity. However, providing people with an extensive set of tools to tailor their search, and to refine their search, can lead to interesting challenges, particularly for large search engines with an extremely diverse set of potential users.</p>
<p>In some ways, the ideal interface anticipates people’s behaviors, understanding what they expect and helping to reveal possibilities without overwhelming them. This can be done in a number of ways. Clearly the static design of the user interface is important, as is the process, or flow, of a search request. Westlaw, among other search engines, provides a thesaurus function to help users build more comprehensive searches. Over time, search engines have picked up certain interface elements, and kept them or left them behind based on response from those interacting with search. Type-ahead search queries, which pre-populate the search box with the top matching queries, were something experimented with by several search engines in the mid-2000s. Now they are a mainstay not just on the major search engines but on many other interfaces that draw on user input (Li et al. 2009). After declaring no interest in social signals for search (e.g., drawing on search results based on what friends produced or searched for), Google for a time provided indications of social results, including a feature they called “Search Plus Your World,” which indicated how your social network was affecting which sites appeared in the results pages. Although by all accounts Google continues to include social signals, neither relationship nor authorship is indicated in the results pages any longer. As more traffic shifts to mobile devices, it seems likely that interfaces that are easier to use without a keyboard, including those that are voice-related and that incorporate the locative context, will be the most visible to those who search online.</p>
<p>Once a set of results are created, they are usually ranked in some way to provide a list of topics that present the most significant hits – sites that contain the keywords – first. The most common way of displaying results is as a simple list, with some form of summary of each page. Often the keywords are presented in the context of the surrounding text. In some cases, there are options to limit or expand the search, to change the search terms, or to alter the search in some other way. On some search engines, results are clustered by topic.</p>
<p>All three of these elements – the crawler, the indexer, and the front end – work together to keep a search engine’s index continuously updated. The largest search engines are constantly under development to better analyze and present searchable databases of the public web. Some of this work is aimed at making search more efficient and useful, but some is required just to keep pace with the growing amount of content available online. The technologies used on the web change frequently, and, when they do, search engines have to change with them. As people employ document formats other than HTML (PDF-formatted documents, for instance), visual formats, or complex interactive sites, search engines need to create tools to make sense of these formats. The sheer amount of material that must be indexed increases exponentially each year, requiring substantial investments in computing hardware and bandwidth. As of 2011, Google data centers used as much electrical power as would normally provide for 200,000 homes (Glanz 2011). Someone visiting a skyscraper can quickly appreciate the work that went into building it, but few are aware of the work that must be continually done to make a search engine function.</p>
<h2>Pre-web internet search</h2>
<p>Once one has used a search engine, it seems obvious that it should exist, but the need for a general search engine during the early days of the web was neither immediate nor apparent. It usually is not until a collection of data grows too large to map in its entirety that the need for a search interface is made clear. Consider the average home library, which may fill only a bookcase or two. The books may be placed randomly, or by size, or by which are used more often or more appreciated, or by some idiosyncratic subject arrangement. At some point, however, a library grows to the point at which looking through everything to find the book you want is impractical, and at that point some form of indexing is necessary. Likewise, networked information started out as relatively small collections in relatively few repositories, and it was not until later that the need for different forms of indexing was made clear and tools were created to meet this need.</p>
<p>Early technologies used for finding files or users were often built into the operating system and, once computers were networked, it was often possible to use the same functions from a distance. Since long before the web has existed,<sup>2</sup> the Unix command “finger,” for example, has provided information about a particular user, including when that user last logged on, and often some personal contact information. Its creator, Les Earnest, designed “finger” to aid in social networking at the Stanford Artificial Intelligence Lab (quoted in Shah 2000):</p>
<blockquote>
<p>People generally worked long hours there, often with unpredictable schedules. When you wanted to meet with some group, it was important to know who was there and when the others would likely reappear. It also was important to be able to locate potential volleyball players when you wanted to play, Chinese food freaks when you wanted to eat, and antisocial computer users when it appeared that something strange was happening on the system.</p>
</blockquote>
<p>When computers were networked via the internet, it was possible to “finger” individuals from across the country or the world, to find out more about them. Eventually, it was used for other purposes, including distributing weather reports.</p>
<p>The first indexes on the internet were created by hand, often by the users of the systems as a guide to others. Consider some of the protocols in use on the internet before the emergence of the World Wide Web, beginning with “File Transfer Protocol” (FTP), one of the first ways of moving files between computers. An early internet user would choose an FTP server from a list of public servers (a list they or someone else probably had downloaded from one of the servers on that list), and request a listing of files on that server. Often, there was a text document that could be downloaded that briefly summarized the content of each of the files on a given server. FTP continues to be used today as a way of transferring files, but the process of browsing through FTP servers in the hope of finding the document you were seeking was laborious and inconsistent, especially as the number of FTP servers increased. This increase also brought with it the rise of “anonymous” FTP servers, which allowed anyone to upload and download files to and from the server. While the increase in content was a boon to those who used the internet, it became increasingly difficult to locate specific files. As a result, what might be considered the first search engine on the internet arrived in 1990, before the World Wide Web had gained a foothold, and at a time when many universities had only recently become a part of the network (P. Deutsch 2000). This system, called “Archie,” periodically visited the existing FTP sites and indexed their directories. It is probably a stretch to say that it “crawled” these sites, since, unlike today’s web crawlers, it did not discover new servers linked to the existing servers. It also did not examine the full content of each of these pages, but limited itself to the titles of the files. Nonetheless, it represented a first effort to rein in a quickly growing, chaotic information resource, not by imposing order on it from above, but by mapping and indexing the disorder to make it more usable.</p>
<p>The “Gopher” system was another attempt to bring order to the early internet. It made browsing files more practical, and represented an intermediary step in the direction of the World Wide Web. People could navigate through menus that organized documents and other files, and made it easier, in theory, to find what you might be looking for. Gopher lacked hypertext – you could not indicate a link and have that link automatically load another document in quite the same way it can be done on the web – but it facilitated working through directory structures, and insulated the individual from a commandline interface. “Veronica,” named after Archie’s girlfriend in 1940s-era comics, was created to provide a broader index of content available on Gopher servers. Like Archie, it provided the capability of searching titles (actually, menu items), rather than the full text of the documents available, but it required a system that could crawl through the menu-structured directories of “gopherspace” to discover each of the files (Parker 1994).</p>
<p>In 1991, the World Wide Web first became available, and with the popularization of a graphical browser, Mosaic, in 1993, it began to grow more quickly. The most useful tool for the web user of the early 1990s was a good bookmark file, a collection of URLs that the person had found to be useful (Abrams, Baecker, &amp; Chignell 1998). People began publishing their bookmark files to the web as pages, and this small gesture had an enormous impact on how we use the web today. The collaborative filtering and tagging sites that are popular today descended from this practice, and the updating and annotating of links to interesting new websites led to some of the first proto-blogs. Most importantly, it gave rise to the first collaborative directories and search engines.</p>
<p>The first of these search engines, Wandex, was developed by Matthew Grey at the Massachusetts Institute of Technology, and was based on the files gathered by his crawler, the World Wide Web Wanderer. It was, again, developed to fulfill a particular need. The web was made for browsing, but perhaps to an even greater degree than FTP and Gopher, it had no overarching structure that would allow people to locate documents easily. Many attribute the genesis of the idea of the web to an article that had appeared at the close of the Second World War entitled “As we may think,” in which Vannevar Bush (1945) suggests that a future global encyclopedia will allow individuals to follow “associative trails” between documents. The web grows in a haphazard fashion, like a library that consists of a pile of books that grows as anyone throws anything they wish onto the pile. A large part of what an index needed to do was to discover these new documents and make sense of them. Perhaps more than any previous collection, the web cried out for indexing, and that is what Wandex did.</p>
<p>As with Veronica, the Wanderer had to work out a way to follow hyperlinks and crawl this new information resource, and, like its predecessors, it limited itself to indexing titles. Brian Pinkerton’s WebCrawler, developed in 1994, was one of the first web-available search engines (along with the Repository-Based Software Engineering [RBSE] spider and indexer – see Eichmann 1994) to index the content of web-pages. This was important, Pinkerton suggested, because titles provided little for the individual to go on; in fact, a fifth of the pages on the web had no titles at all (1994). Receiving its millionth query near the end of 1994, it clearly had found an audience on the early web, and, by that time, more than a half-dozen search engines were indexing the web.</p>
<h2>Searching the web</h2>
<p>Throughout the 1990s, advances in search engine technology were largely incremental, with a few exceptions. Generally, the competitive advantage of one search engine or another had more to do with the comparative size of its index, and how quickly that index was updated. The size of the web and its phenomenal growth were the most daunting technical challenges any search engine designer would have to face. But there were some advances that had a significant impact. A number of search engines, including SavvySearch, provided metasearch: the ability to query multiple search engines at once (Howe &amp; Dreilinger 1997). Several, particularly Northern Light, included material under license as part of their search results, extending access beyond what early web authors were willing to release broadly (and without charge) to the web. Northern Light was also one of the first to experiment with clustering results by topic, something that many search engines continued to develop. Ask Jeeves (which became Ask. com) attempted to make the query process more user-friendly and intuitive, encouraging people to ask fully formed questions rather than use Boolean search queries, and AltaVista provided some early ability to refine results from a search.</p>
<p>One of the greatest challenges search engines had to face, particularly in the late 1990s, was not just the size of the web, but the rapid growth of spam and other attempts to manipulate search engines in an attempt to draw the attention of a larger audience. A later chapter will address this game of cat-and-mouse in more detail, but it is worth noting here that it represented a significant technical obstacle and resulted in a perhaps unintended advantage for Google, which began providing search functionality in 1998. It took some time for those wishing to manipulate search engines to understand how Google’s reliance on hyperlinks as a measure of reputation worked, and to develop strategies to influence it.</p>
<p>At the same time, a number of directories presented a complementary paradigm for organizing the internet. Yahoo!, LookSmart, and others, by using a categorization of the internet, gave their searches a much smaller scope to begin with. The Open Directory Project, by releasing its volunteer-edited, collaborative categorization, provided another way of mapping the space. Each of these provided the ability to search, in addition to browsing their directory structures. Since the indexed material had already been selected, often by hand, as being of general interest or utility, searches on these sites could be very effective. Eventually many of these directory-based portals became major players, particularly Yahoo!, which experimented with a number of search engine partnerships, beginning with combining Inktomi’s search technology with their existing directory in 1998, and eventually acquiring some of the largest general-purpose search engines, including AlltheWeb.com, AltaVista, and HotBot.</p>
<p>The early development of search engines was largely centered in the United States. By the middle of the 1990s, the World Wide Web was beginning to live up to its name, and sites could be found in many parts of the world, but American sites in English continued to make up the bulk of the web. Around the mid-1990s, the number of web users and websites exploded in Europe, as well as Hong Kong, New Zealand, and other countries. While sites were increasingly hosted “world-wide,” the hyperlinks from them either led back to the US or remained within the hosting country. They only very rarely linked to a third country (Halavais 2000). Likewise, users in these countries tended to purchase items from local merchants rather than taking advantage of the global web-based marketplace (Jupiter Communications 1999). Just as search engine competition was heating up in the United States, many around the world were asking why they should use a search engine that was not suited to their own culture and language. The World Wide Web tended to reinscribe existing global flows of information, even as it presented some alternatives.</p>
<p>The rise of regional search engines is often left out of the history of search, but, by the mid-1990s, many countries and linguistic groups were relying on services tailored to their own languages and interests. Early examples included the Swiss search.ch, an Israeli engine called Walla, France’s Voilà, and the Russian Rambler. More recently, non-English-language search is again in the news, with China’s Baidu attracting a strong global following, joined by Yandex in Russia, Naver in Korea, and others focused on Japan, Sweden, Israel, the Czech Republic, Iceland, and more.</p>
<p>By the mid-2000s, search engines had re-ordered the web, making it search-centric. While the anachronistic phrase “surfing the internet” remained, the dominant paradigm was no longer moving from site to site in a sea of hyperlinks, but rather searching for specific items, or browsing through particular guides. In the late 1990s, Jacques Altaber, an official at CERN (Conseil Européen pour la Recherche Nucléaire), the organization that first supported the World Wide Web, suggested that the web would become a new sort of operating system, the platform on which an ever greater proportion of our communication and information tasks would take place (James 1995). By the mid-2000s, search engines became central to that operating system, moving from a useful tool to a powerful focal point of collective attention. Today, although the search box is losing its primacy as the “front door” of the web, the influence of the search engine continues, just beneath the surface. Even when visible, search has largely been taken for granted. Now that it has begun to recede beneath various interfaces, working behind the scenes of our everyday interactions online, it retains that influence while becoming even more obscured.</p>
<p>Many of those who initially developed search engines did so because they had a need and answered it. Many successful search engines were designed by students, and some of those pioneers now work in what has become a substantial search engine industry. The author of Wandex, for example, eventually worked for Google, and the creator of the original WebCrawler moved on to work on a blog search engine called Technorati, each improving on the technology of search. But WebCrawler is emblematic in another way. It was developed in 1993, a year that was important because it marked the commercialization of the World Wide Web, and, with it, the search engine. By 1994, WebCrawler had two commercial advertisers sponsoring the site, and, in the middle of 1995, it had been acquired by America Online as part of their effort to bridge to the web. The story of the development of the search engine is tied inextricably to the commercialization of the online world, and although there continue to be a number of important search engines that are supported directly or indirectly by government or research funding, the search engine wars of the 2000s were driven by the potential profit of online advertising.</p>
<p>The rise of the search engine coincided with the dot-com bubble, especially during the late 1990s, and large sums were invested in developing new and existing search engines and competing for a share of the search engine market. Over time, many of these search engines were acquired by their competitors, and the field narrowed somewhat. By the early 2000s, Google had come onto the scene and rapidly seized a large proportion of the global search market. At present, Google remains the most popular destination for those who want to do a search. There remain other search engines, of course. Microsoft began offering MSN Search in 2005, followed by Live, and then Bing. Others around the world are seeking to capitalize on the search infrastructure of the web, and the potential profits that come with the ability to shape attention and traffic. But Google remains synonymous with search.</p>
<h2>Commodifying search</h2>
<p>The story of search is not simply a technological one; the rise of search goes hand-in-hand with the commercialization of the internet. This is despite the fact that search on the open web is almost universally offered as a free-to-the-customer service. Certainly, enterprise search – providing a search engine for services within an organization – is sold to businesses, universities, and others. But for the giant search engines we are most familiar with, search is provided without charge. And yet the digital economy revolves around search.</p>
<p>With $16.3 billion in profits in 2015, Google’s holding company, Alphabet, was the eighth most profitable business among the Fortune 500, and Google’s revenues have continued growing at a relatively stable rate since the company’s birth. It has long been the dominant search engine, but that reach continues to grow. It has faced a range of antitrust suits, particularly in Europe, and the ultimate effect of these remains an open question. How is it that a company whose core product is free has been so profitable? The most obvious answer to that question is that Google may be a leader in search, but it is more centrally an advertising company.</p>
<p>While Google makes money in a wide range of areas, including selling mobile hardware and search appliances for enterprise search, and provides services (Gmail, Chrome, YouTube) or does research in an even broader set of contexts, the vast majority of its income comes from selling advertising on its own sites and on partnered sites. In this, it is not entirely different from over-the-air television, which is often in the business of “selling eyeballs to advertisers.” Some of these sales are, of course, directly related to their search business. Like many companies, Google places advertising “adjacent” to real search results. But it has also made it much easier for small businesses to bid for advertising in a range of spaces by offering a reverse auction on keywords, a model that now makes up a large part of web advertising as a whole. And, as part of this process, it collects and uses information about its users to target advertising better. There is a significant economic motivation for drawing as many users as possible to its properties, and traditionally search has been an attractive way to do this (see Hillis, Petit, &amp; Jarrett 2012, p. 36).</p>
<p>The major driver of the search engine wars was a recognition that search drew traffic. Less obvious is the power of search to shape traffic: not only does it draw in users, but directs them to other parts of the web. As we will see, the search engines have the power to grant fortunes and to take them away – it is as if they are the builder of roads, stoplights, and front doors for every business online. Naturally, it is vital for search companies to maintain the credibility of their search, and so – at least in the case of general search – they insist that their results are in some sense the “naturally” best match for your query. Nonetheless, the acute attention they garner from both people who are searching the web and companies that are seeking to reach customers makes them a source of significant economic value.</p>
<p>All of that attention has been “baked into” the algorithms that drive search. In particular, one of the earliest sectors of profitable sales online was pornography, and there was significant financial incentive for drawing visitors to websites with adult materials. Search engines were placed in the position of resisting the influence of companies and individuals who sought to lure visitors to such sites, and, again, this affected and shaped the algorithms and the approaches that were embedded in search. A case could be made that a large part of Google’s success was in producing a process that was more capable of resisting such attempts.</p>
<p>For better or worse, the worldviews of those search companies and the engineers who shaped search are made a part of the search process. Some of the competition in search results is because those worldviews are not as universal as people within the bubble of Silicon Valley might imagine. Some alternative search engines limit results to those documents that do not tread into moral or religiously objectionable material (including HalalGoogling.com and Yippy.com), or, on the other side of the coin, there are search engines (including Boodigo.com) intended for those who find the most popular search engines restrict pornography too much. A number of sites, most notably DuckDuckGo, trade on the notion of protecting the user’s information and not providing it to advertisers (and likewise not shaping results based on previous searches). And, as noted, a number of search engines have successfully developed indexes that serve particular linguistic or cultural communities, often with some support from governments in the area. While these examples are intended to exploit areas in which the generalized search engines do not meet customer needs, the search engine giants have significant advantages in having the largest web index and the ability to respond quickly to large numbers of visitors.</p>
<p>The enterprise search market has also provided space for search engines on a different scale. Early on, it seemed as though the largest search purveyors would also dominate this area, leveraging their large-scale efforts (Hines 2007), but a number of vendors have emerged offering a range of products. Enterprise search often must pull from different sources of data (including various databases, email, and potentially both shared and personal disk drives), must manage different levels of access and security, and in some cases must provide a form of backup or archiving, either to protect organizational data or to respond to regulatory requirements. Particularly as these systems integrate with analytics and draw in new kinds of machine learning, it may be that they provide a proving ground for technologies that will then move to general search engines, rather than the other way around (Simone 2015).</p>
<p>Not listed in the above menagerie of search engines is Facebook, which now handles more than 2 billion searches per day (Constine 2016). Like Google, it is developing machine learning – they call their system Deep Text – to analyze the content and sentiment of posts and make them more searchable (Murphy 2016). This is not the general search represented by Google, Bing, and Baidu, but the frequency of use makes it just as important to consider, especially when the nature of search has shifted so much toward social platforms over the last decade. Search engines became central to the web because resources were so widely distributed and difficult to find. Social platforms have changed that, and for many people their link to the rest of the web is via social platforms. In 2016, 62 percent of Americans got their news via social media, more than a 20 percent increase over the number in 2012 (Gottfried &amp; Shearer 2016). More generally, platforms like Facebook, Twitter, Reddit, and others serve, as the motto for Reddit notes, as a “front page of the internet,” and the kind of browsing of the web that used to happen individually now happens more collectively. In some ways, a search of Facebook is a web search, with the millions of words Facebook users type each day serving as a kind of index of the web and beyond. Major search engines have included social signals in various ways in order to produce better search results, but those social connections – which have always been important – have now taken on a much greater importance, and future innovations in search will probably rely heavily on the kinds of meaning that can be extracted from social platforms.</p>
<h2>Search and society</h2>
<p>Search engines were developed as a response to a particular social problem, a problem that did not exist in the same way in the past. The signature technology of the last few decades has been digitization: the ability to transfer communications media into a format that may be transmitted via computer networks. As a result, more information is available in more places than ever before. This embarrassment of riches has necessitated new ways of filtering, sorting, and finding information. This is an old story – necessity as the mother of invention – and it is tempting to leave it at that. Indeed, the technical problems are challenging and exciting. It would be wrong to assume, however, that the social and cultural needs that led to the creation of search engines no longer are of import. Perhaps more than ever, our evolving ideas of what a search engine should do shape its development, either by creating new needs (finding video content, for example), or in some cases by resisting change in favor of familiarity. It is important, if we want to understand the technology better, to understand the social and informational environments in which it is deployed. Social context makes search what it is.</p>
<p>Understanding how people use search engines can also give us a seemingly unobtrusive way of learning about society’s interests in the aggregate. Encouraged in part by Google’s Zeitgeist pages, which provided an indication of search terms that had become suddenly more popular in a given week, John Battelle (2005) presented search engines as a source of a sort of global “database of intentions,” providing what could ultimately become a fine-grained map of our interests and personalities as individuals and groups. In other words, by learning how people behave when using search engines, we may come to understand how they behave in general. Since that suggestion, social scientists’ interest in what has come to be called “big data” has grown exponentially, and the idea that micro-expressions on the social web might be analyzed to better understand sociality is no longer novel. Searching for answers is perhaps the most human of social activities, and we can now study it in ways we have never been able to in the past.</p>
<p>In part, this is because watching the search process online is fairly unobtrusive. The problem is that we are observing a moving target. How most people searched for new information in 2000 differed significantly from how they did so in 2015. By 2030, we will have again changed the schema with which we discover new information. We are living through a period of extremely rapid change in how we interact socially, and search is the bleeding edge of that. How we decide what we need to know, how we find material that will address that information deficit, and how we evaluate and make choices based on those discoveries are all changing nearly as quickly as the topographies of interaction online do. So, while search engines and search mechanisms more broadly offer a window on information-seeking and decision-making, the bigger question is how they are changing the way we relate to the world and think about discovery, because the change in search technology is important, but not nearly as important as how we are changing as searchers.</p>
<p>No new technology leaves us unchanged, and often the changes are unexpected and unpredictable. More than two millennia ago, Plato was already making the case that communication technologies changed who we were, and not always for the better. Rather than enhancing memory, he argues in the Phaedrus (2002), writing subsumes it, and reduces the abilities of those who read rather than remember. Someone visiting a university library in the early 1980s would still have found a card catalog, and would have been able to observe more of the inner workings of the search process. This has now been replaced by a popular acronym, JFGI: Just Fucking Google It. The effort of seeking out an index and evaluating potential resources has been replaced by pressing a button and “feeling lucky.” As with earlier technological advances, this is not a tool with simple consequences. The double edge of technology – and particularly of communication technology, since communication is at the core of our social interactions – represents one of the most pressing reasons we must examine the role of the search engine not just in society, but in permeating our social lives. The following chapter examines how we use search engines, and how they have, in turn, changed us.</p>
<h2>Notes</h2>
<ol>
<li>
<p>For a more thorough overview of the technical elements of search engine construction, see Büttcher, Clarke, &amp; Cormack (2010).</p>
</li>
<li>
<p>This section discusses search on networked computers, including what would come to be known as “the internet,” in the decades preceding the emergence of the web. The web is so ubiquitous at this point that</p>
</li>
</ol>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="Commendary Cultures"
class="paper-story"
data-article-title="Commendary Cultures"
>

<h1 class="article-title" id="h_Commendary Cultures">Commendary Cultures</h1>

<div class="top-meta">Fiona Martin, 2021-06-23 06:01:00 AEST. for week 7.</div>

<p>Social sharing of news has a critical economic and cultural function in an attention economy. It reveals our personal interests, beliefs and tastes to the array of publications trying to win our interest and identifies to them and our social networks what is valuable to us in the cascades of data that we negotiate every day. Through our shares, likes and favourites we help the social platforms determine what is popular and profitable in advertising terms. We also elevate certain events and issues in public debate, and reinforce opinions and attitudes in our social circles. Thus, if most mainstream media users are more likely to redistribute, like or recommend news than to create it, then news sharing is potentially as important a phenomenon to study as participatory or citizen journalism.</p>
<p>This makes it imperative for reporters, editors and news executives to understand, beyond the metrics they might receive about Facebook or Twitter trends, what motivates news sharing in different contexts, as well as how and why we are likely to share stories we come across online. It is also important to recognise how the platforms have ensured news sharing is imbricated in the rhythms of everyday life online and integrated into the editorial processes of news rooms. This shift is driving the reorganisation of news production, consumption and distribution, and redirecting economic, political and cultural power away from the legacy media and towards the platforms.</p>
<p>It’s easy to focus on social media platforms as the primary site of news sharing, as they are designed precisely for that purpose: the easy personal exchange of information with what passes for a self-built social network (although recommendation algorithms play a big role in helping us constructing that sociality). Social media companies make sharing simple to encourage us to disclose more about our everyday lives, so they can analyse that routine evidence of activities and preferences to create more effective forms of advertising. It’s a twenty-first-century design for a radical, globalised consumer sovereignty that seeks to make as much social behaviour as possible accessible to corporate scrutiny or, as Facebook’s most durable first decade mission statement more altruistically puts it, “To give people the power to share and make the world more open and connected”
(Reagan 2009).</p>
<p>Yet, news sharing also takes place via email, apps, forums and other online channels, just through the posting of hyperlinks—a practice as old as the World Wide Web, and which has its basis in earlier hypertext systems. Each time we post a link to a news story, we are curating from our own feeds what might be of interest to others, recommending what they should attend to and demonstrating something of our own concerns and biases. Link sharing is not always an endorsement of the content, but demands those who click through consider its meaning and worth. So, this chapter explores how social news sharing has become central to the creation of commendary cultures online, where ordinary people take on the representational and distributive roles of the news media, as well as something of journalism’s filtering and evaluative functions. It explores the pre-history and evolution of news sharing technologies and the emergence of different ideas about what sharing means, why we do it and how it’s affecting digital journalism.</p>
<p>If link sharing is the basis for online news exchange, how then did social media become synonymous with this practice, to the extent that people around the globe now see these channels as key news sources? To answer this question, we first need to establish what qualifies as ‘social media’. As new media scholar Graham Meikle notes this term evokes “a particular set of technological affordances, a particular set of business models and corporate practices, a particular set of organisations, and a particular set of cultural habits, practices and expectations” (2016: x). The organisations are well recognised worldwide and becoming virtual monopolies in their various niches by virtue of their transnational scale and market dominance. By late 2016, Alphabet (owner of Google and YouTube), Facebook (with Whatsapp and Instagram) and Microsoft (LinkedIn and Yammer) were among the largest companies internationally by market capitalisation, bigger than the finance and energy companies they had succeeded on that list (Flew et al. 2018). Facebook is now the world’s most popular social media platform, with around 2.19 billion monthly active users in the first quarter of 2018. In the same period, WeChat has reached 1 billion Chinese users alone, more than Twitter has worldwide, while YouTube dominates video sharing and video on demand advertising globally.</p>
<p>While each company has a distinct business model, on the whole, the biggest players’ economic success has been based in five factors:</p>
<ol>
<li>broadening the base of production to every subscriber;</li>
<li>making global communication and publishing easier through templating and automation;</li>
<li>reducing or removing the geographic boundaries to social and business transactions;</li>
<li>aggregating and analysing user created data to create more efficient, individually targeted advertising sales models; and 5. operating as international information technology companies rather than national media publishers, which has until recently put them outside traditional media content regulations and allowed them to publish content that others could or would not.</li>
</ol>
<p>Economist Yochai Benkler (2004) suggests internetworked social sharing of information has proved a more efficient form of distribution than historic market forces. It is decentralised, avoiding the strictures, conventions and routines of corporate news gatekeepers; autonomous, allowing anyone and everyone with network access to take part, and personalised, in tying the act of recirculating news to communicative rituals and social conventions of information gifting and reciprocation.</p>
<p>Social media companies’ technological affordances have enabled us to increase our everyday news sharing, extending it to large, curated social networks. Starting with Six Degrees, launched back in 1997, and then Friendster in 2002, social networking applications allowed users to create public or semi-public personal profiles, to build a list of social connections that they could easily navigate, and to communicate publicly or privately with those people using templated publishing tools (Hinton and Hjorth 2013). Later social media technologies also enabled users to create, aggregate, evaluate and share media, to create groups and audiences for this content, and to monitor user analytics based on that service interaction. From 2006, Facebook and others provided widgets or limited functionality scripts for publishers to embed in their sites so users could subscribe to news publishers’ social media channels, or share a story link directly on reading it on a branded website, and later, mobile apps for continuous access to this sharing capacity.</p>
<p>All of these strategies were designed to simultaneously extend our customised communicative reach and to automatically co-opt more users and publishers into the orbit of platform analysis, in what critical media studies scholar Jose van Dijck and Poell (2013: 8) calls a “double logic” of connectivity. Platform analytics are not only “perpetually operational” and so pervasive that we don’t notice them (as [Kennedy 2016: 25] suggests), but are also designed to reward and reinforce our participation; to make it addictive using a series of behaviour reinforcing communication strategies (Alter 2017). Alerts or notifications from our social media feeds tell us how much attention our posts are getting, and detail our network members’ activities, to encourage our reciprocity and to routinise our sharing activity. Sometimes, gamification is built into the systems, so that we are notified where in a hierarchy of users we are placed as a result of our activity. In these ways, platforms cultivate habits of documentation, declaration, discussion and debate, through constant visual and auditory reminders of their presence. They recommend related posts and stories we should like, given our past consumption and interaction history, and make others invisible, through algorithmic processes that maximise our exposure to popular content, personalised advertising and online services. So, while social media are not the simplest or only ways to share news stories, they do provide a widely accessible suite of portable tools for customising our news consumption, accelerating the scale and scope of its distribution and exposing it to the scrutiny of algorithmic tracking, classification and assessment which allows them to monetise any insights into our behaviour and interests.</p>
<p>In positioning themselves as IT companies and carriers of content rather than publishers, social media companies historically have avoided having to conform to the content regulation laws and accountability measures set up for legacy media, or to worry overly about what their users post on their platforms. For example, the U.S. Digital Millennium Copyright Act includes a safe harbour provision, which protects them from liability for the content their users might post—as long as they act to remove any illegal content about which they are informed (Flew et al. 2018). There is, as yet, no legal mechanism for forcing platforms to reveal how their algorithms structure the content we see, and that we don’t see, or what human editorial decision making takes place in content management. Recent national and regional moves to regulate the content we share, like Germany’s Network Enforcement Act (German Law Archive 2017) and the European Commission’s (2017) Code of Conduct on Countering Illegal Hate Speech have put some pressure on the major platforms to remove violent and extreme political speech (Goggin et al. 2017). However, on the whole, what we share online is determined by the guidelines that they set, and which they are not answerable for—even to us.</p>
<p>From this relatively unassailable legal position, and in possession of audience knowledge that the old media could only dream of, major social media platforms have been in a position to influence both cultural production and the production of culture, especially news media culture.</p>
<h2>The Importance of Commendary Culture</h2>
<p>As a source of traffic to news websites, social media’s direct influence on news distribution may well have peaked and passed. Certainly its 2015 dominance of referred news traffic was a blip on the metrics radar. Since then, Google search has reasserted its place as the number one online news referral source. Following the 2016 election misinformation scandal, Facebook also demoted news page content in people’s feeds (Facebook 2018), leading some industry observers to argue that publishers should reorient their strategy away from that platform (Filloux 2018) and engage more deeply with their audiences rather than using social media channels to push out links to stories (Elizabeth 2017).</p>
<p>Yet, some media commentators still argue that social media sharing may have profound effects on the future of journalism. They note that young people’s turn to social media as a primary news source—and social media companies’ capacity to imperceptibly select, filter and promote the news that gets seen—may have three immediate impacts: eroding journalism’s power to connect directly with audiences, to deliver what they need to know in the public interest and to ensure the accuracy and quality of the news they consume (Bell 2016; Bell and Taylor 2017). They worry that there is little platform accountability for what news gets seen, and by whom, and how much revenue is shared as a result (Newman 2018). Some see journalists as being locked into reporting what gets likes and shares, tailoring the news to social media metrics and “dancing to the popular music of consumer driven logic” (Tandoc 2014: 572). Others, like digital media theorist Jodi Dean (2005, 2014), have positioned social media users as unpaid labourers in the platforms’ bid for informational dominance, questioning whether their circulation of ideas can do much to affect the democratic process (as well-informed citizens might hope to), or is attenuated instead in technological fetishism. From this perspective, news sharing may be just so much symbolic chaff, spread in lieu of political engagement or action. Christian Fuchs has called out Facebook CEO Mark Zuckerberg’s claim that “the goal of the company is to help people share more in order to make the world more open and help promote understanding between people”, as a contradictory ruse that belies a ruthless commercial business model (Fuchs 2018: 172).</p>
<p>The more hopeful call social media news sharing a new form of media democracy and creativity, enabling a greater diversity of people to signal to newsmakers and our social networks what’s truly significant to them, in both local contexts and globally. Ostensibly, social signalling should guide journalists to report on what we value most, and on more varied conceptions of that value. In an ideal world, that would make journalism more socially responsive and culturally diverse. This techno-optimist shift is characterised in Henry Jenkins (1992) notion of participatory culture, and his newer concept of “spreadability”, where “new tools have proliferated the means by which people can circulate material, word of mouth recommendations and the sharing of media content” and facilitated the diffusion of cultural artefacts and practices (Jenkins et al. 2013: 2–3). It is also embraced in Bruns’ (2005, 2018) idea of “gatewatching”, where ordinary users publicise news, rather than reporting or publishing it. Bruns sees news sharing as a demotic, habitual practice for most people, and core to the emergence of new forms of expertise. But while these claims may have some basis, we need to know far more about the political economics and cultural forms of shared news, as well as the real-time network dynamics and contexts for its production and consumption, before we can understand its ramifications for the news media or its role in our societies.</p>
<p>Up until now citizen journalism has had far more attention in media research than sharing. Most book-length studies of participatory news cultures to date have focused on novel forms of news creation: blogging, produsage and gatewatching (Bruns 2005, 2008, 2018), user-generated content (Singer et al. 2011), citizen journalism (Allan and Thorsen 2009; Miller 2014), citizen witnessing (Allan 2013) and maker and hacker culture (Usher 2016), rather than the new modes of distribution such as aggregation and sharing. Alfred Hermida’s #TellEveryone: why we share and why it matters, a lively journalism studies account of how everyday social news sharing works, concentrates on the sociology of sharing, leaving the broader questions of cultural change and platform power, their shape and impacts largely unaddressed. In Axel Bruns’ more theoretically engaged <em>Gatewatching and News Curation</em>, he devotes considerable energy to analysing news sharing, but tends to focus on the relationships between users, journalists and platforms, rather than the more complex industrial and regulatory relationships emerging in the social media news ecology. While these books are important interventions in social media research, the study of news sharing remains a relatively understudied transformation of cultural production, and one whose complex power dynamics remain obscure.</p>
<p>Rather than taking one or other polar position on how our social media engagement will affect the future of news, we adopt a critical media perspective on news sharing’s meanings for journalism in society. That is, we want to examine how our online news sharing has been commodified, what role our actions, beliefs and proclivities have played in that process and what impact it will have on the institutional notion of journalism and the new cultures of digital news consumption.</p>
<p>The rest of this chapter examines the rich meanings of sharing, and how they have shifted to accommodate our new socially networked interactions and the commodification of that sociality. It then investigates why we share news online and how, exploring how our motivations for promoting certain types of news and the nature of our interactions is reshaping the way news generally is selected, reported and distributed, and in different ways on different platforms. In these senses, it is an account of the cultural politics of news sharing, or the ways that our cultural practices affect the exercise of news media power, and vice versa. As Angus and Jhally (1989) argued, it is important to understand “the manner in which institutional and ideological structures act as limits to the possibilities of cultural practices” and how cultural activity supports the emergence of new forms of power such as those of the transnational social media platforms.</p>
<p>So, instead of focusing on people’s impulse to create media online or to participate in public debate, as most participatory journalism studies have done to date, we are exploring the rise of a more everyday use of internet technologies—to commend, recommend or condemn the news. In the first instance, news sharing seeks to draw people’s attention to a news item by extending its reach. Sharers often tell others what they think about their shared item to rationalise the reposting, and seek or expect some sort of response from their social networks. They may hope to engage others in discussing or debating or acting on the judgement they have expressed.</p>
<p>The term <em>commendary culture</em>, used here to describe the rituals, beliefs, norms and practices associated with sharing pre-existing messages online, is drawn from the two fourteenth-century Latin meanings of commendare: to entrust someone or something to the care of others, and to commit to writing. These days, the acts of commending and recommending have the same positive connotation of praising the object in question. Those stronger positive associations have developed in contradistinction to the concept of condemnation, criticism or censure, yet to commend something originally meant simply to note it as worthy of attention. The study of commendary culture then, is concerned with all acts of elevating media to the attention of others, regardless of the conclusion drawn about that material. It understands news sharing as a social and cultural practice which seeks to amplify messages, to capture the attention of interested others, and to engage them in a reciprocal evaluative process. It is also interested in the socio-technical systems that allow this sharing of symbolic goods, preferences and opinions, and the means of making sense of these acts—
the techniques of measuring and analysing commendary activities.</p>
<p>As the title of this books suggests, the commendation of news stories to our social networks is commonly described as news ‘sharing’. Sharing is such a polysemic and widely used term in online contexts that it demands some deconstruction before we look at why it is such a compelling activity.</p>
<h2>What Is Sharing?</h2>
<p>As Nicholas John (2017) reveals in his absorbing cultural history of sharing, the phrase ‘to share’ has three different root meanings: to distribute or divide, to have something in common with and to communicate one’s personal experience or feelings. Like marketing scholar Russell Belk, John is intrigued by the association of sharing with economic behaviours, and particularly prosocial internet use.</p>
<p>Belk (2010), from an anthropological perspective, originally argued that sharing is a form of consumption within practices of commodity exchange and gifting, based in mutual association, shared possession or collaborative ownership, and caring relationships with others. For this perspective in sharing news online, we are not losing our share of anything, but expanding what he calls our sense of an ‘extended self’, the projection of our identity in the world through external means (p. 724).<sup>1</sup> However, he saw sharing as a non-commodity relationship, which it clearly is not in the contemporary sense, when social media companies reap both advertising data and attention from our information sharing activities. Thus, while Belk later modified his definition of sharing to include industrial models of collaborative consumption and short-term rental (Belk 2014), John’s work is more relevant to our purposes. He sets out to explore how tech corporations have appropriated the idea of sharing to fuel the expansion of digital capitalism via the ‘sharing economy’—a key concept enabling social media companies to appropriate our personal data, our social connections and our interests.</p>
<p><small>1 See also Belk (1988) Possessions and the Extended Self.</small></p>
<p>John (2017: 62–64) proposes that sharing has acquired new meanings in the age of social networking, associated with the reach, scale, morality and emotional intimacy of online communication. The first has come via the new organisational techniques of early computing, including practices like time sharing and file sharing, which point to sharing’s networked or distributive potential. Wadbring and Ödmark (2016) argue that there is a difference between the news media’s deliberate distribution strategies, which are designed to attract, hold and measure audiences, and social sharing’s ‘circulatory’, participative logics. We disagree with that assessment. As we will argue, platforms have their own deliberate, quantified distribution logics which seek to reach as many as possible with the most popular content their algorithms identify.</p>
<p>The second meaning for news sharing is reproductive, as online messaging collapses sharing’s two primary meanings of communication and distribution. In sharing news, we are simultaneously engaged in an interpersonal act of telling others about ourselves and publishing that information for an audience to read. Sharing in these reproductive senses is also enabled by what Meikle (2016: 26) calls the “intrinsic” capacity of computational technologies to produce perfect copies, which means we can give information without losing it and in a non-rivalrous manner, as the original is still around for others to consume. Despite the culture industries’ ongoing legal proceedings to assert their digital rights in music and film file sharing (Borschke 2017) and in news aggregation (Martin 2015), the capacity to make and exchange digital copies has established online media sharing as a commonplace, even virtuous act—especially where it challenges the constrictive licencing regimes of media and publishing conglomerates. Meikle quotes programmer and former Reddit co-owner Aaron Swartz arguing that “sharing isn’t immoral—it’s a moral imperative. Only those blinded by greed would refuse to let a friend make a copy” (Swartz 2015).</p>
<p>This <em>reproductive potential</em> underpins the third and most potent reason for sharing’s expropriation by Silicon Valley—what John calls “its positive connotations of equality, selflessness and giving” (John 2017: 63). This beneficial sense of online sharing, he notes, accords neatly with origin mythologies of the internet as a democratic force, a network for free, transparent and non-hierarchical exchange of information. So, news sharing has an <em>egalitarian potential</em> that makes us feel good about commending coverage of events and ideas to others.</p>
<p>Fourthly, a factor that John briefly alludes to and Meikle develops, is sharing as intimacy, and immediate personal exchange. We most often share online with our friends, family and workmates, people with whom we have some close, emotional or intellectual connections, and these bonds influence what we share and why we share it in networked circumstances. We share to build, affirm, maintain or repair relationships (Goh et al. 2017; Meikle 2016: 26). As we will see in Chap. 6, the users of an online news service who we surveyed primarily share news to show they care about a topic. They do it to express their feelings about a subject and sometimes to provoke a reaction from their friends or followers. This <em>affective potential</em> of sharing is key to understanding the topics people will respond to, and what types of stories might go viral on a social platform (Fig. 2.1).</p>
<figure>
<p>TODO</p>
<figcaption>
<p>Fig. 2.1 The semantic associations of social media sharing. Image: Fiona R Martin</p>
</figcaption>
<figure>
<p>Over time, social media companies have recognised how to capitalise on these semantic potentials, with Facebook in particular promoting our information sharing as a “mechanism for improving human relations and making the world a better place” (John 2017: 65–66). As John critically observes, they also tend to use the term sharing to underplay the commodity exchanges they have with third-party advertisers or developers, with whom they also ‘share’ our personal information. This appropriation of the positive meanings for sharing to legitimate purely commercial and wholly privatised trade activity is meant to divert user attention from the potential privacy implications of this activity.</p>
<p>The corporate intention is to promote sharing as collectively oriented, authentic and socially productive. Reddit’s 2018 homepage states it is “home to thousands of communities, endless conversation, and authentic human connection”. Twitter too wants us to “spark a global conversation”. Facebook is “giving people the power to build community and bringing the world close together” (Zuckerberg 2017). In this focus on dialogue and community, the platforms are tapping into an old understanding of sharing as a means of intensifying social relations through personal and emotional disclosure. According to media studies researcher Jenny Kennedy (2016), social intensification is one of the three main discourses of sharing in literature on technologically networked exchange.<sup>2</sup><span class="footnote">2 The other two being sharing as an economic exchange, which embraces different types of research on how we allocate access to resources, and sharing as scaled distribution, which explores the extension and contestation of ownership in sharing systems.</span> She uses Wittel’s (2011) sociological analysis to argue that the exchange of immaterial goods, such as news, is ‘inherently social’, as it only serves to invite responses from those in the sharer’s network and to accelerate interaction (2016: 468). In short, we share to connect more and more often. Platforms certainly seek to intensify our connective impulses by engineering rituals of information sharing. They send us regular, repeated daily alerts—who is tweeting what, who you should follow, how many responses you have had. To ignore these is to deny a basic drive to sociality, or so they would have us believe.</p>
<p>The concept of social intensification also alludes to a marriage of old and new meanings for sharing online: the search for connection with like minds, and the increased speed and scale of messaging possible in networked systems. Social media analytics now measure ‘social velocity’ to understand the intensity of news sharing (and other social signals) as a measure of informational relevance. The proposition is that the faster and more often we share, like or favourite a breaking story, the more engaged we are with the topic, and the more important it is to the news media’s agenda. In 2016, Chartbeat subsidiary NewsWhip patented its social velocity algorithm, which it claimed at the time was used to identify breaking news and guide editorial decision making in 300 newsrooms worldwide (PR Web 2016).</p>
<p>This industrial interest in the gauging and valuing of social intensity speaks to the way in which our map of sharing’s semantic evolution is still incomplete. Our research suggests that social media sharing is interesting to journalists and editors for the way it signals the popular worth of stories, and magnifies their reproduction and distribution, supporting the so-called virality of highly shared content. Online we can not only share stories but with more people than we ever could face-to-face, and more quickly. Due to the exponential distribution effect enabled (and encouraged)
by online networks (Kelly 1997) sharing can extend the reach and amplify the impact of false, shocking or scandalous news, with potentially significant effects. In India, for example, social media rumours and disinformation campaigns have recently resulted in riots and lynching (Tharoor 2018). In social media contexts, then, news sharing then not only distributes and reproduces, but <em>amplifies</em>.</p>
<p>Further, to share something immaterial is to seek wider recognition of that report, analysis, idea or opinion. We recommend (and hope) that our friends and followers attend to what we post. From a Bakhtinian perspective, we speak with anticipation of an audience and a response.3 In a social media system, we may add comments to a link or tag it so it is discoverable as part of larger discussions on a platform. We lift this item out of the flows and try to make it more <em>visible</em>. Our success of course is contingent on our playing the social game—sharing regularly, interacting lots with other users, sharing what is already popular, tagging posts with popular keywords, ‘optimising’ them for search-engine discoverability. And while Google argues that social signals do not influence a news story’s visibility in search rankings, they do influence, for example, a post’s Facebook ‘relevancy score’ (Oremus 2016). At Menlo Park, Facebook’s Silicon Valley headquarters, your past performance in signalling what’s important to you is one of the ‘hundreds’ of factors that play into the platform’s algorithmic prediction of what will then show up in your news feed, and be subject to on-sharing.</p>
<p>3 See Mikhail Bakhtin (1981) The Dialogic Imagination: four essays, (Ed. Michael Holquist), University of Texas Press, Austin.</p>
<p>So, in sharing news on social media systems we are not only signalling what we think about that material, but making it available for evaluation by others.</p>
<p>Sharing is a collaborative evaluative process: we amplify and draw attention to a story, our contacts register their assessment (thumbs up, smiley face, heart, downvote), the platform registers, collates and analyses our reactions, and shows us more of what we like. We are entangled in a process of promoting and assessing information, a commendary circuit, which feeds social media companies’ understanding of how audiences behave and express desire, and enables personalised targeting of its behavioural advertising (Fig. 2.2).</p>
<figure>
<p>TODO: News Feed Alert News Consumed Consumer Evaluation and Annotation News Sharing Social response Corporate algorithmic/human evaluation News Feed Story Placement Targeted Advertising</p>
<figcaption>
<p>Fig. 2.2 The commendary circuit of news sharing. Image: Fiona R Martin</p>
</figcaption>
</figure>
<p>In socially networked environments, news sharing accrues meaning through its annotation and iteration. Users will normally frame the link to, an excerpt or copy of, a story with either an iconic evaluation, a like or an emoji, a comment about it, or a discursive categorisation such as a hashtag or category tag. Each type of annotation has different effects in terms of the way that the news item is then indexed, and its relative value is measured by the social system involved. Comments give companies richer data about our opinions and attitudes, so Facebook users are urged to “Say something about it”, while Twitter gives us the option to retweet with a comment. These evaluative gestures set the agenda for any subsequent interpretation and discussion of that material within a social network, and provide the data for the algorithmic placement of those items in the news feeds of the users’ social network. Hashtags, which are now used on Twitter, Facebook and Instagram to organise information flows, also act to amplify the reach of any original share, by making the item visible to interested parties. Thus, it is difficult to interpret the impact of any one act of sharing without also analysing its diffusion, and the accumulation of these incremental social signals.</p>
<p>The other problem for news organisations trying to promote this commendary activity is that social media users seem to favour the entertaining over the newsworthy. In 2017, there were no news organisations on YouTube’s top ten most viewed and subscribed channels, none in Instagram’s most viewed stories list, and only four news articles and two research features in the top fifteen most shared Facebook posts. One study of the best performing WeChat accounts found 24% were ‘media’ companies, but another noted that only 24% of users posted trending news content on Moments (tagline: “Share your life with friends”), and only 16.6% wanted to view this type of content, compared to 66.8% who posted personal life records and 62.7% who wanted to see that material. Only Twitter and Reddit stand out as systems that sustain significant reposting of news journalism (Bastos 2015; Barthel et al. 2016). The Pew Research Center found that 78% of Reddit users relied on its threads for news, either via information from other users or links and excerpts on the site. What then do we know about why people might share news rather than celebrity shots, funny pet videos and political memes, and why they might gravitate to particular news platforms?</p>
<h2>Why We Share News Online</h2>
<p>As many journalism texts will argue, news fulfils a basic human need to know about the actions of others, our place in the society and our capacity to act in the world. Exchanging news with others is fundamental to establishing and maintaining our social connections, to building and demonstrating social (and cultural) capital—and beyond those motivations is a way of projecting ourselves into the world, as self-determining individuals and agents of change. A recent and extensive survey of literature looking at news sharing motivations suggested they fell into three broad categories: we seek to attract attention, promote our reputation and gain social status; to socialise with others, discussing and developing ideas; and to share important information, not just altruistically but in order to process it better and in the hope that others will reciprocate (Kümpel et al. 2016).</p>
<p>While study participants are sometimes unwilling to characterise themselves as self-serving, research by boyd et al. (2010), Lee et al. (2012) and Ihm and Kim (2018) found that there are strong presentational and impression management aspects to news sharing. People will carefully choose what they share to construct an ideal self-image, one that will attract approval from friends and peers. Some are keen to build their followers, or to get a response from a more visible actor in the network. Those who are highly motivated by self-presentation are more likely to share news, and on several platforms, than those who are less motivated by attracting recognition and acknowledgement (Ihm and Kim 2018: 14). This is likely because the more people we share new, credible and arresting information with, the higher our social visibility and the potential for building influence. The need to develop a reputation as a valuable news source applies most strongly when people are building professional networks on platforms like Twitter or Linkedin. But self-presentation factors may not be as broadly important in news sharing as social motives (Picone et al. 2016).</p>
<p>danah boyd and her colleagues found that people retweeted news for a range of social outcomes: as “an act of friendship, loyalty or homage”, to validate others’ ideas, and to recognise less visible participants in a conversation (boyd et al. 2010). A widely cited New York Times study also found the primary motives for their readers to share news were social: to improve the lives of people they cared about and to build and maintain relationships (NYT 2011). They hoped to help others have good experiences (or to avoid bad ones), to save money and to give them information about products that they’d be interested in. Readers also derived enjoyment from giving people useful news, from the responses they received and the sense of connection they felt to the world. Eighty per cent used news sharing as a way of keeping in touch with others, while 73% wanted to connect with those who shared their interests.</p>
<p>The NYT study also found evidence of a strong informational motive for news sharing: three in four of their surveyed readers “process information more deeply, thoroughly and thoughtfully as a result of sharing it with others” and said responses from their network helped them to interpret its meaning (NYT 2011: 6). Importantly, the survey suggested politics was key, as people share news about causes they want to promote. This rationale is supported by many studies that show the centrality of social sharing in mobilising political activity (see Hermida 2016; Papacharissi and de Fatima Oliveira 2012; Halpern et al. 2017; Kahne and Bowyer 2018).</p>
<p>However, context is clearly central to why we share. In cases of natural disasters, we share to express our emotions and to establish how we can best act to respond to the crisis (Shaw et al. 2013). In therapeutic communities, where people gather to self-manage illness, they exchange news about research which might aid their treatment. Pedagogical groups share news about teaching, and which may be of use in the classroom (Swart et al. 2018). In an extensive survey of news sharing literature, researchers also found that people who most often share news on social media “perceive themselves as opinion leaders and tend to have lots of friends or followers”, consume a variety of news, especially on social media and follow news organisations (Kümpel et al. 2016: 5).</p>
<p>We certainly share news to influence others’ opinions, and intimate sharing is very effective in this sense. Both political and sociological studies have shown social recommendations have significant power to shape our belief in news, and the likelihood of us commending news to others. An American Press Institute study (Media Insight Project 2017) argues that Americans evaluate the trustworthiness of news based on who shares it, rather than where it comes from. If they trust the sharer, they are more likely to “recommend the news source to friends, follow the source on social media and sign up to news alerts from that source” (p. 1). This is particularly the case for young people. Boczkowski and his colleagues (Boczkowski et al. 2017) found that much of the news young people encounter is ‘incidental news’, seen in the process of following their social feed rather than accessed from a trusted brand as part of a deliberate news search strategy. In this environment, news appears as part of an undifferentiated flow of social and informational content, its value mediated by social recommendations.</p>
<p>As the fake news moment testifies, some people share news to deceive. In analysing the false stories that she saw circulating online during the 2016 Trump election campaign, digital journalism researcher Clair Wardle found seven different kinds of ‘fake news’—or mis-, dis- and mal-information, as she more accurately labels it (Wardle and Derakhshan 2017). There were items that made false connections or presented false context, as well as manipulated, misleading, imposter and fabricated content, and satire or parody (Wardle 2017). However, it is a moot point whether much of this deceptive material stemmed from ordinary individuals with unhappy intentions. Subsequent academic research suggests that politicised institutional and economic rationales have been driving the circulation of deliberately deceptive news—not in the least the notorious Internet Research Agency of St Petersburg, once Russia’s most prominent trolling operation, which a Guardian investigation (Hern et al. 2017) showed was posting supposed witness accounts from disasters and crime scenes that were picked up by UK and US publications including the Telegraph, BuzzFeed, the Daily Mail, the Huffington Post and the BBC.</p>
<p>Journalists being fooled by imposter accounts is one problem, but a larger concern, which Wardle and Derakhshan (2017) highlight in a report for the Council of Europe, is whether and how ordinary social media users can identify a hoax post. The templating of social media items and their random appearance in our feeds, means that a post from a legitimate news source can look similar to a story from a conspiracy site, and equally shareworthy. They cite political scientists Messing and Westwood’s (2014) observations that social media content is decontextualised, since the focus is the story content, not the source. The Reuters Institute found that less than half of those they surveyed in 2017 usually recognised the brand of news content when they access news from social platforms (Kalogeropoulos and Newman 2017). Thus, without rich indicators of quality or origin, people are left to their social networks to help them identify and critique what’s authentic and what’s not.</p>
<p>Unfortunately, misinformation is far more likely to be recirculated than the truth because it makes a claim that is unexpected and contradicts what people know about the world. Its novel, unusual nature makes it more interesting to share (Vosoughi et al. 2018). Researchers at MIT’s Laboratory for Social Machines found that the average ‘fake’ news item took 10 hours to spread to 1500 users on Twitter, whereas a verified story took 60 hours to reach the same number of people. They also found it travelled “farther … deeper, and more broadly than the truth”, partly because of the strong emotional reactions people had to it (Aral 2018). This points to an interesting aspect of virality that will be explored further in Chaps. 6 and 8—that news we feel strongly about is more likely to be shared.</p>
<p>Research from the last decade indicates that whether we share news will depend on how we feel about what we’re viewing. As Jonah Berger (2011) showed in a ground-breaking marketing psychology study, we are more likely to share information that stimulates or arouses us emotionally, whether we feel positively or negatively about that content. His work with Katherine Milkman (2012), which suggests that arousal increases the speed of news sharing, triggered a wave of studies that have explored how our emotional or affective states influence the sentiment of news we share, and the rate at which it spreads. As Chap. 6 indicates though, this research has provided some confusing and contradictory results.</p>
<p>For a start, it is not clear whether emotional reactions make us more inclined to share positive or negative stories. Decades of research on legacy news distribution has suggested journalists and consumers pay more attention to bad news than good (Galtung and Ruge 1965; Glasgow University Media Group 1980; Trussler and Soroka 2014), a trend reflected in news sharing on Twitter (Hansen et al. 2011). Yet Berger (2013) has argued that if we have a choice we prefer to pass on good news rather than bad, and this is supported by a recent study showing Twitter users share ‘overwhelming positive’ viral news (Al-Rawi 2017). Meanwhile, another group who set out to determine whether everyday bad news is likely to travel faster than good found that it did—at least as far as Brexit news on Twitter was concerned (Fang and Ben-Miled 2017).</p>
<p>It is clear, though, that sharing news is very much an affective pursuit, an immediate reaction to socially significant events, issues and actions. It invites others in our social network to identify with or dispute ideas and helps us to mobilise others around causes or campaigns. Zizi Papacharissi (2015) notes affective publics form around networked expressions of sentiment about news, supporting large-scale, pluralised responses to it, and connective—if not collective—action on it. Social sharing is a move away from the controlled, centralised representative agendas of analogue news, which offered limited means to publicly express our feelings, in our ways about important changes in our worlds. As Chap. 6 will argue, sharing news enables users to place themselves in the news matrix, integrating or contesting the concepts, symbols and ideologies of news narratives in ways particular to themselves and their cultural identities.</p>
<h2>How We Share News Online</h2>
<p>Just as our motives for news sharing vary, we have many ways to do the sharing. People will use any networked communicative tool they read news on to flag or repost the URLs of content they find interesting or valuable, and there are many competing systems designed to allow us to do that. Much news sharing is done via email clients, from secure forums or using messaging apps like WeChat, Whatsapp, LINE or Facebook Messenger. The problem is that these channels, together with a range of mobile social apps, such as those belonging to Reddit, Facebook and Instagram, don’t generate traffic referral information in their message headers. That means measuring and understanding how people share news via these ‘dark social’ avenues is a difficult pursuit, and one that has become more pressing with the upswing in mobile traffic over desktop access to news websites (Breaux 2015).</p>
<p>Dark social is a phrase coined by former Atlantic magazine deputy editor Alexis Madrigal to describe the large volume of traffic coming to his site from sources that he couldn’t track. As Madrigal (2012) noted at the time, this problem exposed not only the range of sharing activities outside social platforms, but one of the great shifts that these platforms had visited on web media consumption—visibility:</p>
<blockquote>
<p>the social sites that arrived in the 2000s did not create the social web, but they did structure it. This is really, really significant. In large part, they made sharing on the Internet an act of publishing (!), with all the attendant changes that come with that switch. Publishing social interactions makes them more visible, searchable, and adds a lot of metadata to your simple link or photo post. (Madrigal 2012)</p>
</blockquote>
<p>Social media has become the main way that we share news online, and are encouraged by news companies to share, because it makes our activity visible and measurable. There are several ways in which Facebook, for example, makes what you share more apparent. It first gives your post a permanent URL, so it is discoverable by search engines. It adds traffic referral data to any link you post, say to a news story. When someone clicks on your linked item, the metadata tells the publisher’s server where your visit came from. Facebook’s software also crawls the web to capture data about that site, and to auto-populate a preview image for that link, excerpting the content and making the share more attention grabbing. This last technique is designed to capitalise on the likelihood that visual material such as photos and videos is more engaging than text alone. Imagery makes your posts more shareworthy. Finally, social media provides a range of automated commendary tools so we can evaluate others’ posts. As a whole, these algorithmic processes greatly elevate social media’s role in promoting media sharing, and produce quantifiable data about the scale of post creation and engagement. In enabling news publishers to collect, aggregate and measure social sharing metadata, or referral data about visits coming from platforms to news sites, social media companies have constructed themselves as key players in the digital distribution of news. As Madrigal also notes, social media platforms are only the latest in a long succession of computational systems for sharing information and news (see Fig. 2.1), each of which presented its own political and economic battles over how we could share information, what was and wasn’t proper use of the system. To get a more complete understanding of these struggles to define the authorised boundaries of news sharing, it is instructive to traverse some of that history, starting with first popular distributed online system, PLATO.</p>
<p>Launched in 1960, the US educational computing platform PLATO connected display terminals at the University of Illinois to dozens of networked mainframe computers. The platform’s development spawned many concepts now familiar in social computing including forums, message boards and chat rooms (Dear 2017) but also saw intense arguments over what was legitimate (coursework) and non-legitimate (gaming) use of the network (Latzko-Toth and Jones 2017). In a similar sense, France’s successful Minitel videotex system, which delivered news, directory, gaming, ticketing and billpaying services to ordinary citizens across the country, as part of a government sponsored roll-out, was scandalised by the growth of ‘messageries roses’, adult oriented chat rooms (Mailland and Driscoll 2017). US commercial service Prodigy offered news, email and bulletin board systems (BBS), but no chat, and alienated its subscriber base with over jealous censoring of content (Banks 2008). The UK’s centralised Prestel service was simply too expensive and visually uninteresting for most subscribers (Lean 2016).</p>
<p>The most successful news sharing systems were those that democratised the hosting and exchange of news, like BBS, which allowed any computer hobbyist with a PC and modem to publish or connect with specialised networks via the telephone network (Fig. 2.3).</p>
<p>Usenet, which was developed in 1979 at Duke University so that people could exchange public messages between connected computers, expanded this concept beyond the national. Over its first decade, Usenet gradually linked more and more research institutions, and became host to an extraordinary variety of specialist discussion or ‘newsgroups’. There were struggles about the structural hierarchies, naming and control of these groups, and debates about what constituted permissible speech, all part of Usenet’s evolution as a public access network. it is remarkable for being the first international scale decentralised news sharing initiative, with the user-led alt. newsgroups still being the largest section of the system. Sharing information with other systems however, like the defence research oriented ARPAnet was not easy, with technical and administrative hurdles to inter-mailing list communications (Hauben and Hauben 1997). In 1982, users dreamed of a World Net “that would tie all sorts of computers worldwide together” (ibid.), a vision that would be realised in 1993 with the World Wide Web, a graphical language, system of resource locators and open transmission software protocol that would enable any computer users to share information with another over existing telecommunications networks.</p>
<figure>
<p>TODO: put picture in here</p>
<figcaption>
<p>Fig. 2.3 Online news sharing systems development timeline, adapted from Weber (2017)</p>
</figcaption>
</figure>
<p>Internet historian Marc Weber (2017) argues that we lack a deep historical account of many of these early networks which might help us compare factors that are key to the effective distribution of information: the efficiency of different linking systems, of strategies to reduce the incidence of misinformation. However, it is likely that the one core reason we chose to share news via privatised, controlled social media rather than the more openly owned and structured World Wide Web is automation.</p>
<p>The advent of the World Wide Web in 1993 gave every PC and modem owner the possibility of being an author-publisher, and with a graphical focus that brought a new, if low-resolution visuality to news sharing. Websites were the new way to share your interests, even if much of the content still consisted of URL lists pointing to interesting sites and documents, and blogrolls of favoured writers. Yet, while the web lowered the barriers to sharing information across the globe, beyond the territoriality of analogue media, it still required technical skill, and an understanding of computing and coding beyond the reach of most people (let alone the billion or so worldwide living without electricity).</p>
<p>Automating the web publishing process made it more accessible to more people. Geocities, the US-based webhosting service founded in 1996, lowered barriers to creating web pages with templates and neighbourhood directories, and later drag and drop publishing tools. Together with Angelfire, Tripod and much later MySpace, Geocities gave users a base from which to learn the principles of html coding and media uploading, but it was templating that simplified, expedited and fully democratised online news sharing. Publishing templates defined the layout and features of many blogging services from Blogger and Live Journal to WordPress, and the first social media services, Six Degrees in 1997, Lunar Storm in 2000 and Friendster in 2000.</p>
<p>In 2006, Facebook further revolutionised the automation of news sharing by enabling websites to instal a share widget or button to their pages, which automated the posting of content to their accounts or contacts, making it more “more efficient by giving people a simple structure to do it” (Facebook 2006). In 2009, it then introduced its version of the like button, originally introduced by Friendfeed in 2007 before Facebook acquired that company. Liking enabled people to react to others’ sharing activities, but only positively. Zuckerberg recognised the value of this positive social reinforcement in encouraging interaction when he rejected calls for a ‘dislike’ button:</p>
<blockquote>
<p>The like button is really valuable because it’s a way for you to very quickly express a positive emotion or sentiment when someone puts themselves out there and shares something. Some people have asked for a dislike button because they want to be able to say, “That thing isn’t good.” That’s not something that we think is good. We’re not going to build that, and I don’t think there needs to be a voting mechanism on Facebook about whether posts are good or bad. I don’t think that’s socially very valuable or good for the community to help people share the important moments in their lives. (Zuckerberg in Lafferty 2016)</p>
</blockquote>
<p>Share and react buttons are purposely designed technological affordances of Facebook that make acting on our impulses to pass on and respond to online information easy, quick and ‘frictionless’ (to use a term favoured in Silicon Valley). They encourage affective responses, but most obviously constructive ones as these are more likely to generate.</p>
<p>Facebook’s resistance to automating critical signals is just one example of <em>affective regulation</em>, the process of controlling and directing expressive responses during social sharing. Another is Facebook’s introduction during 2017 of a set of five new emoji reaction buttons—Love, Haha, Wow, Sad and Angry—to supplement the Like. These options were ostensibly introduced in order to reduce incidences of reaction avoidance, where users felt it was inappropriate to ‘like’ content that made them upset. However, Facebook also indicated it considered the new reactions ‘stronger’ signals of relevance than the original like, raising questions about how it weighs them in calculating post visibility, and what affect users might have on news feeds by choosing different types of emotional response.</p>
<h2>How Users Affect What Is, and Can Be, Shared</h2>
<p>Users have changed the way platforms can be used to share news. Software developer and designer Chris Messina (2007) came up with the idea to use keyword ‘channel tags’ as a way to signal that a group discussion was opening, but keeping the signal short enough to be embedded in the message. Hashtags are now used to organise and aggregate shared content on Facebook and Instagram, illustrating the normalisation of socio-technical standards for sharing online. Tumblr users also adopted the GIF or ‘graphics interchange format’ to animate their personal reactions to posted content, drawing on an eclectic store of appropriated pop culture motifs. This playful convention was later adopted by digital-born news publishers like BuzzFeed, and GIFs are now being used by legacy media to give visual interest to stories and to animate simple infographics.</p>
<p>How we share news and what we share depends not only on a platform’s affordances, but also its commendary culture. This becomes clear in contrasting Reddit and Twitter, the international platforms most clearly focused on news sharing. On Reddit, users take part in discussion groups, called subreddits, devoted to particular topics, and news sharing involves excerpting, explicating and debating, to some extent, stories from existing media sources. The top 5 subreddits in terms of subscribers were humour (funny) world news, and educational (AskReddit, todayilearned, science). Users come from the US, Canada and the UK primarily, and in the US are largely young, 18–29-year-old males (Pew Internet 2016).</p>
<p>Twitter, on the other hand, is more cosmopolitan and gender balanced, with 57% male users and 42% females in total, although this ratio varies by country. 79% of Twitter users come from outside the US, including China, its biggest national market, and India its third largest, while many countries including the UK and Japan are heavier users than North Americans. While its users are diverse, Twitter operates mainly as a professional and expert communications network, with news sharing done primarily through hyperlinks, due to the messaging constraints (280 characters per post, double that of pre-2017 tweets). More than half of the top most retweeted messages in 2017 were motivational, including three from Barack Obama, and two disaster appeals. While there is no recent global survey of account types on Twitter, an Australian study found that aspirational accounts were one of the top four concentrations, alongside teen culture (music and celebrity especially), sport and netizen/technologists (Bruns et al. 2017). That research also showed that user interests had changed over time, with technologists being a more important group in Twitter’s early years, while teens and sports enthusiasts being later adopters.</p>
<p>Each evaluative system then demonstrates different politics of participation and recognition, based on its measures of social visibility, status and approval. On Reddit, which is a community of pseudonymous users, the title, visual content, placement and timing of a post will determine its visibility and popularity more than on Twitter, where real identities are more common and visibility is defined by numbers of followers and popularity of posts. A Twitter user’s profile and status, or social authority, has a distinct positive effect on content sharing. In terms of approval, each Twitter post accumulates a register of signals, including retweets, favourites, replies, follower requests and the addition of the user to expert lists. By way of contrast, Reddit users, in a quasi-democratic gesture, use up and down-voting to register their approval or disapproval of posts. As pseudonymity and anonymity pose particular issues of recognition and behavioural control for Reddit, this service has developed an additional reputation strategy. Users accumulate ‘karma’ points (a Silicon Valley gesture towards the Buddhist concept of an individual’s actions influencing their future), which then determine the degree of freedom they have to post information, the degree of attention paid to moderating their contributions, and their status within the system when users have low karma.</p>
<p>The sharing of politically contentious or illegal material can trigger internal or external regulation to control sharing behaviours, a subject we look at more closely in Chaps. 3 and 8. While the major social media platforms subscribe to the North American protection of speech freedoms, they nevertheless are obliged to control what we share, and how we speak about it in order to prevent the circulation of hate and discrimination, misinformation, propaganda and criminal activity. As Tarleton Gillespie argues in his investigation of content moderation online:</p>
<blockquote>
<p>Platforms must, in some form or another, moderate: both to protect one user from another, or one group from its antagonists, and to remove the offensive, vile, or illegal—as well as to present their best face to new users, to their advertisers and partners, and to the public at large. (Gillespie 2018: 124–125)</p>
</blockquote>
<p>What we share and how it frames our relationship to the legal and political frameworks of nation state and platform revenues then affects what we care able to share. States, for example, routinely step in to regulate news sharing, showing they acknowledge its power to shape public opinions and political processes. Countries like China, Iran, Turkey, and Vietnam control to varying degrees both access to social media and activity on the platforms, usually to prevent political dissidence, and mobile internet access is sometimes restricted in areas dominated by religious and ethnic minorities. Governments will also restrict access to social sharing to further their own political agendas, as when the Ukrainian government blocked access to the popular Russian-owned VKontakte social platform on national security grounds (Kelly et al. 2017). As Chap. 3 will argue, these battles over access to news sharing systems represent a major front in struggles for freedom of expression and media freedom.</p>
<p>What we share is also, as this book argues, fundamentally reshaping the news business, its relationship to the social media platforms and its audiences, and the production of news. To understand its impact on news journalism, we’ll now examine some of the factors that have affected social news sharing’s integration into newsroom routines, and its part in influencing how news is constructed.</p>
<h2>Reshaping the News: The Likeable Engine</h2>
<p>In 2009, Richard Sambrook, then director of the BBC Global News Division, told the Oxford Social Media conference that he thought “the impact of social media was overestimated in the short term and underestimated in long term” (Bunz 2009). Unlike most media predictions, his was remarkably accurate. The legacy news media have not wholesale adopted BuzzFeed’s social first approach to production, or, as Jonah Peretti’s organisation did early on, tied wages to evidence of social impact, clicks, likes and shares. Yet, nearly a decade later, social media organisations and their users have had a profound influence on how news is identified, selected, produced, distributed, promoted and discussed.</p>
<p>At peak social sharing, before Google reasserted its dominance and Facebook changed its algorithm to demote news in favour of personal information from people’s feeds, industry reports suggested anywhere from 7–50% of news traffic would come from social media referrals, depending on the site’s business model and the story topic (Mitchell and Jurkowitz 2014; Parse.ly 2015). Those digital-born companies based on social first publishing strategies like BuzzFeed and Upworthy had referrals at the top of that scale. At this time, social media metrics were a proxy for digital news consumption. This conception drove the uptake of social analytics which we document in the next chapter, and a greater editorial focus on monitoring what was being shared online and why. Although there is now a healthy scepticism about the importance of social media for news making, and a move for news organisations to refocus on a more diversified approach to distribution (Cornia and Sehl 2018), it is worth remembering how and why newsrooms sought to integrate social media during this period.</p>
<p>The growth of commendary culture and the rise in social referrals to news sites saw news organisations become tightly bound into the social media ecology, investing in branded social media channels, advertising and revenue deals, hiring specialised social media teams, adopting digital workflows and analytics systems and exploring occasional partnerships with the platforms (Cherubini and Nielsen 2016). As Bruns (2018) suggests, journalists were under pressure to boost sharing and increase audience trust in news product via personal social media engagement with audiences. In turn, these social branding activities led to power inequities in the way some individual reporters could command public attention and mobilise audiences, and engendered a lesser hold by employers over the opinions and job mobility of those employees (Bruns, 222–223). So, news sharing affected production investment and innovation agendas, while destabilising (to some extent) existing labour models and relations.</p>
<p>From 2010 onwards, we were attempting to measure news sharing, first internal sharing of news across co-owned titles in Australia (Dwyer and Martin 2010) and then, together with our Share Wars colleagues, user-led sharing internationally. For the latter project, we used Share Wars’ Likeable Engine, a homegrown news analytics tool. For four years from 2011, Likeable tracked social news sharing trends using data from 140–160 major news sites worldwide and information feeds from Facebook’s and Twitter’s public application programming interfaces (APIs). Like other later commercial analytics applications like Chartbeat, Newswhip or Parse. ly, or the Guardian’s in-house developed Ophan dashboard, Likeable enabled editors and journalists to monitor changing patterns of social media news distribution and consumption (including their own relative performance), to track trending stories and to strategise live editorial decision making in competitive online news markets.</p>
<p>Likeable was created by the Share Wars group, employees of one of Australia’s top-rated online news sites Nine.com.au (formerly ninemsn). Share Wars was a start-up built by former news editor Hal Crawford, former Windows 8 editor Andrew Hunter and former Network Development Director Domagoj Filipovic. They sought to use its analytics capacity to discover “what makes stories shareable and how this new distribution force will change workflows, roles and resourcing” (Crawford et al. 2015). The project marked a period where company executives started to take an interest in the uses of computational intelligence in audience research via their creative agency Mi9, and as Nine Entertainment split with Microsoft Network. The founders, who have all moved on to senior executive positions in large news media organisations and Facebook, maintain a blog of the project findings at http://share-wars.com/.</p>
<p>The Likeable Engine had four core components:</p>
<ol>
<li>News Feed Processor (extracting story URIs from news websites)</li>
<li>Database (storing story data and matching it with social media data)</li>
<li>Like Processor (extracting commendary data stats from FB and Twitter)</li>
<li>Live reporting Interface (graphing the mashed data)</li>
</ol>
<p>Its architecture demonstrated the classic public/private nature of the social media ecology. It relied on public internet carriage and open standards web content (news sites), accessed public (but privatised) commendary information, formatted by proprietary social platform feeds, using bespoke scraping and querying algorithms and stored it using open source database software (Fig. 2.4).</p>
<p>Until its decommissioning in 2016, the Likeable Engine scraped new news story URIs linked from its sample news homepages every 11–20 minutes and then queried Facebook and Twitter APIs for the share counts of those stories. It requested these counts hourly for the first 24 hours, then less frequently for 5 days. Where possible URIs were canonicalised to their Facebook IDs, to avoid the same story being differently counted on its mobile or web domain. The interface then displayed the top ten stories graphed over 22 hours, and listed the top 100 with their share counts. Users could filter by region (AU, UK, US), by date and by satire (with an eye already to post-truth news).</p>
<figure>
<figcaption>
Fig. 2.4 Likeable Engine information model. Image: Fiona R Martin AU14
</figcaption>
</figure>
<p>The journalists interviewed in the early days of our project used Likeable as a complement to other paid analytics services such as Spike, Chartbeat, BuzzSumo, Omniture, and the in-built or native analytics provided by RedditInsight, YouTube and Google Analytics. Likeable users were primarily the ninemsn editorial staff, although users in several other workplaces, including Fairfax Media (which has since been taken over by Nine Entertainment), adopted the app. Interviews with five online journalists who used Likeable in two commercial newsrooms suggested that it played a useful and important role in their editorial routine when it was released, but had been overtaken by newer, more sophisticated analytics packages which they preferred.</p>
<p>The major insight from the interviews was the way in which analytics had become an important tool in editorial decision making. Interviewees said that they used analytics daily, and often throughout the day, to filter content, identify story ideas and trigger coverage, and to determine news scheduling and placement. Likeable was often consulted in the morning to identify story ideas based on what social media news was getting most user attention, where and when, to indicate whether journalists might need to produce reaction stories or explore new angles such as local perspectives. Two users regularly looked for ‘pre-viral’ stories or videos that were performing well on smaller news sites, and which had yet to be shared internationally. One sought news which “isn’t prominently placed on the original website, or from sites that are not part of the normal news cycle”.</p>
<p>Sharing analytics were also used to monitor the performance of competitor coverage of similar material. One news editor noted that Likeable helped him:</p>
<blockquote>
<p>… to monitor sharing across the day and look at what’s sharing well comparatively—also to think about domestically what might get a push from posting on social media.</p>
</blockquote>
<p>Analytics also emphasised the temporal flows of sharing, with trends suggesting times when stories might be posted so they “move better” and are shared more. One user noted he always looked at the top videos and what time they were posted “live versus the number of shares they get”.</p>
<p>Overall, the interviews suggested social analytics had five distinct uses in editorial decision making. They were regarded as:</p>
<ul>
<li>an evaluative system—to identify stories and topics that were sharing well, or which might go viral, and which stories should stay on the homepage</li>
<li>a news filter—to identify what topics were getting most attention, where and when</li>
<li>an alert system—to signal new stories that are sharing well on smaller sites, or the need for reaction stories to viral content</li>
<li>a scheduling device—to suggest times when stories might be posted to attract more shares</li>
<li>an audience filter—to indicate which on which publications and platform certain stories were being most often shared.</li>
</ul>
<p>These interviews also suggested how traditional new values are being reinterpreted relative to social sharing metrics. A story’s timeliness, which was once understood relative to the publication’s production lead time, is now also determined by whether and how long it has had a presence on social media. The need to ensure optimal news sharing is also determining whether stories are posted to social media or the World Wide Web first. The audience relevance of a story is being assessed by where its sharing is initiated (from the article page or via social platforms) and on which platform/s people are posting about it. Controversial or polarising topics tend to be highly shared, suggesting conflict remains an important news value, but exploiting that interest demands journalists include provocative keywords in story straps, excerpts and headlines to attract searches and shares. Shareable items as a whole sit on either end of the impact spectrum: they must be either novel and pre-viral, or ubiquitous, that is, viral and otherwise newsworthy. These evolving ideas about what makes news significant shows just how subtly and comprehensively social sharing analytics are influencing journalists’ normative interpretations and applications of news values.</p>
<p>While we didn’t directly ask journalists if they understood how these figures were compiled, they did voice a range of concerns about the transparency of the metadata capture from Twitter and Facebook, particularly how analytics tools weighted views against shares or retweets, and how they should interpret differences in sharing relative to publication readership or audience size. One user requested better indexing of Australian news sites. The majority wanted better graphing of sharing in real time, one indicating that Omniture provided the best model.</p>
<p>These journalists’ interest in tracking the rate at which news was shared was consistent with the news media’s obsession with speed in news production and distribution. It also suggests that social virality is a central factor in the adoption of social analytics services such as Chartbeat, and a rationale quite distinct to measuring user attention to stories or journalistic engagement.</p>
<p>Our research was never intended to fully map journalistic responses to social news sharing—far better covered in reports like Caitlin Petre’s <em>Traffic Factories</em> (2015) or Fedrica Cherubini and Rasmus Kleis Nielsen’s <em>Editorial Analytics</em> (2016)—but rather, we wished to trigger a critical enquiry into how social media news sharing is analysed, measured and valued. The next chapter takes up this story, particularly questions about the clarity and reliability of the data captured.</p>
<p>My newsroom encounter also highlighted the diversity of players in the social sharing ecology, with analytics companies based in Ireland, Israel and the US, and a distinct gap in the tracking of non-Western platforms like WeChat, Sina Weibo, LINE and Kakaotalk from our Asian region. This was a reminder that much news sharing knowledge still reflects the late twentieth-century cultural hegemony of transnational Western news domination. The deficiencies of this focus are obvious with the rise of BRICS countries. It was encouraging then to see, in December 2016, that Newswhip recorded IndiaTimes.com as the most shared site internationally on Facebook, part of a shift to it acknowledging greater diversity in the publishers who were achieving high share counts (Corcoran 2017). In an increasingly globalised communications world, we need to understand how our news sharing is shaped by different local, national and extra-national forces, and how commendary cultures might emerge in response to particular economic, political and social contexts.</p>
<p>The rise and fall of Likeable is one small part of that story. Likeable’s shutdown was partly the result of transnational competition, from analytics start-ups with more venture funding, more viable business models and better designed products, and partly due to Facebook and Twitter’s full commodification of what had previously been ‘freemium’ data subscription models. Likeable originally sampled data from the pre-2015 Facebook Developer API, which provided free access to separate counts of shares, likes, comments, and on-page comments—some of which were no longer available from the amended public API. It also drew on Twitter’s public data feed. This had been narrowing for years as the company slowly withdrew users’ permissions to access certain types of information, but it still provided tweet count data which was valuable to app developers and marketing services. Even if the free APIs had been somewhat unstable and subject to sudden change, they still enabled experimentation and innovation in the analytics space among a raft of small technology companies. The closure/commodification of both streams in 2015 undermined Likeable’s already limited functionality, and as it didn’t have a viable subscriber base, it was not a commercial proposition for Nine to buy that data from the platforms. Yet, Likeable had already fulfilled its ideological promise, introducing a group of journalists to the ground zero of analytics use, its incorporation into their news routines and the alteration of their production norms.</p>
<h2>Commending the News</h2>
<p>Social media news sharing has become a powerful new force in digital news production, in its variety of commendary forms and practices, its everyday adoption, scale of interaction and integration with news media production, distribution and consumption. Platform designs and their affordances operate to enable audiences to make visible the news they value as shareworthy, to marshal attention to their judgements, and to enlist others in responding to their reactions. Their evaluations, when tracked, analysed and represented, affect not only platform advertising, but journalism practice. Commendary culture influences the reporting and editorial practices of journalists in ways that are both obvious and also difficult to quantify, especially given tech companies’ relative lack of accountability for their calculus.</p>
<p>Social media platforms have, by promising informational and communicative agency, colonised the lifeworld of their users, and captured their commendary motivations and agency in ways and at a scale that have the potential to transform.</p>
<p>Read in light of this analysis, online sharing means much more than redistribution, communication or disclosure. It now encompasses the amplification of ideas, the speed and scale of reproduction, the ritual and affective nature of our acts and the differing levels of access we provide to our shared material. It also presages an era of machine learning and automated news discovery and redistribution.</p>
<p>There is little doubt that social sharing is reconfiguring news journalism, even where social referrals constitute a small percentage of traffic to a</p>
<p>news site. That is because social media users now routinely influence what gets seen by others, and what is valued in the news selection process, in a circular and self-reinforcing logic, just by redistributing and evaluating news stories. Their sharing metrics feed the editorial algorithms of the platforms, influencing how news is made visible and prominent and generating the metrics that newsrooms will monitor for signs they are producing what the audience wants. It is this commendary dynamic, quite apart from the gravitation of advertising revenue to the platforms, that is reshaping the future of news and how it will reach audiences.</p>
<h2>References</h2>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="Platforms Intervene"
class="paper-story"
data-article-title="Platforms Intervene"
>

<h1 class="article-title" id="h_Platforms Intervene">Platforms Intervene</h1>

<div class="top-meta">Tarleton Gillespie, 2015-04-2601 00:00:00 AEST. for week 7.</div>

<p>Social Media + Society, Volume 1, Issue 1, April-June 2015</p>
<p>© The Author(s) 2015, <a            href="https://sagepub.com/journals-permissions">Article Reuse Guidelines</a></p>
<p><a href="https://doi.org/10.1177/2056305115580479">https://doi.org/10.1177/2056305115580479</a></p>
<h3>SI: Manifesto</h3>
<h1>Platforms Intervene</h1>
<p>Tarleton Gillespie<sup>1,2</sup></p>
<h2>Abstract</h2>
<p>Social media platforms don’t just guide, distort, and facilitate social activity, they also delete some of it. They don’t just link users together, they also suspend them. They don’t just circulate our images and posts, they also algorithmically promote some over others. Platforms pick and choose.</p>
<h2>Keywords</h2>
<ol>
<li>platform 1. algorithms 1. censorship 1. public culture</li>
</ol>
<hr>
<p><sup>1</sup> Microsoft Research, USA</p>
<p><sup>2</sup>Cornell University, USA</p>
<h3>Corresponding author(s):</h3>
<p>Tarleton Gillespie, Department of Communication, Cornell University, 315 Kennedy Hall, Ithaca, NY 14853, USA. Email: <a href="mailto:tlg28@cornell.edu">tlg28@cornell.edu</a></p>
<hr>
<p>Platforms matter. This is now, I think, becoming an established observation in social media research. For some reason, it remains tempting to study social dynamics on platforms while ignoring the platforms themselves, treating them as simply there, irrelevant, or designed in the only way imaginable. But recent work on the socio-technical dynamics, context-specific realities, and political economic dynamics of social media has made clear that platforms, in their technical design, economic imperatives, regulatory frameworks, and public character, have distinct consequences for what users are able to do, and in fact do.</p>
<p>So platforms matter . . . but that is not the end of the story. Even the best of this work, even in its richest understanding of the technical, economic, and political contours of social media platforms, tends to overlook a crucial additional element. Social media platforms don’t just guide, distort, and facilitate social activity—they also delete some of it. They don’t just link users together; they also suspend them. They don’t just circulate our images and posts, they also algorithmically promote some over others. Platforms pick and choose.</p>
<p>This is, of course, something we “know” already. Of course social media platforms police their content: I remember some kerfuffle about Apple removing sexy apps a few years ago. Of course Twitter suspends users: Aren’t those misogynist trolls terrible? Of course YouTube algorithmically promotes some of its content: That is why their front page looks the way it does. It seems that on about a yearly basis, the tech press nails Facebook for deleting a photo that appeared to include an exposed boob.</p>
<p>However, this familiarity obscures some important issues. First, many users do not know all that much about the deliberate interventions platforms make. That is not to say that users are dupes—most of us “savvy users” don’t understand these processes as well as we should either. What I mean is most users don’t encounter the rules imposed by platforms—most have little reason to read them, and most don’t have anything deleted. And though users may be aware that there are algorithms inside their favorite social networking site or search engine, most know very little about how they work. Were this a real part of our conception of and discourse about these platforms, we might approach them differently, expect different things from them, legislate them differently—and study them differently.</p>
<p>Furthermore, platforms regularly downplay these interventions, except in specific moments when it is beneficial for them to trumpet them. When Instagram and Pinterest were accused of hosting pro-anorexic images, they loudly announced their new policies against it. (Whether these policies were effective was a much quieter discussion.) When advertising partners want assurances that their posts will be seen, the platforms show off how sponsored posts are designed to persist longer than regular ones. But beyond that, these companies prefer to emphasize their wide-open field of content and their impartial handling of it.</p>
<p>This constant intervention is an important and under-examined part of what platforms do. We study the topics of discussion and dynamics of sociality that flourish online, but we don’t as often study the topics and dynamics that are asked to leave, or never show up because they know they will be deemed unacceptable. We study what content these platforms circulate, but we too often describe it as what “returns” as search results or “goes viral,” rather than seeing them as the result of strategic actors selecting and assembling user content into a particular composite. This may be a gentler intervention than a newspaper editor deciding what is a front page story and what isn’t worth reporting at all, but it is selection nonetheless, and it matters in many of the same ways.</p>
<p>Of course, the user suspended from a platform has not been silenced entirely, which means that it is hard to call this censorship in the strict sense. The web beyond these platforms still offers a more loosely regulated home for controversial content. But it is a question about when some content is forbidden to appear where people expect it to be, in the massive online spaces where audiences can be built. It is why the common admonition “if you don’t like it here, just leave” is insufficient when it comes to culturally and politically contentious speech. While it is not unreasonable for a platform to want to set rules and install algorithmic mechanisms for highlighting content for its users, things change as these platforms grow. Scale and centrality make a difference; once a platform becomes massive, new kinds of expectations emerge, and new kinds of obligations arise. But we will never identify what these obligations are, or should be, until we recognize that there is selection and deletion going on, all the time.</p>
<p>This also has implications for how we conduct social media research. A savvy researcher will take care when, for instance, making claims about contemporary political discourse by collecting all the tweets that used one particular hashtag. Of course, the researcher is already excluding private tweets, as well other relevant discussions that did not coalesce around that one hashtag. Good methodological caveats. But, Twitter also deletes tweets and suspends users. Some things may not have been said at all by users anticipating those prohibitions. Other tweets deemed popular were displayed in a larger font, or added to Twitter’s email prompts sent out to some users; the hashtag term might have trended, at some point and only in some places. How will these interventions be accounted for, as absent elements or relevant dynamics in the corpus of data?</p>
<p>I don’t mean to be finicky. Or maybe I do. We might think that at the scale of “big data,” these perturbations are small enough to be ignored. After all, plenty of tweets drop out of the data in other ways, through sampling, choice, error, and so forth. But let us be concerned, anyway, about the fact that this corpus is not just the product of people’s participation but has also been crafted by the platform, according to the logic of its algorithms, the imperative of its business model, and the enforcement of its community guidelines.</p>
<p>Recognizing that social media platforms shape the social dynamics that depend on them allows us to draw connections between the design (technical, economic, and political) of platforms and the contours of the public discourse they host. Remembering that they are private businesses reminds us that some of their decisions will be craven, or financially motivated, or constrained in ways even they cannot recognize. But we have not done justice to the fact that like newspaper editors and network broadcasters (and, in important ways, unlike them), social media platforms pick and choose, based on explicit and implicit norms, cultural presumptions about taste and etiquette, at the behest of offended users or concerned lawmakers, and in ways that best suit their economic aims. If we tried on this idea, even if it is overstated, we might shed the compelling myth that these are information flows that happen to be filtered, and instead see our information as only raw material from which platforms assemble an information product for us: a feed for which some content is chosen, some is given prominence, some is discarded, and some is expelled. That is to say, platforms intervene, and the public culture that emerges from them is, in important ways, the outcome.</p>
<h2>Declaration of Conflicting Interests</h2>
<p>The author declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
<h2>Funding</h2>
<p>The author received no financial support for the research, authorship, and/or publication of this article.</p>
<h2>Author Biography</h2>
<p><b>Tarleton Gillespie</b> (PhD, Communication, University of California at San Diego) is a Principal Researcher at Microsoft Research New England, and an Associate Professor in the Department of Communication and the Department of Information Science at Cornell University. His current work considers the regulation of online media platforms and their implications for free speech and public discourse. He is also the co-founder of the blog Culture Digitally.</p>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="Tweet fast and kill things: digital war"
class="paper-story"
data-article-title="Tweet fast and kill things: digital war"
>

<h1 class="article-title" id="h_Tweet fast and kill things: digital war">Tweet fast and kill things: digital war</h1>

<div class="top-meta">William Merrin & Andrew Hoskins, 2020-03-17 00:00:00 AEST. for week 8.</div>

<p>William Merrin &amp; Andrew Hoskins. (2020). Tweet Fast and Kill Things: Digital War. Digital War, 1, 184-193. https://link.springer.com/article/10.1057/s42984-020-00002-1</p>
<hr>
<h2>Abstract</h2>
<p>Digital technologies have disrupted most sectors of human life and activity, and war and conflict are no exceptions. Beyond military systems, the entire battlefield is transformed, with multi-media smartphones, messaging apps, and social media platforms especially creating a global, participative arena, in which the distinctions of combatant, civilian, and informational warrior implode. In an overview of recent developments of digital war, we argue that neoliberal economic ‘creative destruction’ is now <em>destructive creation</em>, as digital technologies have created new possibilities of destructive activity. Facebook’s early mantra of ‘Move Fast and Break Things’ can now be read as ‘tweet fast and kill things’. We have moved from the 1990s US military hopes of ‘full spectrum dominance’ of all battlefield information to the new military reality of full spectrum access. This is an emergent ‘military-social media complex’ in which the most popular US-made apps and platforms serve as a global informational warfare proxy, where empowered ‘citizen militia’ keyboard warriors take on and take down governments and media propaganda units. As computer processing has eaten mass media, it is time to reveal war in its full ecology, as made through an epochal, structural revolution in communication.</p>
<h2>‘WWIII Announced…’</h2>
<p>Just after 1 am local time on 3 January 2020, only minutes after his arrival at Baghdad airport, a US Reaper drone-strike killed Qasem Soleimani, the head of the Iranian Revolutionary Guards Corps’ (IRGC) Quds Force and one of the most powerful and important figures in Iran. The strike was built on a global, networked ISR (intelligence, surveillance, reconnaissance)
system that combined HUMINT (spies at the airport), SIGINT (tracking Soleimani, including homing in on the cell phones in the car in real time to confirm their identities) and years of satellite mapping and terrain information available to the drone operator, the whole being run from US Central Command in Qatar, with camera feeds to the CIA, the White House, the President, and various military locations around the globe (Dilanian and Kube <a title="Dilanian, K., and C. Kube. 2020. Airport informants, overhead drones: How the U.S. killed Soleimani. NBC News, 10 January. https://www.nbcnews.com/news/mideast/airport-informants-overhead-drones-how-u-s-killed-soleimani-n1113726 ." href="/article/10.1057/s42984-020-00002-1#ref-CR33">2020</a>).</p>
<p>US–Iranian hostility had simmered since 8 May 2019, when President Trump announced the US’s withdrawal from the 2015 Joint Comprehensive Plan of Action nuclear deal. Squeezed by the US’s ‘maximum pressure’ campaign of sanctions, the following months saw Iran respond with attacks on and detentions of oil shipping in the Strait of Hormuz and the shooting down of a US RQ-4A Global Hawk surveillance drone on 20 June for violating Iranian airspace. The conflict was happening as much on Twitter as on the ground. Having called off retaliatory airstrikes for the drone loss, Trump felt compelled at least to brag of how US planes had been ‘cocked <em>and</em> loaded’ to go before his humanitarian decision to spare Iranian lives (Wintour and Borger <a title="Wintour, P., and J. Borger. 2019. Trump says he stopped airstrike on Iran because 150 would have died. The Guardian, 21 June. https://www.theguardian.com/world/2019/jun/21/donald-trump-retaliatory-iran-airstrike-cancelled-10-minutes-before." href="/article/10.1057/s42984-020-00002-1#ref-CR103"    >2019</a>). The lack of military response, however, was noted by the Iranian leadership. By the end of the year, facing significant protests at home against the economic impact of the sanctions and the religious leadership, and protests in Iraq against Iraqi government corruption and Iranian influence, the Iranian military leadership hatched a plan. In a meeting, Soleimani decided that if they could provoke the USA into a military attack, they could turn both domestic and Iraqi anti-Iranianism into anti-Americanism, unifying both peoples and forcing the withdrawal of US forces from the region (Reuters <a title="Reuters, I. 2020a. Inside the plot by Iran’s Soleimani to attack U.S. forces in Iraq. Reuters, 4 January. https://www.reuters.com/article/us-iraq-security-soleimani-insight/inside-the-plot-by-irans-soleimani-to-attack-us-forces-in-iraq-idUSKBN1Z301Z             ." href="/article/10.1057/s42984-020-00002-1#ref-CR75">2020a</a>).</p>
<p>Hence, attacks by pro-Iranian militias on US Iraqi bases were stepped up, with a rocket attack by Kata’ib Hezbollah on 27 December succeeding in killing a US contractor. Soleimani’s plan worked. The USA responded with airstrikes against the group on 29, killing 25 and wounding over 50, leading to organised Iraqi mobs attacking the US embassy in Baghdad on 31. The symbolic humiliation of the burning buildings and defaced property stung Trump who took to Twitter to declare, ‘….Iran will be held fully responsible for lives lost, or damage incurred, at any of our facilities. They will pay a very BIG PRICE! This is not a Warning, it is a Threat. Happy New Year!’ On 1 January 2020, Iran’s Ayatollah Sayyed Ali Khamenei, Iran’s Supreme Leader, trolled Trump on the same platform, tweeting, ‘You can’t do anything’
(Khamenei <a title="Khamenei, S.A. 2020. That guy has tweeted… Twitter, 1 January, 9.14 am. https://twitter.com/khamenei_ir/status/1212301034871279616?lang=en." href="/article/10.1057/s42984-020-00002-1#ref-CR47">2020</a>). The drone-strike response came two days later. Boom! Mic drop.</p>
<p>Soleimani hadn’t simply brought it on himself in that October meeting, he’d taunted Trump online for several years. Responding to a Trump tweet in a speech on 26 July 2018, Soleimani denounced Trump as a ‘gambler’ who spoke like ‘a bar-tender or casino-manager’, adding ‘Come, we are waiting for you’
(Dorn <a title="Dorn, S. 2020. Iranian general Qassem Soleimani once taunted Trump in fiery speech. New York Post, 4 January. https://nypost.com/2020/01/04/iranian-general-qassem-soleimani-once-taunted-trump-in-fiery-speech/." href="/article/10.1057/s42984-020-00002-1#ref-CR34">2020</a>). Two days later, Soleimani joined Instagram, with one of his first posts an <em>Olympus Has Fallen</em> spoof photograph of himself in front of an exploding White House. He followed that on the 30th with another post of himself that quoted his own speech under the headline, ‘Mr. Trump! The gambler! Don’t threaten our lives!’ (Memri <a title="Memri. 2018. IRGC Qods Force Commander Qassem Soleimani, Designated By U.S. Treasury Dept., is active on Instagram; posts include image of white house exploding’, MEMRI cyber and jihad lab. 16 August. http://cjlab.memri.org/lab-projects/iran-cyber-initiative-lab-projects/irgc-qods-force-commander-qassem-soleimani-designated-by-u-s-treasury-dept-is-active-on-instagram-posts-include-image-of-white-house-exploding/." href="/article/10.1057/s42984-020-00002-1#ref-CR59">2018</a>). On 3 November 2018, Soleimani responded to a Trump tweet playing on <em>A Game of Thrones</em>’ tagline saying ‘Sanctions are coming’, by posting an Instagram image of himself with the message ‘I will stand against you’ in the same show’s characteristic font. The online pop-cultural troll war would have continued had Instagram not suspended Soleimani’s account in April 2019
(Johnson <a title="Johnson, M. 2020. World war III memes take off on social media after US strike killing Iranian general. The Hill, 4 January. https://thehill.com/homenews/administration/476766-world-war-iii-memes-take-off-on-social-media-after-us-strike-killing." href="/article/10.1057/s42984-020-00002-1#ref-CR46">2020</a>), but the abuse obviously rankled Trump who’d later justify Soleimani’s killing on the basis that he was ‘saying bad things about our country’
(Pengelly <a title="Pengelly, M. 2020. Trump claims Suleimani was ‘saying bad things’ about US before deadly strike. The Guardian, 18 January. https://www.theguardian.com/us-news/2020/jan/18/trump-suleimani-iran-drone-strike." href="/article/10.1057/s42984-020-00002-1#ref-CR67">2020</a>).</p>
<p>Immediately after the Soleimani drone-strike, the hashtags #WWIII and
#FranzFerdinand began trending on twitter and social media exploded with memes about the coming war (Bogart <a title="Bogart, N. 2020. Twitter is convinced ‘World War 3’ is imminent after U.S. kills Iran’s top general. CTV News, 3 January. https://www.ctvnews.ca/world/twitter-is-convinced-world-war-3-is-imminent-after-u-s-kills-iran-s-top-general-1.4752020." href="/article/10.1057/s42984-020-00002-1#ref-CR26">2020</a>). BBC TV’s <em>Have I Got News For You</em> 3 January 2020 tweet was widely shared, expressing a common sentiment:</p>
<blockquote>
<p>Jan 1st: New decade going fairly well, all things considered.</p>
<p>Jan 2nd: Australia appears to be on fire.</p>
<p>Jan 3rd: World War III announced.</p>
</blockquote>
<p>With both genuine and organised mourning for Soleimani whipping up anti-American fury in Iraq and Iran, the fears seemed real, but Iran’s retaliation proved carefully modulated, with precise rocket attacks early in the morning of 8 January on two USA–Iraq bases avoiding fatalities. ‘All is well!’, Trump immediately tweeted, happy with the lack of casualties (Helsel <a title="Helsel, P. 2020. ‘All is well!’ Trump tweets after Iran targets U.S. forces in missile attack in Iraq. NBC News, 8 January. https://www.nbcnews.com/politics/donald-trump/trump-tweets-all-well-after-iranian-missile-attack-targeting-u-n1112211." href="/article/10.1057/s42984-020-00002-1#ref-CR41">2020</a>); but here again, this was just more ‘fake news’ to add to the global disinformation around any event. As information about brain injuries mounted, Trump downplayed the problem as ‘headaches’. By 30 January, the USA admitted that 64 troops had suffered ‘traumatic brain injury’ (Baron <a title="Baron, K. 2020. Now It’s 64. Wounded troop tally from Iran missile strike rises again. Defense one, 30 January. https://www.defenseone.com/threats/2020/01/wounded-troop-tally-iran-missile-strike-expected-rise-again/162763/?oref=defenseone_today_nl." href="/article/10.1057/s42984-020-00002-1#ref-CR11">2020</a>). Iranians were jubilant at the response and the apparent damage, with Iranian state television spreading its own disinformation, claiming over 80 US troops killed and around 200 wounded (Staff <a title="Staff, T. 2020. Iran claims 80 American troops killed in missile barrage; US says no Casualties. The Times of Israel, 8 January. https://www.timesofisrael.com/iranian-state-media-claims-more-than-80-us-soldiers-killed-in-missile-barrage/." href="/article/10.1057/s42984-020-00002-1#ref-CR79">2020</a>). Iran’s pride had been restored, or so it seemed.</p>
<p>But a catastrophic event, caught up in the new military reality of full spectrum access, soon upended this state of affairs. This was the loss of all 176 people on board Ukrainian International Airlines flight PS752 which crashed soon after take-off from Tehran airport just after 6 am local time, a few hours after the missile strikes. For several days, the Iranian leadership blamed ‘technical difficulties’ and began a process of debris clean-up that attracted international concern. What first undermined their claim, however, was user-generated content from their own citizens, with mobile phone videos quickly emerging showing the plane as a small ball of fire coming down in an explosion and small balls of light streaking up and striking the plane (Beaumont et al. <a title="Beaumont, P., P., Torpey, and P. Scruton. 2020. A visual guide to the Iran plane crash. The Guardian, 13 January. https://www.theguardian.com/world/2020/jan/09/iran-plane-crash-visual-guide." href="/article/10.1057/s42984-020-00002-1#ref-CR23">2020</a>). Everything suggested the plane was shot down, and by the 9th US officials announced they had spy-satellite evidence that IRGC anti-aircraft missiles had downed the plane by accident. Iran vehemently denied this, with the head of their Civil Aviation Organization Ali Abedzadeh claiming,
‘Scientifically, it is impossible that a missile hit the Ukrainian plane, and such rumours are illogical’ and government spokesman Ali Rabiei angrily asserting, ‘All these reports are a psychological warfare against Iran’
(Reuters <a title="Reuters, I. 2020b. Iran denies shooting down Ukrainian plane, calls charges illogical rumours’, India Today, 10th January. https://www.indiatoday.in/world/story/iran-denies-ukrainian-plane-was-hit-by-missile-statement-1635509-2020-01-10." href="/article/10.1057/s42984-020-00002-1#ref-CR76">2020b</a>).</p>
<p>The USA was reluctant to release their evidence, but they didn’t have to. More Iranian citizen videos and the full might of Open Source Intelligence Techniques (OSINT) began to undermine their position, with Bellingcat and the <em>New York Times</em> especially working on publicly available evidence to establish the facts. Like a crowd-sourced project, people sent videos and links to Bellingcat who analysed embedded video metadata, including EXIF data with precise latitude and longitude coordinates. They also tried to geolocate footage, mapping buildings, signs, and roads onto satellite imagery and using Google Street View to precisely match landmarks and locate the position and direction of the video. Audio and visual cues also helped, linked with Open Source Flight Trackers to establish that the plane in the video was definitely PS752. Analysis of the missiles in the videos and of videos and photographs of the crash-scene built on this, with research going so far as to acquire and consult the technical manual of the Tor M-1 missile, claimed to have been used to determine its fragmentation pattern so that it could be compared with the damage seen in crash-site imagery
(Stokel-Walker <a title="Stokel-Walker, C. 2020. How digital sleuths unravelled the mystery of Iran’s plane Crash. Wired, 13 January. https://www.wired.co.uk/article/iran-plane-crash-news." href="/article/10.1057/s42984-020-00002-1#ref-CR81">2020</a>).</p>
<p>Iran’s belated admission on 11 January that they <em>had</em> shot down the plane arguably owed more to this investigatory pressure than western government denunciations. The accumulating evidence, much provided by their own citizens, was becoming too difficult to deny. The admission proved to be a key turning point, as the anti-Americanism rapidly reversed itself back against the Iranian government, leading to renewed demonstrations at the deaths, the incompetence, and the lies. Meanwhile, the conflict returned again to the Internet, with international diplomacy continuing to play out over Twitter. On 17 January, Khamenei and Trump played the digital ‘dozens’ again, burning each other with their tweets:
‘Instead of leading Iran towards ruin, its leaders should abandon terror and Make Iran Great Again!’, Trump sniped at the Supreme Leader (Griffith <a title="Griffith, K. 2020b. ‘Abandon terror and Make Iran Great Again!’ Donald Trump trades barbs with Ayatollah Khamenei after Iran’s supreme leader accused him of plotting to ‘stab the Iranian people in the heart with venomous daggers.’ Daily Mail, 18 January. https://www.dailymail.co.uk/news/article-7901197/Donald-Trump-trades-barbs-Ayatollah-Khamenei-Twitter.html." href="/article/10.1057/s42984-020-00002-1#ref-CR39">2020b</a>).</p>
<p><u>This is conflict today</u>. Smartphone-equipped leaders bypass traditional modes of communication and diplomacy to announce their policies
(and every passing thought) directly onto Twitter, globally trading personal insults and threats; top-level generals weaponize social media to spread snark; the public of every country joins in with their own bottom-up memetic and informational warfare; hashtag wars, disinformation and trolling by states, non-state actors, and keyboard warriors proliferate, confusing political debate and blurring knowledge; global, digital, military panopticon, and command systems mobilise unmanned weapons to assassinate enemies with pinpoint precision; government denials are undone within days by their own citizen’s videos taken and spread across messaging apps and investigated by a global army of OS investigators, and, beneath it all, there are the ongoing cyberoperations almost certainly launched by the USA and Iran against each other. Reports of US cyberattacks on 20 June (the day Trump backed down on airstrikes) targeting the computer systems and databases Iran was using to attack Gulf oil shipping and Iranian missile systems demonstrate CNE capabilities are in play (Ibbetson <a title="Ibbetson, R. 2019b. US launched a cyber attack on Iran to destroy computer systems that Tehran was using to target oil tankers in the Gulf. Daily Mail, 29 August. https://www.dailymail.co.uk/news/article-7406177/US-launched-cyber-attack-Iran-destroy-computer-systems-Tehran-used-target-tankers-Gulf.html." href="/article/10.1057/s42984-020-00002-1#ref-CR44">2019b</a>; BBC <a title="BBC. 2019c. US “launched cyber-attack on Iran weapons systems”. BBC News, 23 June. https://www.bbc.co.uk/news/world-us-canada-48735097." href="/article/10.1057/s42984-020-00002-1#ref-CR15">2019c</a>), and there are also claims of Iranian attacks and a possible response after the Soleimani strike (Tucker <a title="Tucker, P. 2019a. Suspected Iranian cyber attacks show no sign of slowing. Defense one. 3 July. https://www.defenseone.com/technology/2019/07/suspected-iranian-cyber-attacks-show-no-sign-slowing/158213/?oref=defenseone_today_nl." href="/article/10.1057/s42984-020-00002-1#ref-CR85">2019a</a>; Griffith <a title="Griffith, K. 2020a. ‘Iranian hackers’ breach US government website operated by the Federal Depository Library Program in retaliation for airstrike. Daily Mail, 5 January. https://www.dailymail.co.uk/news/article-7852819/Iranian-hackers-breach-government-website-retaliation-airstrike.html." href="/article/10.1057/s42984-020-00002-1#ref-CR38">2020a</a>). Given, however, the recent revelation of Russia’s ‘Turla’ group hacking Iranian hackers to masquerade as Iranians in attacks on over 35 countries (Warrell and Fox <a title="Warrell, H., and H. Fox. 2019. Russian cyberattack unit ‘masqueraded’ as Iranian hackers, UK says. Financial Times, 21 October. https://www.ft.com/content/b947b46a-f342-11e9-a79c-bc9acae3b654." href="/article/10.1057/s42984-020-00002-1#ref-CR99">2019</a>), we could honestly ask who knows who’s involved?</p>
<h2>Destructive Creation</h2>
<p>Digital technologies have proven highly disruptive. As Lev Manovich argues, the meeting and merger of computing technologies with mass media at the end of the twentieth century gave rise to contemporary ‘new’ digital media
(Manovich <a title="Manovich, L. 2001. The Language of New Media. London: MIT Press." href="/article/10.1057/s42984-020-00002-1#ref-CR55">2001</a>). Except this merger was closer to a ‘digitalphagy’ (Merrin <a title="Merrin, W. 2014. Media Studies 2.0. Abingdon, Oxon: Routledge." href="/article/10.1057/s42984-020-00002-1#ref-CR60">2014</a>, 34), as computer processing <em>eat</em> mass media, as a meta-medium absorbing all previously separate forms as mere types of digital content, allowing it to be more easily produced, distributed, shared, taken, reworked, remixed, and added to and critiqued. As the technologies spread, the result was an epochal, <em>structural revolution in communication</em>
(Merrin <a title="Merrin, W. 2014. Media Studies 2.0. Abingdon, Oxon: Routledge." href="/article/10.1057/s42984-020-00002-1#ref-CR60">2014</a>).</p>
<p>Within a few decades, the entire broadcast model of mass media that had become dominant in the centuries after Gutenberg’s creation of the printing press was blown apart. The centuries-old division between a minority of creators and the mass of receivers was replaced by a new, dynamic world of empowered individual producers and their p2p, anyone-to-anyone, anything-to-anything, communicational, and technological relationships. The result has been an ongoing churn-up of business models, of news and information, of how we know, what we know, what we’re interested in, and what we want to spend our time doing. Ongoing developments such as the rise of broadband, domestic and public Wi-fi, increasing digital interconnectivity and operability, and increasingly smart and capable, multi-media phones and devices and the Web 2.0 ‘architectures of participation’ that support and promote their use have remade the entire global media ecology. This disruption has also been deliberately produced. Today’s dominant technology companies are heirs to ‘the Californian ideology’, a vision combining countercultural ideals of personal development and self-realisation with a Randian individualism, Neoliberal anti-regulatory libertarianism, and a love of Schumpeterian ‘creative destruction’ (Turner <a title="Turner, F. 2006. From Counterculture to Cyberculture. Chicago: University of Chicago Press." href="/article/10.1057/s42984-020-00002-1#ref-CR96">2006</a>; Barbrook <a title="Barbrook, R. 2007. Imaginary futures. London: Pluto." href="/article/10.1057/s42984-020-00002-1#ref-CR10">2007</a>). Facebook’s early mantra ‘Move Fast and Break Things’ was later revealed to be an all-too-honest expression of the company’s philosophy and business model (Taplin <a title="Taplin, J. 2018. Move Fast and Break Things. London: Pan Books." href="/article/10.1057/s42984-020-00002-1#ref-CR84">2018</a>).</p>
<p>Today it’s hard to find any sector of human life and activity that hasn’t been disrupted by digital technology, and war and conflict are no exceptions. Neoliberal economic ‘creative destruction’ becomes here <em>destructive creation</em>, as digital technologies have created new possibilities of destructive activity. Digital technologies have fundamentally changed how wars are fought, who fights them, how they’re fought, where they’re fought, how we know about them, how we spread information about them and even what war itself is, and they have done so continuously, in an ongoing transformation of a scale and scope that is difficult to track and comprehend: For ‘move fast and break things’, read
‘tweet fast and kill things’.</p>
<p>Importantly, the shock of Soleimani’s death was primarily a shock at who was hit, not at how it was done. As the Drone Wars UK report <em>In The Frame</em>, published on 19 January 2020, argues, this culture of targeted drone killing has become ‘normalised’ today (Sabbagh <a title="Sabbagh, D. 2020. Targeted killings via drone becoming ‘normalised’. The Guardian, 19 January. https://www.theguardian.com/politics/2020/jan/19/military-drone-strikes-becoming-normalised-says-report." href="/article/10.1057/s42984-020-00002-1#ref-CR77">2020</a>). The US drone programme in Afghanistan, for example, continues, along with its similarly normalised civilian casualties (Reuters <a title="Reuters. 2019a. US drone strike intended for Isis hideout kills 30 pine nut workers in Afghanistan. The Guardian, 19 September. https://www.theguardian.com/world/2019/sep/19/us-drone-strike-deaths-afghanistan-pine-nut-workers." href="/article/10.1057/s42984-020-00002-1#ref-CR72">2019a</a>), whilst other nations such as Iran and Turkey have built up their own drone fleets, deploying them, for example, in Syria. Iran is also widely seen as responsible for one of the most important recent drone attacks, the attack on Saudi oil facilities on 14 September 2019 that disrupted global supplies (BBC <a title="BBC. 2019a. Saudi oil attacks: Images show detail of damage. BBC News, 16 September. https://www.bbc.co.uk/news/world-middle-east-49718975." href="/article/10.1057/s42984-020-00002-1#ref-CR13">2019a</a>). China has also emerged as a key source of drone development—as seen in their unveiling of the new Wuzhen-8 supersonic UAV in September 2019 (You <a title="You, T. 2019. China’s top-secret supersonic spy drone ‘which can reach the US territory is unveiled for the first time’. Daily Mail, 17 September. https://www.dailymail.co.uk/news/article-7472991/Beijings-secret-supersonic-spy-drone-spotted-time.html." href="/article/10.1057/s42984-020-00002-1#ref-CR104">2019</a>)—and of proliferation, as they seek to sell their models abroad.</p>
<p>Meanwhile, in January 2020, NATO took delivery of their first NATO-owned and operated drones, US Global Hawks, able to monitor a territory the size of Poland (BBC <a title="BBC. 2019b. ‘Global Hawk drones: A look at NATO’s new spy tool. BBC News, 18 January. https://www.bbc.co.uk/news/av/technology-51156680/global-hawk-drones-a-look-at-nato-s-new-spy-tool." href="/article/10.1057/s42984-020-00002-1#ref-CR14">2019b</a>), whilst the UK Navy began tests on a MAST-13 unmanned sea vehicle (USV)
fleet in September 2019 (Lloyd <a title="Lloyd, P. 2019b. Drones of the sea: Royal Navy begins trials of unmanned military boats which can be remote-controlled for hundreds of miles and find mines or spy on enemy ships. Daily Mail, 12 September. https://www.dailymail.co.uk/sciencetech/article-7456057/Royal-Navy-tests-unmanned-boats-search-mines-spy-enemy-ships.html." href="/article/10.1057/s42984-020-00002-1#ref-CR53">2019b</a>) and the RAF unveiled their new Protector drone in August (Brown <a title="Brown, L. 2019. Unveiled: RAF’s deadly new Protector drone is fitted with ‘game-changing technology’ that detects and avoids other planes and can remain in the air for FORTY hours. Daily Mail, 21 August. https://www.dailymail.co.uk/news/article-7381265/Unveiled-RAFs-deadly-new-Protector-drone-fitted-game-changing-technology.html." href="/article/10.1057/s42984-020-00002-1#ref-CR27">2019</a>). In July 2019, the USA announced the deployment of the first pocket-sized surveillance drones in Afghanistan, the ‘Black Hornet Personal Reconnaissance Systems’ (Bell <a title="Bell, V. 2020. Attack of the drones! U.S. Army reveals the first deployment of its pocket-sized drones in Afghanistan this month. Daily Mail, July. https://www.dailymail.co.uk/sciencetech/article-7204803/First-deployment-pocket-sized-drones-Afghanistan.html." href="/article/10.1057/s42984-020-00002-1#ref-CR24">2020</a>), whilst the month before it announced a new BAE contract to build four 50-ton, armed ‘Extra Large Unmanned Undersea Vehicle’ Orcas (Ardehali <a title="Ardehali, R. 2019. Boeing to build four 50-ton ‘Orca’ undersea drones for the US Navy that can wage war at depths of 11,000 feet, hunting mines and sinking submarines. Daily Mail, 3 June. https://www.dailymail.co.uk/news/article-7100591/Navy-starts-building-new-massive-50-ton-undersea-attack-drone.html." href="/article/10.1057/s42984-020-00002-1#ref-CR7">2019</a>). Key, ongoing developments in drones revolve around their increasing autonomy and in ‘swarm robotics’ research. DARPA is working on Offensive Swarm-Enabled Tactics (OFSET) which envisions humans using virtual reality to control micro-drone formations and have tested their Collaborative Operations in Denied Environments (CODE) human-controlled drone swarms. Meanwhile, Chinese drone developers Zhuhai Ziyan claim to have developed autonomously operating heli-drone swarms that can attack and overwhelm enemy forces (Peck <a title="Peck, M. 2019a. China Will Overwhelm Its Enemies With Swarms of Rocket-Armed Heli-Drones. The National Interest, 26 May. https://nationalinterest.org/blog/buzz/china-will-overwhelm-its-enemies-swarms-rocket-armed-heli-drones-59277." href="/article/10.1057/s42984-020-00002-1#ref-CR65">2019a</a>).</p>
<p>Developments in robotics are slower but are serious enough to warrant increasingly regular warnings from AI experts and campaign groups (Guarav <a title="Guarav, K. 2020. AI expert calls ‘killer robots’ greater threat to humans than climate change. Republic, 19 January. https://www.republicworld.com/world-news/rest-of-the-world-news/ai-expert-calls-killer-robots-greater-threat-to-humans-than-climate.html." href="/article/10.1057/s42984-020-00002-1#ref-CR40">2020</a>; Wareham <a title="Wareham, M. 2020. As killer robots loom, a push to keep humans in control of use of force. Human Rights Watch, 2 January. https://www.hrw.org/news/2020/01/02/killer-robots-loom-push-keep-humans-control-use-force." href="/article/10.1057/s42984-020-00002-1#ref-CR98">2020</a>). In September 2019, for example, a Google software engineer who resigned at being asked to work on drone technology warned that a new generation of autonomous weapons or ‘killer robots’ could accidentally start a war or cause ‘mass atrocities’ (McDonald <a title="McDonald, H. 2019. Ex-Google worker fears ‘killer robots’ could cause mass Atrocities. The Guardian, 15 September. https://www.theguardian.com/technology/2019/sep/15/ex-google-worker-fears-killer-robots-cause-mass-atrocities." href="/article/10.1057/s42984-020-00002-1#ref-CR57">2019</a>). The technologies themselves are progressing and increasingly being deployed. In October 2019, the US Army showed off their new Textron Systems’
Ripsaw M5 ‘robotic combat vehicle’ (Randall <a title="Randall, I. 2019b. Robot tank named ‘Ripsaw M5’ with armour-piercing ammunition and on-board drones is built for the US Army. Daily Mail, 29 October. https://www.dailymail.co.uk/sciencetech/article-7625517/Ripsaw-M5-Robot-TANK-armour-piercing-ammunition-board-drones-built-Army.html." href="/article/10.1057/s42984-020-00002-1#ref-CR71">2019b</a>), whilst in September, Boston Dynamics announced a new leasing scheme for their ‘Spot’ dog robot which, by December, was undergoing tests with the Massachusetts State Police Department (Jackson <a title="Jackson, S. 2019. Boston dynamics robot dog spot used in police training for first time. Daily Star, 27 December. https://www.dailystar.co.uk/news/world-news/boston-dynamics-robot-dog-spot-21169898." href="/article/10.1057/s42984-020-00002-1#ref-CR45">2019</a>).</p>
<p>Beyond robotics, many are warning of the broader dangers of military AI, especially as the USA appears to be in an ‘AI arms-race’ with China, with the Defense Department requesting a tripling of its 2020 AI research budget to $268 m to fight the threat (Ashizuka <a title="Ashizuka, T. 2019. Pentagon seeks to triple AI warfare budget to meet China’s rise. Nikkei Asian Review, 4 October. https://asia.nikkei.com/Business/Aerospace-Defense/Pentagon-seeks-to-triple-AI-warfare-budget-to-meet-China-s-rise." href="/article/10.1057/s42984-020-00002-1#ref-CR8">2019</a>). AI is increasingly being used in military technology, from facial-recognition goggles (Tucker <a title="Tucker, P. 2019b. Army goggles will feature facial recognition tech ‘very soon’. Defense one, 17th July. https://www.defenseone.com/technology/2019/07/army-soldier-goggles-will-feature-facial-recognition-tech-very-soon/158505/?oref=defenseone_today_nl." href="/article/10.1057/s42984-020-00002-1#ref-CR86">2019b</a>), increasingly autonomous missiles such as Israel’s Spice 250 (Frantzman and Atherton <a title="Frantzman, S.J., and K.D. Atherton. 2019. Israel’s Rafael integrates artificial intelligence into Spice bombs. DefenseNews, 17 June. https://www.defensenews.com/artificial-intelligence/2019/06/17/israels-rafael-integrates-artificial-intelligence-into-spice-bombs/?utm_source=Sailthru&amp;utm_medium=email&amp;utm_campaign=EBB%2006.18.19&amp;utm_term=Editorial%20-%20Early%20Bird%20Brief." href="/article/10.1057/s42984-020-00002-1#ref-CR36">2019</a>) and target identification, as in the now-famous Pentagon/Google Project Maven. More generally, the spread of AI raises the interesting point that what we may need to fear in the future isn’t, as many campaign groups suggest, ‘killer robots’, but AI commanders, as their identificatory and decision-making capabilities increase. Highly complex, multi-asset battlefield forces moving at digital speeds will, in all likelihood, leave human capacities behind, leaving AI-based systems as the primary commanders
(Merrin <a title="Merrin, W. 2018. Digital War: A critical introduction.&nbsp;Abingdon, Oxon: Routledge." href="/article/10.1057/s42984-020-00002-1#ref-CR61">2018</a>, 285). AI and robotics, of course, won’t just work on their own, but they’ll be integrated into more complex military systems and forces. In December 2019, it was reported that computer-simulated battles at the Fort Benning’s Maneuver Battle Lab demonstrated that troops reinforced with ground robots and drones repeatedly routed defending forces three times their size without losing a single human soldier, with their addition giving
‘a 10–fold increase in combat power’ (Freedberg <a title="Freedberg, S.J. Jr. 2019. AI and robots crush foes in army wargame. Breaking Defense, 19 December. https://breakingdefense.com/2019/12/ai-robots-crush-foes-in-army-wargame/." href="/article/10.1057/s42984-020-00002-1#ref-CR37">2019</a>).</p>
<p>AI is also seen as central to developments in soldier augmentation and
‘wearable’ technologies. DARPA’s new ‘Next-Generation Nonsurgical Neurotechnology’ (N3) program is exploring how AI could help ‘next generation neurotechnology’. Research areas include the use of brain–computer interfaces (BCI) to enable soldiers to control, feel, and interact with remote machines as if they were part of their own body
(Corrigan <a title="Corrigan, J. 2019. DARPA Thinks AI could help troops telepathically control machines. Defense One, 18 February. https://www.defenseone.com/technology/2019/02/darpa-thinks-ai-could-help-troops-telepathically-control-machines/154937/?oref=d1-related-article." href="/article/10.1057/s42984-020-00002-1#ref-CR32">2019</a>), systems to help machines read and understand human thoughts (Tucker <a title="Tucker, P. 2019c. The army wants AI to read soldiers’ minds. Defense one, 8 April. https://www.defenseone.com/technology/2019/04/army-wants-ai-read-soldiers-minds/156147/?oref=d1-related-article." href="/article/10.1057/s42984-020-00002-1#ref-CR87">2019c</a>), BCI computer strips attached to the neck to control future vehicles
(Tucker <a title="Tucker, P. 2019d. A new joystick for the brain-controlled vehicles of the future. Defense one, 23 September. https://www.defenseone.com/technology/2019/09/new-joystick-brain-controlled-vehicles-future/160092/?oref=defenseone_today_nl." href="/article/10.1057/s42984-020-00002-1#ref-CR88">2019d</a>), robotic arms controllable by EEG caps (Blanchard <a title="Blanchard, S. 2019. The robotic arm controlled by your MIND: Incredible video shows pioneering gadget moving entirely by thought. Daily Mail, 20 June. https://www.dailymail.co.uk/health/article-7163859/The-robotic-arm-controlled-MIND.html." href="/article/10.1057/s42984-020-00002-1#ref-CR25">2019</a>), and the Magnetic, Optical and Acoustic Neural Access (MOANA)
‘mind-reading’ helmet to control robots and drones (Randall <a title="Randall, I. 2019a. US Military funds mind-reading helmet that may let soldiers telepathically control robots or drones and could even give the gift of sight to the blind. Daily Mail, 6 June. https://www.dailymail.co.uk/sciencetech/article-7111199/US-Military-funds-mind-reading-helmet-let-soldiers-TELEPATHICALLY-control-robots-drones.html." href="/article/10.1057/s42984-020-00002-1#ref-CR70">2019a</a>). Research into exo-skeletons continues too. Though the US Army has scrapped its TALOS suit programme (Tucker <a title="Tucker, P. 2019e. The U.S. military is chopping up its iron man suit for parts’, Defense one, 7 February. https://www.defenseone.com/technology/2019/02/us-military-chopping-its-iron-man-suit-parts/154706/." href="/article/10.1057/s42984-020-00002-1#ref-CR89">2019e</a>), individual technologies within it will still be used, whilst in January 2020, Delta and Sarcos robotics demonstrated a functioning exo-skeleton, the Guardian XO for 2020 production, proving the concept has a future (Pero <a title="Pero, J. 2020. Human exoskeleton revealed by Delta and Sarcos Robotics at CES picks up 130-pound airplane tire with ease. Daily Mail, 9. January, 
              https://www.dailymail.co.uk/sciencetech/article-7867651/Exoskeleton-debuted-Delta-Sarcos-Robotics-makes-lifting-airplane-tire-feel-like-20-POUNDS.html." href="/article/10.1057/s42984-020-00002-1#ref-CR68">2020</a>).</p>
<p>The US military’s growing interest in augmentation systems was also seen in Special Operations Command’s (SOCOM) May 2019 announcement of their
‘Hyper-Enabled Operator’ (HEO) concept and subsequent research stemming from it seeking to combine sensors and AI to give elite troops superhuman capacities (Tucker <a title="Tucker, P. 2019f. Special operations command made a mind-reading kit for elite troops’. Defense one, 11 December. https://www.defenseone.com/technology/2019/12/specops-lab-made-mind-reading-kit-elite-troops/161830/?oref=defense_one_breaking_nl." href="/article/10.1057/s42984-020-00002-1#ref-CR90">2019f</a>). The ‘smart’ revolution is also transforming weapons. Guns and bullets are getting increasingly networked, but any item of military hardware could potentially be upgraded, as seen in January 2020 in the US military’s interest in using wirelessly networked, ‘smart’ landmines (Tucker <a title="Tucker, P. 2020a. U.S. expected to loosen restrictions on land mines—Smart ones, anyway’. Defense one, 30 January. https://www.defenseone.com/technology/2020/01/us-expected-loosen-restrictions-land-mines-smart-ones-anyway/162773/?oref=defense_one_breaking_nl." href="/article/10.1057/s42984-020-00002-1#ref-CR93">2020a</a>).</p>
<p>Other recent US military developments include the October 2019 announcement of the upgrading of specific bases for 5G broadband technology to improve connectivity and the range of operations supported by the bases, including smart warehousing and AR/VR training systems (Adamczyk <a title="Adamczyk, E. 2019. Pentagon to prepare four U.S. bases for 5G broadband technology, UPI, 4 November. https://www.upi.com/Defense-News/2019/11/04/Pentagon-to-prepare-four-US-bases-for-5G-broadband-technology/8291572896910/." href="/article/10.1057/s42984-020-00002-1#ref-CR1">2019</a>). The same month saw the Pentagon awarding a $10b cloud-computing Joint Enterprise Defense Infrastructure (JEDI) contract to Microsoft to upgrade the DoD, whilst Summer 2019 saw the USAF starting work on data architecture for its planned Advanced Battle Management System, the family of platforms that will eventually replace the E-8C JSTARS surveillance planes, a project aiming to increase weapon lethality and networking (Weisgerber <a title="Weisgerber, M. 2019. U.S. Air force to shift billions of dollars to network its weapons. Defense one, 17 September. https://www.defenseone.com/business/2019/09/us-air-force-shift-billions-dollars-network-its-weapons/159958/?oref=defenseone_today_nl." href="/article/10.1057/s42984-020-00002-1#ref-CR100">2019</a>).</p>
<p>And all the time cyberoperations and computer network exploitation carry on as the ambient background of international relations. Here, things can get strange, as in recent claims of the Saudi crown prince hacking Jeff Bezos’
phone with WhatsApp spyware messages (Kirchgaessner <a title="Kirchgaessner, S. 2020. Jeff Bezos hack: Amazon boss’s phone ‘hacked by Saudi crown prince’. The Guardian, 22 January. https://www.theguardian.com/technology/2020/jan/21/amazon-boss-jeff-bezoss-phone-hacked-by-saudi-crown-prince." href="/article/10.1057/s42984-020-00002-1#ref-CR49">2020</a>), the exposure of the Russian ‘Turla’ group’s simulation of Iranian hackers (Warrell and Fox <a title="Warrell, H., and H. Fox. 2019. Russian cyberattack unit ‘masqueraded’ as Iranian hackers, UK says. Financial Times, 21 October. https://www.ft.com/content/b947b46a-f342-11e9-a79c-bc9acae3b654." href="/article/10.1057/s42984-020-00002-1#ref-CR99">2019</a>) and Twitter’s recent admission that hackers with possible ‘ties to state-sponsored actors’ in Malaysia, Iran, and Israel stole millions of mobile phone numbers linked to user accounts (Pinkstone <a title="Pinkstone, J. 2020. Twitter admits state-backed hackers in Malaysia, Iran and Israel may have stolen up to 17 million phone numbers linked to Android user accounts. Daily Mail, 4 February. https://www.dailymail.co.uk/sciencetech/article-7963567/Twitter-says-state-backed-actors-accessed-users-phone-numbers.html." href="/article/10.1057/s42984-020-00002-1#ref-CR69">2020</a>).</p>
<p>Other developments have been easier to follow, such as the UK’s January 2020 announcement of a new MOD/GCHQ National Cyber Force (NCF) dedicated to solely offensive cyberoperations against other countries (Sengupta <a title="Sengupta, K. 2020. UK is nearly ready to launch force to hit hostile countries with Cyberattacks. The Independent, 10 January. https://www.independent.co.uk/news/uk/home-news/cyber-warfare-security-force-iran-crisis-ministry-of-defence-a9278591.html." href="/article/10.1057/s42984-020-00002-1#ref-CR78">2020</a>). But things move fast in the realm of cyber. Recent months have seen an array of stories including a ransomware attack on a US base (BBC), Microsoft seizing North-Korean websites used for cyberattacks (Morrison <a title="Morrison, R. 2019. Microsoft seizes control of 50 websites used by a North Korea linked hacking group to carry out cyber-attacks on government workers, human rights groups and nuclear activists. Daily Mail, 31 December. https://www.dailymail.co.uk/sciencetech/article-7840065/Microsoft-seizes-control-50-websites-used-North-Korea-linked-hacking-group.html." href="/article/10.1057/s42984-020-00002-1#ref-CR62">2019</a>), Israeli spyware being discovered on Pakistani government official’s phones (Kirchgaessner <a title="Kirchgaessner, S. 2019. Israeli spyware allegedly used to target Pakistani officials’ Phones. The Guardian, 19 December. https://www.theguardian.com/world/2019/dec/19/israeli-spyware-allegedly-used-to-target-pakistani-officials-phones." href="/article/10.1057/s42984-020-00002-1#ref-CR48">2019</a>), New Orleans declaring a state of emergency following the discovery of suspicious activity over the city’s networks (Winder <a title="Winder, D. 2019. New Orleans declares state of emergency following cyber attack. Forbes, 14 December. https://www.forbes.com/sites/daveywinder/2019/12/14/new-orleans-declares-state-of-emergency-following-cyber-attack/#7f82322d6a05." href="/article/10.1057/s42984-020-00002-1#ref-CR101">2019</a>), possible Chinese spying attacks on Iran (BBC <a title="BBC. 2019d. Iran “foils second cyber-attack in a week”. BBC News, 15 December. https://www.bbc.co.uk/news/world-middle-east-50799147." href="/article/10.1057/s42984-020-00002-1#ref-CR16">2019d</a>), DDOS attacks on the UK Labour Party during the November election (Walker and Hern <a title="Walker, P., and A. Hern. 2019. Labour suffers second cyber-attack in two days. The Guardian, 12 November. https://www.theguardian.com/politics/2019/nov/12/labour-reveals-large-scale-cyber-attack-on-digital-platforms." href="/article/10.1057/s42984-020-00002-1#ref-CR97">2019</a>), Iranians hacking India’s space programme (Stickings <a title="Stickings, T. 2019. India’s doomed moon mission was hacked by North Korea, cyber experts believe. Daily Mail, 8 November. https://www.dailymail.co.uk/news/article-7663917/Indias-doomed-moon-mission-hacked-North-Korea-cyber-experts-believe.html." href="/article/10.1057/s42984-020-00002-1#ref-CR80">2019</a>), a cyberattack on India’s largest nuclear power plant at Kudankulam
(Stickings <a title="Stickings, T. 2019. India’s doomed moon mission was hacked by North Korea, cyber experts believe. Daily Mail, 8 November. https://www.dailymail.co.uk/news/article-7663917/Indias-doomed-moon-mission-hacked-North-Korea-cyber-experts-believe.html." href="/article/10.1057/s42984-020-00002-1#ref-CR80">2019</a>), and Chinese online and cyberoperations against Uighurs, Hong Kong protestors, and even UK mobile phone users (Hern <a title="Hern, A. 2019. Uighurs in China were target of two-year iOS malware attack—reports. The Guardian, 2 September. https://www.theguardian.com/world/2019/sep/02/uighurs-china-target-two-year-ios-malware-attack-reports." href="/article/10.1057/s42984-020-00002-1#ref-CR42">2019</a>; Paul <a title="Paul, K. 2019b. Twitter and Facebook crack down on accounts linked to Chinese campaign against Hong Kong. The Guardian, 20 August. https://www.theguardian.com/technology/2019/aug/19/twitter-china-hong-kong-accounts." href="/article/10.1057/s42984-020-00002-1#ref-CR64">2019b</a>; Young <a title="Young, A. 2019. Chinese hackers ‘stole data from UK mobile phones for up to seven Years’ in one of the world’s biggest cyberattacks, experts reveal. Daily Mail, 29 June. https://www.dailymail.co.uk/news/article-7196471/Chinese-hackers-stole-data-UK-mobile-phones-SEVEN-years.html." href="/article/10.1057/s42984-020-00002-1#ref-CR105">2019</a>).</p>
<p>One response to these threats has been to move towards protected, Chinese-style ‘sovereign’ networks, with local storage and control of data. Russia’s own ‘sovereign internet’ law came into force in November 2019, and in December, the government successfully tested their new cyber-defensive strategy of being able to cut off their own network from the Internet, to thwart what they see as increasing US penetration and any future full-scale cyber-war (BBC <a title="BBC. 2019e. Russia “successfully tests” its unplugged internet’. BBC News, 24 December. https://www.bbc.co.uk/news/technology-50902496." href="/article/10.1057/s42984-020-00002-1#ref-CR17">2019e</a>). Global intrusions are now so frequent, however, so as to call the very concept of ‘cyberattacks’ and even ‘war’ itself into question. For example, the UK Chief of Defence Staff General Nick Carter warned in a speech in September 2019, daily state cyberattacks and online influence operations are confusing traditional military categories:</p>
<figure>  
>The changing character of warfare has exposed the distinctions that don’t exist any longer between peace and war. I feel I am now at war, but it’s not a war in the way we would have defined it in the past. And that is because great power competition and the battle of ideas with non-state actors is threatening us on a daily basis.
<figcaption>
(Peck <a title="Peck, M. 2019b. Britain’s top commander: We Are At ‘War Every Day’ with Russia. National Interest. 2 November. https://nationalinterest.org/blog/buzz/britain’s-top-commander-we-are-“war-every-day”-russia-92666." href="/article/10.1057/s42984-020-00002-1#ref-CR66">2019b</a>)
</figcaption>
<figure>
<p>For Carter, the old domains of land sea and air will be extended and perhaps even replaced by the new domains of ‘cyber’ and space.</p>
<p>Space, especially, has emerged as a new military focus. In December 2019, President Trump officially launched the US ‘Space Force’, declaring, ‘Space is the world’s new war-fighting domain’ (Associated Press <a title="Associated Press. 2019. Donald Trump officially launches U.S. space force. The Guardian, 21 December. https://www.theguardian.com/us-news/2019/dec/21/donald-trump-officially-launches-us-space-force." href="/article/10.1057/s42984-020-00002-1#ref-CR9">2019</a>). The primary aim of the force is to defend US interests in space, especially satellites used for navigation and communication, and this new intent was immediately seen in the January 2020 US government decision to restrict the sales of AI-based software that another nation could use to analyse satellite imagery (Tucker <a title="Tucker, P. 2020b. U.S. government to restrict sale of AI for satellite image analysis’. Defense one, 6 January. https://www.defenseone.com/technology/2020/01/us-government-restrict-sale-ai-satellite-image-analysis/162255/?oref=defense_one_breaking_nl." href="/article/10.1057/s42984-020-00002-1#ref-CR94">2020b</a>). In September 2019, it was reported that the NSA was using AI to analyse satellites to detect anomalous readings that might indicate penetration or enemy control (Tucker <a title="Tucker, P. 2019g. The NSA is studying satellite hacking. Defense one, 20 September. https://www.defenseone.com/technology/2019/09/nsa-studying-satellite-hacking/160009/." href="/article/10.1057/s42984-020-00002-1#ref-CR91">2019g</a>), whilst earlier in the year, the Defense Department had indicated it was working on satellites that could dodge missiles or employ their own space-based weapons (Tucker <a title="Tucker, P. 2019h. Pentagon wants satellites that can dodge incoming fire. Defense one, 22 February. https://www.defenseone.com/technology/2019/02/pentagon-wants-satellites-can-dodge-incoming-fire/155088/?oref=defense_one_breaking_nl." href="/article/10.1057/s42984-020-00002-1#ref-CR92">2019h</a>).</p>
<p>Other nations are also interested in space, including France who, in July 2019, announced their plans for a new arsenal of laser-armed satellites, with protective patrolling nano-satellites by 2023 (Lloyd <a title="Lloyd, P. 2019a. ‘Fearsome’ spy satellites armed with lasers and machine guns to be launched by French military by 2023—and an armada of tiny drones could be sent into orbit to bolster its defences. Daily Mail, 29 July. https://www.dailymail.co.uk/sciencetech/article-7297867/Fearsome-spy-satellites-armed-lasers-machine-guns-launched-French.html." href="/article/10.1057/s42984-020-00002-1#ref-CR52">2019a</a>), and India who, in March 2019, conducted a successful test to shoot a satellite down with a missile (AFP). The USA, Russia, and China have all carried out similar tests, with each seeing control of space as a future priority. This battle is almost certainly already happening, as seen in late January 2020 when the Russian satellite, Cosmos 2542, synchronised its orbit with USA 245, a US satellite deployed for military and intelligence applications in order to stalk it (Chadwick <a title="Chadwick, J. 2020. Mysterious Russian spacecraft spotted stalking a U.S. spy satellite “will make its closest approach yet this week”. Daily Mail, 4 February. https://www.dailymail.co.uk/sciencetech/article-7964933/Russian-spacecraft-closer-satellite-weekend.html." href="/article/10.1057/s42984-020-00002-1#ref-CR28">2020</a>). The increasing ubiquity of satellites and ‘GEOINT’ has also forced the USA and others to look for counter-measures and deceptions against space-based surveillance (Koller <a title="Koller, J. 2019. U.S. forces can’t hide from ubiquitous satellites. They need to fool them. Defense One. 16 December. https://www.defenseone.com/ideas/2019/12/us-forces-cant-hide-ubiquitous-satellites-they-need-learn-fool-them/161913/?oref=defenseone_today_nl." href="/article/10.1057/s42984-020-00002-1#ref-CR50">2019</a>).</p>
<p>Beyond military systems, digital technology has transformed the entire battlefield, with multi-media smartphones, messaging apps, and social media platforms especially creating a global, participative battlefield, where the distinctions of combatant, civilian, and informational warrior implode. Today information pours onto, from, about and around the battlefield. We have moved from the 1990s US military hopes of ‘full spectrum dominance’ of all battlefield information to the new military reality of <em>full spectrum access</em>—a mode of ‘participative war’ where everyone can experience and take part in conflict, from governments and militaries to organised non-state actors, to civilians on the battlefield and the entire, interested, engaged global public. Whatever our age, experience, or expertise, we can all fight our own hegemonic battles in a fractal, digital infowar aimed at exposing a particular situation or promoting preferred political interpretations. The military ‘information warfare’
systematically theorised through the 1990s has been completely democratized to anyone with a phone. That is, to anyone.</p>
<p>‘Social media’ in the broadest sense, therefore, has become central to wars and conflicts, imploding with the event, to simultaneously capture it, promote it, denounce it, deny it, spread images, videos, bloopers, memes, jokes, graphics, gifs, and comments, help organise it, raise funds, raise awareness, accrue new recruits, direct combat operations, spread disinformation and propaganda, and rally aid and help for its victims. Since the Abu Ghraib torture was revealed in 2004, digital cameras have regularly exposed the abuse of power in conflict zones, and this was seen again in November 2019 in the leaked checkpoint footage of Israeli police shooting a Palestinian in the back ‘for fun’ (Cole <a title="Cole, W. 2019. Leaked footage shows shocking moment Israeli policewoman shoots Palestinian in the back “for fun”. Daily Mail, 5 November. https://www.dailymail.co.uk/news/article-7649189/Leaked-footage-shows-Israeli-policewoman-shoots-innocent-Palestinian-fun.html." href="/article/10.1057/s42984-020-00002-1#ref-CR30">2019</a>). The Syrian civil war is a major source of this footage, with groups like the Syrian Archive continuing to collect videos from the battlefield, verifying their contents using Open Source tools and curating them for possible future war-crimes trials and to aid post-conflict reconstruction
(Syrian Archive <a title="Syrian Archive. 2020. About: Mission, vision, and workflow. Syrian Archive. https://syrianarchive.org/en/about." href="/article/10.1057/s42984-020-00002-1#ref-CR82">2020</a>). The issue of potential war-crimes, for example, made the news in October 2019 when mobile phone footage emerged of Turkish-backed Arab forces torturing captives and mutilating dead bodies, following a new Turkish offensive against the Kurds (Chulov <a title="Chulov, M. 2019. Syria: Videos of Turkey-backed militias show ‘potential war crimes’. The Guardian, 26 October. https://www.theguardian.com/world/2019/oct/26/syria-turkey-arab-videos-torture-kurdish-bodies-militia." href="/article/10.1057/s42984-020-00002-1#ref-CR29">2019</a>; BBC <a title="BBC. 2019f. Syria conflict: The ‘war crimes’ caught in brutal phone footage. BBC News, 3 November. https://www.bbc.co.uk/news/world-middle-east-50250330." href="/article/10.1057/s42984-020-00002-1#ref-CR18">2019f</a>). Similarly, in May 2019, a BBC Arabic investigation found potential war-crimes footage from the Libyan conflict being shared on Facebook and Twitter (BBC <a title="BBC. 2019g. Libya ‘war crimes’ videos shared on social media. BBC News, 1 May. https://www.bbc.co.uk/news/av/world-africa-48105968/libya-war-crimes-videos-shared-on-social-media." href="/article/10.1057/s42984-020-00002-1#ref-CR19">2019g</a>).</p>
<p>Despite being pushed out of their territory in Syria and northern Iraq and the disruption of their media production units, Islamic State have retained a social media presence. Through 2019, for example, the IS-linked Ash Shaff media foundation released mocked-up posters threatening attacks on New York and London’s Big Ben and Westminster Palace (Aldersley <a title="Aldersley, M. 2019. ISIS fanatics depict Big Ben on fire as chilling posters warn of ‘London attacks soon’ and show knife-wielding suicide bomber in New York. Daily Mail, 22 May. https://www.dailymail.co.uk/news/article-7057465/ISIS-posters-depict-Big-Ben-fire-warn-London-attacks-soon.html." href="/article/10.1057/s42984-020-00002-1#ref-CR6">2019</a>; Elsom <a title="Elsom, J. 2019. Palace of Westminster is seen on fire in chilling online ISIS threat that also shows a hooded jihadist with a handgun. Daily Mail, 11 July. https://www.dailymail.co.uk/news/article-7237365/Palace-Westminster-seen-fire-chilling-online-ISIS-threat.html." href="/article/10.1057/s42984-020-00002-1#ref-CR35">2019</a>). In December 2019, the EU’s Internet Referral Unit (IRU) launched a major offensive against IS’s Telegram operations and supporter groups, ‘resulting in a comprehensive decimation of many of the Islamic State’s most important online networks’ (Winter and Amarasingam <a title="Winter, C., and A. Amarasingam. 2019. The decimation of Isis on Telegram is big, but it has consequences. Wired, 2 December. https://www.wired.co.uk/article/isis-telegram-security." href="/article/10.1057/s42984-020-00002-1#ref-CR102">2019</a>). IS have rebuilt their networks before, however, and they have proven adept at moving onto the latest apps and platforms—there were already reports in October 2019, for example, of their discovery and use of TikTok to spread their videos (BBC <a title="BBC. 2019h. TikTok used by Islamic State to spread propaganda videos. BBC News, 22 October. https://www.bbc.co.uk/news/technology-50138740." href="/article/10.1057/s42984-020-00002-1#ref-CR20">2019h</a>). IS-affiliates also remain active, as seen in the January 2020 release of a video by Amaq News Agency showing a young child from the Islamic State West Africa Province (ISWAP) executing a Nigerian Christian in Borno (Tanno <a title="Tanno, S. 2020. Young boy executes Nigerian Christian prisoner in horrifying ISIS video after declaring: ‘We won’t stop until we take revenge for all the blood that was spilled’. Daily Mail, 21 January. https://www.dailymail.co.uk/news/article-7911765/Young-boy-executes-Nigerian-Christian-prisoner-horrifying-ISIS-video.html." href="/article/10.1057/s42984-020-00002-1#ref-CR83">2020</a>). Meanwhile, the IRU aren’t the only ones targeting IS online. In August 2019, Al Qaeda’s media wing, Hidayah Media Production, released an IS blooper video reel showing young fighters in Yemen fluffing their lines from 2017 with the aim of discrediting the group (Ibbetson <a title="Ibbetson, R. 2019a. ISIS jihadis chuckle as they fluff their lines of Islamist hate in a bizarre blooper reel leaked by their Al-Qaeda rivals in Yemen to undermine them. Daily Mail, 15 August. https://www.dailymail.co.uk/news/article-7360589/ISIS-fighters-chuckle-fluff-lines-Islamist-hate-bizarre-blooper-reel.html." href="/article/10.1057/s42984-020-00002-1#ref-CR43">2019a</a>).</p>
<p>Social media apps and platforms continue to be central to conflict today. In December 2019, the US Navy banned the short-video app TikTok from government-issued mobile devices, claiming the Chinese-owned app represented a cyber-security threat (Reuters <a title="Reuters, I. 2019b. US Navy bans TikTok from mobile devices saying it’s a cybersecurity threat. The Guardian, 21 December. https://www.theguardian.com/technology/2019/dec/21/us-navy-bans-tiktok-from-mobile-devices-saying-its-a-cybersecurity-threat." href="/article/10.1057/s42984-020-00002-1#ref-CR73">2019b</a>). The scale and scope of the Russian online, social media disinformation/information warfare campaign in the 2016 US presidential election took years to be understood, and, like cyber-war operations, we can assume it has continued since as an ongoing background ‘noise’, promoting particular stories and agendas and working against others. Though Facebook, Google, and Twitter have implemented protective measures and continue to remove suspect accounts, many are warning about probable attempts to undermine the 2020 election. The tactics and platforms employed, however, keep evolving. In particular, we are seeing more domestically organised and spread disinformation, the use of ‘organic’ posts from seemingly genuine users rather than paid-for posts and ads, the spread of commercial companies who can be hired to promote or suppress certain messages or actions, the threat of manipulated video (‘deepfakes’), and a range of new platforms being exploited, suggesting the problem has intensified since 2016 (Levine et al. <a title="Levine, A.S., N. Scola, S. Overly, and C. Lima. 2019. Why the fight against disinformation, sham accounts and trolls won’t be any easier in 2020. Politico, 1 December. https://www.politico.com/news/2019/12/01/fight-against-disinformation-2020-election-074422." href="/article/10.1057/s42984-020-00002-1#ref-CR51">2019</a>). In October 2019, it was reported that Iran had already started its 2020 operation by targeting a US 2020 presidential campaign (Reuters <a title="Reuters, I. 2019c. Iranian hackers targeted a U.S. presidential campaign, Microsoft says. The Guardian, 4 October. https://www.theguardian.com/technology/2019/oct/04/iranian-hackers-targeted-a-us-presidential-campaign-microsoft-says." href="/article/10.1057/s42984-020-00002-1#ref-CR74">2019c</a>).</p>
<p>The problem has also now globalised. The UN declared Facebook had a
‘determining role’ in spreading genocidal hate speech in Myanmar against the Rohingya in 2018 (BBC News <a title="BBC. 2018. The country where Facebook posts whipped up hate. BBC News. 12 September. https://www.bbc.co.uk/news/blogs-trending-45449938." href="/article/10.1057/s42984-020-00002-1#ref-CR12">2018</a>), and in January 2020, Myanmar’s Union Election Commission (UEC) warned that fake and false information posed a threat to the 2020 general election, claiming ‘hate speech and fabrication can negatively affect the five norms of the poll’ (Lwin <a title="Lwin, T. 2020. Myanmar election commission warns of fake news ahead of 2020 election. The Irrawaddy, 22 January. https://www.irrawaddy.com/news/burma/myanmar-election-commission-warns-fake-news-ahead-2020-election.html." href="/article/10.1057/s42984-020-00002-1#ref-CR54">2020</a>). Online disinformation is now a widely recognised domestic and international policy, and recent months have seen: Twitter suspend 88,000 accounts linked to a Saudi disinformation campaign (Agence France-Presse <a title="Agence France-Presse. 2019a. Twitter blocks accounts linked to Saudi “state-backed” manipulation effort. The Guardian, 20 December. https://www.theguardian.com/technology/2019/dec/20/twitter-blocks-accounts-saudi-arabia-manipulation-effort." href="/article/10.1057/s42984-020-00002-1#ref-CR4">2019a</a>); YouTube, Facebook, and Twitter discovering Chinese anti-Hong Kong protests disinformation campaigns (Conger <a title="Conger, K. 2019. Hong Kong: China is spreading disinformation about pro-democracy protests, Facebook and Twitter say. The Independent, 20 August. https://www.independent.co.uk/news/world/asia/hong-kong-protests-latest-china-disinformation-facebook-twitter-social-media-a9071046.html." href="/article/10.1057/s42984-020-00002-1#ref-CR31">2019</a>; Agence France-Presse <a title="Agence France-Presse. 2019b. Hong Kong protests: YouTube takes down 200 channels spreading disinformation. The Guardian, 23 August. https://www.theguardian.com/technology/2019/aug/23/hong-kong-protests-youtube-takes-down-200-channels-spreading-disinformation." href="/article/10.1057/s42984-020-00002-1#ref-CR5">2019a</a>; Paul <a title="Paul, K. 2019b. Twitter and Facebook crack down on accounts linked to Chinese campaign against Hong Kong. The Guardian, 20 August. https://www.theguardian.com/technology/2019/aug/19/twitter-china-hong-kong-accounts." href="/article/10.1057/s42984-020-00002-1#ref-CR64">2019b</a>); Facebook removing 304 fake accounts, with 1.4 m followers, linked to a Saudi disinformation campaign (Martin <a title="Martin, G. 2019. Facebook dismantles network of Saudi Arabian propaganda accounts and pages promoting the state and attacking rivals. Daily Mail, 1 August. https://www.dailymail.co.uk/news/article-7311315/Facebook-dismantles-network-Saudi-Arabian-propaganda-accounts.html." href="/article/10.1057/s42984-020-00002-1#ref-CR56">2019</a>); Twitter removing 4800 accounts with links to the Iranian government
(Paul <a title="Paul, K. 2019a. Twitter removes thousands of accounts linked to Iran government. The Guardian, 13 June. https://www.theguardian.com/technology/2019/jun/13/twitter-iran-accounts-deleted-iranian-government-election-interference." href="/article/10.1057/s42984-020-00002-1#ref-CR63">2019a</a>); and Facebook removing thousands of fake accounts and Instagram pages linked to Iran and Russia (AFP and Palmer <a title="AFP and Palmer, A. 2019. Facebook removes thousands of fake accounts and Instagram pages linked to Iran and Russia in major crack down on “coordinated inauthentic behaviour”. Daily Mail, 26 March. https://www.dailymail.co.uk/sciencetech/article-6851895/Facebook-blocks-accounts-influence-campaigns.html." href="/article/10.1057/s42984-020-00002-1#ref-CR3">2019</a>). Clearly, many nations have learnt about the possibilities offered by online manipulation, with new global social media <em>infowar influencers</em> such as Iran emerging (Tucker <a title="Tucker, P. 2020c. Iran is expanding its online disinformation operations’. Defense one, 9 January. https://www.defenseone.com/technology/2020/01/iran-expanding-its-online-disinformation-operations/162357/?oref=defense_one_breaking_nl." href="/article/10.1057/s42984-020-00002-1#ref-CR95">2020c</a>).</p>
<p>But this discussion of states misses everything else that’s going on. Because digital media empower everybody, everybody now gets involved. Determining the origins and motivations of actors is becoming impossible as anyone with an opinion, a patriotic or political conviction, or just a grudge can now let fly their likes and comments and gifs and memes and burns whilst picking the kids up from school or doing the shopping. Today the most popular US-made apps and platforms serve as a global informational warfare proxy: a new ‘military-social media complex’, where empowered ‘citizen militia’ keyboard warriors take on and take down governments and media propaganda units. It happened in Iran with Ukrainian International Airlines flight PS752. But it’s happening everywhere, all the time, with war and conflict now globally dissolved throughout everyday life. 1960s media theorist Marshall McLuhan saw this coming: after WWI’s railway war, World War II’s radio war, and Vietnam’s TV war, he suggested, ‘World War III is a guerrilla information war with no division between military and civilian participation’ (McLuhan <a title="McLuhan, M. 1970. Culture is our business. New York: McGraw Hill." href="/article/10.1057/s42984-020-00002-1#ref-CR58">1970</a>, 66). Our recent announcement, it seems, came too late. As McLuhan suggests, World War III has been happening for years.</p>
<h2>References</h2>
<div class="notes-and-refs">
<ul>
<li>Adamczyk, E. 2019. Pentagon to prepare four U.S. bases for 5G broadband technology, <em>UPI</em>, 4 November. <a href="https://www.upi.com/Defense-News/2019/11/04/Pentagon-to-prepare-four-US-bases-for-5G-broadband-technology/8291572896910/">https://www.upi.com/Defense-News/2019/11/04/Pentagon-to-prepare-four-US-bases-for-5G-broadband-technology/8291572896910/</a>.</li>
<li>AFP. 2019. India shoots down a satellite, becoming only the fourth nation to do so—As country’s PM declares the country has now “entered the space super league”. Daily Mail, 27 March. <a href="https://www.dailymail.co.uk/news/article-6855031/India-shoots-satellite-enters-space-super-league.html">https://www.dailymail.co.uk/news/article-6855031/India-shoots-satellite-enters-space-super-league.html</a>.</li>
<li>AFP and Palmer, A. 2019. Facebook removes thousands of fake accounts and Instagram pages linked to Iran and Russia in major crack down on “coordinated inauthentic behaviour”. Daily Mail, 26 March. <a href="https://www.dailymail.co.uk/sciencetech/article-6851895/Facebook-blocks-accounts-influence-campaigns.html">https://www.dailymail.co.uk/sciencetech/article-6851895/Facebook-blocks-accounts-influence-campaigns.html</a>.</li>
<li>Agence France-Presse. 2019a. Twitter blocks accounts linked to Saudi “state-backed” manipulation effort. The Guardian, 20 December. <a href="https://www.theguardian.com/technology/2019/dec/20/twitter-blocks-accounts-saudi-arabia-manipulation-effort">https://www.theguardian.com/technology/2019/dec/20/twitter-blocks-accounts-saudi-arabia-manipulation-effort</a>.</li>
<li>Agence France-Presse. 2019b. Hong Kong protests: YouTube takes down 200 channels spreading disinformation. The Guardian, 23 August. <a href="https://www.theguardian.com/technology/2019/aug/23/hong-kong-protests-youtube-takes-down-200-channels-spreading-disinformation">https://www.theguardian.com/technology/2019/aug/23/hong-kong-protests-youtube-takes-down-200-channels-spreading-disinformation</a>.</li>
<li>Aldersley, M. 2019. ISIS fanatics depict Big Ben on fire as chilling posters warn of ‘London attacks soon’ and show knife-wielding suicide bomber in New York. Daily Mail, 22 May. <a href="https://www.dailymail.co.uk/news/article-7057465/ISIS-posters-depict-Big-Ben-fire-warn-London-attacks-soon.html">https://www.dailymail.co.uk/news/article-7057465/ISIS-posters-depict-Big-Ben-fire-warn-London-attacks-soon.html</a>.</li>
<li>Ardehali, R. 2019. Boeing to build four 50-ton ‘Orca’ undersea drones for the US Navy that can wage war at depths of 11,000 feet, hunting mines and sinking submarines. Daily Mail, 3 June. <a href="https://www.dailymail.co.uk/news/article-7100591/Navy-starts-building-new-massive-50-ton-undersea-attack-drone.html">https://www.dailymail.co.uk/news/article-7100591/Navy-starts-building-new-massive-50-ton-undersea-attack-drone.html</a>.</li>
<li>Ashizuka, T. 2019. Pentagon seeks to triple AI warfare budget to meet China’s rise. Nikkei Asian Review, 4 October. <a href="https://asia.nikkei.com/Business/Aerospace-Defense/Pentagon-seeks-to-triple-AI-warfare-budget-to-meet-China-s-rise">https://asia.nikkei.com/Business/Aerospace-Defense/Pentagon-seeks-to-triple-AI-warfare-budget-to-meet-China-s-rise</a>.</li>
<li>Associated Press. 2019. Donald Trump officially launches U.S. space force. The Guardian, 21 December. <a href="https://www.theguardian.com/us-news/2019/dec/21/donald-trump-officially-launches-us-space-force">https://www.theguardian.com/us-news/2019/dec/21/donald-trump-officially-launches-us-space-force</a>.</li>
<li>Barbrook, R. 2007. <em>Imaginary futures</em>. London: Pluto. <a href="http://scholar.google.com/scholar_lookup?&amp;title=Imaginary%20futures&amp;publication_year=2007&amp;author=Barbrook%2CR">Google Scholar</a> </li>
<li>Baron, K. 2020. Now It’s 64. Wounded troop tally from Iran missile strike rises again. Defense one, 30 January. <a href="https://www.defenseone.com/threats/2020/01/wounded-troop-tally-iran-missile-strike-expected-rise-again/162763/%3foref%3ddefenseone_today_nl">https://www.defenseone.com/threats/2020/01/wounded-troop-tally-iran-missile-strike-expected-rise-again/162763/?oref=defenseone_today_nl</a>.</li>
<li>BBC. 2018. The country where Facebook posts whipped up hate. BBC News. 12 September. <a href="https://www.bbc.co.uk/news/blogs-trending-45449938">https://www.bbc.co.uk/news/blogs-trending-45449938</a>.</li>
<li>BBC. 2019a. Saudi oil attacks: Images show detail of damage. BBC News, 16 September. <a href="https://www.bbc.co.uk/news/world-middle-east-49718975">https://www.bbc.co.uk/news/world-middle-east-49718975</a>.</li>
<li>BBC. 2019b. ‘Global Hawk drones: A look at NATO’s new spy tool. BBC News, 18 January. <a href="https://www.bbc.co.uk/news/av/technology-51156680/global-hawk-drones-a-look-at-nato-s-new-spy-tool">https://www.bbc.co.uk/news/av/technology-51156680/global-hawk-drones-a-look-at-nato-s-new-spy-tool</a>.</li>
<li>BBC. 2019c. US “launched cyber-attack on Iran weapons systems”. BBC News, 23 June. <a href="https://www.bbc.co.uk/news/world-us-canada-48735097">https://www.bbc.co.uk/news/world-us-canada-48735097</a>.</li>
<li>BBC. 2019d. Iran “foils second cyber-attack in a week”. BBC News, 15 December. <a href="https://www.bbc.co.uk/news/world-middle-east-50799147">https://www.bbc.co.uk/news/world-middle-east-50799147</a>.</li>
<li>BBC. 2019e. Russia “successfully tests” its unplugged internet’. BBC News, 24 December. <a href="https://www.bbc.co.uk/news/technology-50902496">https://www.bbc.co.uk/news/technology-50902496</a>.</li>
<li>BBC. 2019f. Syria conflict: The ‘war crimes’ caught in brutal phone footage. BBC News, 3 November. <a href="https://www.bbc.co.uk/news/world-middle-east-50250330">https://www.bbc.co.uk/news/world-middle-east-50250330</a>.</li>
<li>BBC. 2019g. Libya ‘war crimes’ videos shared on social media. BBC News, 1 May. <a href="https://www.bbc.co.uk/news/av/world-africa-48105968/libya-war-crimes-videos-shared-on-social-media">https://www.bbc.co.uk/news/av/world-africa-48105968/libya-war-crimes-videos-shared-on-social-media</a>.</li>
<li>BBC. 2019h. TikTok used by Islamic State to spread propaganda videos. BBC News, 22 October. <a href="https://www.bbc.co.uk/news/technology-50138740">https://www.bbc.co.uk/news/technology-50138740</a>.</li>
<li>BBC. 2020. Ransomware attack takes U.S. maritime base offline. BBC News, 2 January. <a href="https://www.bbc.co.uk/news/technology-50972890?fbclid=IwAR1ycNTdbYhT-T3MbJ3EsLw8VPc-c_FpQr-PbJjnUecGhxk-jZfiGl2szQ8">https://www.bbc.co.uk/news/technology-50972890?fbclid=IwAR1ycNTdbYhT-T3MbJ3EsLw8VPc-c_FpQr-PbJjnUecGhxk-jZfiGl2szQ8</a>.</li>
<li>Beaumont, P., P., Torpey, and P. Scruton. 2020. A visual guide to the Iran plane crash. The Guardian, 13 January. <a href="https://www.theguardian.com/world/2020/jan/09/iran-plane-crash-visual-guide">https://www.theguardian.com/world/2020/jan/09/iran-plane-crash-visual-guide</a>.</li>
<li>Bell, V. 2020. Attack of the drones! U.S. Army reveals the first deployment of its pocket-sized drones in Afghanistan this month. Daily Mail, July. <a href="https://www.dailymail.co.uk/sciencetech/article-7204803/First-deployment-pocket-sized-drones-Afghanistan.html">https://www.dailymail.co.uk/sciencetech/article-7204803/First-deployment-pocket-sized-drones-Afghanistan.html</a>.</li>
<li>Blanchard, S. 2019. The robotic arm controlled by your MIND: Incredible video shows pioneering gadget moving entirely by thought. Daily Mail, 20 June. <a href="https://www.dailymail.co.uk/health/article-7163859/The-robotic-arm-controlled-MIND.html">https://www.dailymail.co.uk/health/article-7163859/The-robotic-arm-controlled-MIND.html</a>.</li>
<li>Bogart, N. 2020. Twitter is convinced ‘World War 3’ is imminent after U.S. kills Iran’s top general. CTV News, 3 January. <a href="https://www.ctvnews.ca/world/twitter-is-convinced-world-war-3-is-imminent-after-u-s-kills-iran-s-top-general-1.4752020">https://www.ctvnews.ca/world/twitter-is-convinced-world-war-3-is-imminent-after-u-s-kills-iran-s-top-general-1.4752020</a>.</li>
<li>Brown, L. 2019. Unveiled: RAF’s deadly new Protector drone is fitted with ‘game-changing technology’ that detects and avoids other planes and can remain in the air for FORTY hours. Daily Mail, 21 August. <a href="https://www.dailymail.co.uk/news/article-7381265/Unveiled-RAFs-deadly-new-Protector-drone-fitted-game-changing-technology.html">https://www.dailymail.co.uk/news/article-7381265/Unveiled-RAFs-deadly-new-Protector-drone-fitted-game-changing-technology.html</a>.</li>
<li>Chadwick, J. 2020. Mysterious Russian spacecraft spotted stalking a U.S. spy satellite “will make its closest approach yet this week”. Daily Mail, 4 February. <a href="https://www.dailymail.co.uk/sciencetech/article-7964933/Russian-spacecraft-closer-satellite-weekend.html">https://www.dailymail.co.uk/sciencetech/article-7964933/Russian-spacecraft-closer-satellite-weekend.html</a>.</li>
<li>Chulov, M. 2019. Syria: Videos of Turkey-backed militias show ‘potential war crimes’. The Guardian, 26 October. <a href="https://www.theguardian.com/world/2019/oct/26/syria-turkey-arab-videos-torture-kurdish-bodies-militia">https://www.theguardian.com/world/2019/oct/26/syria-turkey-arab-videos-torture-kurdish-bodies-militia</a>.</li>
<li>Cole, W. 2019. Leaked footage shows shocking moment Israeli policewoman shoots Palestinian in the back “for fun”. Daily Mail, 5 November. <a href="https://www.dailymail.co.uk/news/article-7649189/Leaked-footage-shows-Israeli-policewoman-shoots-innocent-Palestinian-fun.html">https://www.dailymail.co.uk/news/article-7649189/Leaked-footage-shows-Israeli-policewoman-shoots-innocent-Palestinian-fun.html</a>.</li>
<li>Conger, K. 2019. Hong Kong: China is spreading disinformation about pro-democracy protests, Facebook and Twitter say. The Independent, 20 August. <a href="https://www.independent.co.uk/news/world/asia/hong-kong-protests-latest-china-disinformation-facebook-twitter-social-media-a9071046.html">https://www.independent.co.uk/news/world/asia/hong-kong-protests-latest-china-disinformation-facebook-twitter-social-media-a9071046.html</a>.</li>
<li>Corrigan, J. 2019. DARPA Thinks AI could help troops telepathically control machines. Defense One, 18 February. <a href="https://www.defenseone.com/technology/2019/02/darpa-thinks-ai-could-help-troops-telepathically-control-machines/154937/%3foref%3dd1-related-article">https://www.defenseone.com/technology/2019/02/darpa-thinks-ai-could-help-troops-telepathically-control-machines/154937/?oref=d1-related-article</a>.</li>
<li>Dilanian, K., and C. Kube. 2020. Airport informants, overhead drones: How the U.S. killed Soleimani. NBC News, 10 January. <a href="https://www.nbcnews.com/news/mideast/airport-informants-overhead-drones-how-u-s-killed-soleimani-n1113726">https://www.nbcnews.com/news/mideast/airport-informants-overhead-drones-how-u-s-killed-soleimani-n1113726</a>.</li>
<li>Dorn, S. 2020. Iranian general Qassem Soleimani once taunted Trump in fiery speech. New York Post, 4 January. <a href="https://nypost.com/2020/01/04/iranian-general-qassem-soleimani-once-taunted-trump-in-fiery-speech/">https://nypost.com/2020/01/04/iranian-general-qassem-soleimani-once-taunted-trump-in-fiery-speech/</a>.</li>
<li>Elsom, J. 2019. Palace of Westminster is seen on fire in chilling online ISIS threat that also shows a hooded jihadist with a handgun. Daily Mail, 11 July. <a href="https://www.dailymail.co.uk/news/article-7237365/Palace-Westminster-seen-fire-chilling-online-ISIS-threat.html">https://www.dailymail.co.uk/news/article-7237365/Palace-Westminster-seen-fire-chilling-online-ISIS-threat.html</a>.</li>
<li>Frantzman, S.J., and K.D. Atherton. 2019. Israel’s Rafael integrates artificial intelligence into Spice bombs. DefenseNews, 17 June. <a href="https://www.defensenews.com/artificial-intelligence/2019/06/17/israels-rafael-integrates-artificial-intelligence-into-spice-bombs/%3futm_source%3dSailthru%26utm_medium%3demail%26utm_campaign%3dEBB%2006.18.19%26utm_term%3dEditorial%20-%20Early%20Bird%20Brief">https://www.defensenews.com/artificial-intelligence/2019/06/17/israels-rafael-integrates-artificial-intelligence-into-spice-bombs/?utm_source=Sailthru&amp;utm_medium=email&amp;utm_campaign=EBB%2006.18.19&amp;utm_term=Editorial%20-%20Early%20Bird%20Brief</a>.</li>
<li>Freedberg, S.J. Jr. 2019. AI and robots crush foes in army wargame. Breaking Defense, 19 December. <a href="https://breakingdefense.com/2019/12/ai-robots-crush-foes-in-army-wargame/">https://breakingdefense.com/2019/12/ai-robots-crush-foes-in-army-wargame/</a>.</li>
<li>Griffith, K. 2020a. ‘Iranian hackers’ breach US government website operated by the Federal Depository Library Program in retaliation for airstrike. Daily Mail, 5 January. <a href="https://www.dailymail.co.uk/news/article-7852819/Iranian-hackers-breach-government-website-retaliation-airstrike.html">https://www.dailymail.co.uk/news/article-7852819/Iranian-hackers-breach-government-website-retaliation-airstrike.html</a>.</li>
<li>Griffith, K. 2020b. ‘Abandon terror and Make Iran Great Again!’ Donald Trump trades barbs with Ayatollah Khamenei after Iran’s supreme leader accused him of plotting to ‘stab the Iranian people in the heart with venomous daggers.’ Daily Mail, 18 January. <a href="https://www.dailymail.co.uk/news/article-7901197/Donald-Trump-trades-barbs-Ayatollah-Khamenei-Twitter.html">https://www.dailymail.co.uk/news/article-7901197/Donald-Trump-trades-barbs-Ayatollah-Khamenei-Twitter.html</a>.</li>
<li>Guarav, K. 2020. AI expert calls ‘killer robots’ greater threat to humans than climate change. Republic, 19 January. <a href="https://www.republicworld.com/world-news/rest-of-the-world-news/ai-expert-calls-killer-robots-greater-threat-to-humans-than-climate.html">https://www.republicworld.com/world-news/rest-of-the-world-news/ai-expert-calls-killer-robots-greater-threat-to-humans-than-climate.html</a>.</li>
<li>Helsel, P. 2020. ‘All is well!’ Trump tweets after Iran targets U.S. forces in missile attack in Iraq. NBC News, 8 January. <a href="https://www.nbcnews.com/politics/donald-trump/trump-tweets-all-well-after-iranian-missile-attack-targeting-u-n1112211">https://www.nbcnews.com/politics/donald-trump/trump-tweets-all-well-after-iranian-missile-attack-targeting-u-n1112211</a>.</li>
<li>Hern, A. 2019. Uighurs in China were target of two-year iOS malware attack—reports. The Guardian, 2 September. <a href="https://www.theguardian.com/world/2019/sep/02/uighurs-china-target-two-year-ios-malware-attack-reports">https://www.theguardian.com/world/2019/sep/02/uighurs-china-target-two-year-ios-malware-attack-reports</a>.</li>
<li>Ibbetson, R. 2019a. ISIS jihadis chuckle as they fluff their lines of Islamist hate in a bizarre blooper reel leaked by their Al-Qaeda rivals in Yemen to undermine them. Daily Mail, 15 August. <a href="https://www.dailymail.co.uk/news/article-7360589/ISIS-fighters-chuckle-fluff-lines-Islamist-hate-bizarre-blooper-reel.html">https://www.dailymail.co.uk/news/article-7360589/ISIS-fighters-chuckle-fluff-lines-Islamist-hate-bizarre-blooper-reel.html</a>.</li>
<li>Ibbetson, R. 2019b. US launched a cyber attack on Iran to destroy computer systems that Tehran was using to target oil tankers in the Gulf. Daily Mail, 29 August. <a href="https://www.dailymail.co.uk/news/article-7406177/US-launched-cyber-attack-Iran-destroy-computer-systems-Tehran-used-target-tankers-Gulf.html">https://www.dailymail.co.uk/news/article-7406177/US-launched-cyber-attack-Iran-destroy-computer-systems-Tehran-used-target-tankers-Gulf.html</a>.</li>
<li>Jackson, S. 2019. Boston dynamics robot dog spot used in police training for first time. Daily Star, 27 December. <a href="https://www.dailystar.co.uk/news/world-news/boston-dynamics-robot-dog-spot-21169898">https://www.dailystar.co.uk/news/world-news/boston-dynamics-robot-dog-spot-21169898</a>.</li>
<li>Johnson, M. 2020. World war III memes take off on social media after US strike killing Iranian general. The Hill, 4 January. <a href="https://thehill.com/homenews/administration/476766-world-war-iii-memes-take-off-on-social-media-after-us-strike-killing">https://thehill.com/homenews/administration/476766-world-war-iii-memes-take-off-on-social-media-after-us-strike-killing</a>.</li>
<li>Khamenei, S.A. 2020. That guy has tweeted… Twitter, 1 January, 9.14 am. <a href="https://twitter.com/khamenei_ir/status/1212301034871279616%3flang%3den">https://twitter.com/khamenei_ir/status/1212301034871279616?lang=en</a>.</li>
<li>Kirchgaessner, S. 2019. Israeli spyware allegedly used to target Pakistani officials’ Phones. The Guardian, 19 December. <a href="https://www.theguardian.com/world/2019/dec/19/israeli-spyware-allegedly-used-to-target-pakistani-officials-phones">https://www.theguardian.com/world/2019/dec/19/israeli-spyware-allegedly-used-to-target-pakistani-officials-phones</a>.</li>
<li>Kirchgaessner, S. 2020. Jeff Bezos hack: Amazon boss’s phone ‘hacked by Saudi crown prince’. The Guardian, 22 January. <a href="https://www.theguardian.com/technology/2020/jan/21/amazon-boss-jeff-bezoss-phone-hacked-by-saudi-crown-prince">https://www.theguardian.com/technology/2020/jan/21/amazon-boss-jeff-bezoss-phone-hacked-by-saudi-crown-prince</a>.</li>
<li>Koller, J. 2019. U.S. forces can’t hide from ubiquitous satellites. They need to fool them. Defense One. 16 December. <a href="https://www.defenseone.com/ideas/2019/12/us-forces-cant-hide-ubiquitous-satellites-they-need-learn-fool-them/161913/%3foref%3ddefenseone_today_nl">https://www.defenseone.com/ideas/2019/12/us-forces-cant-hide-ubiquitous-satellites-they-need-learn-fool-them/161913/?oref=defenseone_today_nl</a>.</li>
<li>Levine, A.S., N. Scola, S. Overly, and C. Lima. 2019. Why the fight against disinformation, sham accounts and trolls won’t be any easier in 2020. Politico, 1 December. <a href="https://www.politico.com/news/2019/12/01/fight-against-disinformation-2020-election-074422">https://www.politico.com/news/2019/12/01/fight-against-disinformation-2020-election-074422</a>.</li>
<li>Lloyd, P. 2019a. ‘Fearsome’ spy satellites armed with lasers and machine guns to be launched by French military by 2023—and an armada of tiny drones could be sent into orbit to bolster its defences. Daily Mail, 29 July. <a href="https://www.dailymail.co.uk/sciencetech/article-7297867/Fearsome-spy-satellites-armed-lasers-machine-guns-launched-French.html">https://www.dailymail.co.uk/sciencetech/article-7297867/Fearsome-spy-satellites-armed-lasers-machine-guns-launched-French.html</a>.</li>
<li>Lloyd, P. 2019b. Drones of the sea: Royal Navy begins trials of unmanned military boats which can be remote-controlled for hundreds of miles and find mines or spy on enemy ships. Daily Mail, 12 September. <a href="https://www.dailymail.co.uk/sciencetech/article-7456057/Royal-Navy-tests-unmanned-boats-search-mines-spy-enemy-ships.html">https://www.dailymail.co.uk/sciencetech/article-7456057/Royal-Navy-tests-unmanned-boats-search-mines-spy-enemy-ships.html</a>.</li>
<li>Lwin, T. 2020. Myanmar election commission warns of fake news ahead of 2020 election. The Irrawaddy, 22 January. <a href="https://www.irrawaddy.com/news/burma/myanmar-election-commission-warns-fake-news-ahead-2020-election.html">https://www.irrawaddy.com/news/burma/myanmar-election-commission-warns-fake-news-ahead-2020-election.html</a>.</li>
<li>Manovich, L. 2001. <em>The Language of New Media</em>. London: MIT Press. <a href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Language%20of%20New%20Media&amp;publication_year=2001&amp;author=Manovich%2CL"> Google Scholar</a> </li>
<li>Martin, G. 2019. Facebook dismantles network of Saudi Arabian propaganda accounts and pages promoting the state and attacking rivals. Daily Mail, 1 August. <a href="https://www.dailymail.co.uk/news/article-7311315/Facebook-dismantles-network-Saudi-Arabian-propaganda-accounts.html">https://www.dailymail.co.uk/news/article-7311315/Facebook-dismantles-network-Saudi-Arabian-propaganda-accounts.html</a>.</li>
<li>McDonald, H. 2019. Ex-Google worker fears ‘killer robots’ could cause mass Atrocities. The Guardian, 15 September. <a href="https://www.theguardian.com/technology/2019/sep/15/ex-google-worker-fears-killer-robots-cause-mass-atrocities">https://www.theguardian.com/technology/2019/sep/15/ex-google-worker-fears-killer-robots-cause-mass-atrocities</a>.</li>
<li>McLuhan, M. 1970. <em>Culture is our business</em>. New York: McGraw Hill.<a href="http://scholar.google.com/scholar_lookup?&amp;title=Culture%20is%20our%20business&amp;publication_year=1970&amp;author=McLuhan%2CM"> Google Scholar</a> </li>
<li>Memri. 2018. IRGC Qods Force Commander Qassem Soleimani, Designated By U.S. Treasury Dept., is active on Instagram; posts include image of white house exploding’, MEMRI cyber and jihad lab. 16 August. <a href="http://cjlab.memri.org/lab-projects/iran-cyber-initiative-lab-projects/irgc-qods-force-commander-qassem-soleimani-designated-by-u-s-treasury-dept-is-active-on-instagram-posts-include-image-of-white-house-exploding/">http://cjlab.memri.org/lab-projects/iran-cyber-initiative-lab-projects/irgc-qods-force-commander-qassem-soleimani-designated-by-u-s-treasury-dept-is-active-on-instagram-posts-include-image-of-white-house-exploding/</a>.</li>
<li>Merrin, W. 2014. <em>Media Studies 2.0</em>. Abingdon, Oxon: Routledge. <a href="https://doi.org/10.4324%2F9780203083581">Book</a> <a href="http://scholar.google.com/scholar_lookup?&amp;title=Media%20Studies%202.0&amp;publication_year=2014&amp;author=Merrin%2CW">Google Scholar</a> </li>
<li>Merrin, W. 2018. <em>Digital War: A critical introduction.</em> Abingdon, Oxon: Routledge. <a href="https://doi.org/10.4324%2F9781315707624">Book</a> <a href="http://scholar.google.com/scholar_lookup?&amp;title=Digital%20War%3A%20A%20critical%20introduction&amp;publication_year=2018&amp;author=Merrin%2CW"> Google Scholar</a></li>
<li>Morrison, R. 2019. Microsoft seizes control of 50 websites used by a North Korea linked hacking group to carry out cyber-attacks on government workers, human rights groups and nuclear activists. Daily Mail, 31 December. <a href="https://www.dailymail.co.uk/sciencetech/article-7840065/Microsoft-seizes-control-50-websites-used-North-Korea-linked-hacking-group.html">https://www.dailymail.co.uk/sciencetech/article-7840065/Microsoft-seizes-control-50-websites-used-North-Korea-linked-hacking-group.html</a>.</li>
<li>Paul, K. 2019a. Twitter removes thousands of accounts linked to Iran government. The Guardian, 13 June. <a href="https://www.theguardian.com/technology/2019/jun/13/twitter-iran-accounts-deleted-iranian-government-election-interference">https://www.theguardian.com/technology/2019/jun/13/twitter-iran-accounts-deleted-iranian-government-election-interference</a>.</li>
<li>Paul, K. 2019b. Twitter and Facebook crack down on accounts linked to Chinese campaign against Hong Kong. The Guardian, 20 August. <a href="https://www.theguardian.com/technology/2019/aug/19/twitter-china-hong-kong-accounts">https://www.theguardian.com/technology/2019/aug/19/twitter-china-hong-kong-accounts</a>.</li>
<li>Peck, M. 2019a. China Will Overwhelm Its Enemies With Swarms of Rocket-Armed Heli-Drones. The National Interest, 26 May. <a href="https://nationalinterest.org/blog/buzz/china-will-overwhelm-its-enemies-swarms-rocket-armed-heli-drones-59277">https://nationalinterest.org/blog/buzz/china-will-overwhelm-its-enemies-swarms-rocket-armed-heli-drones-59277</a>.</li>
<li>Peck, M. 2019b. Britain’s top commander: We Are At ‘War Every Day’ with Russia. National Interest. 2 November. <a href="https://nationalinterest.org/blog/buzz/britain%e2%80%99s-top-commander-we-are-%e2%80%9cwar-every-day%e2%80%9d-russia-92666">https://nationalinterest.org/blog/buzz/britain’s-top-commander-we-are-“war-every-day”-russia-92666</a>.</li>
<li>Pengelly, M. 2020. Trump claims Suleimani was ‘saying bad things’ about US before deadly strike. The Guardian, 18 January. <a href="https://www.theguardian.com/us-news/2020/jan/18/trump-suleimani-iran-drone-strike">https://www.theguardian.com/us-news/2020/jan/18/trump-suleimani-iran-drone-strike</a>.</li>
<li>Pero, J. 2020. Human exoskeleton revealed by Delta and Sarcos Robotics at CES picks up 130-pound airplane tire with ease. Daily Mail, 9. January, <a href="https://www.dailymail.co.uk/sciencetech/article-7867651/Exoskeleton-debuted-Delta-Sarcos-Robotics-makes-lifting-airplane-tire-feel-like-20-POUNDS.html">https://www.dailymail.co.uk/sciencetech/article-7867651/Exoskeleton-debuted-Delta-Sarcos-Robotics-makes-lifting-airplane-tire-feel-like-20-POUNDS.html</a>.</li>
<li>Pinkstone, J. 2020. Twitter admits state-backed hackers in Malaysia, Iran and Israel may have stolen up to 17 million phone numbers linked to Android user accounts. Daily Mail, 4 February. <a href="https://www.dailymail.co.uk/sciencetech/article-7963567/Twitter-says-state-backed-actors-accessed-users-phone-numbers.html">https://www.dailymail.co.uk/sciencetech/article-7963567/Twitter-says-state-backed-actors-accessed-users-phone-numbers.html</a>.</li>
<li>Randall, I. 2019a. US Military funds mind-reading helmet that may let soldiers telepathically control robots or drones and could even give the gift of sight to the blind. Daily Mail, 6 June. <a href="https://www.dailymail.co.uk/sciencetech/article-7111199/US-Military-funds-mind-reading-helmet-let-soldiers-TELEPATHICALLY-control-robots-drones.html">https://www.dailymail.co.uk/sciencetech/article-7111199/US-Military-funds-mind-reading-helmet-let-soldiers-TELEPATHICALLY-control-robots-drones.html</a>.</li>
<li>Randall, I. 2019b. Robot tank named ‘Ripsaw M5’ with armour-piercing ammunition and on-board drones is built for the US Army. Daily Mail, 29 October. <a href="https://www.dailymail.co.uk/sciencetech/article-7625517/Ripsaw-M5-Robot-TANK-armour-piercing-ammunition-board-drones-built-Army.html">https://www.dailymail.co.uk/sciencetech/article-7625517/Ripsaw-M5-Robot-TANK-armour-piercing-ammunition-board-drones-built-Army.html</a>.</li>
<li>Reuters. 2019a. US drone strike intended for Isis hideout kills 30 pine nut workers in Afghanistan. The Guardian, 19 September. <a href="https://www.theguardian.com/world/2019/sep/19/us-drone-strike-deaths-afghanistan-pine-nut-workers">https://www.theguardian.com/world/2019/sep/19/us-drone-strike-deaths-afghanistan-pine-nut-workers</a>.</li>
<li>Reuters, I. 2019b. US Navy bans TikTok from mobile devices saying it’s a cybersecurity threat. The Guardian, 21 December. <a href="https://www.theguardian.com/technology/2019/dec/21/us-navy-bans-tiktok-from-mobile-devices-saying-its-a-cybersecurity-threat">https://www.theguardian.com/technology/2019/dec/21/us-navy-bans-tiktok-from-mobile-devices-saying-its-a-cybersecurity-threat</a>.</li>
<li>Reuters, I. 2019c. Iranian hackers targeted a U.S. presidential campaign, Microsoft says. The Guardian, 4 October. <a href="https://www.theguardian.com/technology/2019/oct/04/iranian-hackers-targeted-a-us-presidential-campaign-microsoft-says">https://www.theguardian.com/technology/2019/oct/04/iranian-hackers-targeted-a-us-presidential-campaign-microsoft-says</a>.</li>
<li>Reuters, I. 2020a. Inside the plot by Iran’s Soleimani to attack U.S. forces in Iraq. Reuters, 4 January. <a href="https://www.reuters.com/article/us-iraq-security-soleimani-insight/inside-the-plot-by-irans-soleimani-to-attack-us-forces-in-iraq-idUSKBN1Z301Z">https://www.reuters.com/article/us-iraq-security-soleimani-insight/inside-the-plot-by-irans-soleimani-to-attack-us-forces-in-iraq-idUSKBN1Z301Z</a>.</li>
<li>Reuters, I. 2020b. Iran denies shooting down Ukrainian plane, calls charges illogical rumours’, India Today, 10th January. <a href="https://www.indiatoday.in/world/story/iran-denies-ukrainian-plane-was-hit-by-missile-statement-1635509-2020-01-10">https://www.indiatoday.in/world/story/iran-denies-ukrainian-plane-was-hit-by-missile-statement-1635509-2020-01-10</a>.</li>
<li>Sabbagh, D. 2020. Targeted killings via drone becoming ‘normalised’. The Guardian, 19 January. <a href="https://www.theguardian.com/politics/2020/jan/19/military-drone-strikes-becoming-normalised-says-report">https://www.theguardian.com/politics/2020/jan/19/military-drone-strikes-becoming-normalised-says-report</a>.</li>
<li>Sengupta, K. 2020. UK is nearly ready to launch force to hit hostile countries with Cyberattacks. The Independent, 10 January. <a href="https://www.independent.co.uk/news/uk/home-news/cyber-warfare-security-force-iran-crisis-ministry-of-defence-a9278591.html">https://www.independent.co.uk/news/uk/home-news/cyber-warfare-security-force-iran-crisis-ministry-of-defence-a9278591.html</a>.</li>
<li>Staff, T. 2020. Iran claims 80 American troops killed in missile barrage; US says no Casualties. The Times of Israel, 8 January. <a href="https://www.timesofisrael.com/iranian-state-media-claims-more-than-80-us-soldiers-killed-in-missile-barrage/">https://www.timesofisrael.com/iranian-state-media-claims-more-than-80-us-soldiers-killed-in-missile-barrage/</a>.</li>
<li>Stickings, T. 2019. India’s doomed moon mission was hacked by North Korea, cyber experts believe. Daily Mail, 8 November. <a href="https://www.dailymail.co.uk/news/article-7663917/Indias-doomed-moon-mission-hacked-North-Korea-cyber-experts-believe.html">https://www.dailymail.co.uk/news/article-7663917/Indias-doomed-moon-mission-hacked-North-Korea-cyber-experts-believe.html</a>.</li>
<li>Stokel-Walker, C. 2020. How digital sleuths unravelled the mystery of Iran’s plane Crash. Wired, 13 January. <a href="https://www.wired.co.uk/article/iran-plane-crash-news">https://www.wired.co.uk/article/iran-plane-crash-news</a>.</li>
<li>Syrian Archive. 2020. About: Mission, vision, and workflow. Syrian Archive. <a href="https://syrianarchive.org/en/about">https://syrianarchive.org/en/about</a>.</li>
<li>Tanno, S. 2020. Young boy executes Nigerian Christian prisoner in horrifying ISIS video after declaring: ‘We won’t stop until we take revenge for all the blood that was spilled’. Daily Mail, 21 January. <a href="https://www.dailymail.co.uk/news/article-7911765/Young-boy-executes-Nigerian-Christian-prisoner-horrifying-ISIS-video.html">https://www.dailymail.co.uk/news/article-7911765/Young-boy-executes-Nigerian-Christian-prisoner-horrifying-ISIS-video.html</a>.</li>
<li>Taplin, J. 2018. <em>Move Fast and Break Things</em>. London: Pan Books. <a href="http://scholar.google.com/scholar_lookup?&amp;title=Move%20Fast%20and%20Break%20Things&amp;publication_year=2018&amp;author=Taplin%2CJ">Google Scholar</a></li>
<li>Tucker, P. 2019a. Suspected Iranian cyber attacks show no sign of slowing. Defense one. 3 July. <a href="https://www.defenseone.com/technology/2019/07/suspected-iranian-cyber-attacks-show-no-sign-slowing/158213/%3foref%3ddefenseone_today_nl">https://www.defenseone.com/technology/2019/07/suspected-iranian-cyber-attacks-show-no-sign-slowing/158213/?oref=defenseone_today_nl</a>.</li>
<li>Tucker, P. 2019b. Army goggles will feature facial recognition tech ‘very soon’. Defense one, 17th July. <a href="https://www.defenseone.com/technology/2019/07/army-soldier-goggles-will-feature-facial-recognition-tech-very-soon/158505/%3foref%3ddefenseone_today_nl">https://www.defenseone.com/technology/2019/07/army-soldier-goggles-will-feature-facial-recognition-tech-very-soon/158505/?oref=defenseone_today_nl</a>.</li>
<li>Tucker, P. 2019c. The army wants AI to read soldiers’ minds. Defense one, 8 April. <a href="https://www.defenseone.com/technology/2019/04/army-wants-ai-read-soldiers-minds/156147/%3foref%3dd1-related-article">https://www.defenseone.com/technology/2019/04/army-wants-ai-read-soldiers-minds/156147/?oref=d1-related-article</a>.</li>
<li>Tucker, P. 2019d. A new joystick for the brain-controlled vehicles of the future. Defense one, 23 September. <a href="https://www.defenseone.com/technology/2019/09/new-joystick-brain-controlled-vehicles-future/160092/%3foref%3ddefenseone_today_nl">https://www.defenseone.com/technology/2019/09/new-joystick-brain-controlled-vehicles-future/160092/?oref=defenseone_today_nl</a>.</li>
<li>Tucker, P. 2019e. The U.S. military is chopping up its iron man suit for parts’, Defense one, 7 February. <a href="https://www.defenseone.com/technology/2019/02/us-military-chopping-its-iron-man-suit-parts/154706/">https://www.defenseone.com/technology/2019/02/us-military-chopping-its-iron-man-suit-parts/154706/</a>.</li>
<li>Tucker, P. 2019f. Special operations command made a mind-reading kit for elite troops’. Defense one, 11 December. <a href="https://www.defenseone.com/technology/2019/12/specops-lab-made-mind-reading-kit-elite-troops/161830/%3foref%3ddefense_one_breaking_nl">https://www.defenseone.com/technology/2019/12/specops-lab-made-mind-reading-kit-elite-troops/161830/?oref=defense_one_breaking_nl</a>.</li>
<li>Tucker, P. 2019g. The NSA is studying satellite hacking. Defense one, 20 September. <a href="https://www.defenseone.com/technology/2019/09/nsa-studying-satellite-hacking/160009/">https://www.defenseone.com/technology/2019/09/nsa-studying-satellite-hacking/160009/</a>.</li>
<li>Tucker, P. 2019h. Pentagon wants satellites that can dodge incoming fire. Defense one, 22 February. <a href="https://www.defenseone.com/technology/2019/02/pentagon-wants-satellites-can-dodge-incoming-fire/155088/%3foref%3ddefense_one_breaking_nl">https://www.defenseone.com/technology/2019/02/pentagon-wants-satellites-can-dodge-incoming-fire/155088/?oref=defense_one_breaking_nl</a>.</li>
<li>Tucker, P. 2020a. U.S. expected to loosen restrictions on land mines—Smart ones, anyway’. Defense one, 30 January. <a href="https://www.defenseone.com/technology/2020/01/us-expected-loosen-restrictions-land-mines-smart-ones-anyway/162773/%3foref%3ddefense_one_breaking_nl">https://www.defenseone.com/technology/2020/01/us-expected-loosen-restrictions-land-mines-smart-ones-anyway/162773/?oref=defense_one_breaking_nl</a>.</li>
<li>Tucker, P. 2020b. U.S. government to restrict sale of AI for satellite image analysis’. Defense one, 6 January. <a href="https://www.defenseone.com/technology/2020/01/us-government-restrict-sale-ai-satellite-image-analysis/162255/%3foref%3ddefense_one_breaking_nl">https://www.defenseone.com/technology/2020/01/us-government-restrict-sale-ai-satellite-image-analysis/162255/?oref=defense_one_breaking_nl</a>.</li>
<li>Tucker, P. 2020c. Iran is expanding its online disinformation operations’. Defense one, 9 January. <a href="https://www.defenseone.com/technology/2020/01/iran-expanding-its-online-disinformation-operations/162357/%3foref%3ddefense_one_breaking_nl">https://www.defenseone.com/technology/2020/01/iran-expanding-its-online-disinformation-operations/162357/?oref=defense_one_breaking_nl</a>.</li>
<li>Turner, F. 2006. <em>From Counterculture to Cyberculture</em>. Chicago: University of Chicago Press. <a href="https://doi.org/10.7208%2Fchicago%2F9780226817439.001.0001">Book</a> <a href="http://scholar.google.com/scholar_lookup?&amp;title=From%20Counterculture%20to%20Cyberculture&amp;publication_year=2006&amp;author=Turner%2CF">Google Scholar</a></li>
<li>Walker, P., and A. Hern. 2019. Labour suffers second cyber-attack in two days. The Guardian, 12 November. <a href="https://www.theguardian.com/politics/2019/nov/12/labour-reveals-large-scale-cyber-attack-on-digital-platforms">https://www.theguardian.com/politics/2019/nov/12/labour-reveals-large-scale-cyber-attack-on-digital-platforms</a>.</li>
<li>Wareham, M. 2020. As killer robots loom, a push to keep humans in control of use of force. Human Rights Watch, 2 January. <a href="https://www.hrw.org/news/2020/01/02/killer-robots-loom-push-keep-humans-control-use-force">https://www.hrw.org/news/2020/01/02/killer-robots-loom-push-keep-humans-control-use-force</a>.</li>
<li>Warrell, H., and H. Fox. 2019. Russian cyberattack unit ‘masqueraded’ as Iranian hackers, UK says. Financial Times, 21 October. <a href="https://www.ft.com/content/b947b46a-f342-11e9-a79c-bc9acae3b654">https://www.ft.com/content/b947b46a-f342-11e9-a79c-bc9acae3b654</a>.</li>
<li>Weisgerber, M. 2019. U.S. Air force to shift billions of dollars to network its weapons. Defense one, 17 September. <a href="https://www.defenseone.com/business/2019/09/us-air-force-shift-billions-dollars-network-its-weapons/159958/%3foref%3ddefenseone_today_nl">https://www.defenseone.com/business/2019/09/us-air-force-shift-billions-dollars-network-its-weapons/159958/?oref=defenseone_today_nl</a>.</li>
<li>Winder, D. 2019. New Orleans declares state of emergency following cyber attack. Forbes, 14 December. <a href="https://www.forbes.com/sites/daveywinder/2019/12/14/new-orleans-declares-state-of-emergency-following-cyber-attack/#7f82322d6a05">https://www.forbes.com/sites/daveywinder/2019/12/14/new-orleans-declares-state-of-emergency-following-cyber-attack/#7f82322d6a05</a>.</li>
<li>Winter, C., and A. Amarasingam. 2019. The decimation of Isis on Telegram is big, but it has consequences. Wired, 2 December. <a href="https://www.wired.co.uk/article/isis-telegram-security">https://www.wired.co.uk/article/isis-telegram-security</a>.</li>
<li>Wintour, P., and J. Borger. 2019. Trump says he stopped airstrike on Iran because 150 would have died. The Guardian, 21 June. <a href="https://www.theguardian.com/world/2019/jun/21/donald-trump-retaliatory-iran-airstrike-cancelled-10-minutes-before">https://www.theguardian.com/world/2019/jun/21/donald-trump-retaliatory-iran-airstrike-cancelled-10-minutes-before</a>.</li>
<li>You, T. 2019. China’s top-secret supersonic spy drone ‘which can reach the US territory is unveiled for the first time’. Daily Mail, 17 September. <a href="https://www.dailymail.co.uk/news/article-7472991/Beijings-secret-supersonic-spy-drone-spotted-time.html">https://www.dailymail.co.uk/news/article-7472991/Beijings-secret-supersonic-spy-drone-spotted-time.html</a>.</li>
<li>Young, A. 2019. Chinese hackers ‘stole data from UK mobile phones for up to seven Years’ in one of the world’s biggest cyberattacks, experts reveal. Daily Mail, 29 June. <a href="https://www.dailymail.co.uk/news/article-7196471/Chinese-hackers-stole-data-UK-mobile-phones-SEVEN-years.html">https://www.dailymail.co.uk/news/article-7196471/Chinese-hackers-stole-data-UK-mobile-phones-SEVEN-years.html</a>.</li>
</ul>
</div>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="Big Data, new epistemologies and paradigm shifts"
class="paper-story"
data-article-title="Big Data, new epistemologies and paradigm shifts"
>

<h1 class="article-title" id="h_Big Data, new epistemologies and paradigm shifts">Big Data, new epistemologies and paradigm shifts</h1>

<div class="top-meta">Rob Kitchin, 2014-04-01 00:00:00 AEST. for week 9.</div>

<h4>Article Information</h4>
<p>Volume: 1 issue: 1, <strong>Article first published online:</strong> April 1, 2014; <a href="https://doi.org/10.1177/2053951714528481">DOI</a></p>
<h4>Corresponding Author:</h4>
<p>Rob Kitchin, National Institute for Regional and Spatial Analysis, National University of Ireland Maynooth, County Kildare, Ireland. Email: <a href="mailto:Rob.Kitchin@nuim.ie">Rob.Kitchin@nuim.ie</a></p>
<p>This article is distributed under the terms of the Creative Commons Attribution-NonCommercial 3.0 License (<a href="http://www.creativecommons.org/licenses/by-nc/3.0/">http://www.creativecommons.org/licenses/by-nc/3.0/</a>) which permits non-commercial use, reproduction and distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open Access page(<a    href="http://www.uk.sagepub.com/aboutus/openaccess.htm">http://www.uk.sagepub.com/aboutus/openaccess.htm</a>).</p>
<h2>Abstract</h2>
<p>This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities, and assesses the extent to which they are engendering paradigm shifts across multiple disciplines. In particular, it critically explores new forms of empiricism that declare ‘the end of theory’, the creation of data-driven rather than knowledge-driven science, and the development of digital humanities and computational social sciences that propose radically different ways to make sense of culture, history, economy and society. It is argued that: (1) Big Data and new data analytics are disruptive innovations which are reconfiguring in many instances how research is conducted; and (2) there is an urgent need for wider critical reflection within the academy on the epistemological implications of the unfolding data revolution, a task that has barely begun to be tackled despite the rapid changes in research practices presently taking place. After critically reviewing emerging epistemological positions, it is contended that a potentially fruitful approach would be the development of a situated, reflexive and contextually nuanced epistemology.</p>
<h2>Introduction</h2>
<figure>
<blockquote>
<p>Revolutions in science have often been preceded by revolutions in measurement.</p>
</blockquote>
<figcaption>
<p>Sinan Aral (cited in Cukier, 2010)</p>
</figcaption>
</figure>
<figure>
<blockquote>
<p>Big Data creates a radical shift in how we think about research …. [It offers] a profound change at the levels of epistemology and ethics. Big Data reframes key questions about the constitution of knowledge, the processes of research, how we should engage with information, and the nature and the categorization of reality … Big Data stakes out new terrains of objects, methods of knowing, and definitions of social life.</p>
</blockquote>
<figcaption>
<p>(boyd and Crawford, 2012)</p>
</figcaption>
</figure>
<p>As with many rapidly emerging concepts, Big Data has been variously defined and operationalized, ranging from trite proclamations that Big Data consists of datasets too large to fit in an Excel spreadsheet or be stored on a single machine (Strom, 2012) to more sophisticated ontological assessments that tease out its inherent characteristics (boyd and Crawford, 2012; Mayer-Schonberger and Cukier, 2013). Drawing on an extensive engagement with the literature, Kitchin (2013) details that Big Data is:</p>
<ul>
<li>huge in <em>volume</em>, consisting of terabytes or petabytes of data;</li>
<li>high in <em>velocity</em>, being created in or near real-time;</li>
<li>diverse in <em>variety</em>, being structured and unstructured in nature;</li>
<li><em>exhaustive</em> in scope, striving to capture entire populations or systems (n = all);</li>
<li>fine-grained in <em>resolution</em> and uniquely <em>indexical</em> in identification;</li>
<li><em>relational</em> in nature, containing common fields that enable the conjoining of different data sets;</li>
<li><em>flexible</em>, holding the traits of <em>extensionality</em> (can add new fields easily) and <em>scaleability</em> (can expand in size rapidly). (see boyd and Crawford, 2012; Dodge and Kitchin, 2005; Laney, 2001; Marz and Warren, 2012; Mayer-Schonberger and Cukier, 2013; Zikopoulos et al., 2012).</li>
</ul>
<p>In other words, Big Data is not simply denoted by volume. Indeed, industry, government and academia have long produced massive data sets – for example, national censuses. However, given the costs and difficulties of generating, processing, analysing and storing such datasets, these data have been produced in tightly controlled ways using sampling techniques that limit their scope, temporality and size (Miller, 2010). To make the exercise of compiling census data manageable they have been produced once every five or 10 years, asking just 30 to 40 questions, and their outputs are usually quite coarse in resolution (e.g. local areas or counties rather than individuals and households). Moreover, the methods used to generate them are quite inflexible (for example, once a census is set and is being administered it is impossible to tweak or add/remove questions). Whereas the census seeks to be exhaustive, enumerating all people living in a country, most surveys and other forms of data generation are samples, seeking to be representative of a population.</p>
<p>In contrast, Big Data is characterized by being generated continuously, seeking to be exhaustive and fine-grained in scope, and flexible and scalable in its production. Examples of the production of such data include: digital CCTV; the recording of retail purchases; digital devices that record and communicate the history of their own use (e.g. mobile phones); the logging of transactions and interactions across digital networks (e.g. email or online banking); clickstream data that record navigation through a website or app; measurements from sensors embedded into objects or environments; the scanning of machine-readable objects such as travel passes or barcodes; and social media postings (Kitchin, 2014). These are producing massive, dynamic flows of diverse, fine-grained, relational data. For example, in 2012 Wal-Mart was generating more than 2.5 petabytes (2<sup>50</sup> bytes) of data relating to more than 1 million customer transactions <em>every hour</em> (Open Data Center Alliance, 2012) and Facebook reported that it was processing 2.5 billion pieces of content (links, comments, etc.), 2.7 billion ‘Like’ actions and 300 million photo uploads <em>per day</em> (Constine, 2012). Handling and analysing such data is a very different proposition to dealing with a census every 10 years or a survey of a few hundred respondents.</p>
<p>Whilst the production of such Big Data has existed in some domains, such as remote sensing, weather prediction, and financial markets, for some time, a number of technological developments, such as ubiquitous computing, widespread internet working, and new database designs and storage solutions, have created a tipping point for their routine generation and analysis, not least of which are new forms of data analytics designed to cope with data abundance (Kitchin, 2014). Traditionally, data analysis techniques have been designed to extract insights from scarce, static, clean and poorly relational data sets, scientifically sampled and adhering to strict assumptions (such as independence, stationarity, and normality), and generated and analysed with a specific question in mind (Miller, 2010). The challenge of analysing Big Data is coping with abundance, exhaustivity and variety, timeliness and dynamism, messiness and uncertainty, high relationality, and the fact that much of what is generated has no specific question in mind or is a by-product of another activity. Such a challenge was until recently too complex and difficult to implement, but has become possible due to high-powered computation and new analytical techniques. These new techniques are rooted in research concerning artificial intelligence and expert systems that have sought to produce machine learning that can computationally and automatically mine and detect patterns and build predictive models and optimize outcomes (Han et al., 2011; Hastie et al., 2009). Moreover, since different models have their strengths and weaknesses, and it is often difficult to prejudge which type of model and its various versions will perform best on any given data set, an ensemble approach can be employed to build multiple solutions (Seni and Elder, 2010). Here, literally hundreds of different algorithms can be applied to a dataset to determine the best or a composite model or explanation (Siegel, 2013), a radically different approach to that traditionally used wherein the analyst selects an appropriate method based on their knowledge of techniques and the data. In other words, Big Data analytics enables an entirely new epistemological approach for making sense of the world; rather than testing a theory by analysing relevant data, new data analytics seek to gain insights ‘born from the data’.</p>
<p>The explosion in the production of Big Data, along with the development of new epistemologies, is leading many to argue that a data revolution is under way that has far-reaching consequences to how knowledge is produced, business conducted, and governance enacted (Anderson, 2008; Bollier, 2010; Floridi, 2012; Mayer-Schonberger and Cukier, 2013). With respect to knowledge production, it is contended that Big Data presents the possibility of a new research paradigm across multiple disciplines. As set out by Kuhn (1962), a paradigm constitutes an accepted way of interrogating the world and synthesizing knowledge common to a substantial proportion of researchers in a discipline at any one moment in time. Periodically, Kuhn argues, a new way of thinking emerges that challenges accepted theories and approaches. For example, Darwin’s theory of evolution radically altered conceptual thought within the biological sciences, as well as challenging the religious doctrine of creationism. Jim Gray (as detailed in Hey et al., 2009) charts the evolution of science through four broad paradigms (see Table 1). Unlike Kuhn’s proposition that paradigm shifts occur because the dominant mode of science cannot account for particular phenomena or answer key questions, thus demanding the formulation of new ideas, Gray’s transitions are founded on advances in forms of data and the development of new analytical methods. He thus proposes that science is entering a fourth paradigm based on the growing availability of Big Data and new analytics.</p>
<figure>
<p><img src="/assets/4data.jpeg" alt="alt text"></p>
<figcaption>
<p>Table 1. Four paradigms of science.</p>
</figcaption>
</figure>
<p>Kuhn’s argument has been subject to much critique, not least because within some academic domains there is little evidence of paradigms operating, notably in some social sciences where there is a diverse set of philosophical approaches employed (e.g. human geography, sociology), although in other domains, such as the sciences, there has been more epistemological unity around how science is conducted, using a well defined scientific method, underpinned by hypothesis testing to verify or falsify theories. Moreover, paradigmatic accounts produce overly sanitized and linear stories of how disciplines evolve, smoothing over the messy, contested and plural ways in which science unfolds in practice. Nevertheless, whilst the notion of paradigms is problematic, it has utility in framing the current debates concerning the development of Big Data and their consequences because many of the claims being made with respect to knowledge production contend that a fundamentally different epistemology is being created; that a transition to a new paradigm is under way. However, the form that this new epistemology is taking is contested. The rest of this paper critically examines the development of an emerging fourth paradigm in science and its form, and explores to what extent the data revolution is leading to alternative epistemologies in the humanities and social sciences and changing research practices.</p>
<h2>A fourth paradigm in science?</h2>
<p>Whilst Jim Gray envisages the fourth paradigm of science to be data-intensive and a radically new extension of the established scientific method, others suggest that Big Data ushers in a new era of empiricism, wherein the volume of data, accompanied by techniques that can reveal their inherent truth, enables data to speak for themselves free of theory. The empiricist view has gained credence outside of the academy, especially within business circles, but its ideas have also taken root in the new field of data science and other sciences. In contrast, a new mode of data-driven science is emerging within traditional disciplines in the academy. In this section, the epistemological claims of both approaches are critically examined, mindful of the different drivers and aspirations of business and the academy, with the former preoccupied with employing data analytics to identify new products, markets and opportunities rather than advance knowledge per se, and the latter focused on how best to make sense of the world and to determine explanations as to phenomena and processes.</p>
<h3>The end of theory: Empiricism reborn</h3>
<p>For commentators such as Chris Anderson, former editor-in-chief at <em>Wired</em> magazine, Big Data, new data analytics and ensemble approaches signal a new era of knowledge production characterized by ‘the end of theory’. In a provocative piece, Anderson (2008) argues that ‘the data deluge makes the scientific method obsolete’; that the patterns and relationships contained within Big Data inherently produce meaningful and insightful knowledge about complex phenomena. Essentially arguing that Big Data enables an empiricist mode of knowledge production, he contends:</p>
<blockquote>
<p>There is now a better way. Petabytes allow us to say: ‘Correlation is enough.’ … We can analyze the data without hypotheses about what it might show. We can throw the numbers into the biggest computing clusters the world has ever seen and let statistical algorithms find patterns where science cannot … Correlation supersedes causation, and science can advance even without coherent models, unified theories, or really any mechanistic explanation at all. There’s no reason to cling to our old ways.</p>
</blockquote>
<p>Similarly, Prensky (2009) argues:</p>
<blockquote>
<p>scientists no longer have to make educated guesses, construct hypotheses and models, and test them with data-based experiments and examples. Instead, they can mine the complete set of data for patterns that reveal effects, producing scientific conclusions <em>without</em> further experimentation.</p>
</blockquote>
<p>Dyche (2012) thus argues that ‘mining Big Data reveals relationships and patterns that we didn’t even know to look for.’ Likewise, Steadman (2013) argues:</p>
<blockquote>
<p>The Big Data approach to intelligence gathering allows an analyst to get the full resolution on worldwide affairs. Nothing is lost from looking too closely at one particular section of data; nothing is lost from trying to get too wide a perspective on a situation that the fine detail is lost … . The analyst doesn't even have to bother proposing a hypothesis anymore.</p>
</blockquote>
<p>The examples used to illustrate such a position usually stem from marketing and retail. For example, Dyche (2012) details the case of a retail chain that analysed 12 years’ worth of purchase transactions for possible unnoticed relationships between products that ended up in shoppers’ baskets. Discovering correlations between certain items led to new product placements and a 16% increase in revenue per shopping cart in the first month’s trial. There was no hypothesis that Product A was often bought with Product H that was then tested. The data were simply queried to discover what relationships existed that might have previously been unnoticed. Similarly, Amazon’s recommendation system produces suggestions for other items a shopper might be interested in without knowing anything about the culture and conventions of books and reading; it simply identifies patterns of purchasing across customers in order to determine if Person A likes Book X they are also likely to like Book Y given their own and others’ consumption patterns. Whilst it might be desirable to explain why associations exist within the data and why they might be meaningful, such explanation is cast as largely unnecessary. Siegel (2013: 90) thus argues with respect to predictive analytics: ‘We usually don’t know about causation, and we often don’t necessarily care … the objective is more to predict than it is to understand the world … It just needs to work; prediction trumps explanation’.</p>
<p>Some data analytics software is sold on precisely this notion. For example, the data mining and visualization software Ayasdi claims to be able to</p>
<blockquote>
<p>automatically discover insights—regardless of complexity—without asking questions. Ayasdi's customers can finally learn the answers to questions that they didn't know to ask in the first place. Simply stated, Ayasdi is ‘digital serendipity’. (Clark, 2013)</p>
</blockquote>
<p>Further, it purports to have totally removed</p>
<blockquote>
<p>the human element that goes into data mining—and, as such, all the human bias that goes with it. Instead of waiting to be asked a question or be directed to specific existing data links, the system will—undirected—deliver patterns a human controller might not have thought to look for. (Clark, 2013)</p>
</blockquote>
<p>There is a powerful and attractive set of ideas at work in the empiricist epistemology that runs counter to the deductive approach that is hegemonic within modern science:</p>
<ul>
<li>Big Data can capture a whole domain and provide full resolution;</li>
<li>there is no need for a priori theory, models or hypotheses;</li>
<li>through the application of agnostic data analytics the data can speak for themselves free of human bias or framing, and any patterns and relationships within Big Data are inherently meaningful and truthful;</li>
<li>meaning transcends context or domain-specific knowledge, thus can be interpreted by anyone who can decode a statistic or data visualization.</li>
</ul>
<p>These work together to suggest that a new mode of science is being created, one in which the <em>modus operandi</em> is purely inductive in nature.</p>
<p>Whilst this empiricist epistemology is attractive, it is based on fallacious thinking with respect to the four ideas that underpin its formulation. First, though Big Data may seek to be exhaustive, capturing a whole domain and providing full resolution, it is both a representation and a sample, shaped by the technology and platform used, the data ontology employed and the regulatory environment, and it is subject to sampling bias (Crawford, 2013; Kitchin, 2013). Indeed, all data provide oligoptic views of the world: views from certain vantage points, using particular tools, rather than an all-seeing, infallible God’s eye view (Amin and Thrift, 2002; Haraway, 1991). As such, data are not simply natural and essential elements that are abstracted from the world in neutral and objective ways and can be accepted at face value; data are created within a complex assemblage that actively shapes its constitution (Ribes and Jackson, 2013).</p>
<p>Second, Big Data does not arise from nowhere, free from the ‘the regulating force of philosophy’ (Berry, 2011: 8). Contra, systems are designed to capture certain kinds of data and the analytics and algorithms used are based on scientific reasoning and have been refined through scientific testing. As such, an inductive strategy of identifying patterns within data does not occur in a scientific vacuum and is discursively framed by previous findings, theories, and training; by speculation that is grounded in experience and knowledge (Leonelli, 2012). New analytics might present the illusion of automatically discovering insights without asking questions, but the algorithms used most certainly did arise and were tested scientifically for validity and veracity.</p>
<p>Third, just as data are not generated free from theory, neither can they simply speak for themselves free of human bias or framing. As Gould (1981: 166) notes, ‘inanimate data can never speak for themselves, and we always bring to bear some conceptual framework, either intuitive and ill-formed, or tightly and formally structured, to the task of investigation, analysis, and interpretation’. Making sense of data is always framed – data are examined through a particular lens that influences how they are interpreted. Even if the process is automated, the algorithms used to process the data are imbued with particular values and contextualized within a particular scientific approach. Further, patterns found within a data set are not inherently meaningful. Correlations between variables within a data set can be random in nature and have no or little causal association, and interpreting them as such can produce serious ecological fallacies. This can be exacerbated in the case of Big Data as the empiricist position appears to promote the practice of data dredging – hunting for every association or model.</p>
<p>Fourth, the idea that data can speak for themselves suggests that anyone with a reasonable understanding of statistics should be able to interpret them without context or domain-specific knowledge. This is a conceit voiced by some data and computer scientists and other scientists, such as physicists, all of whom have become active in practising social science and humanities research. For example, a number of physicists have turned their attention to cities, employing Big Data analytics to model social and spatial processes and to identify supposed laws that underpin their formation and functions (Bettencourt et al., 2007; Lehrer, 2010). These studies often wilfully ignore a couple of centuries of social science scholarship, including nearly a century of quantitative analysis and model building. The result is an analysis of cities that is reductionist, functionalist and ignores the effects of culture, politics, policy, governance and capital (reproducing the same kinds of limitations generated by the quantitative/positivist social sciences in the mid-20th century). A similar set of concerns is shared by those in the sciences. Strasser (2012), for example, notes that within the biological sciences, bioinformaticians who have a very narrow and particular way of understanding biology are claiming ground once occupied by the clinician and the experimental and molecular biologist. These scientists are undoubtedly ignoring the observations of Porway (2013):</p>
<blockquote>
<p>Without subject matter experts available to articulate problems in advance, you get [poor] results … . Subject matter experts are doubly needed to assess the results of the work, especially when you’re dealing with sensitive data about human behavior. As data scientists, we are well equipped to explain the ‘what’ of data, but rarely should we touch the question of ‘why’ on matters we are not experts in.</p>
</blockquote>
<p>Put simply, whilst data can be interpreted free of context and domain-specific expertise, such an epistemological interpretation is likely to be anaemic or unhelpful as it lacks embedding in wider debates and knowledge.</p>
<p>These fallacious notions have gained some traction, especially within business circles, because they possess a convenient narrative for the aspirations of knowledge-orientated businesses (e.g. data brokers, data analytic providers, software vendors, consultancies) in selling their services. Within the empiricist frame, data analytics offer the possibility of insightful, objective and profitable knowledge without science or scientists, and their associated overheads of cost, contingencies, and search for explanation and truth. In this sense, whilst the data science techniques employed might hold genuine salience for practioners, the articulation of a new empiricism operates as a discursive rhetorical device designed to simplify a more complex epistemological approach and to convince vendors of the utility and value of Big Data analytics.</p>
<h3>Data-driven science</h3>
<p>In contrast to new forms of empiricism, data-driven science seeks to hold to the tenets of the scientific method, but is more open to using a hybrid combination of abductive, inductive and deductive approaches to advance the understanding of a phenomenon. It differs from the traditional, experimental deductive design in that it seeks to generate hypotheses and insights ‘born from the data’ rather than ‘born from the theory’ (Kelling et al., 2009: 613). In other words, it seeks to incorporate a mode of induction into the research design, though explanation through induction is not the intended end-point (as with empiricist approaches). Instead, it forms a new mode of hypothesis generation before a deductive approach is employed. Nor does the process of induction arise from nowhere, but is situated and contextualized within a highly evolved theoretical domain. As such, the epistemological strategy adopted within data-driven science is to use guided knowledge discovery techniques to identify potential questions (hypotheses)
worthy of further examination and testing.</p>
<p>The process is guided in the sense that existing theory is used to direct the process of knowledge discovery, rather than simply hoping to identify all relationships within a dataset and assuming they are meaningful in some way. As such, how data are generated or repurposed is directed by certain assumptions, underpinned by theoretical and practical knowledge and experience as to whether technologies and their configurations will capture or produce appropriate and useful research material. Data are not generated by every means possible, using every kind of available technology or every kind of sampling framework; rather, strategies of data generation and repurposing are carefully thought out, with strategic decisions made to harvest certain kinds of data and not others. Similarly, how these data are processed, managed and analysed is guided by assumptions as to which techniques might provide meaningful insights. The data are not subject to every ontological framing possible, or every form of data-mining technique in the hope that they reveal some hidden truth. Rather, theoretically informed decisions are made as to how best to tackle a data set such that it will reveal information which will be of potential interest and is worthy of further research. And instead of testing whether every relationship revealed has veracity, attention is focused on those – based on some criteria – that seemingly offer the most likely or valid way forward. Indeed, many supposed relationships within data sets can quickly be dismissed as trivial or absurd by domain specialists, with others flagged as deserving more attention ( Miller, 2010).</p>
<p>Such decision-making with respect to methods of data generation and analysis are based on abductive reasoning. Abduction is a mode of logical inference and reasoning forwarded by C. S. Peirce (1839–1914) (Miller, 2010). It seeks a conclusion that makes reasonable and logical sense, but is not definitive in its claim. For example, there is no attempt to deduce what is the best way to generate data, but rather to identify an approach that makes logical sense given what is already known about such data production. Abduction is very commonly used in science, especially in the formulation of hypotheses, though such use is not widely acknowledged. Any relationships revealed within the data do not then arise from nowhere and nor do they simply speak for themselves. The process of induction – of insights emerging from the data – is contextually framed. And those insights are not the end-point of an investigation, arranged and reasoned into a theory. Rather, the insights provide the basis for the formulation of hypotheses and the deductive testing of their validity. In other words, data-driven science is a reconfigured version of the traditional scientific method, providing a new way in which to build theory. Nonetheless, the epistemological change is significant.</p>
<p>Rather than empiricism and the end of theory, it is argued by some that data-driven science will become the new paradigm of scientific method in an age of Big Data because the epistemology favoured is suited to extracting additional, valuable insights that traditional ‘knowledge-driven science’
would fail to generate (Kelling et al., 2009; Loukides, 2010; Miller, 2010). Knowledge-driven science, using a straight deductive approach, has particular utility in understanding and explaining the world under the conditions of scarce data and weak computation. Continuing to use such an approach, however, when technological and methodological advances mean that it is possible to undertake much richer analysis of data –
applying new data analytics and being able to connect together large, disparate data together in ways that were hitherto impossible, and which produce new valuable data and identify and tackle questions in new and exciting ways – makes little sense. Moreover, the advocates of data-driven science argue that it is much more suited to exploring, extracting value and making sense of massive, interconnected data sets, fostering interdisciplinary research that conjoins domain expertise (as it is less limited by the starting theoretical frame), and that it will lead to more holistic and extensive models and theories of entire complex systems rather than elements of them (Kelling et al., 2009).</p>
<p>For example, it is contended that data-driven science will transform our understanding of environmental systems (Bryant et al., 2008; Lehning et al., 2009). It will enable high-resolution data being generated from a variety of sources, often in real-time (such as conventional and mobile weather stations, satellite and aerial imagery, weather radar, stream observations and gauge stations, citizen observations, ground and aerial LIDAR, water-quality sampling, gas measures, soil cores, and distributed sensors that measure selected domains such as air temperature and moisture) to be integrated together to provide very detailed models of environments in flux (as opposed to at freeze-points in time and space) and to identify specific relationships between phenomena and processes that generate new hypotheses and theories that can then be tested further to establish their veracity. It will also help to identify and further understand connection points between different environmental spheres</p>
<blockquote>
<p>– such as the atmosphere (air), biosphere (ecosystems), hydrosphere (water systems), lithosphere (rocky shell of the Earth) and pedosphere (soils) –
and aid in the integration of theories into a more holistic theoretical assemblage. This will provide a better comprehension of the diverse, inter-related processes at work and the interconnections with human systems, and can be used to guide models and simulations for predicting long-term trends and possible adaptive strategies.</p>
</blockquote>
<h2>Computational social sciences and digital humanities</h2>
<p>Whilst the epistemologies of Big Data empiricism and data-driven science seem set to transform the approach to research taken in the natural, life, physical and engineering sciences, their trajectory in the humanities and social sciences is less certain. These areas of scholarship are highly diverse in their philosophical underpinnings, with only some scholars employing the epistemology common in the sciences. Those using the scientific method in order to explain and model social phenomena, in general terms, draw on the ideas of positivism (though they might not adopt such a label; Kitchin, 2006). Such work tends to focus on factual, quantified information – empirically observable phenomena that can be robustly measured
(such as counts, distance, cost, and time), as opposed to more intangible aspects of human life such as beliefs or ideology – using statistical testing to establish causal relationships and to build theories and predictive models and simulations. Positivistic approaches are well established in economics, political science, human geography and sociology, but are rare in the humanities. However, within those disciplines mentioned, there has been a strong move over the past half century towards post-positivist approaches, especially in human geography and sociology.</p>
<p>For positivistic scholars in the social sciences, Big Data offers a significant opportunity to develop more sophisticated, wider-scale, finer-grained models of human life. Notwithstanding concerns over access to social and economic Big Data (much of which is generated by private interests) and issues such as data quality, Big Data offers the possibility of shifting ‘from data-scarce to data-rich studies of societies; from static snapshots to dynamic unfoldings; from coarse aggregations to high resolutions; from relatively simple models to more complex, sophisticated simulations’ (Kitchin, 2014: 3). The potential exists for a new era of computational social science that produces studies with much greater breadth, depth, scale, and timeliness, and that are inherently longitudinal, in contrast to existing social sciences research (Lazer et al., 2009; Batty et al., 2012). Moreover, the variety, exhaustivity, resolution, and relationality of data, plus the growing power of computation and new data analytics, address some of the critiques of positivistic scholarship to date, especially those of reductionism and universalism, by providing more finely-grained, sensitive, and nuanced analysis that can take account of context and contingency, and can be used to refine and extend theoretical understandings of the social and spatial world (Kitchin, 2013). Further, given the extensiveness of data, it is possible to test the veracity of such theory across a variety of settings and situations. In such circumstances, it is argued that knowledge about individuals, communities, societies and environments will become more insightful and useful with respect to formulating policy and addressing the various issues facing humankind.</p>
<p>For post-positivist scholars, Big Data offers both opportunities and challenges. The opportunities are a proliferation, digitization and interlinking of a diverse set of analogue and unstructured data, much of it new (e.g. social media) and much of which has heretofore been difficult to access (e.g. millions of books, documents, newspapers, photographs, art works, material objects, etc., from across history that have been rendered into digital form over the past couple of decades by a range of organizations; Cohen, 2008), and also the provision of new tools of data curation, management and analysis that can handle massive numbers of data objects. Consequently, rather than concentrating on a handful of novels or photographs, or a couple of artists and their work, it becomes possible to search and connect across a large number of related works; rather than focus on a handful of websites or chat rooms or videos or online newspapers, it becomes possible to examine hundreds of thousands of such media (Manovich, 2011). These opportunities are most widely being examined through the emerging field of digital humanities.</p>
<p>Initially, the digital humanities consisted of the curation and analysis of data that are born digital and the digitization and archiving projects that sought to render analogue texts and material objects into digital forms that could be organized and searched and be subjected to basic forms of overarching, automated or guided analysis such as summary visualizations of content (Schnapp and Presner, 2009). Subsequently, its advocates have been divided into two camps. The first group believes that new digital humanities techniques – counting, graphing, mapping and distant reading – bring methodological rigour and objectivity to disciplines that heretofore have been unsystematic and random in their focus and approach (Moretti, 2005; Ramsay, 2010). In contrast, the second group argues that, rather than replacing traditional methods or providing an empiricist or positivistic approach to humanities scholarship, new techniques complement and augment existing humanities methods and facilitate traditional forms of interpretation and theory-building, enabling studies of much wider scope to answer questions that would be all but unanswerable without computation
(Berry, 2011; Manovich, 2011).</p>
<p>The digital humanities has not been universally welcomed, with detractors contending that using computers as ‘reading machines’ (Ramsay, 2010) to undertake ‘distant reading’ (Moretti, 2005) runs counter to and undermines traditional methods of close reading. Culler (2010: 22) notes that close reading involves paying ‘attention to how meaning is produced or conveyed, to what sorts of literary and rhetorical strategies and techniques are deployed to achieve what the reader takes to be the effects of the work or passage’ – something that a distant reading is unable to perform. His worry is that a digital humanities approach promotes literary scholarship that involves no actual reading. Similarly, Trumpener (2009: 164) argues that a ‘statistically driven model of literary history … seems to necessitate an impersonal invisible hand’, continuing: ‘any attempt to see the big picture needs to be informed by broad knowledge, an astute, historicized sense of how genres and literary institutions work, and incisive interpretive tools’ (pp. 170–171). Likewise, Marche (2012) contends that cultural artefacts, such as literature, cannot be treated as mere data. A piece of writing is not simply an order of letters and words; it is contextual and conveys meaning and has qualities that are ineffable. Algorithms are very poor at capturing and deciphering meaning or context and, Marche argues, treat ‘all literature as if it were the same’. He continues:</p>
<blockquote>
<p>[t]he algorithmic analysis of novels and of newspaper articles is necessarily at the limit of reductivism. The process of turning literature into data removes distinction itself. It removes taste. It removes all the refinement from criticism. It removes the history of the reception of works.</p>
</blockquote>
<p>Jenkins (2013) thus concludes:</p>
<blockquote>
<p>the value of the arts, the quality of a play or a painting, is not measurable. You could put all sorts of data into a machine: dates, colours, images, box office receipts, and none of it could explain what the artwork is, what it means, and why it is powerful. That requires man [sic], not machine.</p>
</blockquote>
<p>For many, then, the digital humanities is fostering weak, surface analysis, rather than deep, penetrating insight. It is overly reductionist and crude in its techniques, sacrificing complexity, specificity, context, depth and critique for scale, breadth, automation, descriptive patterns and the impression that interpretation does not require deep contextual knowledge.</p>
<p>The same kinds of argument can be levelled at computational social science. For example, a map of the language of tweets in a city might reveal patterns of geographic concentration of different ethnic communities (Rogers, 2013), but the important questions are who constitutes such concentrations, why do they exist, what were the processes of formation and reproduction, and what are their social and economic consequences? It is one thing to identify patterns; it is another to explain them. This requires social theory and deep contextual knowledge. As such, the pattern is not the end-point but rather a starting point for additional analysis, which almost certainly is going to require other data sets.</p>
<p>As with earlier critiques of quantitative and positivist social sciences, computational social sciences are taken to task by post-positivists as being mechanistic, atomizing, and parochial, reducing diverse individuals and complex, multidimensional social structures to mere data points (Wyly, in press). Moreover, the analysis is riddled with assumptions of social determinism, as exemplified by Pentland (2012): ‘the sort of person you are is largely determined by your social context, so if I can see some of your behaviors, I can infer the rest, just by comparing you to the people in your crowd’. In contrast, human societies, it is argued, are too complex, contingent and messy to be reduced to formulae and laws, with quantitative models providing little insight into phenomena such as wars, genocide, domestic violence and racism, and only circumscribed insight into other human systems such as the economy, inadequately accounting for the role of politics, ideology, social structures, and culture (Harvey, 1972). People do not act in rational, pre-determined ways, but rather live lives full of contradictions, paradoxes, and unpredictable occurrences. How societies are organized and operate varies across time and space and there is no optimal or ideal form, or universal traits. Indeed, there is an incredible diversity of individuals, cultures and modes of living across the planet. Reducing this complexity to the abstract subjects that populate universal models does symbolic violence to how we create knowledge. Further, positivistic approaches wilfully ignore the metaphysical aspects of human life (concerned with meanings, beliefs, experiences) and normative questions (ethical and moral dilemmas about how things should be as opposed to how they are)
(Kitchin, 2006). In other words, positivistic approaches only focus on certain kinds of questions, which they seek to answer in a reductionist way that seemingly ignores what it means to be human and to live in richly diverse societies and places. This is not to say that quantitative approaches are not useful – they quite patently are – but that their limitations in understanding human life should be recognized and complemented with other approaches.</p>
<p>Brooks (2013) thus contends that Big Data analytics struggles with the social (people are not rationale and do not behave in predictable ways; human systems are incredibly complex, having contradictory and paradoxical relation); struggles with context (data are largely shorn of the social, political and economic and historical context); creates bigger haystacks
(consisting of many more spurious correlations, making it difficult to identify needles); has trouble addressing big problems (especially social and economic ones); favours memes over masterpieces (identifies trends but not necessarily significant features that may become a trend); and obscures values (of the data producers and those that analyse them and their objectives). In other words, whilst Big Data analytics might provide some insights, it needs to be recognized that they are limited in scope, produce particular kinds of knowledge, and still need contextualization with respect to other information, whether that be existing theory, policy documents, small data studies, or historical records, that can help to make sense of the patterns evident (Crampton et al., 2012).</p>
<p>Beyond the epistemological and methodological approach, part of the issue is that much Big Data and analysis seem to be generated with no specific questions in mind, or the focus is driven by the application of a method or the content of the data set rather than a particular question, or the data set is being used to seek an answer to a question that it was never designed to answer in the first place. With respect to the latter, geotagged Twitter data has not been produced to provide answers with respect to the geographical concentration of language groups in a city and the processes driving such spatial autocorrelation. We should perhaps not be surprised then that it only provides a surface snapshot, albeit an interesting snapshot, rather than deep penetrating insights into the geographies of race, language, agglomeration and segregation in particular locales.</p>
<p>Whereas most digital humanists recognize the value of close readings, and stress how distant readings complement them by providing depth and contextualization, positivistic forms of social science are oppositional to post-positivist approaches. The difference between the humanities and social sciences in this respect is because the statistics used in the digital humanities are largely descriptive – identifying and plotting patterns. In contrast, the computational social sciences employ the scientific method, complementing descriptive statistics with inferential statistics that seek to identify associations and causality. In other words, they are underpinned by an epistemology wherein the aim is to produce sophisticated statistical models that explain, simulate and predict human life. This is much more difficult to reconcile with post-positivist approaches. Advocacy then rests on the utility and value of the method and models, not on providing complementary analysis of a more expansive set of data.</p>
<p>There is a potentially fruitful alternative to this position that adopts and extends the epistemologies employed in critical GIS and radical statistics.These approaches employ quantitative techniques, inferential statistics, modelling and simulation whilst being mindful and open with respect to their epistemological shortcomings, drawing on critical social theory to frame how the research is conducted, how sense is made of the findings, and the knowledge employed. Here, there is recognition that research is not a neutral, objective activity that produces a view from nowhere, and that there is an inherent politics pervading the datasets analysed, the research conducted, and the interpretations made (Haraway, 1991; Rose, 1997). As such, the researcher is acknowledged to possess a certain positionality (with respect to their knowledge, experience, beliefs, aspirations, etc.), that the research is situated (within disciplinary debates, the funding landscape, wider societal politics, etc.), the data are reflective of the technique used to generate them and hold certain characteristics (relating to sampling and ontological frames, data cleanliness, completeness, consistency, veracity and fidelity), and the methods of analysis utilized produce particular effects with respect to the results produced and interpretations made. Moreover, it is recognized that how the research is employed is not ideologically-neutral but is framed in subtle and explicit ways by the aspirations and intentions of the researchers and funders/sponsors, and those that translate such research into various forms of policy, instruments, and action. In other words, within such an epistemology the research conducted is reflexive and open with respect to the research process, acknowledging the contingencies and relationalities of the approach employed, thus producing nuanced and contextualized accounts and conclusions. Such an epistemology also does not foreclose complementing situated computational social science with small data studies that provide additional and amplifying insights (Crampton et al., 2012). In other words, it is possible to think of new epistemologies that do not dismiss or reject Big Data analytics, but rather employ the methodological approach of data-driven science within a different epistemological framing that enables social scientists to draw valuable insights from Big Data that are situated and reflexive.</p>
<h2>Conclusion</h2>
<p>There is little doubt that the development of Big Data and new data analytics offers the possibility of reframing the epistemology of science, social science and humanities, and such a reframing is already actively taking place across disciplines. Big Data and new data analytics enable new approaches to data generation and analyses to be implemented that make it possible to ask and answer questions in new ways. Rather than seeking to extract insights from datasets limited by scope, temporality and size, Big Data provides the counter problem of handling and analysing enormous, dynamic, and varied datasets. The solution has been the development of new forms of data management and analytical techniques that rely on machine learning and new modes of visualization.</p>
<p>With respect to the sciences, access to Big Data and new research praxes has led some to proclaim the emergence of a new fourth paradigm, one rooted in data-intensive exploration that challenges the established scientific deductive approach. At present, whilst it is clear that Big Data is a disruptive innovation, presenting the possibility of a new approach to science, the form of this approach is not set, with two potential paths proposed that have divergent epistemologies – empiricism, wherein the data can speak for themselves free of theory, and data-driven science that radically modifies the existing scientific method by blending aspects of abduction, induction and deduction. Given the weaknesses in the empiricist arguments it seems likely that the data-driven approach will eventually win out and over time, as Big Data becomes more common and new data analytics are advanced, will present a strong challenge to the established knowledge-driven scientific method. To accompany such a transformation the philosophical underpinnings of data-driven science, with respect to its epistemological tenets, principles and methodology, need to be worked through and debated to provide a robust theoretical framework for the new paradigm.</p>
<p>The situation in the humanities and social sciences is somewhat more complex given the diversity of their philosophical underpinnings, with Big Data and new analytics being unlikely to lead to the establishment of new disciplinary paradigms. Instead, Big Data will enhance the suite of data available for analysis and enable new approaches and techniques, but will not fully replace traditional small data studies. This is partly due to philosophical positions, but also because it is unlikely that suitable Big Data will be produced that can be utilized to answer particular questions, thus necessitating more targeted studies. Nonetheless, as Kitchin (2013) and Ruppert (2013) argue, Big Data presents a number of opportunities for social scientists and humanities scholars, not least of which are massive quantities of very rich social, cultural, economic, political and historical data. It also poses a number of challenges, including a skills deficit for analysing and making sense of such data, and the creation of an epistemological approach that enables post-positivist forms of computational social science. One potential path forward is an epistemology that draws inspiration from critical GIS and radical statistics in which quantitative methods and models are employed within a framework that is reflexive and acknowledges the situatedness, positionality and politics of the social science being conducted, rather than rejecting such an approach out of hand. Such an epistemology also has potential utility in the sciences for recognizing and accounting for the use of abduction and creating a more reflexive data-driven science. As this tentative discussion illustrates, there is an urgent need for wider critical reflection on the epistemological implications of Big Data and data analytics, a task that has barely begun despite the speed of change in the data landscape.</p>
<h2>Acknowledgements</h2>
<p>Evelyn Ruppert and Mark Boyle provided some useful comments on an initial draft of this paper. The research for this paper was funded by a European Research Council Advanced Investigator Award, ‘The Programmable City’
(ERC-2012-AdG-323636).</p>
<h2>References</h2>
<div class="notes-and-refs">
<ul>
<li>Amin, A, Thrift, N (<span class="NLM_year">2002</span>) Cities: Reimagining the Urban, <span class="NLM_publisher-loc">London</span>: <span class="NLM_publisher-name">Polity</span>.</li>
<li>Anderson C (2008) The end of theory: The data deluge makes the scientific method obsolete. <em>Wired</em>, 23 June 2008. Available at: <a class="ext-link" href="http://www.wired.com/science/discoveries/magazine/16-07/pb_theory">http://www.wired.com/science/discoveries/magazine/16-07/pb_theory</a> (accessed 12 October 2012).</li>
<li>Batty, M, Axhausen, KW, Giannotti, F (<span class="NLM_year">2012</span>) <span class="NLM_article-title">Smart cities of the future</span>. European Physical Journal Special Topics 214: <span class="NLM_fpage">481</span>–<span class="NLM_lpage">518</span>.</li>
<li>Berry D (2011) The computational turn: Thinking about the digital humanities. <em>Culture Machine</em> 12. Available at: <a class="ext-link" href="http://www.culturemachine.net/index.php/cm/article/view/440/470">http://www.culturemachine.net/index.php/cm/article/view/440/470</a>
(accessed 3 December 2012).</li>
<li>Bettencourt, LMA, Lobo, J, Helbing, D (<span class="NLM_year">2007</span>) <span class="NLM_article-title">Growth, innovation, scaling, and the pace of life in cities</span>. Proceedings of the National Academy of Sciences 104(17): <span class="NLM_fpage">7301</span>–<span class="NLM_lpage">7306</span>.</li>
<li>Bollier D (2010) <em>The Promise and Peril of Big Data</em>. The Aspen Institute. Available at: <a class="ext-link" href="http://www.aspeninstitute.org/sites/default/files/content/docs/pubs/The_Promise_and_Peril_of_Big_Data.pdf">http://www.aspeninstitute.org/sites/default/files/content/docs/pubs/The_Promise_and_Peril_of_Big_Data.pdf</a>
(accessed 1 October 2012).</li>
<li>boyd, D, Crawford, K (<span class="NLM_year">2012</span>) <span class="NLM_article-title">Critical questions for big data</span>. Information, Communication and Society 15(5): <span class="NLM_fpage">662</span>–<span class="NLM_lpage">679</span>.</li>
<li>Brooks D (2013) What data can’t do. <em>New York Times</em>, 18 February 2013. Available at: <a class="ext-link" href="http://www.nytimes.com/2013/02/19/opinion/brooks-what-data-cant-do.html">http://www.nytimes.com/2013/02/19/opinion/brooks-what-data-cant-do.html</a> (accessed 18 February 2013).</li>
<li>Bryant R, Katz RH and Lazowska ED (2008) Big-data computing: Creating revolutionary breakthroughs in commerce, science and society. In: <em>Computing Research Initiatives for the 21st Century, Computing Research Association, Ver. 8</em>. Available at: <a class="ext-link" href="http://www.cra.org/ccc/docs/init/Big_Data.pdf">http://www.cra.org/ccc/docs/init/Big_Data.pdf</a>
(accessed 12 October 2012).</li>
<li>Clark L (2013) No questions asked: Big data firm maps solutions without human input. <em>Wired</em>, 16 January 2013. Available at: <a class="ext-link" href="http://www.wired.co.uk/news/archive/2013-01/16/ayasdi-big-data-launch">http://www.wired.co.uk/news/archive/2013-01/16/ayasdi-big-data-launch</a>
(accessed 28 January 2013).</li>
<li>Cohen, D (<span class="NLM_year">2008</span>) <span class="NLM_article-title">Contribution to: The promise of digital history (roundtable discussion)</span>. Journal of American History 95(2): <span class="NLM_fpage">452</span>–<span class="NLM_lpage">491</span>.</li>
<li>Constine J (2012) How big is Facebook’s data? 2.5 billion pieces of content and 500+ terabytes ingested every day, 22 August 2012. Available at: <a class="ext-link" href="http://techcrunch.com/2012/08/22/how-big-is-facebooks-data-2-5-billion-pieces-of-content-and-500-terabytes-ingested-every-day/">http://techcrunch.com/2012/08/22/how-big-is-facebooks-data-2-5-billion-pieces-of-content-and-500-terabytes-ingested-every-day/</a>
(accessed 28 January 2013).</li>
<li>Crampton J, Graham M, Poorthuis A, et al. (2012) <em>Beyond the Geotag? Deconstructing ‘Big Data’ and Leveraging the Potential of the Geoweb</em>. Available at: <a class="ext-link" href="http://www.uky.edu/∼tmute2/geography_methods/readingPDFs/2012-Beyond-the-Geotag-2012.10.01.pdf">http://www.uky.edu/∼tmute2/geography_methods/readingPDFs/2012-Beyond-the-Geotag-2012.10.01.pdf</a> (accessed 21 February 2013).</li>
<li>Crawford K (2013) The hidden biases of big data. <em>Harvard Business Review Blog</em>. 1 April. Available at: <a class="ext-link" href="http://blogs.hbr.org/2013/04/the-hidden-biases-in-big-data/">http://blogs.hbr.org/2013/04/the-hidden-biases-in-big-data/</a> (accessed 18 September 2013).</li>
<li>Cukier K (2010) Data, data everywhere. <em>The Economist</em>, 25 February (accessed 12 November 2012).</li>
<li>Culler, J (<span class="NLM_year">2010</span>) <span class="NLM_article-title">The closeness of close reading</span>. ADE Bulletin 149: <span class="NLM_fpage">20</span>–<span class="NLM_lpage">25</span>.</li>
<li>Dodge, M, Kitchin, R (<span class="NLM_year">2005</span>) <span class="NLM_article-title">Codes of life: Identification codes and the machine-readable world</span>. Environment and Planning D: Society and Space 23(6): <span class="NLM_fpage">851</span>–<span class="NLM_lpage">881</span>.</li>
<li>Dyche J (2012) Big data ‘Eurekas!’ don't just happen. <em>Harvard Business Review Blog</em>. 20 November. Available at: <a class="ext-link" href="http://blogs.hbr.org/cs/2012/11/eureka_doesnt_just_happen.html">http://blogs.hbr.org/cs/2012/11/eureka_doesnt_just_happen.html</a> (accessed 23 November 2012).</li>
<li>Floridi, L (<span class="NLM_year">2012</span>) <span class="NLM_article-title">Big data and their epistemological challenge</span>. Philosophy and Technology 25(4): <span class="NLM_fpage">435</span>–<span class="NLM_lpage">437</span>.</li>
<li>Gould, P (<span class="NLM_year">1981</span>) <span class="NLM_article-title">Letting the data speak for themselves</span>. Annals of the Association of American Geographers 71(2): <span class="NLM_fpage">166</span>–<span class="NLM_lpage">176</span>.</li>
<li>Han, J, Kamber, M, Pei (<span class="NLM_year">2011</span>) Data Mining: Concepts and Techniques, <span class="NLM_edition">3rd ed</span>. <span class="NLM_publisher-loc">Waltham</span>: <span class="NLM_publisher-name">Morgan Kaufmann</span>.</li>
<li>Haraway, D (<span class="NLM_year">1991</span>) Simians, Cyborgs and Women: The Reinvention of Nature, <span class="NLM_publisher-loc">New York</span>: <span class="NLM_publisher-name">Routledge</span>.</li>
<li>Harvey, D (<span class="NLM_year">1972</span>) Social Justice and the City, <span class="NLM_publisher-loc">Oxford</span>: <span class="NLM_publisher-name">Blackwell</span>.</li>
<li>Hastie, T, Tibshirani, R, Friedman, J (<span class="NLM_year">2009</span>) The Elements of Statistical Learning: Data Mining, Inference, and Prediction, <span class="NLM_edition">2nd ed</span>. <span class="NLM_publisher-loc">New York</span>: <span class="NLM_publisher-name">Springer</span>.</li>
<li>Hey, T, Tansley, S, Tolle, K (<span class="NLM_year">2009</span>) <span class="NLM_article-title">Jim Grey on eScience: A transformed scientific method</span>. In: Hey, T, Tansley, S, Tolle, K (eds) The Fourth Paradigm: Data-Intensive Scientific Discovery, <span class="NLM_publisher-loc">Redmond</span>: <span class="NLM_publisher-name">Microsoft Research</span>, pp. <span class="NLM_fpage">xvii</span>–<span class="NLM_lpage">xxxi</span>.</li>
<li>Jenkins T (2013) Don’t count on big data for answers. <em>The Scotsman</em>, 12 February 2013. Available at: <a class="ext-link" href="http://www.scotsman.com/the-scotsman/opinion/comment/tiffany-jenkins-don-t-count-on-big-data-for-answers-1-2785890">http://www.scotsman.com/the-scotsman/opinion/comment/tiffany-jenkins-don-t-count-on-big-data-for-answers-1-2785890</a>
(accessed 11 March 2013).</li>
<li>Kelling, S, Hochachka, W, Fink, D (<span class="NLM_year">2009</span>) <span class="NLM_article-title">Data-intensive Science: A new paradigm for biodiversity studies</span>. BioScience 59(7): <span class="NLM_fpage">613</span>–<span class="NLM_lpage">620</span>.</li>
<li>Kitchin, R (<span class="NLM_year">2006</span>) <span class="NLM_article-title">Positivistic geography and spatial science</span>. In: Aitken, S, Valentine, G (eds) Approaches in Human Geography, <span class="NLM_publisher-loc">London</span>: <span class="NLM_publisher-name">Sage</span>, pp. <span class="NLM_fpage">20</span>–<span class="NLM_lpage">29</span>.</li>
<li>Kitchin, R (<span class="NLM_year">2013</span>) <span class="NLM_article-title">Big data and human geography: Opportunities, challenges and risks</span>. Dialogues in Human Geography 3(3): <span class="NLM_fpage">262</span>–<span class="NLM_lpage">267</span>.</li>
<li>Kitchin, R (<span class="NLM_year">2014</span>) <span class="NLM_article-title">The real-time city? Big data and smart urbanism</span>. GeoJournal 79: <span class="NLM_fpage">1</span>–<span class="NLM_lpage">14</span>.</li>
<li>Kuhn, T (<span class="NLM_year">1962</span>) The Structure of Scientific Revolutions, <span class="NLM_publisher-loc">Chicago</span>: <span class="NLM_publisher-name">University of Chicago Press</span>.</li>
<li>Laney D (2001) 3D data management: Controlling data volume, velocity and variety. Meta group. Available at: <a class="ext-link" href="http://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf">http://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf</a>
(accessed 16 January 2013).</li>
<li>Lazer, D, Pentland, A, Adamic, L (<span class="NLM_year">2009</span>) <span class="NLM_article-title">Computational social science</span>. Science 323: <span class="NLM_fpage">721</span>–<span class="NLM_lpage">733</span>.</li>
<li>Lehning M, Dawes N, Bavay M. et al. (2009) Instrumenting the earth: Next-generation sensor networks and environmental science. In: Hey T, Tansley S and Tolle K (eds) <em>The Fourth Paradigm: Data-Intensive Scientific Discovery</em>. Redmond: Microsoft Research, pp. 45–51.</li>
<li>Lehrer J (2010) A physicist solves the city. <em>New York Times</em>, 17 December. Available at: <a class="ext-link" href="http://www.nytimes.com/2010/12/19/magazine/19Urban_West-t.html">http://www.nytimes.com/2010/12/19/magazine/19Urban_West-t.html</a>
(accessed 23 December 2013).</li>
<li>Leonelli, S (<span class="NLM_year">2012</span>) <span class="NLM_article-title">Introduction: Making sense of data-driven research in the biological and biomedical sciences</span>. Studies in History and Philosophy of Biological and Biomedical Sciences 43(1): <span class="NLM_fpage">1</span>–<span class="NLM_lpage">3</span>.</li>
<li>Loukides M (2010) What is data science? <em>O’Reilly Radar</em>, 2 June 2010. Available at: <a class="ext-link" href="http://radar.oreilly.com/2010/06/what-is-data-science.html">http://radar.oreilly.com/2010/06/what-is-data-science.html</a>
(accessed 28 January 2013).</li>
<li>Manovich L (2011) Trending: The promises and the challenges of big social data. Available at: <a class="ext-link" href="http://www.manovich.net/DOCS/Manovich_trending_paper.pdf">http://www.manovich.net/DOCS/Manovich_trending_paper.pdf</a>
(accessed 9 November 2012).</li>
<li>Marche S (2012) Literature is not data: Against digital humanities. <em>Los Angeles Review of Books</em>, 28 October 2012. Available at: <a class="ext-link" href="http://lareviewofbooks.org/article.php?id=1040&amp;fulltext=1">http://lareviewofbooks.org/article.php?id=1040&amp;fulltext=1</a>
(accessed 4 April 2013).</li>
<li>Marz, N, Warren, J. MEAP (<span class="NLM_year">2012</span>) Big Data: Principles and Best Practices of Scalable Realtime Data Systems, <span class="NLM_publisher-loc">Westhampton</span>: <span class="NLM_publisher-name">Manning</span>.</li>
<li>Mayer-Schonberger, V, Cukier, K (<span class="NLM_year">2013</span>) Big Data: A Revolution that Will Change How We Live, Work and Think, <span class="NLM_publisher-loc">London</span>: <span class="NLM_publisher-name">John Murray</span>.</li>
<li>Miller, HJ (<span class="NLM_year">2010</span>) <span class="NLM_article-title">The data avalanche is here. Shouldn’t we be digging?</span> Journal of Regional Science 50(1): <span class="NLM_fpage">181</span>–<span class="NLM_lpage">201</span>.</li>
<li>Moretti, F (<span class="NLM_year">2005</span>) Graphs, Maps, Trees: Abstract Models for a Literary History, <span class="NLM_publisher-loc">London</span>: <span class="NLM_publisher-name">Verso</span>.</li>
<li>Open Data Center Alliance (2012) <em>Big Data Consumer Guide</em>. Open Data Center Alliance. Available at: <a class="ext-link" href="http://www.opendatacenteralliance.org/docs/Big_Data_Consumer_Guide_Rev1.0.pdf">http://www.opendatacenteralliance.org/docs/Big_Data_Consumer_Guide_Rev1.0.pdf</a>
(accessed 11 February 2013).</li>
<li>Pentland A (2012) Reinventing society in the wake of big data. <em>Edge</em>, 30 August 2012. Available at: <a class="ext-link" href="http://www.edge.org/conversation/reinventing-society-in-the-wake-of-big-data">http://www.edge.org/conversation/reinventing-society-in-the-wake-of-big-data</a>
(accessed 28 January 2013).</li>
<li>Porway J (2013) You can’t just hack your way to social change. <em>Harvard Business Review Blog</em>, 7 March 2013. Available at: <a class="ext-link" href="http://blogs.hbr.org/cs/2013/03/you_cant_just_hack_your_way_to.html">http://blogs.hbr.org/cs/2013/03/you_cant_just_hack_your_way_to.html</a>
(accessed 9 March 2013).</li>
<li>Prensky M (2009) H. sapiens digital: From digital immigrants and digital natives to digital wisdom. <em>Innovate</em> 5(3). Available at: <a class="ext-link" href="http://www.innovateonline.info/index.php?view=article&amp;id=705">http://www.innovateonline.info/index.php?view=article&amp;id=705</a>
(accessed 12 October 2012).</li>
<li>Ramsay, S (<span class="NLM_year">2010</span>) Reading Machines: Towards an Algorithmic Criticism, <span class="NLM_publisher-loc">Champaign</span>: <span class="NLM_publisher-name">University of Illinois Press</span>.</li>
<li>Ribes, D, Jackson, SJ (<span class="NLM_year">2013</span>) <span class="NLM_article-title">Data bite man: The work of sustaining long-term study</span>. In: Gitelman, L (ed) ‘Raw Data’ is an Oxymoron, <span class="NLM_publisher-loc">Cambridge, MA</span>: <span class="NLM_publisher-name">MIT Press</span>, pp. <span class="NLM_fpage">147</span>–<span class="NLM_lpage">166</span>.</li>
<li>Rogers S (2013) Twitter's languages of New York mapped. <em>The Guardian</em>, 21 February 2013. Available at: <a class="ext-link" href="http://www.guardian.co.uk/news/datablog/interactive/2013/feb/21/twitter-languages-new-york-mapped">http://www.guardian.co.uk/news/datablog/interactive/2013/feb/21/twitter-languages-new-york-mapped</a> (accessed 3 April 2013).</li>
<li>Rose, G (<span class="NLM_year">1997</span>) <span class="NLM_article-title">Situating knowledges: Positionality, reflexivities and other tactics</span>. Progress in Human Geography 21(3): <span class="NLM_fpage">305</span>–<span class="NLM_lpage">320</span>.</li>
<li>Ruppert, E (<span class="NLM_year">2013</span>) <span class="NLM_article-title">Rethinking empirical social sciences</span>. Dialogues in Human Geography 3(3): <span class="NLM_fpage">268</span>–<span class="NLM_lpage">273</span>.</li>
<li>Schnapp J and Presner P (2009) Digital Humanities Manifesto 2.0. Available at: <a class="ext-link" href="http://www.humanitiesblast.com/manifesto/Manifesto_V2.pdf">http://www.humanitiesblast.com/manifesto/Manifesto_V2.pdf</a>
(accessed 13 March 2013).</li>
<li>Seni, G, Elder, J (<span class="NLM_year">2010</span>) Ensemble Methods in Data Mining: Improving Accuracy Through Combining Predictions, <span class="NLM_publisher-loc">San Rafael</span>: <span class="NLM_publisher-name">Morgan and Claypool</span>.</li>
<li>Siegel, E (<span class="NLM_year">2013</span>) Predictive Analytics, <span class="NLM_publisher-loc">Hoboken</span>: <span class="NLM_publisher-name">Wiley</span>.</li>
<li>Steadman I (2013) Big data and the death of the theorist. <em>Wired</em>, 25 January 2013. Available at: <a class="ext-link" href="http://www.wired.co.uk/news/archive/2013-01/25/big-data-end-of-theory">http://www.wired.co.uk/news/archive/2013-01/25/big-data-end-of-theory</a>
(accessed 30 January 2013).</li>
<li>Strasser, BJ (<span class="NLM_year">2012</span>) <span class="NLM_article-title">Data-driven sciences: From wonder cabinets to electronic databases</span>. Studies in History and Philosophy of Biological and Biomedical Sciences 43: <span class="NLM_fpage">85</span>–<span class="NLM_lpage">87</span>.</li>
<li>Strom D (2012) Big data makes things better. <em>Slashdot</em>, 3 August. Available at: <a class="ext-link" href="http://slashdot.org/topic/bi/big-data-makes-things-better/">http://slashdot.org/topic/bi/big-data-makes-things-better/</a>
(accessed 24 October 2013).</li>
<li>Trumpener, K (<span class="NLM_year">2009</span>) <span class="NLM_article-title">Critical response I. Paratext and genre system: A response to Franco Moretti</span>. Critical Inquiry 36(1): <span class="NLM_fpage">159</span>–<span class="NLM_lpage">171</span>.</li>
<li>Wyly E (in press) Automated (post)positivism. <em>Urban Geography</em>.</li>
<li>Zikopoulos, PC, Eaton, C, DeRoos, D (<span class="NLM_year">2012</span>) Understanding Big Data, <span class="NLM_publisher-loc">New York</span>: <span class="NLM_publisher-name">McGraw Hill</span>.</li>
</ul>
</div>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="Self-branding, ‘micro-celebrity’ and the rise of Social Media Influencers"
class="paper-story"
data-article-title="Self-branding, ‘micro-celebrity’ and the rise of Social Media Influencers"
>

<h1 class="article-title" id="h_Self-branding, ‘micro-celebrity’ and the rise of Social Media Influencers">Self-branding, ‘micro-celebrity’ and the rise of Social Media Influencers</h1>

<div class="top-meta">Susie Khamis, Lawrence Ang & Raymond Welling, 2016-02-04 00:00:00 AEST. for week 10.</div>

<p>Pages 191-208, Received 04 Feb 2016, Accepted 21 Jul 2016, Published online: 25 Aug 2016, <a href="https://doi-org.wwwproxy1.library.unsw.edu.au/10.1080/19392397.2016.1218292">Download citation</a></p>
<h2>ABSTRACT</h2>
<p>The notion of self-branding has drawn myriad academic responses over the last decade. First popularised in a provocative piece published in <em>Fast Company</em>, self-branding has been criticised by some on theoretical, practical and ethical grounds, while others have endorsed and propelled the idea. This article considers how and why the concept of self-branding has become so prevalent. We contend that it parallels the growth of digital technology (particularly social media) embedded in the current political climate: neoliberal individualism. Another objective here is to imbue the concept of self-branding with a marketing perspective and show how the ‘celebrities’ of self-branding manifest at a marketing media nexus distinct to the opening decades of the twenty-first century. Building on literature from mostly media and cultural studies, this critique sees self-branding as a distortion of key branding principles that has obvious implications for its practitioners and advocates. The article shows that, despite inherent tensions and problematic ironies, self-branding persists through the rise of Social Media Influencers; we consider three of these whose fame and following was achieved via the practices and phenomena under consideration.</p>
<h2>Introduction</h2>
<p>Self-branding, which is sometimes called personal branding, involves individuals developing a distinctive public image for commercial gain and/or cultural capital. The number of books, websites, workshops and seminars devoted to its principles and promotion is evidence of its prevalence and appeal (Khedher 2014, p. 30). Central to self-branding is the idea that, just like commercially branded products, individuals benefit from having a unique selling point, or a public identity that is singularly charismatic and responsive to the needs and interests of target audiences. This idea has permeated business literature since at least the 1920s, with best-selling titles that extol the merits of self-improvement and a positive attitude, but its broader resonance over the last 20 years is significant. In terms of pushing the idea of self-branding from the margins of marketing literature to the forefront of mainstream media, a 1997 article published in the business magazine <em>Fast Company</em> bears noting. In the article ‘The Brand Called You’, Tom Peters argues that individuals must assume control of their own brand identity to stand out in the labour market, project a dynamic and memorable image, and consistently deliver value to consumers, employers and markets. Grafting the logic of branding onto individuals is not only possible or desirable, he argues; it is imperative and inevitable.</p>
<p>Lest individuals surrender their brand identities to others, for lack of initiative, interest or strategy, Peters believes that self-branding requires the same dedication and drive that saw the likes of Nike and Starbucks achieve prominence and loyalty. He writes: ‘We are CEOs of our own companies: Me Inc. To be in business today, our most important job is to be head marketer of the brand called You’ (Peters 1997). Peters thus encourages individuals to turn their résumé into a ‘marketing brochure’ full of ‘braggables’ for which they want to be famous (the term he uses): ‘being CEO of Me Inc. requires you to act selfishly – to grow yourself, to promote yourself, to get the market to reward yourself’ (Peters 1997). His message captured popular audiences with its clarity, simplicity and conviction; and, as argued shortly, its seamless consonance with the reigning tenets of a neoliberal ideology.</p>
<h2>A problematic concept and practice</h2>
<p>Branding is inextricably tied to marketing; however, the concept of self-branding does not fit neatly as a subset of branding, and scaling the branding concept down to the individual is problematic. Branding an individual raises conceptual, practical and ethical issues, which are either not acknowledged or are simply glossed over by its advocates. Moreover, there is an implicit assumption that everyone is expected to self-brand in order to realise his or her fullest potential. There is even a call for academics to build a personal brand in order to help sell their university online (Brandabur 2012), while one researcher has developed (albeit facetiously) the ‘Kardashian Index’ to measure the popularity of scientists by their number of followers on Twitter (Hall 2014).</p>
<p>The word ‘brand’ is derived from the Old Norse word <em>brandr</em>, meaning ‘to burn’, and referred to the practice whereby livestock owners would burn a unique and differentiating symbol into their animals’ skins. In its contemporary use for marketing, a brand signifies a certain quality or idea associated with a commodity which ostensibly simplifies the consumer’s decision-making. Ideally, a brand must be seen to possess strong, favourable, unique and relevant mental associations (Keller 2007), which helps differentiate the brand in an otherwise crowded and cacophonous market. Another function of branding is to imbue the product, service or firm with a personality. Presumably, personality dimensions such as ruggedness, sophistication, sincerity, excitement and competence (Aaker 1997) give a product, service or firm a human-like quality and thus make it more relatable. The brand’s usefulness therefore rests on the promise of consistency, which mitigates risks for the consumer. That is, one can more or less know what to expect when they commit to a reputable brand: the Starbucks ‘experience’ varies little from Sydney to New York to Shanghai, and this holds more or less true for Nike, Apple, Coke and so on. The brand’s consistency thus encourages repeat purchases (over space and time) and, most importantly, brand loyalty.</p>
<p>Herein lays the obvious problem when the concept of branding is applied to a person: consistency is notoriously difficult to sustain. One needs only to consider the numerous examples of celebrities caught doing or saying something that undermines the brands with which they are affiliated. For example, when news broke of Tiger Woods’ extramarital infidelities in late 2009, several sponsors suspended their contracts with him almost immediately, including Accenture, AT&amp;T, Gatorade, General Motors, Gillette and TAG Heuer. Their message was clear: Woods no longer embodied the brand attributes that they hoped to secure through his endorsement, and falls in their market value confirm that there was subsequent material loss (Knittel and Stango 2014). This is the risk every brand takes when a celebrity has been engaged for promotion: the celebrity must maintain at least a charade of consistently desirable, aspirational attributes – a quest bedevilled by not just the paparazzi industry, but also the average passer-by who can instantly capture every indiscretion on his or her smartphone. Of course, it is not just celebrities who go ‘off message’. Political leaders suffer a similar fate when they deviate from policies and are then punished by voters for having abandoned their promises. The point is that consistency requires vigilance, authenticity and the absence of unexpected hurdles that would require amendments or negotiation, all of which are extremely difficult for humans to ensure.</p>
<p>Despite these issues, the concept of self-branding continues to be both popular and influential. However apart from the issue of maintaining consistency (and hence authenticity), the ‘ordinary’ person wanting to be famous faces another major hurdle: how to build and cultivate a large target audience. To make sense of this, we need to consider the interplay between marketing, media and celebrity.</p>
<h2>Audience size and celebrity: where does the opportunity lie?</h2>
<p>Marketing and media are mutually dependent. Media relies on advertising revenue for commercial viability, while advertisers have traditionally relied on media to address the audience (their potential consumers). To deliver an audience, media organisations create interesting, engaging content; this is their primary objective. One type of content that has been broadly popular with audiences is celebrity.</p>
<p>There is an obvious marketing relationship between a brand, media, audience and celebrity. At a basic level, the brand represents the identity of a commodity (a product, service or firm), and its main function is to convey a certain level of quality. But to reach the target audience (at an optimal frequency) with its message, the brand owners (or advertisers) have to pay media organisations for the advertising. When a celebrity, or a human brand, is introduced into the picture, the dynamics change slightly. A human brand is defined here as ‘any well-known persona who is the subject of marketing communications efforts’ (Thomson 2006, p. 104). The biggest change is that the human brand can now bring his or her own audience into the equation. Of course, the human brand can still rely on traditional media to deliver the audience. But celebrities with a following can also use their own media (e.g. websites, blogs, Facebook, Twitter and Instagram) to influence this audience (e.g. the Kardashians). Eventually, with consistent juxtaposition, the human brand can become synonymous with the brand and hence with the product, service or firm. This suggests that self-branding makes most sense if celebrities can lend their names profitably to major brands. Sports stars, for instance, can earn many times more from their endorsement fees than from prize money. This is because major sporting events command a large audience. This provides the endorsed brand with massive exposure, and if the sports star also wins major tournaments, the ‘halo effect’ will flow onto the endorsed brand. While not all celebrities have an equal amount of marketing pull, the more successful have talent and personal agents to help convert their fame into lucrative endorsement deals.</p>
<p>Our interest here is in fame-seekers who lack both a strong public identity and the resources to self-promote on the scale of an established celebrity. What would they do? The opportunity may lie in social media (and/or reality television) to help build a strong fan base, sizable enough to interest advertisers. In other words, through social media, reality television and strategies of ‘micro-celebrity’ (discussed shortly), a modicum of even transient fame can still be achieved. However, given the challenges already discussed (lack of consistency and the challenge of building a sizable target audience), we now return to our original question of why self-branding has continued to grow in popularity. We contend that there are three main reasons for the rise of self-branding:</p>
<ol>
<li>
<p>Social media tacitly promises fame (and subsequent wealth) to ‘ordinary’ users and thus encourages practices of micro-celebrity.</p>
</li>
<li>
<p>Within a political culture of neoliberal individualism, self-branding is encouraged with the promise of reward.</p>
</li>
<li>
<p>The commercial viability of some Social Media Influencers (SMIs; to be discussed shortly), whose success depends on self-branding and practices of micro-celebrity, has proven to be both inspirational and seemingly replicable.</p>
</li>
</ol>
<p>Our contention is that the increased ease of projecting one’s image through social media coupled with the rise of individualism has made the notion of self-branding more popular. This in turn creates the illusion – often exemplified by the success of reality television stars – that anyone can be famous and hence become ostensibly successful.</p>
<h2>Social media and the practices of micro-celebrity</h2>
<p>Peters (1997) did not attribute the importance of self-branding exclusively to the Internet, but his central message has certainly been amplified and extended by others who see in the digital age a heightened need for the practices and mind-set that Peters encourages. At the very least, the (mostly) open platform of online media makes it highly amenable to the strategic and targeted packaging of users’ identities, insofar as content production and distribution becomes a seemingly egalitarian affair. As Labrecque <em>et al.</em> argue:</p>
<blockquote>
<p>No longer does a person need to be familiar with complex coding languages or other technicalities to build Web sites, because virtually anyone can upload text, pictures and video instantly to a site from a personal computer or phone. With technological barriers crumbling and its increasing ubiquity, the Web has become the perfect platform for personal branding. (2011, p. 38)</p>
</blockquote>
<p>Online media is, moreover, an exceedingly consumer-centric space, because individuals actively and autonomously seek out the resources they are most interested in – and therein lies the ‘need’ for self-branding. In an environment and era of media surplus, where audiences are saturated with so much to choose from, the premium on distinctiveness and visibility grows. For this reason, marketing personnel began to speak more of the ‘attention economy’ (Brody 2001, p. 20), wherein an unprecedented number of communicators compete across more screens for increasingly distracted, dispersed and privatised audiences. According to Fairchild, ‘Regardless of its sociological vacuity or validity, the attention economy is by now an established reality for advertisers. It has inspired new thinking about how to create lasting, flexible, and evolving relationships with consumers’ (2007, p. 359). With this in mind, and as Shepherd notes, self-branding is ‘essentially an attention-getting device, and is frequently sold as the key to helping the aspiring professional to achieve competitive advantage in a crowded marketplace’ (2005, p. 597).</p>
<p>By enabling ordinary users to assert strong identities that can underpin and animate high public profiles, self-branding makes fame and/or celebrity more attainable – indeed, this is often the <em>raison d’être</em> for self-branding practices since they are designed for maximising prominence, recognition and loyalty. While it is not pertinent here to detail the machinations by which fame and/or celebrity was achieved before the digital age, it suffices to note that, at the very least, it was a relatively rare experience generally enjoyed by those who had achieved something remarkable (like elite sportspeople, politicians and innovators), were hugely popular in the culture industries (such as cinema or music) or were born into the privileged echelons of society (like royalty or the extremely wealthy). Furthermore, such individuals usually had at least two things in common: they could attract attention easily; and, depending on the basis of their fame, each embodied a narrative of sorts.</p>
<p>From the early 2000s, self-branding was practised not just by those for whom a strong public image was expected (such as sportspeople, professional musicians and such) but also by ‘ordinary’ people who had shrewdly gauged the marketing possibilities of contemporary convergent technologies, particularly social media. Whilst it was possible to establish a strong online identity through personal blogs and websites, platforms such as Facebook, YouTube, Twitter and Instagram accelerate and accentuate the means by which users can package, perform and sell a lucrative personal brand across several online sites. In turn, the shift towards media convergence, as content flows across multiple channels with diverse access points accordingly, seemingly aids the (self-)branding process inasmuch as the narrative, the emotive and/or ‘human’ pull of an effective brand (Herskovitz and Crystal 2010, p. 21) is sustained more widely, and hence strengthens the bond between the brand and the audience (Granitz and Forman 2015, p. 5).</p>
<p>In this way, self-branding could benefit from the ‘context collapse’ of social media activity – that is, what Vitak terms ‘the flattening out of multiple distinct audiences in one’s social network, such that people from different contexts become part of a singular group of message recipients’ (2012, p. 451). This has several consequences. First, ‘context collapse’ problematically inhibits the practices of selective self-presentation that Goffman (1959) described: the idea that individuals modify ‘performance’ (or the ‘presentation of self’) according to different audiences and expectations. Occasionally, social media users circumvent this through various tactics, such as decoy profiles, privacy settings or minimal disclosure of personal information (Marwick 2013b, p. 360). Second, however, for self-branding purposes, to further visibility and salience, ‘context collapse’ can be viewed as a promotional boon. To this end, a distinction provided by Davis and Jurgenson is useful: they differentiate between context collusion and context collision; both represent context collapse but only the former is intentional. That is, context collision occurs when ‘different social environments unintentionally and unexpectedly come crashing into each other’, while collusion is ‘the process whereby social actors intentionally collapse, blur and flatten contexts, especially using various social media’ (Davis and Jurgenson 2014, p. 480). Viewed thus, context collusion speaks to the audience reach enabled by the exhilarating diversity of multiple social media platforms, and the efficient crafting of messages to address this <em>‘en masse’</em>.</p>
<p>Self-branding through social media pivots on attention and narrative, yet significantly extends the potential for fame and celebrity. Compelling narratives potentially attract audiences for a multitude of reasons – they could be inspirational, relatable, instructive, cautionary and so on. What matters is that they find a following through social media and thus stand out in the attention economy. Moreover, through trans-media narratives, the hallmarks of all effective branding are theoretically sustained (consistency, distinctiveness and value) and the brand is consolidated as audiences/followers/fans embed it within their own individualised media flows through likes, shares and comments. This collaborative, dialogic space facilitates self-branding as attention-seeking users produce a public persona that is targeted and strategic. As such, and as Page argues, there is ‘particular emphasis on the construction of identity as a product to be consumed by others, and on interaction which treats the audience as an aggregated fan base to be developed and maintained in order to achieve social or economic benefit’ (2012, p. 182).</p>
<p>Social media is driven by a specific kind of identity construction – self-mediation – and what users post, share and like effectively creates a highly curated and often abridged snapshot of how they want to be seen. Self-mediation was clearly possible before the Internet era; for example, diaries preceded blogs, photo albums preceded Instagram, and hardcopy scrapbooks preceded Facebook (Good 2012, p. 569). The main difference with personal archives on social media, however, is how convergent technologies provide a platform for global, interactive and commercial communication, on a scale and at a speed hitherto not possible except for privileged elites. Since it is designed for public consumption rather than personal reflection, the branded self not only plays to postmodern notions of identity, with an emphasis on construction, style and fluidity; it also and necessarily claims distinctiveness (Berger 2011, p. 235).</p>
<p>Social media both accommodates ordinary users with distinctive stories and/or content, and furnishes them with highly visible metrics of popularity and endorsement. These metrics are inextricably tied to self-branding: a following can evolve into a fan base and in this way ‘ordinary’ users find online fame. Keeping in mind the importance of visibility and attention, the pursuit of this recognition entails practices of ‘micro-celebrity’: the concerted and strategic cultivation of an audience through social media with a view to attaining celebrity status.</p>
<p>Theresa M. Senft first coined the term ‘micro-celebrity’ in 2001 during her research on how ‘camgirls’ used conditions afforded by online tools to forge a then-new style of performance. This entailed ‘people “amping up” their popularity over the web using technologies like video, blogs and social networking sites’ (Senft 2008, p. 25). While this popularity required micro-celebrities to sustain a relationship with their audience that seemed more ‘real’ than the conventional one between mainstream media stars and fans, there was at least one important similarity: ‘both must brand or die’ (2008, p. 26). Whilst Senft’s research chronicled the relatively early adopters of such strategies, within a few years both the concept and its practices had become a pervasive cultural phenomenon, such that, as Marwick and boyd point out, micro-celebrity ‘implies that all individuals have an audience that they can strategically maintain through ongoing communication and interaction’ (2010, p. 121). Again, success here is registered through the number of likes, shares, retweets, followers and comments that one can boast – albeit superficially, the bigger the audience, the stronger the brand. This phenomenon is fuelled by at least three interrelated forces: the extent to which social media proceeds without the gamut of gatekeepers that otherwise determines and limits content flows; audiences increasingly predisposed to ‘ordinary’ people in the spotlight; and a cultural economy that contours almost everything (including conceptions of the self) along consumerist lines. The ‘celebrities’ of self-branding thus manifest and triumph at a marketing media nexus distinct to the opening decades of the twenty-first century.</p>
<h2>The ‘demotic turn’</h2>
<p>As ‘ordinary’ people seek and find fame through practices of micro-celebrity, they redistribute cultural power in both media and marketing: implicitly, micro-celebrity points to the growing agency, enterprise and business acumen of everyday media users. However, while social media in particular places users in a command position insofar as self-branding is enabled and encouraged, it bears stressing that this seemingly egalitarian shift in media did not originate online. Rather, it surfaced most notably in the early 1990s with the popularity of reality television and that genre’s reliance on ‘factuality’ for entertainment. Global hits such as <em>Big Brother</em> (1999–), the <em>American Idol</em> (2002–2016) franchise, <em>Survivor</em> (1992–) and <em>Masterchef</em> (1990–2001; 2005–present) turned ‘ordinary’ participants into primetime stars, moving them from the peripheries of cultural life (the ‘non-media’ margins) to its centre: celebrity (Couldry 2002, p. 289). Turner (2006) calls this seminal change in media the ‘demotic turn’, with the growing visibility of the ordinary person across media generally, and certain genres especially: reality television (e.g. <em>Big Brother</em>), confessional talk shows (e.g. <em>Jerry Springer</em> [1991–]), docu-soaps (e.g. <em>Sylvania Waters</em> [1992]) and reality-based game shows – all of which depended on ordinary people wanting fame. Using Rojek’s term ‘celetoid’ to describe the ‘ordinary’ person whose primary goal is media visibility (or fame), no matter how fleeting or fragile, Turner writes:</p>
<blockquote>
<p>Given what appears to be our culture’s appetite for consuming celebrity and the scale of the demand for new stories, gossip and pictures the celebrity-media industries generate, the accelerated commodity life cycle of the celetoid has emerged as an effective industrial solution to the problem of satisfying demand. (2006, p. 156)</p>
</blockquote>
<p>For Turner, the demotic turn validates the celetoid commercially inasmuch as he/she experiences celebrity not despite their ordinariness, but because of it, since it is a precondition for eligibility.</p>
<p>Importantly, Turner saw in the demotic turn – this spotlight on the ‘ordinary’ – its production-side appeal. He writes:</p>
<blockquote>
<p>Installing ordinary people into game shows, docu-soaps and reality TV programming enables television to ‘grow their own’ celebrity, to control how they are marketed before, during and after production – all of this while still subordinating the celebrity of each individual to the needs of the particular programme or format. (Turner 2006, p. 156)</p>
</blockquote>
<p>Reality television seemingly welcomes ‘ordinary’ participants into the mediasphere, and baits them with the high likelihood of fame, celebrity or, at the very least, mass exposure. However, this is conditional on their fit with the product at hand and its commercial imperatives as participants are embedded into a given programme and repurposed across its media with implicit marketing goals in mind. For instance, in 2009 the inaugural winner of <em>Masterchef</em> Australia (2009–) Julie Goodwin was the archetypal relatable mum whose ‘ordinariness’ served the show on several fronts. Her ‘back to basics’ style – in cooking, demeanour and looks – was easily woven into the <em>Masterchef</em> model, with its emphasis on contestants’ personalities, backstories and ‘journeys’; in turn, her win was a fitting tribute to the <em>Masterchef</em> brand and its associated merchandising (Khamis 2013). Considering its commercial aims, being the first Australian television show to break the $100 million advertising revenue mark (Hargreaves 2010, p. 90), it was crucial that the <em>Masterchef</em> winner complemented the show’s wide suite of sponsors, which included grocery giant Coles, Western Star butter and Campbell’s Real Stock. Given <em>Masterchef</em>’s target demographic, the cultural middle ground and ‘everyday’ cooks, Goodwin’s persona (an endearing and accessible suburban mum) worked well for its brand.</p>
<h2>The rise of ‘instafame’</h2>
<p>The demotic turn that Turner refers to is extended on social media. Users need not be folded into an existing narrative structure (such as <em>Masterchef</em>) and can instead fashion their own autonomously authored brand. In this way, self-branding ostensibly frees practitioners from the top-down dynamic that ultimately characterises reality television, despite whatever democracy it suggests. Micro-celebrity is predicated on this, and takes for granted users’ ability to muster a following and fan base independent of the resources and dictates of legacy media (the big-name bastions of television, print and radio); online, self-branding is a decidedly individualised process. While the goal might be to eventually link up with advertisers and parlay an online profile towards a broader public presence, self-branding through social media does not require initial affiliation with the ‘already powerful’. Rather, and to reiterate, what matters most is visibility and attention – and therein lays the critical importance of self-branding strategies and practices of micro-celebrity.</p>
<p>The scale of potential audience reach for ‘ordinary’ people through social media is such that popularity and prominence no longer rest on the go-ahead from traditional gatekeepers (editors, producers, etc.). As Marwick notes, for instance: ‘With Instagram’s user base of 150 million comes the possibility of achieving <em>Instafame</em>, the condition of having a relatively great number of followers on the app’ (2015, p. 137; original emphasis). While Marwick concedes that the most followed users of Instagram remain celebrities whose fame is conferred by traditional mainstream media (such as Beyoncé, Oprah Winfrey and Kobe Bryant), she highlights how ordinary users have become ‘Instagram famous’ through what appears to be little more than streams of eye-catching ‘selfies’ (self-portraits) – for example Cayla Friesz, a photogenic and conventionally attractive high school student from Indiana whose otherwise ‘ordinary’ pictures of herself, friends, food and outings are seen by over 35,000 followers, many of whom have dedicated fan pages to her. Marwick argues: ‘Instafamous people like Friesz have the potential to reach an audience that rivals that of television networks in size, what we might call a mass audience’ (2015, p. 150).</p>
<p>Marwick’s notion of the Instafamous is easily applied across the most common social media sites, especially Facebook, YouTube and Twitter. Their popularity does not just challenge that of legacy media but increasingly eclipses it, especially among young people. For these ‘digital natives’, most media activity (production, distribution and consumption) is conducted overwhelmingly online. Not surprisingly, the fact that micro-celebrity such as that enjoyed by Friesz appears disproportionately dependent on the vanity and ego of attention-seekers fuels wider fears that social media underwrites an epidemic of self-obsession. Young people in particular appear convinced that good looks, good living and conspicuous consumption (through artfully composed images of outfits, make-up, meals, holiday resorts, etc.) warrant adoration and emulation. This emphasis on spectacle seems to have a lamentable psychodynamic consequence. According to MacDonald, for instance, social media is primarily a gateway to self-promotion and therefore is at least partly responsible (alongside changes to traditional family life and the growth of celebrity worship) for an increasingly narcissistic society. For MacDonald, the desire for social media fame prompts young people to focus on image and artifice at the expense of ‘real’ achievements of depth and substance, which in turn warps perceptions of actual accomplishment – that is, it can be articulated through a false and materialistic grandiosity (2014, p. 147).</p>
<p>This article is not interested in how narcissism functions in (or is a product of) self-branding through social media; it will suffice to note that, in the packaging of image for commercial and/or cultural gain, it makes sense that users enhance what they consider their most appealing or lucrative aspects, and underplay those that do not further their branding objectives. What is more pertinent here is the widespread willingness of fame-seekers to be submitted to personalised scrutiny in the media. For P. David Marshall, this marks a specific historic moment: ‘the ubiquity of the exposed public self’ whereby ‘the individual is more than invited to participate in a world of general exposure and learns to inhabit the risks that such a world entails’ (2016, p. 235). Moreover, this openness to ‘exposure’ can be rationalised in terms of how the ‘attention economy’ expects from everyone what was once associated with celebrities: ‘The recognition culture that operates as a form of economic value in this wider culture industry is similarly the model through which the populace begins to calibrate their own value’ (2016, p. 507). As such, the normalisation of these practices speaks to the dissolution of any social demarcation between celebrities and ordinary people. As Gamson notes:</p>
<blockquote>
<p>The ordinary turn in celebrity culture is ultimately part of a heightened consciousness of everyday life as a public performance – an increased expectation that we are being watched, a growing willingness to offer up private parts of the self to watchers known and unknown, and a hovering sense that perhaps the unwatched life is invalid or insufficient. (2011, p. 1068)</p>
</blockquote>
<p>This last provocative point – that ‘perhaps the unwatched life is invalid or insufficient’ – merits further discussion. Obviously it points to the philosophical and existential questions at play, but this is beyond the thematic breadth of this discussion. The focus turns instead to the political economy behind Gamson’s claim, specifically: how self-branding through social media and the attendant logic of micro-celebrity marks the extension of a consumerist ideology and orientation to practically every area of contemporary cultural life, and the totalising rise of largely neoliberal values, ideals and assumptions.</p>
<h2>The political economy of self-branding</h2>
<p>Self-branding operates through principles and practices distinct to the ‘promotional culture’ (Wernick 1992) of advanced consumer capitalism. It shows how private individuals have internalised ideas that were designed for the marketing of commodities, and thus represents a seminal turning point in how subjectivity itself is understood and articulated. There is a historical logic to this: global capitalism coupled with the communication technologies of social media has wrought significant cultural, economic and political upheaval, and the concept of self-branding manifests as an apposite navigational strategy for otherwise vulnerable, overwhelmed individuals. As such, self-branding through social media can be understood as a way to retain and assert personal agency and control within a general context of uncertainty and flux. Therefore, it harmonises with neoliberal notions of individual efficacy and responsibility; and rests on capitalist faith in enterprising, resourceful and self-directed labour. Within the twenty-first-century context of intense media activity and competition, the emphasis on the atomised, distinctive self is framed as an affirmation of control and conviction. In this schema, just to be noticed is a victory of sorts. As Senft makes clear, whatever ‘immaterial labor’ (in the Marxian sense) is required to assert the branded self through social media is ‘almost always cast in narratives of empowerment’ (2013, p. 350) – which effectively celebrates those who triumph in the ‘attention economy’.</p>
<p>Self-branding explicitly invokes labour to be malleably responsive to dynamic market conditions. It calls for what Duffy and Hund term ‘creative self-enterprise’ (2015, p. 1) and sits easily within dominant discourses of creative economies, cities and precincts (Florida 2003). Here, cultural entrepreneurs (rather than ‘labourers’) assume both the risks and rewards of economic opportunities and constitute a ‘creative class’ that is, argue Banet-Weiser and Sturken, ‘comprised not only of professionals who are paid for their creative labor but also of “creative amateurs”, encouraged to be “empowered” by the flexibility and openness of new technological formats and expanded markets’ (2010, p. 272). In turn, and as Chen notes, ‘For amateur individuals in social media, personal branding becomes a very important business concept because it demonstrates self-performances and presents a sense of individuality that can help to differentiate a personal brand from its competitors’ (2013, p. 334). However, the fact that this requirement to project a distinctive character is channelled through a discourse of autonomy and independence is highly disingenuous. On the one hand, platforms such as YouTube, Twitter and Facebook empower users to address audiences without the constrictive scaffolding of traditional media. Through strategically inspired image control, self-branding through social media relies on rhetoric of freedom and agency. On the other hand, however, the fact that self-branding shifts the onus of labour security to the individual and their capacity for commercial relevance sits within increasingly dominant economic realities and political priorities. Ironically, self-branding can therefore be seen less as a testament to personal control and more as a reflection of unstable and uncertain labour markets, whereby workers are expected to be as adaptive and nuanced as all branded products (from sneakers and fast-food to smartphones and furniture) in post-Ford globalised economies. As such, and as Bandinelli and Arvidsson (2012) argue, the rise of self-branding constitutes another form of neoliberal governance by compelling (or ‘empowering’) people to consider themselves entrepreneurial subjects, ultimately responsible for their own success or failure in the marketplace. Moreover, it has spawned a belief system that now infiltrates the neoliberal knowledge economy: marketing, coaches, therapists, teachers, social workers and universities, all of which promote self-branding skills as both life-changing and life-making and thus succeed in the social production of market relations (Bandinelli and Arvidsson 2012, p. 68).</p>
<p>The branded self, with subjectivity shaped by and for the market, is always working. For Hearn (drawing on Tronti), this monetisation of just being makes most sense through the concept of the ‘social factory’, which:</p>
<blockquote>
<p>describes a situation under contemporary capitalism in which work extends far beyond the temporal and spatial limits of traditional workplaces, eluding effective forms of capture and measurement, and capital’s productivity penetrates ever more deeply into all, including the most intimate, aspects of our lives. (Hearn 2011, p. 316)</p>
</blockquote>
<p>With the commodification of the self, individuals are locked into a mode of constant promotion. This surfaces spectacularly on social media sites, since these ‘produce inventories of branded selves; their logic encourages users to see themselves and others as commodity-signs to be collected and consumed in the social marketplace’ (Hearn 2008a, p. 211). Self-branding asks the individual to view relationships as transactional and instrumental, and to look to the market to gauge personal accomplishment – each social encounter effectively tests how useful (and hence valuable) the branded self is (Wee and Brooks 2010, p. 54). In this way, and as Hearn points out, self-branding ultimately exacerbates the insecurity it aims to resolve, since it relies on economic conditions that are notoriously precarious, decentralised and flexible. She writes: ‘Here, we see the “self” as a commodity for sale in the labour market, which must generate its own rhetorically persuasive packaging, its own promotional skin, within the confines of the dominant corporate imaginary’ (Hearn 2008b, p. 497). All branding requires consistency of narrative and image, yet the market – the ‘dominant corporate imaginary’ – is highly changeable (under the pretext of consumer choice and variety), and therein lays a constant and inescapable tension.</p>
<p>In its breathless appeals to self-motivation, the literature of self-branding reworks one of the most haloed motifs in US culture: the resourceful individual. With its upbeat and optimistic tone, this concept demands the successful individual to be driven and future focused, and posits naysayers and sceptics as cynical, defeatist and/or lazy. As Lair <em>et al</em>. note, the concept:</p>
<blockquote>
<p>resonates strongly with the by-your-bootstrap mythos that has historically played a central role in American culture in general and American business culture in particular, as well as with the neoliberal economic philosophy that has become so prominent for many Western governments. (2005, p. 322)</p>
</blockquote>
<p>It casts economic turmoil as a default setting for which anything other than a ‘can-do’ attitude is futile. The more <em>laissez faire</em> the economy, the more creative agility an individual needs – or to put it another way, this concept implies that it is not the economy which should be corrected or adjusted, but rather the individual. In this way, self-branding effectively absolves governments of fiscal intervention, and thus plays straight into the <em>modus operandi</em> of free-market ideologues.</p>
<h2>Recent cases of self-branding and the rise of social media influencers</h2>
<p>To consider strategies of micro-celebrity in practice, and to see the phenomena discussed thus far manifest with varying consequences, three recent examples are highly pertinent. These examples illustrate a particular kind of online micro-celebrity: the SMI. As Hearn and Schoenhoff explain: ‘The SMI works to generate a form of “celebrity” capital by cultivating as much attention as possible and crafting an authentic “personal brand” via social networks, which can subsequently be used by companies and advertisers for consumer outreach’ (2016, p. 194). SMIs determine their success in terms of return on influence as marketers seek them out to capitalise on their wide social networks and benefit from the intimate, more ‘trustworthy’ relationships SMIs have ostensibly created (2016, p. 203, Gormley 2016).</p>
<p>In 2015, two Australian food bloggers made headlines for very different but not entirely unrelated reasons. In February, Jess Anscough – better known to her fans as the Wellness Warrior – died from a rare form of cancer, epithelioid sarcoma, at the age of 30. Anscough, who had been diagnosed seven years earlier, and had lost her mother Sharyn to breast cancer in 2013, found social media fame by eschewing conventional cancer treatment and instead advocating the controversial Gerson Therapy (Corderoy 2015). Developed in the 1930s, Gerson Therapy claims to cure cancer and other degenerative diseases through diet, which for Anscough entailed huge amounts of fruit and vegetables and up to six daily coffee enemas. In April, 23-year-old Belle Gibson, who found social media fame by claiming to have cured her terminal brain cancer through diet and lifestyle alone, revealed that she had lied about having cancer (Davey 2015, Phillip 2015). By the time her hoax was exposed, Gibson’s empire, under the name ‘The Whole Pantry’, had grown from a blog to a widely publicised phone app and a book deal. This article is not concerned so much with the ire, scepticism or pity these women generated in their eager embrace of ‘wellness’ strategies that were obviously contentious: their fame rested on their rejection of conventional medicine and science. Instead, it is argued here that, by strategically embedding compelling narratives within their respective online personas, both Anscough and Gibson show how contemporary social media enables and powers online celebrity, whereby ‘ordinary’ users cultivate fame and influence that can be then leveraged more widely.</p>
<p>Through stories that were inspirational, accessible and consistent with burgeoning mainstream interest in ‘wellness’, the process of making active choices towards a healthy and fulfilling life, Anscough and Gibson attracted fan bases, media attention and cultural traction. Both had also traded on one of the most import facets of micro-celebrity: a promise of ‘authenticity’. Micro-celebrity is a mind-set and a set of practices that courts attention through insights into its practitioners’ private lives, and a sense of realness that renders their narratives, their branding, both accessible and intimate. That is, writes Marwick, they ‘know their fans, respond to them, and often feel an obligation to continue this interaction to boost their popularity, breaking down the traditional audience/performer spectator/spectacle dichotomy’ (2016, p. 345). This requires an ‘always on’ work mode, with the constant vigilance and monitoring of this ‘authentic’ self that is paradoxically both edited (since it is outward-looking) and ‘real’. Such ‘emotional labour’ can have adverse consequences, requiring, as Marwick writes, ‘a thick skin, and an ongoing awareness of the audience’ (2013a, p. 196). At the same time, however, the perception of authenticity creates a space that is readily exploitable, insofar as SMIs can parlay the trust they inspire into myriad commercial arrangements. Indeed, as Abidin argues, the sense of closeness that SMIs contrive is central to their material success, since their allure ‘is premised on the ways they engage with their followers to give the impression of exclusive, “intimate” exchange’, and followers ‘are privy to what appears to be genuine, raw and usually inaccessible aspects of influencers’ personal lives’ (Abidin 2015). This perceived authenticity was at work in the online profiles of both Anscough and Gibson.</p>
<p>Crucially, both women crafted an online presence that effectively monetised their personal image: through self-branding, their ‘authentic’ public identities were commodified. In this way, both showed the ironic inversion of authenticity as it manifests through self-branding. As Banet-Weiser puts it, the traditional notion of authenticity is one based on ‘intrinsic motivation, which values uniqueness, original expression, and independence from the market’; in the schema of micro-celebrity, however, ‘it is about external gratification’ (2012, p. 80), its recognition and reward determined by others. Once their celebrity was secured in the blogosphere, Anscough and Gibson went on to make television appearances, magazine interviews, speaking engagements and more. They had shrewdly appraised the marketing value of their attention-getting, authentic-seeming brands, and found wide popularity as two of Australia’s most well-known SMIs.</p>
<p>Since these women had so convincingly converted ‘Internet fame’ into ‘proper’ fame, there was intense interest (and scrutiny) when Anscough succumbed to her cancer and Gibson was shown to have lied. Despite the scale of criticism and anger levelled at both Anscough and Gibson for what many deemed a dangerously tenuous grasp of nutritional science, it is clear that – until early 2015 – both had successfully contrived attractive and lucrative careers through social media. In their advocacy of a nebulously holistic understanding of personal well-being, with a diet-based approach to health and nutrition, both exploited growing popular interest in food education, which is being increasingly sought online. Moreover, there are numerous examples of other bloggers who have successfully created high media profiles by promoting similarly construed ideas. Given just how quick and low-cost online nutrition information is, this is hardly surprising: around 80% of all Internet users aged 18–46 go online for health information, and the majority of these are women (Lohse 2013, p. 69). Because of the potential reach of such information, professional nutritionists have called for ‘best practice’ industry guidelines to ensure quality control for such online resources (Tobey and Manore 2014, p. 128), but the nature of social media obviously defies such containment. Clearly, the absence of industry-endorsed qualifications did not impede these women’s social media ascent; it probably made them more relatable and endearing to their fans. Yet despite the controversy that these cases generated (around the efficacy and merits of Gerson Therapy as advocated by Anscough; and the flagrant lies that Gibson had told to her growing fan base), they show just how seductive social media is as a profile-boosting platform, and that strategies of micro-celebrity can forge a loyal following on even the flimsiest of grounds. One of the most famous food bloggers, for instance, is 36-year-old Vani Hari, better known around the world as the Food Babe. Hari began blogging in April 2011 and chronicled how she regained her health and vitality after an appendectomy through a more mindful diet, and by combing through food labels to better understand the typical American food system. Aghast at what she considered an alarming rate of toxic chemicals in popular everyday foods, and convinced that these were to the nutritional detriment of consumers, Hari established her signature mission: to reveal the ‘truth’ behind packaged, processed foods and to lobby for greater transparency on the part of big business. To this end, Hari uses the ‘Food Babe Army’, her legion of online fans – in June 2015 her Facebook page had 972,000 likes, her Instagram account had over 46,000 followers and her Twitter handle had over 89,000 followers.</p>
<p>Through practices of micro-celebrity on their social media platforms, these three SMIs found both fame and marketability through strategic self-branding. Ultimately (and obviously) Hari, aka the Food Babe, has been the most successful. As James Hamblin (2015) wrote in <em>The Atlantic</em>, hyperbolically perhaps, ‘the idea of a lone consultant becoming, in three short years, more influential than entire university departments of Ph.Ds., is indicative of a new level of potential for celebrity in health messaging’. That is not to say that her contribution to the wellness industry has been any more robust, considered or valid – on social media, celebrity is not necessarily dependent on such ‘logical’ indices. Hari has been the subject of much derision from science writers precisely because of her populist spin on nutritional advice, but her profile continues to grow, with coverage across the <em>New York Times</em>, NBC News and the <em>Washington Post</em> and her appointment as CNN’s food expert. She is a savvy entrepreneur as much as a consumer advocate, and sells eating guides with meal calendars, recipes and grocery lists replete with ‘approved brands’ – that is, those with which she has a commercial arrangement (Schultz and Morrison 2014). The size of her fan base bodes well for her online petitions that demand change from the giants of the American food industry, including Subway, Lean Cuisine, McDonalds, General Mills, Starbucks and Coca-Cola – all of which have, according to Hari, buckled to Food Babe Army pressure and dropped what she claimed were harmful chemicals in their foods. The Food Babe’s brand is strong, distinctive and consistent, much to the chagrin of actual scientists who argue that just because an ingredient is hard to pronounce or is indecipherable for the average consumer this does not render it dangerous (Gorski 2014). Moreover, like Anscough and Gibson, she has a story – a journey to ‘wellness’ through diet – that has been reconfigured as a popularly accessible promise.</p>
<h2>Conclusion</h2>
<p>The aim of this article is to critically examine the idea of self-branding first popularised in the 1990s. Although it is conceptually flawed, its popularity has not waned. The question is why? In terms of the examples considered (Anscough, Gibson and Hari), the issue is not their motivations, credentials or even sincerity. Rather, it is the degree to which contemporary social, economic and technological processes both accommodate and reward their style of message management, insofar as social media propelled them from relative obscurity to become prominent SMIs, and the role of self-branding in this development. Their visibility and efficacy are clearly indebted to communication capabilities distinct to the early twenty-first century, and a cultural milieu increasingly primed for self-promotion and triumphant individualism. This article shows how social media encourages the practices of self-branding that these three women engaged in. At stake is how these practices capitalise on the apparent democratisation of media production and distribution, whereby entry levels are comparatively low and potential reach, in terms of audience and influence, is spectacularly high. The wide-ranging effects of participatory media and user-generated content have been amply documented and discussed for almost two decades. It is argued here, however, that, in the early twenty-first century, key trends appear especially pronounced – not the least of which is the extent to which social media like Facebook, Twitter, YouTube and Instagram facilitate not just participation but practices of self-branding.</p>
<p>The rapid globalisation of advanced consumer capitalism has obviously widened the scope and scale of all brand marketing, but it is the ascent and entrenchment of self-branding that is considered here, and the ways this phenomenon links dominant notions of individual success, personal responsibility and subjectivity to a political economy defined almost completely by consumerist logic. Our analysis suggests that the rise of social media and our current consumerist orientation may have contributed to this popularity. The rise of both ‘Instafame’ and SMIs – their pursuit and realisation – effectively underscores three distinct and interrelated processes: the transformative and seminal effects of social, interactive and conversational media in the Information Age; the mercurial dismantling of what were once ‘knowledge monopolies’, as the likes of Anscough, Gibson and Hari become quasi-experts and assume the role historically reserved for highly trained specialists (such as doctors, dieticians and scientists); and the near-total extension of marketing logic and language into more areas of contemporary social life. While all these processes predate and are not exclusive to social media, cumulatively social media intensifies and spotlights their salience.</p>
<h2>Disclosure statement</h2>
<p>No potential conflict of interest was reported by the authors.</p>
<h2>Additional information</h2>
<h3>Notes on contributors</h3>
<h4>Susie Khamis</h4>
<p>Susie Khamis is Senior Lecturer in the School of Communication at the University of Technology Sydney. Her doctoral thesis ‘Bushells and the Cultural Logic of Branding’ won the Sydney Harbour Foreshore Heritage Prize in 2007, and in 2011 she was founding editor of <em>Locale: The Australasian-Pacific Journal of Regional Food Studies</em>. Her research areas are branding, representations of cultural diversity and consumer cultures.</p>
<h4>Lawrence Ang</h4>
<p>Lawrence Ang is an Associate Professor at the Department of Marketing and Management in the Faculty of Business &amp; Economics at Macquarie University. Prior to academia, he was a senior consultant in a market research company. He has a keen interest in customer relationship management, advertising creativity and effectiveness. His latest book is <em>Principles of Integrated Marketing Communications</em> 2014 (Cambridge University Press).</p>
<h4>Raymond Welling</h4>
<p>Raymond Welling is an adjunct lecturer in media and marketing in the Faculty of Business &amp; Economics and the Department of Media, Music, Communication &amp; Cultural Studies at Macquarie University. He also teaches marketing at The University of Sydney Business School, and works in industry as a digital publisher and content marketer. His research focuses on media/marketing convergence and ethics in the digital era.</p>
<h2 id="figures">References</h2>
<ul class="references numeric-ordered-list">
    <li id="CIT0001">
        <span
            ><span class="hlFld-ContribAuthor"
                >Aaker, <span class="NLM_given-names">J.L.</span></span
            >, <span class="NLM_year">1997</span>.
            <span class="NLM_article-title"
                >Dimensions of brand personality</span
            >. _Journal of marketing research_, 34 (3),
            <span class="NLM_fpage">347</span>–<span class="NLM_lpage">357</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0002">
        <span
            ><span class="hlFld-ContribAuthor"
                >Abidin, <span class="NLM_given-names">C.</span></span
            >, <span class="NLM_year">2015</span>.
            <span class="NLM_article-title"
                >Communicative intimacies: influencers and perceived
                interconnectedness</span
            >.
            _Ada: a journal of gender, new media, &amp; technology_
            [online], 8. Available from:
            <a
                class="ext-link"
                href="http://adanewmedia.org/2015/11/issue8-abidin/"
                target="_blank"
                >http://adanewmedia.org/2015/11/issue8-abidin/</a
            >
            [Accessed <span class="NLM_day">23</span>
            <span class="NLM_month">June</span> 2016].<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0003">
        <span
            >_American idol_, <span class="NLM_year">2002–2016</span>. TV,
            Fremantle Media North America.<span class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0004">
        <span
            ><span class="hlFld-ContribAuthor"
                >Bandinelli, <span class="NLM_given-names">C.</span></span
            >
            and
            <span class="hlFld-ContribAuthor"
                >Arvidsson, <span class="NLM_given-names">A.</span></span
            >, <span class="NLM_year">2012</span>.
            <span class="NLM_article-title">Brand yourself a changemaker!</span>
            _Journal of macromarketing_, 33 (1),
            <span class="NLM_fpage">67</span>–<span class="NLM_lpage">71</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0005">
        <span
            ><span class="hlFld-ContribAuthor"
                >Banet-Weiser, <span class="NLM_given-names">S.</span></span
            >, <span class="NLM_year">2012</span>.
            <i
                >Authentic<sup>TM</sup>: the politics of ambivalence in a brand
                culture</i
            >. <span class="NLM_publisher-loc">New York</span>:
            <span class="NLM_publisher-name">New York University Press</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0006">
        <span
            ><span class="hlFld-ContribAuthor"
                >Banet-Weiser, <span class="NLM_given-names">S.</span></span
            >
            and
            <span class="hlFld-ContribAuthor"
                >Sturken, <span class="NLM_given-names">M.</span></span
            >, <span class="NLM_year">2010</span>.
            <span class="NLM_chapter-title"
                >The politics of commerce: Shepard Fairey and the new cultural
                entrepreneurship</span
            >. _In_:
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">M.</span> Aronczyk</span
            >
            and
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">D.</span> Powers</span
            >, eds.
            <i
                >Blowing up the brand: critical perspectives on promotional
                culture</i
            >. <span class="NLM_publisher-loc">New York</span>:
            <span class="NLM_publisher-name">Peter Lang</span>,
            <span class="NLM_fpage">263</span>–<span class="NLM_lpage">283</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0007">
        <span
            ><span class="hlFld-ContribAuthor"
                >Berger, <span class="NLM_given-names">A.A.</span></span
            >, <span class="NLM_year">2011</span>.
            <span class="NLM_article-title"
                >The branded self: on the semiotics of identity</span
            >. _The American sociologist_, 42 (2–3),
            <span class="NLM_fpage">232</span>–<span class="NLM_lpage">237</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0008">
        <span
            ><span class="hlFld-ContribAuthor"
                >Brandabur, <span class="NLM_given-names">R.E.</span></span
            >, <span class="NLM_year">2012</span>.
            <span class="NLM_chapter-title"
                >Personal branding of a teacher – an approach into e-educational
                environment. _elearning and software for education_</span
            >, (1), <span class="NLM_fpage">44</span>–<span class="NLM_lpage"
                >49</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0009">
        <span
            >_Big brother_, <span class="NLM_year">1999</span>–present. TV,
            Endemol.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0010">
        <span
            ><span class="hlFld-ContribAuthor"
                >Brody, <span class="NLM_given-names">E.W.</span></span
            >, <span class="NLM_year">2001</span>.
            <span class="NLM_article-title">The “Attention” economy</span>.
            _Public relations quarterly_ (Fall, October),
            <span class="NLM_fpage">18</span>–<span class="NLM_lpage">21</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0011">
        <span
            ><span class="hlFld-ContribAuthor"
                >Chen, <span class="NLM_given-names">C.-P.</span></span
            >, <span class="NLM_year">2013</span>.
            <span class="NLM_article-title"
                >Exploring personal branding on YouTube</span
            >. _Journal of internet commerce_, 12 (4),
            <span class="NLM_fpage">332</span>–<span class="NLM_lpage">347</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0012">
        <span
            ><span class="hlFld-ContribAuthor"
                >Corderoy, <span class="NLM_given-names">A.</span></span
            >, <span class="NLM_year">2015</span>.
            <span class="NLM_article-title"
                >Cancer death of “Wellness Warrior” Jess Ainscough brings focus
                onto alternative treatments</span
            >. _Sydney Morning Herald_, 5 March. Available from:
            <a
                class="ext-link"
                href="http://smh.com.au.wwwproxy1.library.unsw.edu.au"
                target="_blank"
                >http://smh.com.au.wwwproxy1.library.unsw.edu.au</a
            >
            [Accessed <span class="NLM_month">May</span> 2015].<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0013">
        <span
            ><span class="hlFld-ContribAuthor"
                >Couldry, <span class="NLM_given-names">N.</span></span
            >, <span class="NLM_year">2002</span>.
            <span class="NLM_article-title"
                >Playing for celebrity: _big brother_ as ritual event</span
            >. _Television &amp; new media_, 3 (3),
            <span class="NLM_fpage">283</span>–<span class="NLM_lpage">293</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0014">
        <span
            ><span class="hlFld-ContribAuthor"
                >Davey, <span class="NLM_given-names">M.</span></span
            >, <span class="NLM_year">2015</span>.
            <span class="NLM_article-title"
                >“None of it’s true”: Wellness blogger Belle Gibson admits she
                never had cancer</span
            >. _The Guardian_, 22 April. Available from:
            <a
                class="ext-link"
                href="http://www.theguardian.com/australia"
                target="_blank"
                >www.theguardian.com/australia</a
            >
            [Accessed <span class="NLM_month">January</span> 2016].<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0015">
        <span
            ><span class="hlFld-ContribAuthor"
                >Davis, <span class="NLM_given-names">J.L.</span></span
            >
            and
            <span class="hlFld-ContribAuthor"
                >Jurgenson, <span class="NLM_given-names">N.</span></span
            >, <span class="NLM_year">2014</span>.
            <span class="NLM_article-title"
                >Context collapse: theorizing context collusions and
                collisions</span
            >. _Information, communication &amp; society_, 17 (4),
            <span class="NLM_fpage">476</span>–<span class="NLM_lpage">485</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0016">
        <span
            ><span class="hlFld-ContribAuthor"
                >Dufy, <span class="NLM_given-names">B.E.</span></span
            >
            and
            <span class="hlFld-ContribAuthor"
                >Hund, <span class="NLM_given-names">E.</span></span
            >, <span class="NLM_year">2015</span>.
            <span class="NLM_article-title"
                >‘Having it all’ on social media: entrpreneurial femininity and
                self-branding among fashion bloggers</span
            >. _Social media &amp; society_,
            <span class="NLM_month">July–December</span>, 1 (2),
            <span class="NLM_fpage">1</span>–<span class="NLM_lpage">11</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0017">
        <span
            ><span class="hlFld-ContribAuthor"
                >Fairchild, <span class="NLM_given-names">C.</span></span
            >, <span class="NLM_year">2007</span>.
            <span class="NLM_article-title"
                >Building the authentic celebrity: the “Idol” phenomenon in the
                attention economy</span
            >. _Popular music and society_, 30 (3),
            <span class="NLM_fpage">355</span>–<span class="NLM_lpage">375</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0018">
        <span
            ><span class="hlFld-ContribAuthor"
                >Florida, <span class="NLM_given-names">R.</span></span
            >, <span class="NLM_year">2003</span>.
            <span class="NLM_article-title">Cities and the creative class</span
            >. _City and community_, 2 (1),
            <span class="NLM_fpage">3</span>–<span class="NLM_lpage">19</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0019">
        <span
            ><span class="hlFld-ContribAuthor"
                >Gamson, <span class="NLM_given-names">J.</span></span
            >, <span class="NLM_year">2011</span>.
            <span class="NLM_article-title"
                >The unwatched life is not worth living: the elevation of the
                ordinary in celebrity culture</span
            >. _Theories and methodologies_, 126 (4),
            <span class="NLM_fpage">1061</span>–<span class="NLM_lpage"
                >1069</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0020">
        <span
            ><span class="hlFld-ContribAuthor"
                >Gandini, <span class="NLM_given-names">A.</span></span
            >, <span class="NLM_year">2015</span>.
            <span class="NLM_article-title"
                >Digital work: self-branding and social capital in the freelance
                knowledge economy</span
            >. _Marketing theory_, <span class="NLM_month">October</span>,
            16 (1), <span class="NLM_fpage">1</span>–<span class="NLM_lpage"
                >19</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0021">
        <span
            ><span class="hlFld-ContribAuthor"
                >Goffman, <span class="NLM_given-names">E.</span></span
            >, <span class="NLM_year">1959</span>.
            _The presentation of self in everyday life_.
            <span class="NLM_publisher-loc">New York</span>:
            <span class="NLM_publisher-name">Anchor Books</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0022">
        <span
            ><span class="hlFld-ContribAuthor"
                >Good, <span class="NLM_given-names">K.D.</span></span
            >, <span class="NLM_year">2012</span>.
            <span class="NLM_article-title"
                >From scrapbook to Facebook: a history of personal media
                assemblage and archives</span
            >. _New media &amp; society_, 15 (4),
            <span class="NLM_fpage">557</span>–<span class="NLM_lpage">573</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0023">
        <span
            ><span class="hlFld-ContribAuthor"
                >Gormley, <span class="NLM_given-names">A.</span></span
            >, <span class="NLM_year">2016</span>.
            <span class="NLM_article-title"
                >How brands can get more from their influencer
                relationships</span
            >. _Mumbrella_ [online]. Available from:
            <a
                class="ext-link"
                href="https://mumbrella.com.au/five-top-tips-influencing-influencers-372025"
                target="_blank"
                >https://mumbrella.com.au/five-top-tips-influencing-influencers-372025</a
            >
            [Accessed <span class="NLM_day">23</span>
            <span class="NLM_month">June</span> 2016].<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0024">
        <span
            ><span class="hlFld-ContribAuthor"
                >Gorski, <span class="NLM_given-names">D.</span></span
            >, <span class="NLM_year">2014</span>.
            <span class="NLM_article-title"
                >Vari Hari, a.k.a. “The Food Babe”, finally responds to
                critics</span
            >. _Science-based medicine_, 8 December. Available from:
            <a
                class="ext-link"
                href="https://www.sciencebasedmedicine.org"
                target="_blank"
                >https://www.sciencebasedmedicine.org</a
            >
            [Accessed <span class="NLM_month">May</span> 2015].<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0025">
        <span
            ><span class="hlFld-ContribAuthor"
                >Granitz, <span class="NLM_given-names">N.</span></span
            >
            and
            <span class="hlFld-ContribAuthor"
                >Forman, <span class="NLM_given-names">H.</span></span
            >, <span class="NLM_year">2015</span>.
            <span class="NLM_article-title"
                >Building self-brand connections: exploring brand stories
                through a transmedia perspective</span
            >. _Journal of brand management_, 22 (1),
            <span class="NLM_fpage">38</span>–<span class="NLM_lpage">59</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0026">
        <span
            ><span class="hlFld-ContribAuthor"
                >Hall, <span class="NLM_given-names">N.</span></span
            >, <span class="NLM_year">2014</span>.
            <span class="NLM_article-title"
                >The Kardashian index: a measure of discrepant social media
                profile for scientists</span
            >. _GenomeBiology_, 15 (424). Available from::
            <a
                class="ext-link"
                href="http://www.genomebiology.com/2014/15/7/424"
                target="_blank"
                >http://www.genomebiology.com/2014/15/7/424</a
            >
            [Accessed <span class="NLM_month">January</span> 2016].<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0027">
        <span
            ><span class="hlFld-ContribAuthor"
                >Hamblin, <span class="NLM_given-names">J.</span></span
            >, <span class="NLM_year">2015</span>.
            <span class="NLM_article-title"
                >The Food Babe: enemy of chemicals</span
            >. _The Atlantic_, 11 February [online]. Available from:
            <a
                class="ext-link"
                href="http://www.theatlantic.com/health/archive/2015/02/the-food-babe-enemy-of-chemicals/385301/"
                target="_blank"
                >http://www.theatlantic.com/health/archive/2015/02/the-food-babe-enemy-of-chemicals/385301/</a
            >
            [Accessed <span class="NLM_day">23</span>
            <span class="NLM_month">June</span> 2016].<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0028">
        <span
            ><span class="hlFld-ContribAuthor"
                >Hargreaves, <span class="NLM_given-names">W.</span></span
            >, <span class="NLM_year">2010</span>.
            <span class="NLM_article-title"
                >Happy to toast the tasteless kitchen plus</span
            >. _Sunday Herald-Sun_,
            <span class="NLM_day">13</span>
            <span class="NLM_month">June</span>,
            <span class="NLM_fpage">90</span>.<span class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0029">
        <span
            ><span class="hlFld-ContribAuthor"
                >Hearn, <span class="NLM_given-names">A.</span></span
            >, <span class="NLM_year">2008a</span>.
            <span class="NLM_article-title"
                >“Meat, mask, burden”: probing the contours of the branded
                “self”’</span
            >. _Journal of consumer culture_, 8 (2),
            <span class="NLM_fpage">197</span>–<span class="NLM_lpage">217</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0030">
        <span
            ><span class="hlFld-ContribAuthor"
                >Hearn, <span class="NLM_given-names">A.</span></span
            >, <span class="NLM_year">2008b</span>.
            <span class="NLM_article-title"
                >Insecure: narratives and economies of the branded self in
                transformation television</span
            >. _Continuum: journal of media &amp; cultural studies_, 22
            (4), <span class="NLM_fpage">495</span>–<span class="NLM_lpage"
                >504</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0031">
        <span
            ><span class="hlFld-ContribAuthor"
                >Hearn, <span class="NLM_given-names">A.</span></span
            >, <span class="NLM_year">2011</span>.
            <span class="NLM_article-title"
                >Confessions of a radical eclectic: reality television,
                self-branding, social media and autonomist marxism</span
            >. _Journal of communication inquiry_, 35 (4),
            <span class="NLM_fpage">313</span>–<span class="NLM_lpage">321</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0032">
        <span
            ><span class="hlFld-ContribAuthor"
                >Hearn, <span class="NLM_given-names">A.</span></span
            >
            and
            <span class="hlFld-ContribAuthor"
                >Schoenhoff, <span class="NLM_given-names">S.</span></span
            >, <span class="NLM_year">2016</span>.
            <span class="NLM_chapter-title"
                >From celebrity to influencer: tracing the diffusion of
                celebrity value across the data stream</span
            >. _In_:
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">P.</span> David Marshall</span
            >
            and
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">S.</span> Redmond</span
            >, eds. _A companion to celebrity_.
            <span class="NLM_publisher-loc">Chichester</span>:
            <span class="NLM_publisher-name">John Wiley &amp; Sons</span>,
            <span class="NLM_fpage">194</span>–<span class="NLM_lpage">212</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0033">
        <span
            ><span class="hlFld-ContribAuthor"
                >Herskovitz, <span class="NLM_given-names">S.</span></span
            >
            and
            <span class="hlFld-ContribAuthor"
                >Crystal, <span class="NLM_given-names">M.</span></span
            >, <span class="NLM_year">2010</span>.
            <span class="NLM_article-title"
                >The essential brand persona: Storytelling and branding</span
            >. _Journal of business strategy_, 31 (3),
            <span class="NLM_fpage">21</span>–<span class="NLM_lpage">28</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0034">
        <span
            >_Jerry Springer_, <span class="NLM_year">1991</span>–present.
            TV, Stamford Media.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0035">
        <span
            ><span class="hlFld-ContribAuthor"
                >Keller, <span class="NLM_given-names">K. L.</span></span
            >
            <span class="NLM_year">2007</span>. Strategic brand management:
            Building, measuring, and managing brand equity.
            <span class="NLM_publisher-loc">Harlow</span>:
            <span class="NLM_publisher-name">Pearson Education</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0036">
        <span
            ><span class="hlFld-ContribAuthor"
                >Khamis, <span class="NLM_given-names">S.</span></span
            >, <span class="NLM_year">2013</span>.
            <span class="NLM_article-title"
                >Mastering the brand: how an ‘ordinary’ cook achieved
                extraordinary cook book success</span
            >. _TEXT: journal of writing and writing courses_, 24,
            <span class="NLM_fpage">1</span>–<span class="NLM_lpage">8</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0037">
        <span
            ><span class="hlFld-ContribAuthor"
                >Khedher, <span class="NLM_given-names">M.</span></span
            >, <span class="NLM_year">2014</span>.
            <span class="NLM_article-title">Personal branding phenomenon</span>.
            _International journal of information, business and management</i
            >, 6 (2), <span class="NLM_fpage">29</span>–<span class="NLM_lpage"
                >40</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0038">
        <span
            ><span class="hlFld-ContribAuthor"
                >Knittel, <span class="NLM_given-names">C.R.</span></span
            >
            and
            <span class="hlFld-ContribAuthor"
                >Stango, <span class="NLM_given-names">V.</span></span
            >, <span class="NLM_year">2014</span>.
            <span class="NLM_article-title"
                >Celebrity endorsements, firm value, and reputation risk:
                evidence from the Tiger Woods scandal</span
            >. _Management science_, 60 (1),
            <span class="NLM_fpage">21</span>–<span class="NLM_lpage">37</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0039">
        <span
            ><span class="hlFld-ContribAuthor"
                >Labrecque, <span class="NLM_given-names">L.I.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Markos, <span class="NLM_given-names">E.</span></span
            >, and
            <span class="hlFld-ContribAuthor"
                >Milne, <span class="NLM_given-names">G.R.</span></span
            >, <span class="NLM_year">2011</span>.
            <span class="NLM_article-title"
                >Online personal branding: processes, challenges, and
                implications</span
            >. _Journal of interactive marketing_, 25,
            <span class="NLM_fpage">37</span>–<span class="NLM_lpage">50</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0040">
        <span
            ><span class="hlFld-ContribAuthor"
                >Lair, <span class="NLM_given-names">D.J.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Sullivan, <span class="NLM_given-names">K.</span></span
            >, and
            <span class="hlFld-ContribAuthor"
                >Cheney, <span class="NLM_given-names">G.</span></span
            >, <span class="NLM_year">2005</span>.
            <span class="NLM_article-title"
                >Marketization and the recasting of the professional self</span
            >. _Management communication quarterly_, 18 (3),
            <span class="NLM_fpage">307</span>–<span class="NLM_lpage">343</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0041">
        <span
            ><span class="hlFld-ContribAuthor"
                >Lohse, <span class="NLM_given-names">B.</span></span
            >, <span class="NLM_year">2013</span>.
            <span class="NLM_article-title"
                >Facebook is an effective strategy to recruit low-income women
                to online nutrition education</span
            >. _Journal of nutrition education and behavior_, 45 (1),
            <span class="NLM_fpage">69</span>–<span class="NLM_lpage">76</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0042">
        <span
            ><span class="hlFld-ContribAuthor"
                >MacDonald, <span class="NLM_given-names">P.</span></span
            >, <span class="NLM_year">2014</span>.
            <span class="NLM_article-title">Narcissism in the modern world</span
            >. _Psychodynamic practice_, 20 (2),
            <span class="NLM_fpage">144</span>–<span class="NLM_lpage">153</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0043">
        <span
            ><span class="hlFld-ContribAuthor"
                >Marshall, <span class="NLM_given-names">P.D.</span></span
            >, <span class="NLM_year">2016</span>.
            <span class="NLM_chapter-title"
                >Exposure: the public self explore</span
            >. _In_:
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">P.D.</span> Marshall</span
            >
            and
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">S.</span> Redmond</span
            >, eds. _A companion to celebrity_.
            <span class="NLM_publisher-loc">Chichester</span>:
            <span class="NLM_publisher-name">John Wiley &amp; Sons</span>,
            <span class="NLM_fpage">497</span>–<span class="NLM_lpage">517</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0044">
        <span
            ><span class="hlFld-ContribAuthor"
                >Marwick, <span class="NLM_given-names">A.E.</span></span
            >, <span class="NLM_year">2013a</span>.
            _Status update: celebrity, publicity, and branding_.
            <span class="NLM_publisher-loc">New Haven</span>:
            <span class="NLM_publisher-name">Yale University Press</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0045">
        <span
            ><span class="hlFld-ContribAuthor"
                >Marwick, <span class="NLM_given-names">A.E.</span></span
            >, <span class="NLM_year">2013b</span>.
            <span class="NLM_chapter-title">Online Identity</span>. _In_:
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">J.</span> Hartley</span
            >,
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">J.</span> Burgess</span
            >, and
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">A.</span> Bruns</span
            >, eds. _A companion to new media dynamics_.
            <span class="NLM_publisher-loc">Chichester</span>:
            <span class="NLM_publisher-name">Wiley-Blackwell</span>,
            <span class="NLM_fpage">355</span>–<span class="NLM_lpage">364</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0046">
        <span
            ><span class="hlFld-ContribAuthor"
                >Marwick, <span class="NLM_given-names">A.E.</span></span
            >, <span class="NLM_year">2015</span>.
            <span class="NLM_article-title"
                >Instafame: luxury selfies in the attention economy</span
            >. _Public culture_, 27 (75),
            <span class="NLM_fpage">137</span>–<span class="NLM_lpage">160</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0047">
        <span
            ><span class="hlFld-ContribAuthor"
                >Marwick, <span class="NLM_given-names">A.E.</span></span
            >, <span class="NLM_year">2016</span>.
            <span class="NLM_chapter-title"
                >You may know me from YouTube: (micro-) celebrity in social
                media</span
            >. _In_:
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">P.D.</span> Marshall</span
            >
            and
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">S.</span> Redmond</span
            >, eds. _A companion to celebrity_.
            <span class="NLM_publisher-loc">Chichester</span>:
            <span class="NLM_publisher-name">John Wiley &amp; Sons</span>,
            <span class="NLM_fpage">333</span>–<span class="NLM_lpage">350</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0048">
        <span
            ><span class="hlFld-ContribAuthor"
                >Marwick, <span class="NLM_given-names">A.E.</span></span
            >
            and
            <span class="hlFld-ContribAuthor"
                >boyd, <span class="NLM_given-names">d.</span></span
            >, <span class="NLM_year">2010</span>.
            <span class="NLM_article-title"
                >I tweet honestly, I tweet passionately: Twitter users, context
                collapse, and the imagined audience</span
            >. _New media &amp; society_, 13 (1),
            <span class="NLM_fpage">114</span>–<span class="NLM_lpage">133</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0049">
        <span
            >_Masterchef_, <span class="NLM_year">1990-2001</span>. TV,
            Franc Roddam.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0050">
        <span
            >_Masterchef_, <span class="NLM_year">2005-present</span>. TV,
            Franc Roddam.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0051">
        <span
            >_Masterchef Australia_,
            <span class="NLM_year">2009-present</span>. TV, Fremantle Media
            Australia.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0052">
        <span
            ><span class="hlFld-ContribAuthor"
                >Page, <span class="NLM_given-names">R.</span></span
            >, <span class="NLM_year">2012</span>.
            <span class="NLM_article-title"
                >The linguistics of self-branding and micro-celebrity in
                Twitter: the role of hashtags</span
            >. _Discourse &amp; communication_, 6 (2),
            <span class="NLM_fpage">181</span>–<span class="NLM_lpage">201</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0053">
        <span
            ><span class="hlFld-ContribAuthor"
                >Peters, <span class="NLM_given-names">T.</span></span
            >, <span class="NLM_year">1997</span>.
            <span class="NLM_article-title">The brand called you</span>.
            _Fast company_. Available from:
            <a
                class="ext-link"
                href="http://www.fastcompany.com"
                target="_blank"
                >http://www.fastcompany.com</a
            >
            [Accessed <span class="NLM_month">May</span> 2015].<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0054">
        <span
            ><span class="hlFld-ContribAuthor"
                >Phillip, <span class="NLM_given-names">A.</span></span
            >, <span class="NLM_year">2015</span>.
            <span class="NLM_article-title"
                >“None of it’s true”: disgraced wellness guru Belle Gibson comes
                clean on cancer hoax</span
            >. _The Washington Post_, 22 April. Available from:
            <a
                class="ext-link"
                href="http://www.washingtonpost.com"
                target="_blank"
                >http://www.washingtonpost.com</a
            >
            [Accessed <span class="NLM_month">May</span> 2015].<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0055">
        <span
            ><span class="hlFld-ContribAuthor"
                >Schultz, <span class="NLM_given-names">E.J.</span></span
            >
            and
            <span class="hlFld-ContribAuthor"
                >Morrison, <span class="NLM_given-names">M.</span></span
            >, <span class="NLM_year">2014</span>.
            <span class="NLM_article-title"
                >Activist or capitalist? How “Food Babe” makes money</span
            >. _Ad age_, 14 July. Available from:
            <a class="ext-link" href="http://adage.com" target="_blank"
                >http://adage.com</a
            >
            [Accessed <span class="NLM_month">May</span> 2015].<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0056">
        <span
            ><span class="hlFld-ContribAuthor"
                >Senft, <span class="NLM_given-names">T.M.</span></span
            >, <span class="NLM_year">2008</span>.
            <i
                >Camgirls: celebrity and community in the age of social
                networks</i
            >. <span class="NLM_publisher-loc">New York</span>:
            <span class="NLM_publisher-name">Peter Lang</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0057">
        <span
            ><span class="hlFld-ContribAuthor"
                >Senft, <span class="NLM_given-names">T.M.</span></span
            >, <span class="NLM_year">2013</span>.
            <span class="NLM_chapter-title"
                >Microcelebrity and the branded self</span
            >. _In_:
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">J.</span> Hartley</span
            >,
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">J.</span> Burgess</span
            >, and
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">A.</span> Bruns</span
            >, eds. _A companion to new media dynamics_.
            <span class="NLM_publisher-loc">Chichester</span>:
            <span class="NLM_publisher-name">Wiley-Blackwell</span>,
            <span class="NLM_fpage">346</span>–<span class="NLM_lpage">354</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0058">
        <span
            ><span class="hlFld-ContribAuthor"
                >Shepherd, <span class="NLM_given-names">I.D.H.</span></span
            >, <span class="NLM_year">2005</span>.
            <span class="NLM_article-title"
                >From cattle and coke to Charlie: meeting the challenge of self
                marketing and personal branding</span
            >. _Journal of marketing management_, 21 (5–6),
            <span class="NLM_fpage">589</span>–<span class="NLM_lpage">606</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0059">
        <span
            >_Survivor_, <span class="NLM_year">1992</span>–present. TV,
            Castaway Television.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0060">
        <span
            >_Sylvania Waters_, <span class="NLM_year">1992</span>. TV,
            Paul Watson/ABC.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0061">
        <span
            ><span class="hlFld-ContribAuthor"
                >Thomson, <span class="NLM_given-names">M.</span></span
            >, <span class="NLM_year">2006</span>.
            <span class="NLM_article-title"
                >Human brands: investigating antecedents to consumers’ strong
                attachments to celebrities</span
            >. _Journal of marketing_, 70,
            <span class="NLM_fpage">104</span>–<span class="NLM_lpage">119</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0062">
        <span
            ><span class="hlFld-ContribAuthor"
                >Tobey, <span class="NLM_given-names">L.N.</span></span
            >
            and
            <span class="hlFld-ContribAuthor"
                >Manore, <span class="NLM_given-names">M.M.</span></span
            >, <span class="NLM_year">2014</span>.
            <span class="NLM_article-title"
                >Social media and nutrition education: the food hero
                experience</span
            >. _Journal of nutrition education and behavior_, 46 (2),
            <span class="NLM_fpage">128</span>–<span class="NLM_lpage">133</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0063">
        <span
            ><span class="hlFld-ContribAuthor"
                >Turner, <span class="NLM_given-names">G.</span></span
            >, <span class="NLM_year">2006</span>.
            <span class="NLM_article-title"
                >The mass production of celebrity: “Celetoids”, reality TV and
                the “demotic turn”</span
            >. _International journal of cultural studies_, 9 (2),
            <span class="NLM_fpage">153</span>–<span class="NLM_lpage">165</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0064">
        <span
            ><span class="hlFld-ContribAuthor"
                >Vitak, <span class="NLM_given-names">J.</span></span
            >, <span class="NLM_year">2012</span>.
            <span class="NLM_article-title"
                >The impact of context collapse and privacy on social network
                site disclosures</span
            >. _Journal of broadcasting &amp; electronic media_, 56 (4),
            <span class="NLM_fpage">451</span>–<span class="NLM_lpage">470</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0065">
        <span
            ><span class="hlFld-ContribAuthor"
                >Wee, <span class="NLM_given-names">L.</span></span
            >
            and
            <span class="hlFld-ContribAuthor"
                >Brooks, <span class="NLM_given-names">A.</span></span
            >, <span class="NLM_year">2010</span>.
            <span class="NLM_article-title"
                >Personal branding and the commodification of reflexivity</span
            >. _Cultural sociology_, 4 (1),
            <span class="NLM_fpage">45</span>–<span class="NLM_lpage">62</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0066">
        <span
            ><span class="hlFld-ContribAuthor"
                >Wernick, <span class="NLM_given-names">A.</span></span
            >, <span class="NLM_year">1992</span>.
            <i
                >Promotional culture, advertising, ideology and symbolic
                expression</i
            >. <span class="NLM_publisher-loc">London</span>:
            <span class="NLM_publisher-name">Sage</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
</ul>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="‘It’s like the gold rush’: the lives and careers of professional video game streamers on Twitch.tv"
class="paper-story"
data-article-title="‘It’s like the gold rush’: the lives and careers of professional video game streamers on Twitch.tv"
>

<h1 class="article-title" id="h_‘It’s like the gold rush’: the lives and careers of professional video game streamers on Twitch.tv">‘It’s like the gold rush’: the lives and careers of professional video game streamers on Twitch.tv</h1>

<div class="top-meta">Mark R. Johnson & Jamie Woodcock, 2017-01-05 00:00:00 AEST. for week 10.</div>

<h1>TODO: go though and take out extended refs in text</h1>
<p>Mark R. Johnson &amp; Jamie Woodcock</p>
<p>Pages 336-351 | Received 05 Jan 2017, Accepted 15 Sep 2017, Published online: 16 Oct 2017</p>
<h2>ABSTRACT</h2>
<p>This paper explores the lives and careers of video game live broadcasters, especially those who gain their primary real-world income through this practice. We introduce the dominant market leader – the platform Twitch.tv – and outline its immensely rapid growth and the communities of millions of broadcasters, and tens of millions of viewers, it now boasts. Drawing on original interview data with professional and aspiring-professional game broadcasters (‘streamers’), we examine the pasts, presents, and anticipated futures of streamers: how professional streamers began streaming, the everyday labour practices of streaming, and their concerns and hopes about the future of their chosen career. Through these examinations we explore the sociotechnical entanglements – digital intimacy, celebrity, content creation, and video games – that exemplify this new media form. Live streaming is an online practice expanding in both production and consumption at immense speed, and Twitch and its streamers appear to be at the forefront of that revolution.</p>
<h2>Introduction</h2>
<p>Playing video games is a full-time occupation for our respondent, P1. Before finding this career, he dropped out of university twice, worked minimum-wage jobs, and was unemployed for almost half a decade. He then discovered the possibility of broadcasting (‘streaming’) himself playing video games over the Internet. It then became apparent that other people would actually watch him play, and that this could be monetised, transforming adventures in virtual worlds into real-world income. ‘When I first started streaming, there wasn’t any money involved, […] there were just people doing it because they loved to do it’, he explains. As time went by his games ‘channel’ grew in popularity, and the various means provided by streaming platforms for bringing in money began to bear fruit. The career path of streaming, he says, remains very new and open to innovation and disruption, and there are few ways to predict who will capture the interest of an audience: ‘it’s like the Wild West, it’s like the Gold Rush, there’s still no real way to succeed. There’s no “this is how you get viewers”. You can be whatever you want’. He emphasises the personal value of being his own boss and streaming whatever hours he chooses, but also states he is live for six or seven unbroken hours five days a week, alongside many further hours spent behind the camera; it is a time-consuming career that depends upon regularity and reliability, much like the scheduling of traditional television broadcasts, whilst also evoking freedom and self-actualisation. ‘It has changed my life’, he says with clear enthusiasm and excitement. ‘I get to travel the world, […] I’ve paid off all my student debt, I get to meet people, I come to America quite often’. He does acknowledge uncertainty over the future of this career ‒ ‘It’s a very tough industry. It’s very competitive’ – but remains unabashed in relating the transformation of his life:</p>
<blockquote>
<p>Everyone thought I was a drifter, [but now] people can’t believe my success, […] they’re so happy for me. People are so happy that I’m living the dream, that I am my own boss, and that I get to play computer games every day. That, in a way, is a bigger value than the actual money.</p>
</blockquote>
<p>Ultimately, he concludes, streaming has ‘given me a reason to live, almost. This is my life’.</p>
<p>The website on which he broadcasts his video game play, <em>Twitch</em>, is the dominant market leader in live-streaming. <em>Twitch</em> was recently purchased by Amazon for almost $1bn and has become emblematic of shifts within the digital media economy towards an increasingly central role for content creation: in 2015 approximately <em>two million</em> people streamed regularly on average each month, producing over 450,000 years of video, and there were normally over half a million people watching channels at any one time (Twitch, 2015). Through <em>Twitch</em> anyone with access to a computer or games console, a reasonably fast Internet connection, and a game can broadcast gameplay to a global audience. The streamer’s channel (see Figure 1) can include a webcam that displays the player’s face (and therefore emotions and expressions), a chat box to interact with viewers, pop-up notifications of donations or ‘subscriptions’ (when viewers agree to give monthly financial support to the streamer), animations or pictures, hyperlinks to their presences on other social media sites, titles and bands of music playing on their stream, and so forth. The most successful streamers have over or close to one million ‘followers’ and regularly pull in tens of thousands of viewers, demonstrating the scale of the phenomenon and the ability of these technical affordances, and the personalities and practices of streamers, to accrue substantial visibility and celebrity status.</p>
<figure>
<p><img src="/assets/twitch1.jpeg" alt=""></p>
<figcaption>
<p>Figure 1. Twitch broadcast (<a href="https://www.twitch.tv/manvsgame">https://www.twitch.tv/manvsgame</a>).</p>
</figcaption>
</figure>
<p>In this paper, we will examine for the first time the lives and careers of those like P1 who make (or are aspiring to make) their primary source of income from the live broadcasting of video games on <em>Twitch</em>. In doing so we will seek to understand how streamers navigate the transition from a non-streamer to the aspirational goal of becoming a <em>Twitch</em> ‘professional’ (one who earns their primary income on the platform), and how these individuals understand their own practice and the wider emerging media ecosystem they both exist within and help to construct. Drawing on original interview data with 39 experienced and in many cases full-time video game streamers (24 directly quoted in this work), the paper examines the past, present, and future of the live-streaming career path: firstly, how streamers first started streaming and the increasing presence of games and games culture within a range of different cultural and economic media ecosystems; secondly, the particular kinds of (often strenuous and difficult) work and labour that professional and aspiring-professional streamers must engage in to be successful; and thirdly, the perspectives of these new media workers on the future of their streaming activities, and the future of streaming per se. In doing so, this paper aims to more fully open up the practice of streaming for future research, and develop our understanding of the freelance workers whose investments of time and effort have enabled the growth and professionalisation of this contemporary media phenomenon.</p>
<h2>Understanding Twitch: the existing literature</h2>
<p>The interwoven elements at play in the <em>Twitch</em> phenomenon ‒ of digital intimacy, celebrity, community, content creation, media production and consumption, and video games ‒ make <em>Twitch</em> a rich site for study. However, as a result of its newness and novelty, it has seen minimal sociological investigation to date. Live-streaming has, however, been already defined as a media phenomenon through which ‘anyone can become a TV provider’ (Pires &amp; Simon, 2015), broadcasting themselves and their activities to a potentially large crowd of online viewers. Initial research into the phenomenon to date has tended to focus on why viewers <em>watch</em> others stream video game play, and the psychological motivations and interests of those who spectate the activities of others (Sjöblom &amp; Hamari, 2016). Spectatorship has always been a part of video game culture more broadly (Taylor, 2016b), but those studying streaming have argued that streaming has given a newfound <em>intimacy</em> to game spectatorship (cf. Taylor, 2016b). This is a result of the <em>live</em> broadcasting of content, the ability for viewers and broadcasters to chat in real-time (Nematzadeh, Ciampaglia, Ahn, &amp; Flammini, 2016), and the development – via the technical affordances of <em>Twitch</em> and the behaviours of viewers – of tightly knit communities around each broadcaster. These communities offer a feeling of closeness to one’s preferred digital celebrities rarely matched in other media forms – <em>Twitch</em>, as Churchill and Xu (2016) argue, has consequently become ‘more than just an entertainment medium; it is the home of the largest gaming community in history’.</p>
<p>These elements all make <em>Twitch</em> a rich site for the study of contemporary media spectatorship and consumption, and the communities that arise around those practices. However, as the above comments from P1 illustrate, there is also a highly unusual and contemporary form of <em>employment</em> to be found within this ‘protoindustry of social media entertainment’ (Cunningham &amp; Craig, 2016). Such employment is rapidly growing as a career path for those who achieve financial success in their game broadcasting. Particular demographics have already been seen to dominate the practice: streamers from the United States, for example, tend to be adults under the age of 25, earning under 50,000 dollars annually, and predominantly but not exclusively male (Quantcast, <span>2016<span><span><span>Quantcast</span>. (<span>2016</span>). Twitch.tv. Available from <a  href="https://www.quantcast.com/twitch.tv#demographicsCard">https://www.quantcast.com/twitch.tv#demographicsCard</a>, accessed on 04/11/2016.<span> <span><a  href="http://scholar.google.com/scholar?hl=en&amp;q=Quantcast.+%282016%29.+Twitch.tv.+Available+from+https%3A%2F%2Fwww.quantcast.com%2Ftwitch.tv%23demographicsCard%2C+accessed+on+04%2F11%2F2016.">[Google Scholar]</a></span></span></span></span></span>). This is comparable to those who compete in professional video gaming (Taylor, <span>2012<span><span><span>Taylor, <span>T. L.</span></span> (<span>2012</span>). <em>Raising the stakes</em>. <span>Cambridge, MA</span>: <span>MIT Press</span>.<span> <span><a href="/servlet/linkout?suffix=CIT0036&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.7551%2Fmitpress%2F8624.001.0001">[Crossref]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2012&amp;author=T.+L.+Taylor&amp;title=Raising+the+stakes">[Google Scholar]</a></span></span></span></span></span>), another new media industry enabled by the play and broadcast of video games. Nevertheless, those who make up this streaming demographic have not been examined beyond simply these demographic markers, and why they pursue streaming careers is entirely unexplored. We are, therefore, without data to understand the careers and aspirations of these new media workers, or how the lives of young people are being transformed through their streaming practices. This paper offers a first step towards answering these questions.</p>
<h2>Methodology</h2>
<p>Interviews were carried out during the three-day 2016 ‘TwitchCon’ event in San Diego, for which <em>Twitch’s</em> European division provided us with ‘Special Guest’ passes that ensured access to all areas of the event. TwitchCon is an event with attendance in the thousands, designed to enable broadcasters to meet their fans, fans to meet their favourite broadcasters, and the sale of numerous first-party and third-party goods and merchandise. These were semi-structured interviews (Schmidt, <span>2004<span><span><span>Schmidt, <span>C.</span></span> (<span>2004</span>). <span>The analysis of semi-structured interviews</span>. In <span><span>U.</span> Flick</span>, <span><span>E.</span> von Kardoff</span>, &amp; <span><span>I.</span> Steinke</span> (Eds.), <em>A companion to qualitative research</em> (pp. <span>253</span>–<span>258</span>). <span>London, Thousand Oaks, New Delhi</span>: <span>SAGE Publications</span>.<span> <span><a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2004&amp;pages=253-258&amp;author=C.+Schmidt&amp;title=A+companion+to+qualitative+research">[Google Scholar]</a></span></span></span></span></span>), in which we questioned respondents about their lives as streamers, their experiences of ‘professionalization’ towards becoming full-time earners on <em>Twitch</em>, and their personal reflections on the platform and the rapid growth of streaming as a practice. We acquired 39 interviews with ‘partnered’ streamers, those who are popular enough that they earn part of the advert revenue on their streams, can offer viewers the opportunity to subscribe, and can also gain income through players ‘cheering’ for them (financial micro-transactions), by securing merchandising deals, by joining an ‘Affiliate’ programme with Amazon (for those in the US), and through ‘tips’ or ‘donations’ from viewers via off-platform sites such as Paypal. Of these partners, approximately half streamed as their full-time source of income, the majority of the remainder were streaming as part-time income and aspired to quit their other jobs, and a small number maintained non-<em>Twitch</em> jobs and used the platform for pleasure and additional income. Interviews lasted up to half an hour, and were facilitated primarily through our own recruiting during the conference, and in a small number of cases with the assistance of <em>Twitch</em> staff (who helped find gaps in the schedules of the most famous streamers).</p>
<p>Our sampling strategy, therefore, relied on the guidance of insiders, along with deliberately seeking out a range of participants. This started from an understanding of the gendering (Harvey &amp; Fisher, <span>2013<span><span><span>Harvey, <span>A.</span></span>, &amp; <span>Fisher, <span>S.</span></span> (<span>2013</span>). <span>Making a name in games: Immaterial labour, indie game design, and gendered social network markets</span>. <em>Information, Communication and Society</em>, <em>16</em>(3), <span>362</span>–<span>380</span>. doi: <span>10.1080/1369118X.2012.756048</span><span> <span><a href="https://www-tandfonline-com.wwwproxy1.library.unsw.edu.au/doi/10.1080/1369118X.2012.756048">[Taylor &amp; Francis Online]</a>, <a href="/servlet/linkout?suffix=CIT0016&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000319101500005">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=16&amp;publication_year=2013&amp;pages=362-380&amp;issue=3&amp;author=A.+Harvey&amp;author=S.+Fisher&amp;title=Making+a+name+in+games%3A+Immaterial+labour%2C+indie+game+design%2C+and+gendered+social+network+markets&amp;doi=10.1080%2F1369118X.2012.756048">[Google Scholar]</a></span></span></span></span></span>) and racialising (Gill, <span>2010<span><span><span>Gill, <span>R.</span></span> (<span>2010</span>). <span>Life is a pitch: Managing the self in new media work</span>. In <span><span>M.</span> Deuze</span> (Ed.), <em>Managing media work</em> (pp. <span>249</span>–<span>262</span>). <span>London</span>: <span>SAGE Publishing</span>.<span> <span><a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2010&amp;pages=249-262&amp;author=R.+Gill&amp;title=Managing+media+work">[Google Scholar]</a></span></span></span></span></span>) of new media work, as apparent on <em>Twitch</em> as any other media platform (Gray, <span>2017<span><span><span>Gray, <span>K. L.</span></span> (<span>2017</span>). <span>They’re just too urban’: Black gamers streaming on Twitch</span>. In <span><span>J.</span> Daniels</span>, <span><span>K.</span> Gregory</span>, &amp; <span><span>T.</span> McMillan Cottom</span> (Eds.), <em>Digital sociologies</em> (pp. <span>355</span>–<span>369</span>). <span>Bristol</span>: <span>Policy Press</span>.<span> <span><a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2017&amp;pages=355-369&amp;author=K.+L.+Gray&amp;title=Digital+sociologies">[Google Scholar]</a></span></span></span></span></span>, p. 355), and research should thereby ensure that their voices are granted equal attention. We, therefore, attempted to seek out a range of different views from partnered streamers, particularly looking for potentially marginalised perspectives. Transcripts totalling over 50,000 words were coded by the authors in keeping with a grounded theory methodological orientation (Corbin &amp; Strauss, <span>1990<span><span><span>Corbin, <span>M.</span></span>, &amp; <span>Strauss, <span>S.</span></span> (<span>1990</span>). <span>Grounded theory research: Procedures, canons, and evaluative criteria</span>. <em>Qualitative Sociology</em>, <em>13</em>(1), <span>3</span>–<span>21</span>. doi: <span>10.1007/BF00988593</span><span> <span><a href="/servlet/linkout?suffix=CIT0006&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1007%2FBF00988593">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0006&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=A1990ER75400002">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=13&amp;publication_year=1990&amp;pages=3-21&amp;issue=1&amp;author=M.+Corbin&amp;author=S.+Strauss&amp;title=Grounded+theory+research%3A+Procedures%2C+canons%2C+and+evaluative+criteria&amp;doi=10.1007%2FBF00988593">[Google Scholar]</a></span></span></span></span></span>), designed to allow any and all themes to arise from the data with minimal intervention from preconceived notions. Through this process, it became clear that three temporal themes were at the forefront of streamers’ thinking about their activities, and structured their reflections on their streaming careers. These are the origins and motivations behind their streaming activity, the particular forms of labour required for everyday successful streaming and streamers’ perceptions of the future of both their streaming activity and <em>Twitch</em> itself. It is these we examine in this paper.</p>
<p>However, we should also note limitations of this initial study, which is part of an ongoing multi-year research project into live-streaming. We focused here on one event and on successful streamers; this was because we sought primarily to examine the processes of ‘professionalization’ and career-development by those who pursue <em>Twitch</em> streaming as their primary source of income. The largest annual gathering of those who make their full-time income from the practice, and those who aspire to do so, was an obvious research site. However, numerous other avenues of research presented themselves during the study, three of which are particularly clear. Firstly, the examination of those who constitute the long tail of <em>Twitch</em> (millions of non-professional streamers); secondly, those who stream the range of non-video game <em>Twitch</em> content; and thirdly, how demographic differences shape <em>Twitch</em> experiences for its users. Future publications from this research project will address such questions, but our focus here is on the lives and careers of those who make, or seek to make, a full-time income from their streaming practice. These interviews on these topics offer the broadest scholarly examination of the experiences of professionalised and professionalising streamers to date, something that has previously been held back by a lack of access to the professional and aspiring-professional community. Our ability to attend the most important annual event in the streaming community, and to have unlimited access offered by <em>Twitch</em>, resolved these difficulties; by talking directly to streamers in person, we are able to analyse the phenomenon through the perspectives and life stories of those pursuing these distinctive new career paths.</p>
<h2>How do people become streamers?</h2>
<p>We begin by examining the origins of streamers, who recounted several different routes into the practice. The first dominant path into <em>Twitch</em> we uncovered was through streamers’ existing experiences, and in some cases employed work, within ‘eSports’ or professional competitive video game competition. Professional gaming is a practice that has grown substantially in recent years, supported by the easy broadcast of tournaments through live streaming platforms (Hutchins, <span>2008<span><span><span>Hutchins, <span>B.</span></span> (<span>2008</span>). <span>Signs of meta-change in second modernity: the growth of e-Sport and the world cyber games</span>. <em>New Media &amp; Society</em>, <em>10</em>(6), <span>851</span>–<span>869</span>. doi: <span>10.1177/1461444808096248</span><span> <span><a href="/servlet/linkout?suffix=CIT0017&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1177%2F1461444808096248">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0017&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000260839500003">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=10&amp;publication_year=2008&amp;pages=851-869&amp;issue=6&amp;author=B.+Hutchins&amp;title=Signs+of+meta-change+in+second+modernity%3A+the+growth+of+e-Sport+and+the+world+cyber+games&amp;doi=10.1177%2F1461444808096248">[Google Scholar]</a></span></span></span></span></span>, p. 857) such as <em>Twitch</em>, as well as deep grass-roots movements. Over a hundred million people watched eSports tournaments in 2015 (Kresse, <span>2016<span><span><span>Kresse, <span>C.</span></span> (<span>2016</span>). eSports in 2015 by the numbers: Attendance figures, investments and prize money, <em>Esports Marketing Blog</em>.<span> <span><a  href="http://scholar.google.com/scholar?hl=en&amp;q=Kresse%2C+C.+%282016%29.+eSports+in+2015+by+the+numbers%3A+Attendance+figures%2C+investments+and+prize+money%2C+Esports+Marketing+Blog.">[Google Scholar]</a></span></span></span></span></span>) that awarded over $65 million prize money; such growth represents the ‘legitimization of gaming as spectator sport’ (Taylor, <span>2016a<span><span><span>Taylor, <span>N.</span></span> (<span>2016a</span>). <span>Play to the camera: Video ethnography, spectatorship, and e-sports</span>. <em>Convergence: The International Journal of Research Into New Media Technologies</em>, <em>22</em>(2), <span>115</span>–<span>130</span>. doi: <span>10.1177/1354856515580282</span><span> <span><a href="/servlet/linkout?suffix=CIT0033&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1177%2F1354856515580282">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0033&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000377598700001">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=22&amp;publication_year=2016a&amp;pages=115-130&amp;issue=2&amp;author=N.+Taylor&amp;title=Play+to+the+camera%3A+Video+ethnography%2C+spectatorship%2C+and+e-sports&amp;doi=10.1177%2F1354856515580282">[Google Scholar]</a></span></span></span></span></span>, p. 115). Following from such a definition, we consider streaming to be the legitimisation of gaming as a spectator <em>activity</em> more broadly, and <em>Twitch</em> opening up a space for ‘communities of practice’ (Burroughs &amp; Rama, <span>2015<span><span><span>Burroughs, <span>B.</span></span>, &amp; <span>Rama, <span>P.</span></span> (<span>2015</span>). <span>The eSports Trojan Horse: Twitch and streaming futures’</span>. <em>Journal of Virtual Worlds Research</em>, <em>8</em>(2), <span>1</span>–<span>5</span>. doi: <span>10.4101/jvwr.v8i2.7176</span><span> <span><a href="/servlet/linkout?suffix=CIT0004&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.4101%2Fjvwr.v8i2.7176">[Crossref]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=8&amp;publication_year=2015&amp;pages=1-5&amp;issue=2&amp;author=B.+Burroughs&amp;author=P.+Rama&amp;title=The+eSports+Trojan+Horse%3A+Twitch+and+streaming+futures%E2%80%99&amp;doi=10.4101%2Fjvwr.v8i2.7176">[Google Scholar]</a></span></span></span></span></span>, p. 3) where people learn to play video games. In the case of <em>Twitch</em>, these are comprised of ‘gamer-spectators’ (Hamilton, Garretson, &amp; Kerne, <span>2014<span><span><span>Hamilton, <span>W. A.</span></span>, <span>Garretson, <span>O.</span></span>, &amp; <span>Kerne, <span>A.</span></span> (<span>2014</span>). <span><em>Streaming on twitch: Fostering participatory communities of play within live mixed media</em></span>. <span>CHI '14 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</span>, <span>Toronto</span>, <span>April 26-May 1 2014</span>.<span> <span><a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2014&amp;author=W.+A.+Hamilton&amp;author=O.+Garretson&amp;author=A.+Kerne&amp;title=Streaming+on+twitch%3A+Fostering+participatory+communities+of+play+within+live+mixed+media">[Google Scholar]</a></span></span></span></span></span>, p. 1315). They provide an important opportunity for competitive players to learn and improve, and given the high skill levels required for such competition, there is a clear motivation towards both streaming and watching streams. For example, P2 starting streaming because they were ‘a competitive Counter-Strike player’ and ‘watched eSports’, whilst another respondent P3 had been a ‘shoutcaster’ ‒ someone who commentates over competitive play online, rather than a formal tournament context ‒ for several years. They had found success in this area, before then ‘stepping back’ into a producer role, producing ‘a variety of different online leagues and tournaments as well as work[ing] with <em>Twitch</em> almost every day [to] help just create more buzz within the community of <em>Twitch</em> in general’. This crossover between eSports and streaming was also found with P4 who organised live tournaments of <em>Super Smash Brothers Melee</em> (2001) and streamed the game, along with P5, who broadcast tournaments and built their stream while assisting a major eSports team with their publicity. This route of entry into <em>Twitch</em> represents an extension of existing eSports behaviours into a more personalised and individual form, through the growth of streamers’ own eSports channels, and the application of existing digital skills into a new potentially profitable context.</p>
<p>The second route into streaming identified from the interview data was getting into streaming via other online platforms that are not necessarily themselves ‘gaming’ platforms, but have many gamers active on them, and with communities that integrate closely with wider gaming culture. Gamers have long socialised via the communities that spring up in the ‘mediated environments’ (Dalisay, Kushin, Yamamoto, Liu, &amp; Skalski, <span>2015<span><span><span>Dalisay, <span>F.</span></span>, <span>Kushin, <span>M. J.</span></span>, <span>Yamamoto, <span>M.</span></span>, <span>Liu, <span>Y. I.</span></span>, &amp; <span>Skalski, <span>P.</span></span> (<span>2015</span>). <span>Motivations for game play and the social capital and civic potential of video games</span>. <em>New Media and Society</em>, <em>17</em>(9), <span>1399</span>–<span>1417</span>. doi: <span>10.1177/1461444814525753</span><span> <span><a href="/servlet/linkout?suffix=CIT0008&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1177%2F1461444814525753">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0008&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000361127400001">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=17&amp;publication_year=2015&amp;pages=1399-1417&amp;issue=9&amp;author=F.+Dalisay&amp;author=M.+J.+Kushin&amp;author=M.+Yamamoto&amp;author=Y.+I.+Liu&amp;author=P.+Skalski&amp;title=Motivations+for+game+play+and+the+social+capital+and+civic+potential+of+video+games&amp;doi=10.1177%2F1461444814525753">[Google Scholar]</a></span></span></span></span></span>, p. 1414) of virtual online worlds; for lots of our interviewees, <em>Twitch</em> was a logical expansion of such existing social ties and obligations. Many interviewees had come to streaming via <em>YouTube</em>, the dominant world-leader in video uploading and sharing, with a strong gaming community that is over a decade old. Given their overlap in video production, this was not surprising, whilst interviewees stressed the desire for <em>live</em> feedback and viewer interaction being a key part of their transitions into <em>Twitch</em>. P6 had begun their career making videos on <em>YouTube</em>, but they ‘didn’t really enjoy the feedback’ because it ‘wasn’t instant’, so they tried <em>Twitch</em>; ‘the moment we started we had a few viewers, and automatically knew that it was something suited more for our style, having the instant feedback’. Similarly, P7 emphasised that <em>Twitch</em> has ‘great ways to interact with your viewers’, and they wanted to expand their existing work on <em>YouTube</em> ‘to a new platform in a way that’s engaging’ and helps their viewers ‘connect with me as a creator’. The connectivity of <em>Twitch</em> was clearly a strong draw when contrasted with existing platforms, allowing people to connect with those they had already forged social gaming ties with.</p>
<p>Alongside <em>YouTube</em>, other routes from other kinds of gaming practice were also visible, such as coming to streaming via <em>Reddit</em> (a popular news aggregation and discussion website with a strong gamer presence), via games blogging across a range of platforms and desire to connect more closely with one’s fans, and ‘modding’ ‒ the practice of programming alterations to existing games and then distributing those ‘modded’ (modified) versions. P8 was previously a games blogger, but then ‘discovered <em>Twitch</em>, and I decided that talking about games and getting the immediate feedback was so much more fun than writing a blog post’ and having to wait for a period before any feedback came through; another respondent, P9, transitioned from being a creator of <em>Minecraft</em> mods, stating that ‘I basically started streaming just to show people how to make mod packs in <em>Minecraft</em> and that quickly escalated’. Similar but somewhat distinctive was the story of P10, who said that they were ‘found’ by the ‘right person’ who advertised them heavily in the gaming community on <em>Reddit</em>, resulting in a massive influx of traffic to their channel which launched them rapidly to their currently success, going from starting streaming to being a <em>Twitch</em> partner in under a month ‒ an incredibly short length of time for a process that takes years for many thousands, and can feel unattainable indefinitely for millions of others. Gaming communities are complex and often multi-site social phenomena (Seay, Jerome, Lee, &amp; Kraut, <span>2004<span><span><span>Seay, <span>A. F.</span></span>, <span>Jerome, <span>W.</span></span>, <span>Lee, <span>K. S.</span></span>, &amp; <span>Kraut, <span>R. E.</span></span> (<span>2004</span>). <span><em>Project massive: A study of online gaming communities</em></span>. <span>CHI'04 extended abstracts on Human factors in computing systems</span>, <span>Vienna</span>, <span>24-29 April, 2004</span>.<span> <span><a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2004&amp;author=A.+F.+Seay&amp;author=W.+Jerome&amp;author=K.+S.+Lee&amp;author=R.+E.+Kraut&amp;title=Project+massive%3A+A+study+of+online+gaming+communities">[Google Scholar]</a></span></span></span></span></span>), and such routes into <em>Twitch</em> demonstrate the ready transition of gamers from one medium of gaming culture into another, and the ability to bring in fans that one had already accrued on other platforms, whilst connecting more easily with new fans.</p>
<p>Interviewees, therefore, presented stories of being deeply involved in another gaming practice or community, and moving over to <em>Twitch</em> as the logical extension of existing behaviours. Considering both of these paths ‒ involvement in the competitive gaming industry, and involvement in digital gaming culture and content production ‒ it is clear that <em>Twitch</em> streaming is not a self-contained phenomenon. It is deeply interwoven with the convergence of existing platforms and practices through which gamers both produce and consume content, but <em>Twitch</em> in all cases has given a new <em>immediacy</em> and (perceived) <em>intimacy</em> between the producer and the consumer. Content creators from other digital domains and communities are shifting towards <em>Twitch</em> for these reasons, and these moves represent a shift towards content that promotes ‘social presence’ ‒ the degree to which a medium conveys the actual presence of those who are communicating (Short, Williams, &amp; Christie, <span>1976<span><span><span>Short, <span>J.</span></span>, <span>Williams, <span>E.</span></span>, &amp; <span>Christie, <span>B.</span></span> (<span>1976</span>). <em>The social psychology of telecommunications</em>. <span>London</span>: <span>John Wiley &amp; Sons</span>.<span> <span><a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=1976&amp;author=J.+Short&amp;author=E.+Williams&amp;author=B.+Christie&amp;title=The+social+psychology+of+telecommunications">[Google Scholar]</a></span></span></span></span></span>). <em>Twitch</em> is live, with its broadcasters visible on webcam, with conversations possible through the near-instantaneous chat window, and the ability of viewers to take actions visible on the channel (donating, subscribing, and so forth). These affordances of the platform are all ways for both streamers and viewers to enhance their visibility to the other, and <em>Twitch</em> is thereby extremely appealing for those already creating game content and seeking more intimate interaction with their viewers; such potential has led the way in the adoption of <em>Twitch</em> by those who are now professional or aspiring-professional streamers.</p>
<h2>The work of streaming</h2>
<p>Once people have opened their <em>Twitch</em> channel, what is streaming actually like? Our interviews explored streamers’ experiences of work and labour in streaming, and it was immediately clear that previous experiences outside of <em>Twitch</em> had fundamentally shaped interviewees’ attitudes to streaming. There were streamers who had worked – or continued to if they were not streaming full-time – as a software developer, graduate teaching assistant, stay-at-home parent, IT technician, registered nurse, teacher, sales manager, freelance graphic designer, public relations employee, and casino dealer – or were previously unemployed or studying. A number of interviewees had actually studied related degrees in higher education, such as journalism, film production, communication, and radio production. However, there were also streamers with less related educational backgrounds like political science and economics, and urban planning – although this degree choice did make more sense when we discovered that the interviewee had a passion for city-building games like the recently released <em>Cities: Skylines</em>. Other than the interviewee who had studied streaming for their Master’s dissertation, the application of traditional university education to online streaming was more complicated than a simple transition of skills or interests. As P11 explains:</p>
<blockquote>
<p>[My degree] was good in the sense that I practiced creating content, [but] I would hope that I am correct in assuming that, very soon, we’ll see maybe modern versions of the education that I took, [such as] an education that’s saying ‘we want you to create content online’.</p>
</blockquote>
<p>The lack of formal training or education on offer to streamers meant that many had developed their abilities independently. For those who grew up with digital technologies, this was not seen as a challenge. For example, ‘I learnt it by myself […] and just by getting into it, doing it every single day, you will get used to of it and you learn more’ (P12), whilst another interviewee, P4, described themselves as ‘mostly entirely self-taught. There's enough documentation online for anyone to become a streamer’. Similarly, P13 was keen to explain that their channel ‘specifically was the first to do 720 [a high-definition video format] and […] the video guy told us we couldn’t do it, so we did it’. This particular demonstration of technical knowledge, particularly when they had been told it was not possible, comes from a ‘passion for pushing things stronger, faster, making the stream better, the community and all of that’. Technical skill, as Kirkpatrick (<span>2004<span><span><span>Kirkpatrick, <span>G.</span></span> (<span>2004</span>). <em>Critical technology: A social theory of personal computing</em>. <span>Aldershot</span>: <span>Ashgate</span>.<span> <span><a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2004&amp;author=G.+Kirkpatrick&amp;title=Critical+technology%3A+A+social+theory+of+personal+computing">[Google Scholar]</a></span></span></span></span></span>, p. 23) has pointed out, is important in ‘contemporary computer culture’, just as Taylor (<span>2006<span><span><span>Taylor, <span>T. L.</span></span> (<span>2006</span>). <em>Play between worlds: Exploring online game culture</em>. <span>Cambridge, MA</span>: <span>MIT Press</span>.<span> <span><a href="/servlet/linkout?suffix=CIT0035&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.7551%2Fmitpress%2F5418.001.0001">[Crossref]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2006&amp;author=T.+L.+Taylor&amp;title=Play+between+worlds%3A+Exploring+online+game+culture">[Google Scholar]</a></span></span></span></span></span>, p. 72) has noted that ‘power gamers’ place a high value on ‘technical skill and proficiency’. Skills were seen as central to both streaming and streamers’ senses of self-worth and ability, but skills and knowledge taught in a traditional <em>university</em> environment, even one meant to prepare the individual for a range of jobs including those that might be within the digital economy or new media, seemed inadequate, inappropriate, and simply unnecessary.</p>
<p>The amount of working time that the interviewees devoted to streaming was significant, often far more than the 35 hours that, for example, equates to full-time employment in the United Kingdom. P14 explains that they were streaming ‘fifteen hours a day to launch things […] I mean my first three months of <em>Twitch</em> was nearly every waking moment’, while P15 would stream ‘say 70, over 70 hours a week’ and ‘not take a single day off aside from those main critical days, emergency so on so forth’. Many of the interviewees balanced – or at least had to balance – streaming alongside other forms of paid work. For example, one streamer worked eight hours as a registered nurse, would ‘come home and stream eight hours, sleep like four [laughter]’ (P16). This experience was compared by P13 to working in IT with upwards of ‘90 hour weeks’. Although they explained they still do that many hours as a professional streamer, ‘the difference is, the work that I’m doing now is 100% passion driven’. This kind of work ethic was stressed as part of the necessary process of becoming partnered by <em>Twitch</em>, but extremely hard to sustain in the long term. For example, P5 explained they would</p>
<blockquote>
<p>wake up around 7. I had to go to work 9am. then I came back home at 6pm when I started my stream and I streamed till 1 or 2. So it was really just exhausting [be]cause I had no time for myself.</p>
</blockquote>
<p>For those streamers that successfully maintained such an arduous schedule and became partnered, there was then a tendency to reduce the amount of time streaming – although this did not necessarily mean less work overall. For P17, it would be around four hours each day, between ‘2 to 6 […] so a good amount of time’. Another very successful streamer explained that ‘generally I wake up in the afternoon. I have a cup of tea, some biscuits, some breakfast. Then I just stream whatever I feel like, whatever I’m into’. The benefit of streaming was that they were their ‘own boss. […] I can make my own hours. […] I average between six and seven hours five days a week’ (P1). However, in addition to the activity of streaming, ‘there’s a lot that goes into it behind the scenes’ (P1). This involves general preparation for the stream: what game is going to be played, ensuring the technical aspect set up and calibrated correctly, discussion topics, and so on. There are also administrative tasks like answering emails, and maintaining contacts and networking, all of which become increasingly central as the popularity and reach of one’s channel grows. The time investments towards the acquisition of celebrity status are large in any domain (Wajcman, <span>2015<span><span><span>Wajcman, <span>J.</span></span> (<span>2015</span>). <em>Pressed for time: The acceleration of life in digital capitalism</em>. <span>Chicago</span>: <span>University of Chicago Press</span>.<span> <span><a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2015&amp;author=J.+Wajcman&amp;title=Pressed+for+time%3A+The+acceleration+of+life+in+digital+capitalism">[Google Scholar]</a></span></span></span></span></span>) and we see this trend reflected very strongly in the substantial temporal investments made by both aspiring streamers seeking to build a channel, and already-successful streamers seeking to maintain one.</p>
<p>In addition to the discussion of the number of hours worked, many interviewees addressed what makes a successful streamer ‒ this is a particularly interesting topic given the newness of the game streaming phenomenon and the flexibility of career path we have already commented on. As P14 explains, ‘if you’re a little bit of a social butterfly I think streaming works really well’, a comment which contrasts sharply with pop-cultural tropes of video game players as quiet, reclusive, and introverted. Others provided quite vague advice, like ‘what has helped me do that I don’t really know … probably consistency, like always having a schedule and sticking to it’ (P17). Having a regular slot in which viewers can find the stream was clearly important, making it different to other Video on Demand (VoD) services like <em>YouTube</em>. In other interviews, more abstract factors were credited with success, such as being ‘100% passion driven and the huge difference between [traditional work is that] my workload is more, it’s more stressful in a lot of ways, it’s harder, it’s heavier because you’re chasing a dream’ (P13). Many streamers discussed setting themselves targets – numbers of viewers, becoming partners, subscriptions, and so on – and that this could push a streamer forward to become successful. For example, P15 explained that: ‘I had a lot of goals set and I wanted to meet those goals so I did whatever it took to meet them’. Such discourses reflect an internalisation of the metricisation of success according to the ‘popularity principle’ (Van Dijck, <span>2013<span><span><span>Van Dijck, <span>J.</span></span> (<span>2013</span>). <em>The culture of connectivity: A critical history of social media</em>. <span>Oxford, New York</span>: <span>Oxford University Press</span>.<span> <span><a href="/servlet/linkout?suffix=CIT0039&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1093%2Facprof%3Aoso%2F9780199970773.001.0001">[Crossref]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2013&amp;author=J.+Van+Dijck&amp;title=The+culture+of+connectivity%3A+A+critical+history+of+social+media">[Google Scholar]</a></span></span></span></span></span>), a feature of online platforms of this sort whose algorithmic structures emphasise hierarchy and competition, with those at the top attaining a disproportionately high volume of attention and interest compared to those at the bottom. Understanding that rewards are distributed in an extremely top-heavy fashion, streamers were both aspiring to reach those heights and reflecting back with varying degrees of criticality upon what they thought it would take in order to obtain those goals.</p>
<p>There was, therefore, also clear neoliberal subjectivity presented in the interviews, through which streamers argued that hard work, in streaming, is automatically rewarded. For example, ‘it’s basically the hard work you’re willing to put in’ (P18); ‘in the end it’s all about you and it’s all about you working your hardest’ (P15); ‘there’s no shortcuts of this platform or any kind of content creation but it’s absolutely worth the time you put in’ (P7); and ‘basically the end of the day we’re entrepreneurs in this environment because we are our own bosses’ (P9). This is a development of what Cunningham and Craig (<span>2016<span><span><span>Cunningham, <span>S.</span></span>, &amp; <span>Craig, <span>D.</span></span> (<span>2016</span>). <span>Online entertainment: A new wave of media globalization?</span> <em>International Journal of Communication</em>, <em>10</em>, <span>5409</span>–<span>5425</span>.<span> <span><a href="/servlet/linkout?suffix=CIT0007&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000391147100001">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=10&amp;publication_year=2016&amp;pages=5409-5425&amp;author=S.+Cunningham&amp;author=D.+Craig&amp;title=Online+entertainment%3A+A+new+wave+of+media+globalization%3F">[Google Scholar]</a></span></span></span></span></span>, p. 5413) have analysed as ‘a rapidly professionalizing and monetizing wave of diverse, multicultural, previously amateur content creators from around the world’ who have successfully ‘harnessed these platforms to incubate their own media brands, engage in content innovation, and cultivate often massive, transnational, and cross-cultural fan communities’. This emphasis on work ethic from the streamer ties in with the broader trends of de-industrialisation: the decline in long-term management employment and the growth of precarious service work. This has taken place alongside an ‘effective strategy of subjectification’ which encourages people to see themselves as ‘companies of one’, as ‘individuals for whom every action, from taking courses on a new computer software application to having their teeth whitened, can be considered an investment in human capital’ (Read, <span>2009<span><span><span>Read, <span>J.</span></span> (<span>2009</span>). <span>A genealogy of homo-economicus: Neoliberalism and the production of subjectivity</span>. <em>Foucault Studies</em>, <em>6</em>, <span>25</span>–<span>36</span>. doi: <span>10.22439/fs.v0i0.2465</span><span> <span><a href="/servlet/linkout?suffix=CIT0025&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.22439%2Ffs.v0i0.2465">[Crossref]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=6&amp;publication_year=2009&amp;pages=25-36&amp;author=J.+Read&amp;title=A+genealogy+of+homo-economicus%3A+Neoliberalism+and+the+production+of+subjectivity&amp;doi=10.22439%2Ffs.v0i0.2465">[Google Scholar]</a></span></span></span></span></span>, p. 30). Success is seen as the ‘result of accomplished self-regulation’, whilst failure is a ‘symptom and consequence of a failure of self and self-regulation – the failure of insufficient enterprise’ (Storey, Salaman, &amp; Platman, <span>2005<span><span><span>Storey, <span>J.</span></span>, <span>Salaman, <span>G.</span></span>, &amp; <span>Platman, <span>K.</span></span> (<span>2005</span>). <span>Living with enterprise in an enterprise economy: Freelance and contract workers in the media</span>. <em>Human Relations</em>, <em>58</em>(8), <span>1033</span>–<span>1054</span>. doi: <span>10.1177/0018726705058502</span><span> <span><a href="/servlet/linkout?suffix=CIT0032&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1177%2F0018726705058502">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0032&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000232777100004">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=58&amp;publication_year=2005&amp;pages=1033-1054&amp;issue=8&amp;author=J.+Storey&amp;author=G.+Salaman&amp;author=K.+Platman&amp;title=Living+with+enterprise+in+an+enterprise+economy%3A+Freelance+and+contract+workers+in+the+media&amp;doi=10.1177%2F0018726705058502">[Google Scholar]</a></span></span></span></span></span>, p. 1036). In this way, the act of playing video games – albeit now in front of an online audience – has become an option for the hardworking ‘homo economicus’ (the supposed rational economic man), that Foucault (<span>2008<span><span><span>Foucault, <span>M.</span></span> (<span>2008</span>). <em>The birth of biopolitics: Lectures at the collège de France, 1978–1979</em> (G. Burchell, Trans.). <span>New York, NY</span>: <span>Palgrave Macmillan</span>.<span> <span><a href="/servlet/linkout?suffix=CIT0009&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1057%2F9780230594180">[Crossref]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2008&amp;author=M.+Foucault&amp;title=The+birth+of+biopolitics%3A+Lectures+at+the+coll%C3%A8ge+de+France%2C+1978%E2%80%931979">[Google Scholar]</a></span></span></span></span></span>, p. 226) defines as ‘an entrepreneur, an entrepreneur of himself’. The platform has, therefore, provided the opportunity for the hosting and development of an incredibly driven layer of young people seeking to make a living from the broadcasting of their own game playing. As we have shown in this section, this far from a straightforward process and it is clear that it entails a multiplicity of skills, practices and engagements that go far beyond simply ‘playing games’.</p>
<h2>The future: Twitch and Twitch streamers</h2>
<h3>Streamer futures</h3>
<p>Having considered the past – how streamers begin streaming ‒ and the present ‒ what they do when they stream – we then turned to streamers’ perceptions of the <em>future</em> of their practice. The responses fall into two groups: perceptions of the viability of their individual futures (if any) on <em>Twitch</em>, and their thoughts on the future of <em>Twitch</em> and streaming as a whole. In the first instance, all streamers we interviewed except two (who were retired and planning retirement from streaming) were strongly committed to continue streaming as long as possible. This included statements that ‘I’ll stream as long as I can’ (P5), ‘I would love to pursue this no matter what and if I could, and if I wanted, I would love to stream for the rest of my life’ (P15), and ‘I love doing what I do, and I hope to continue it for some more years to come’ (P12). Such comments demonstrated that despite the substantial amounts of time and effort investment needed to stream successfully, alongside the emotional and background labour, streamers still tremendously enjoy their work and want it to continue indefinitely. Vorderer, Klimmt, and Ritterfeld (<span>2004<span><span><span>Vorderer, <span>P.</span></span>, <span>Klimmt, <span>C.</span></span>, &amp; <span>Ritterfeld, <span>U.</span></span> (<span>2004</span>). <span>Enjoyment: At the heart of media entertainment</span>. <em>Communication theory</em>, <em>14</em>(4), <span>388</span>–<span>408</span>. doi: <span>10.1111/j.1468-2885.2004.tb00321.x</span><span> <span><a href="/servlet/linkout?suffix=CIT0040&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1111%2Fj.1468-2885.2004.tb00321.x">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0040&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000225133700007">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=14&amp;publication_year=2004&amp;pages=388-408&amp;issue=4&amp;author=P.+Vorderer&amp;author=C.+Klimmt&amp;author=U.+Ritterfeld&amp;title=Enjoyment%3A+At+the+heart+of+media+entertainment&amp;doi=10.1111%2Fj.1468-2885.2004.tb00321.x">[Google Scholar]</a></span></span></span></span></span>, p. 394) argue that ‘a certain sense of achievement, control, and self-efficacy is associated with playing computer games’, just as Ryan, Rigby, and Przybylski (<span>2006<span><span><span>Ryan, <span>R. M.</span></span>, <span>Rigby, <span>C. S.</span></span>, &amp; <span>Przybylski, <span>A.</span></span> (<span>2006</span>). <span>The motivational pull of video games: A self-determination theory approach</span>. <em>Motivation and Emotion</em>, <em>30</em>(4), <span>347</span>–<span>363</span>. doi: <span>10.1007/s11031-006-9051-8</span><span> <span><a href="/servlet/linkout?suffix=CIT0026&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1007%2Fs11031-006-9051-8">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0026&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000242830600009">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=30&amp;publication_year=2006&amp;pages=347-363&amp;issue=4&amp;author=R.+M.+Ryan&amp;author=C.+S.+Rigby&amp;author=A.+Przybylski&amp;title=The+motivational+pull+of+video+games%3A+A+self-determination+theory+approach&amp;doi=10.1007%2Fs11031-006-9051-8">[Google Scholar]</a></span></span></span></span></span>) argue that the impact of games on personal well-being is strongest when players feel competent and skilled during play; drawing on such understandings, we, therefore, suggest that the feeling of being a skilled and competent <em>streamer</em> is one that brings a strong sense of self-actualisation and personal well-being, and that such feelings merit the time and effort investments they require.</p>
<p>However, despite their commitment to and enjoyment of the career path, almost all respondents felt a clear sense of precariousness in their streaming activities. P19 emphasised the importance of having what they called a ‘backup plan’, essential because ‘I know realistically that I’m not going to be able to be a streamer forever’. They suggested this could be due to being unable to stream any more, or if streaming for ‘whatever reason is not viable’ in the future; similarly, P13 put an equally high value on ‘stability’, which they defined as ‘getting that constant income to make sure that I have my nest egg’ in case of ‘accidental things’ that might end a streaming career. Shedding light on such perspectives, P12 stated ‘I don’t think anybody can say [where] live-streaming, eSports or YouTube will end up in five, ten years’, whilst P20 said ‘we will see how long the industry lasts’ as a prelude to discussing their own long-term plans for remaining part of, or leaving, <em>Twitch</em>. All of these comments demonstrate a strong awareness of the fundamental <em>newness</em> of streaming as a career path, and – although (as we explore below) streamers took great pride in this newness – streamers were concerned about the long-term viability of such a disruptive new media form.</p>
<p>Interviewees in turn proposed explicit backup plans ‒ P19 intended to do more charity work and convert their existing charity-focused <em>Twitch</em> channel into a non-profit, or work for another non-profit they already support through their gaming; P13 was looking for jobs at <em>Twitch</em> or a third-party company working with them, and saw streaming as a route into such a career; a third P15 proposed transitioning out of streaming into mentoring those who wanted to stream professionally, which was echoed by P21 who claimed that many streamers they had spoken to were thinking along similar lines. The most astute streamers are, therefore, <em>already</em> trying to position themselves for an escape from such a precarious career, whilst also trying to make the most of this career opportunity whilst it lasts. Such a pressure ‒ even if it means sacrificing a job all seem to enjoy so deeply ‒ shows how these streamers have not escaped the contemporary dynamics of work, but have replaced them with a new set of precarious relationships. Where individuals from <em>Reddit</em>, <em>YouTube</em> and blogging used those platforms to transition into <em>Twitch</em>, so too are many streamers now seeing <em>Twitch</em> as a way to transition <em>out</em> into other more career paths seen as more stable such as the games industry, or working for the <em>Twitch</em> itself instead of supporting oneself via <em>Twitch’s</em> broadcasting platform. Under the pressures of the contemporary contradiction and precariousness of career opportunities, <em>Twitch</em> streamers see this <em>enjoyable</em> career as only a transition into some less enjoyable, but more <em>stable</em>, alternative. The idea the enjoyable one might also remain stable seems unlikely to these new media workers, and they are actively preparing themselves for what they see as a highly uncertain future.</p>
<h3>Platform futures</h3>
<p>Interviewees also commented about the future of <em>Twitch</em> and streaming alongside their own place(s) within it. All interviewees expressed strong agreement on two major points: firstly, the feeling that current streamers were in on the ‘ground floor’ of a massive new media platform and global social phenomenon, which made many streamers feel quite privileged; secondly, the common belief that <em>Twitch</em> and streaming would only continue to grow in future years, deploying a range of justifications for this belief, and that <em>Twitch</em> represented the earliest stages of a world-changing technological trajectory that would expand years or decades into the future. The first of these – the feeling of ‘being there at the start’ – was most clearly espoused by P13, who framed this in terms of another highly-competitive employment domain:</p>
<blockquote>
<p>We’re just in the brand new stages of this new [streaming] explosion, so now a professional streamer [is] way more plausible than saying ‘I’m gonna be a professional NBA player’ or ‘I’m gonna be a professional baseball player’. It’s way more reasonable to think that you can be a professional streamer.</p>
</blockquote>
<p>This belief was repeated by many respondents. ‘<em>Twitch</em> was the first one to really take things seriously and really streamline live streaming for gaming’, P22 stated, implicitly noting that although the technology is not new, the strengths of <em>Twitch’s</em> particular platform are distinct. ‘They’re the pioneers’, they added, and that ‘everyone looks to <em>Twitch</em> […] because <em>Twitch</em> is the best’. P23, meanwhile, stressed that they believed <em>Twitch</em> could not be usefully compared to <em>YouTube</em> anymore and had developed its own, unique, new media ecosystem, and that the commonality in video recording and distribution was surface only. They emphasised the rate of change in <em>Twitch</em> as a young service that ‘changes every six months’, just as P21 said ‘Its been a wild ride’ about the first few years of the platform. In turn, looking to the future, ‘the only thing I can see’, stated P16, ‘is <em>Twitch</em> just growing and growing even bigger and bigger’. This was echoed by P24 who stated ‘I see [<em>Twitch</em>] continuously growing with giving more options’, P9’s comment that ‘there’s so much growth and potential in [the] technology’, and P5’s belief that ‘The potential [of <em>Twitch</em>] is enormous, so I think it’ll grow even bigger’. P7 stated that ‘the possibilities are endless for <em>Twitch</em>, and that’s what I love’, a perspective implicitly echoed by the prediction of P19 that <em>Twitch</em> might one day become a ‘live replacement for a regular TV’. Interviewees, therefore, believed that <em>Twitch</em> was in its early days now, and they were proud to be streaming at this moment in time, but that in the longer term <em>Twitch</em> was all but destined to become a major global media force.</p>
<p>The discourse of <em>Twitch’s</em> present sociotechnical innovation and the profound future impact it should have is most richly expressed in the comment of P7, who drew upon broader historical conceptions of innovation and disruptive technological change to express their feelings on the importance of <em>Twitch</em> to the digital media ecosystem:</p>
<blockquote>
<p>It’s like the equivalent of Alexander Bell, I think his name was, laying down the first telephone lines back in the 1800s, 1700s, whenever it was. I think that’s what we’re doing right here, right now with Twitch, and that’s something I want to be a part of.</p>
</blockquote>
<p>The same respondent later added that the ‘gaming industry is laying the foundation for every single technology aspect that we have’. Although these seem extreme comments to make, they are only a little more dramatic than those of other respondents; whilst interviewees varied in the strength of their certainty that <em>Twitch</em> was on the ground floor of massive new media change, they were united in that certainty per se. Such narratives of predicted technological development ‒ from a new invention into a widely-used technology ‒ serve to emphasise the ‘legitimacy’ (Barnes, <span>1974<span><span><span>Barnes, <span>B.</span></span> (<span>1974</span>). <em>Scientific knowledge and sociological theory</em>. <span>Oxford</span>: <span>Routledge &amp; Kegan Paul</span>.<span> <span><a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=1974&amp;author=B.+Barnes&amp;title=Scientific+knowledge+and+sociological+theory">[Google Scholar]</a></span></span></span></span></span>, p. 140) of new inventions, such as live game streaming. As Bourgonjon, Vandermeersche, De Wever, Soetaert, and Valcke (<span>2016<span><span><span>Bourgonjon, <span>J.</span></span>, <span>Vandermeersche, <span>G.</span></span>, <span>De Wever, <span>B.</span></span>, <span>Soetaert, <span>R.</span></span>, &amp; <span>Valcke, <span>M.</span></span> (<span>2016</span>). <span>Players’ perspectives on the positive impact of video games: A qualitative content analysis of online forum discussions</span>. <em>New Media and Society</em>, <em>18</em>(8), <span>1732</span>–<span>1749</span>. doi: <span>10.1177/1461444815569723</span><span> <span><a href="/servlet/linkout?suffix=CIT0003&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1177%2F1461444815569723">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0003&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000382854600019">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=18&amp;publication_year=2016&amp;pages=1732-1749&amp;issue=8&amp;author=J.+Bourgonjon&amp;author=G.+Vandermeersche&amp;author=B.+De+Wever&amp;author=R.+Soetaert&amp;author=M.+Valcke&amp;title=Players%E2%80%99+perspectives+on+the+positive+impact+of+video+games%3A+A+qualitative+content+analysis+of+online+forum+discussions&amp;doi=10.1177%2F1461444815569723">[Google Scholar]</a></span></span></span></span></span>) argue, such statements are ‘constitutive of both the personal and social construction of the impact of video games’, and we see here streamers attempts to position their activities as more than mere ‘play’, and within the domain of broader and highly-impactful global technological and media changes. By articulating confidence in the importance of <em>Twitch’s</em> innovations and anticipated future impacts, interviewees were legitimising their own practices ‒ and the large volumes of time streaming require ‒ through presenting them as the start of a new historical epoch in media production and consumption. We can understand the motivation behind these discourses further through Kirkpatrick’s (<span>2016<span><span><span>Kirkpatrick, <span>G.</span></span> (<span>2016</span>). <span>Making games normal: Computer gaming discourse in the 1980s</span>. <em>New Media and Society</em>, <em>18</em>(8), <span>1439</span>–<span>1454</span>. doi: <span>10.1177/1461444814558905</span><span> <span><a href="/servlet/linkout?suffix=CIT0020&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1177%2F1461444814558905">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0020&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000382854600003">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=18&amp;publication_year=2016&amp;pages=1439-1454&amp;issue=8&amp;author=G.+Kirkpatrick&amp;title=Making+games+normal%3A+Computer+gaming+discourse+in+the+1980s&amp;doi=10.1177%2F1461444814558905">[Google Scholar]</a></span></span></span></span></span>, p. 1439) observation, after studying the early decades of gaming culture, that ‘gaming cannot escape the logic of its field, which determines that it will always try to be something more and better than gaming’ in its quest for broader cultural legitimation and acceptance. Such beliefs are clearly still extant in the era of streaming, and these discourses of streamers should be understood as a further presentation of this same desire for gaming and play ‒ often trivialised pastimes ‒ to transcend their current places in wider society.</p>
<h3>Personal futures and company futures</h3>
<p>To conclude this final analysis section, we now briefly note an intriguing tension in the interview data. We have demonstrated here a clear emphasis upon feelings of <em>precariousness</em> expressed by our respondents about their long-term <em>Twitch</em> careers. When considering the future of <em>Twitch</em> as a company, however, the opposite was the case, where comments ranged from the generally optimistic to the borderline techno-utopian. This contradiction articulates an important tension observed by professional and aspiring-professional streamers, which we suggest is indicative of a keen understanding of the dynamics of new technologies, and specifically new technological industries and their knock-on effects upon labour practices: innovative companies and inventors can profit tremendously from technologies and new forms of work that leave those actually performing the work or using the technologies ever more precarious or insecure. Streamers can consequently be seen as belonging to what Standing (<span>2011<span><span><span>Standing, <span>G.</span></span> (<span>2011</span>). <em>The Precariat: The new dangerous class</em>. <span>London</span>: <span>A&amp;C Black</span>.<span> <span><a href="/servlet/linkout?suffix=CIT0031&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.5040%2F9781849664554">[Crossref]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2011&amp;author=G.+Standing&amp;title=The+Precariat%3A+The+new+dangerous+class">[Google Scholar]</a></span></span></span></span></span>) calls the ‘precariat’, a class of people with perpetually insecure careers. Many such individuals work in what has been termed the gig economy (Friedman, <span>2014<span><span><span>Friedman, <span>G.</span></span> (<span>2014</span>). <span>Workers without employers: Shadow corporations and the rise of the gig economy</span>. <em>Review of Keynesian Economics</em>, <em>2</em>, <span>171</span>–<span>188</span>. doi: <span>10.4337/roke.2014.02.03</span><span> <span><a href="/servlet/linkout?suffix=CIT0011&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.4337%2Froke.2014.02.03">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0011&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000344196800004">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=2&amp;publication_year=2014&amp;pages=171-188&amp;author=G.+Friedman&amp;title=Workers+without+employers%3A+Shadow+corporations+and+the+rise+of+the+gig+economy&amp;doi=10.4337%2Froke.2014.02.03">[Google Scholar]</a></span></span></span></span></span>), entailing flexible and non-permanent arrangements with employees (Weststar, <span>2015<span><span><span>Weststar, <span>J.</span></span> (<span>2015</span>). <span>Understanding video game developers as an occupational community</span>. <em>Information, Communication and Society</em>, <em>18</em>(10), <span>1238</span>–<span>1252</span>. doi: <span>10.1080/1369118X.2015.1036094</span><span> <span><a href="https://www-tandfonline-com.wwwproxy1.library.unsw.edu.au/doi/10.1080/1369118X.2015.1036094">[Taylor &amp; Francis Online]</a>, <a href="/servlet/linkout?suffix=CIT0042&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000359529200007">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=18&amp;publication_year=2015&amp;pages=1238-1252&amp;issue=10&amp;author=J.+Weststar&amp;title=Understanding+video+game+developers+as+an+occupational+community&amp;doi=10.1080%2F1369118X.2015.1036094">[Google Scholar]</a></span></span></span></span></span>), or with privately owned platforms such as <em>Twitch</em>. This is also the case within the related career path of eSports, where professional players are precariously employed whilst eSports as a whole only continues to grow in economic value (Johnson, &amp; Woodcock, <span>2017<span><span><span>Johnson, <span>M. R.</span></span>, &amp; <span>Woodcock, <span>J.</span></span> (<span>2017</span>). Work, Play, and Precariousness: An Overview of the Labour Ecosystem of Esports, International Journal of Gaming and Computer-Mediated Simulations.<span> <span><a  href="http://scholar.google.com/scholar?hl=en&amp;q=Johnson%2C+M.+R.%2C+%26+Woodcock%2C+J.+%282017%29.+Work%2C+Play%2C+and+Precariousness%3A+An+Overview+of+the+Labour+Ecosystem+of+Esports%2C+International+Journal+of+Gaming+and+Computer-Mediated+Simulations.">[Google Scholar]</a></span></span></span></span></span>). Streamers, like those in these other domains, are clearly aware of this tension, and it is already affecting their reflections upon their careers and their plans for the future. Subsequent longitudinal research, however, will be required to unpick these anxieties in more detail and how – if at all – they shape the co-evolution of <em>Twitch</em>, and its streamers, in the years and decades to come.</p>
<h2>Conclusion</h2>
<blockquote>
<p>Before I could walk I’ve been playing video games, and it's a passion of mine, so I wanted to turn that passion to paycheck. (P15)</p>
</blockquote>
<p>Computer games have become an inescapable part of our overall media culture (Dalisay et al., <span>2015<span><span><span>Dalisay, <span>F.</span></span>, <span>Kushin, <span>M. J.</span></span>, <span>Yamamoto, <span>M.</span></span>, <span>Liu, <span>Y. I.</span></span>, &amp; <span>Skalski, <span>P.</span></span> (<span>2015</span>). <span>Motivations for game play and the social capital and civic potential of video games</span>. <em>New Media and Society</em>, <em>17</em>(9), <span>1399</span>–<span>1417</span>. doi: <span>10.1177/1461444814525753</span><span> <span><a href="/servlet/linkout?suffix=CIT0008&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1177%2F1461444814525753">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0008&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000361127400001">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=17&amp;publication_year=2015&amp;pages=1399-1417&amp;issue=9&amp;author=F.+Dalisay&amp;author=M.+J.+Kushin&amp;author=M.+Yamamoto&amp;author=Y.+I.+Liu&amp;author=P.+Skalski&amp;title=Motivations+for+game+play+and+the+social+capital+and+civic+potential+of+video+games&amp;doi=10.1177%2F1461444814525753">[Google Scholar]</a></span></span></span></span></span>), and examining gaming activities is consequently crucial for understanding an increasingly media-saturated society (Thompson, <span>1995<span><span><span>Thompson, <span>J. B.</span></span> (<span>1995</span>). <em>The media and modernity: A social theory of the media</em>. <span>Cambridge</span>: <span>Polity Press</span>.<span> <span><a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=1995&amp;author=J.+B.+Thompson&amp;title=The+media+and+modernity%3A+A+social+theory+of+the+media">[Google Scholar]</a></span></span></span></span></span>). The growth of cheap and effective communication media, meanwhile, has enabled a small number of performers to obtain global celebrity on a far greater scale than ever before (Freeland, <span>2012<span><span><span>Freeland, <span>C.</span></span> (<span>2012</span>). <em>Plutocrats: The rise of the new global super-rich and the fall of everyone else</em>. <span>New York, NY</span>: <span>Penguin</span>.<span> <span><a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;publication_year=2012&amp;author=C.+Freeland&amp;title=Plutocrats%3A+The+rise+of+the+new+global+super-rich+and+the+fall+of+everyone+else">[Google Scholar]</a></span></span></span></span></span>). Such media industries are a rich site for studying these ‘enterprising’ and independent careers (Storey et al., <span>2005<span><span><span>Storey, <span>J.</span></span>, <span>Salaman, <span>G.</span></span>, &amp; <span>Platman, <span>K.</span></span> (<span>2005</span>). <span>Living with enterprise in an enterprise economy: Freelance and contract workers in the media</span>. <em>Human Relations</em>, <em>58</em>(8), <span>1033</span>–<span>1054</span>. doi: <span>10.1177/0018726705058502</span><span> <span><a href="/servlet/linkout?suffix=CIT0032&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1177%2F0018726705058502">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0032&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000232777100004">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=58&amp;publication_year=2005&amp;pages=1033-1054&amp;issue=8&amp;author=J.+Storey&amp;author=G.+Salaman&amp;author=K.+Platman&amp;title=Living+with+enterprise+in+an+enterprise+economy%3A+Freelance+and+contract+workers+in+the+media&amp;doi=10.1177%2F0018726705058502">[Google Scholar]</a></span></span></span></span></span>, p. 1049), and let us examine the distinctive features of digital ‘cultural work’ at a moment when successful creative workers are seen as exemplary entrepreneurial citizens (Gill &amp; Pratt, <span>2008<span><span><span>Gill, <span>R.</span></span>, &amp; <span>Pratt, <span>A.</span></span> (<span>2008</span>). <span>In the social factory? Immaterial labour, precariousness and cultural work</span>. <em>Theory, Culture and Society</em>, <em>25</em>(7-8), <span>1</span>–<span>30</span>. doi: <span>10.1177/0263276408097794</span><span> <span><a href="/servlet/linkout?suffix=CIT0012&amp;dbid=16&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=10.1177%2F0263276408097794">[Crossref]</a>, <a href="/servlet/linkout?suffix=CIT0012&amp;dbid=128&amp;doi=10.1080%2F1369118X.2017.1386229&amp;key=000262288900001">[Web of Science ®]</a></span><span>, <a  href="http://scholar.google.com/scholar_lookup?hl=en&amp;volume=25&amp;publication_year=2008&amp;pages=1-30&amp;issue=7-8&amp;author=R.+Gill&amp;author=A.+Pratt&amp;title=In+the+social+factory%3F+Immaterial+labour%2C+precariousness+and+cultural+work&amp;doi=10.1177%2F0263276408097794">[Google Scholar]</a></span></span></span></span></span>, p. 1). In this paper, we have brought together these concerns with games media and digital celebrity by examining the lives and careers of those who broadcast themselves playing video games as their source of full-time income, and those who aspire to such a goal. Drawing on original interview data, we explored how streamers entered this career path, the work of streaming, and the future of streaming and their own channels. In doing so, we uncovered how <em>Twitch</em> slots into the ongoing convergence of digital and online media platforms, the strenuous yet rewarding labour of becoming a professional broadcaster, and the complex mix of anxiety and confidence streamers have about the future. Streaming shows no signs of shrinking in the immediate future as more and more become embroiled in the practice as both consumers and producers, whilst even in this initial investigation we have identified a number of tensions that will shape its growth in the coming years. In this paper, we have only begun to unpick the complexities and entanglements of such a platform, but it is clear that greater study of live streaming will offer us new insights into the distributed production of our contemporary media environment, and the lives and careers of those who labour to produce it.</p>
<h2>References</h2>
<div class="notes-and-refs">
<ul>
    <li id="CIT0002">
        <span
            ><span class="hlFld-ContribAuthor"
                >Barnes, <span class="NLM_given-names">B.</span></span
            >
            (<span class="NLM_year">1974</span>).
            _Scientific knowledge and sociological theory_.
            <span class="NLM_publisher-loc">Oxford</span>:
            <span class="NLM_publisher-name">Routledge &amp; Kegan Paul</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0003">
        <span
            ><span class="hlFld-ContribAuthor"
                >Bourgonjon, <span class="NLM_given-names">J.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Vandermeersche, <span class="NLM_given-names">G.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >De Wever, <span class="NLM_given-names">B.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Soetaert, <span class="NLM_given-names">R.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Valcke, <span class="NLM_given-names">M.</span></span
            >
            (<span class="NLM_year">2016</span>).
            <span class="NLM_article-title"
                >Players’ perspectives on the positive impact of video games: A
                qualitative content analysis of online forum discussions</span
            >. _New Media and Society_, _18_(8),
            <span class="NLM_fpage">1732</span>–<span class="NLM_lpage"
                >1749</span
            >. doi: <span class="NLM_pub-id">10.1177/1461444815569723</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0004">
        <span
            ><span class="hlFld-ContribAuthor"
                >Burroughs, <span class="NLM_given-names">B.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Rama, <span class="NLM_given-names">P.</span></span
            >
            (<span class="NLM_year">2015</span>).
            <span class="NLM_article-title"
                >The eSports Trojan Horse: Twitch and streaming futures’</span
            >. _Journal of Virtual Worlds Research_, _8_(2),
            <span class="NLM_fpage">1</span>–<span class="NLM_lpage">5</span>.
            doi: <span class="NLM_pub-id">10.4101/jvwr.v8i2.7176</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0005">
        <span
            ><span class="hlFld-ContribAuthor"
                >Churchill,
                <span class="NLM_given-names">B.&nbsp;C.&nbsp;B.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Xu, <span class="NLM_given-names">W.</span></span
            >
            (<span class="NLM_year">2016</span>).
            <span class="NLM_article-title"
                ><i
                    >The modem nation: A first study on Twitch.tv social
                    structure and player/game relationships</i
                ></span
            >.
            <span class="NLM_conf-name"
                >2016 IEEE international conferences on BDCloud, SocialCom,
                SustainCom</span
            >, <span class="NLM_conf-loc">Atlanta</span>,
            <span class="NLM_conf-date">8-10 October 2016</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0006">
        <span
            ><span class="hlFld-ContribAuthor"
                >Corbin, <span class="NLM_given-names">M.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Strauss, <span class="NLM_given-names">S.</span></span
            >
            (<span class="NLM_year">1990</span>).
            <span class="NLM_article-title"
                >Grounded theory research: Procedures, canons, and evaluative
                criteria</span
            >. _Qualitative Sociology_, _13_(1),
            <span class="NLM_fpage">3</span>–<span class="NLM_lpage">21</span>.
            doi: <span class="NLM_pub-id">10.1007/BF00988593</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0007">
        <span
            ><span class="hlFld-ContribAuthor"
                >Cunningham, <span class="NLM_given-names">S.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Craig, <span class="NLM_given-names">D.</span></span
            >
            (<span class="NLM_year">2016</span>).
            <span class="NLM_article-title"
                >Online entertainment: A new wave of media globalization?</span
            >
            _International Journal of Communication_, _10_,
            <span class="NLM_fpage">5409</span>–<span class="NLM_lpage"
                >5425</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0008">
        <span
            ><span class="hlFld-ContribAuthor"
                >Dalisay, <span class="NLM_given-names">F.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Kushin, <span class="NLM_given-names">M. J.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Yamamoto, <span class="NLM_given-names">M.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Liu, <span class="NLM_given-names">Y. I.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Skalski, <span class="NLM_given-names">P.</span></span
            >
            (<span class="NLM_year">2015</span>).
            <span class="NLM_article-title"
                >Motivations for game play and the social capital and civic
                potential of video games</span
            >. _New Media and Society_, _17_(9),
            <span class="NLM_fpage">1399</span>–<span class="NLM_lpage"
                >1417</span
            >. doi: <span class="NLM_pub-id">10.1177/1461444814525753</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0009">
        <span
            ><span class="hlFld-ContribAuthor"
                >Foucault, <span class="NLM_given-names">M.</span></span
            >
            (<span class="NLM_year">2008</span>).
            <i
                >The birth of biopolitics: Lectures at the collège de France,
                1978–1979</i
            >
            (G. Burchell, Trans.).
            <span class="NLM_publisher-loc">New&nbsp;York, NY</span>:
            <span class="NLM_publisher-name">Palgrave Macmillan</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0010">
        <span
            ><span class="hlFld-ContribAuthor"
                >Freeland, <span class="NLM_given-names">C.</span></span
            >
            (<span class="NLM_year">2012</span>).
            <i
                >Plutocrats: The rise of the new global super-rich and the fall
                of everyone else</i
            >. <span class="NLM_publisher-loc">New&nbsp;York, NY</span>:
            <span class="NLM_publisher-name">Penguin</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0011">
        <span
            ><span class="hlFld-ContribAuthor"
                >Friedman, <span class="NLM_given-names">G.</span></span
            >
            (<span class="NLM_year">2014</span>).
            <span class="NLM_article-title"
                >Workers without employers: Shadow corporations and the rise of
                the gig economy</span
            >. _Review of Keynesian Economics_, _2_,
            <span class="NLM_fpage">171</span>–<span class="NLM_lpage">188</span
            >. doi: <span class="NLM_pub-id">10.4337/roke.2014.02.03</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0013">
        <span
            ><span class="hlFld-ContribAuthor"
                >Gill, <span class="NLM_given-names">R.</span></span
            >
            (<span class="NLM_year">2010</span>).
            <span class="NLM_article-title"
                >Life is a pitch: Managing the self in new media work</span
            >. In
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">M.</span> Deuze</span
            >
            (Ed.), _Managing media work_ (pp.
            <span class="NLM_fpage">249</span>–<span class="NLM_lpage">262</span
            >). <span class="NLM_publisher-loc">London</span>:
            <span class="NLM_publisher-name">SAGE Publishing</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0012">
        <span
            ><span class="hlFld-ContribAuthor"
                >Gill, <span class="NLM_given-names">R.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Pratt, <span class="NLM_given-names">A.</span></span
            >
            (<span class="NLM_year">2008</span>).
            <span class="NLM_article-title"
                >In the social factory? Immaterial labour, precariousness and
                cultural work</span
            >. _Theory, Culture and Society_, _25_(7-8),
            <span class="NLM_fpage">1</span>–<span class="NLM_lpage">30</span>.
            doi: <span class="NLM_pub-id">10.1177/0263276408097794</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0014">
        <span
            ><span class="hlFld-ContribAuthor"
                >Gray, <span class="NLM_given-names">K. L.</span></span
            >
            (<span class="NLM_year">2017</span>).
            <span class="NLM_article-title"
                >They’re just too urban’: Black gamers streaming on Twitch</span
            >. In
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">J.</span> Daniels</span
            >,
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">K.</span> Gregory</span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">T.</span> McMillan Cottom</span
            >
            (Eds.), _Digital sociologies_ (pp.
            <span class="NLM_fpage">355</span>–<span class="NLM_lpage">369</span
            >). <span class="NLM_publisher-loc">Bristol</span>:
            <span class="NLM_publisher-name">Policy Press</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0015">
        <span
            ><span class="hlFld-ContribAuthor"
                >Hamilton, <span class="NLM_given-names">W. A.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Garretson, <span class="NLM_given-names">O.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Kerne, <span class="NLM_given-names">A.</span></span
            >
            (<span class="NLM_year">2014</span>).
            <span class="NLM_article-title"
                ><i
                    >Streaming on twitch: Fostering participatory communities of
                    play within live mixed media</i
                ></span
            >.
            <span class="NLM_conf-name"
                >CHI '14 Proceedings of the SIGCHI Conference on Human Factors
                in Computing Systems</span
            >, <span class="NLM_conf-loc">Toronto</span>,
            <span class="NLM_conf-date">April 26-May 1 2014</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0016">
        <span
            ><span class="hlFld-ContribAuthor"
                >Harvey, <span class="NLM_given-names">A.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Fisher, <span class="NLM_given-names">S.</span></span
            >
            (<span class="NLM_year">2013</span>).
            <span class="NLM_article-title"
                >Making a name in games: Immaterial labour, indie game design,
                and gendered social network markets</span
            >. _Information, Communication and Society_, _16_(3),
            <span class="NLM_fpage">362</span>–<span class="NLM_lpage">380</span
            >. doi: <span class="NLM_pub-id">10.1080/1369118X.2012.756048</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0017">
        <span
            ><span class="hlFld-ContribAuthor"
                >Hutchins, <span class="NLM_given-names">B.</span></span
            >
            (<span class="NLM_year">2008</span>).
            <span class="NLM_article-title"
                >Signs of meta-change in second modernity: the growth of e-Sport
                and the world cyber games</span
            >. _New Media &amp; Society_, _10_(6),
            <span class="NLM_fpage">851</span>–<span class="NLM_lpage">869</span
            >. doi: <span class="NLM_pub-id">10.1177/1461444808096248</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0018">
        <span
            ><span class="hlFld-ContribAuthor"
                >Johnson, <span class="NLM_given-names">M. R.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Woodcock, <span class="NLM_given-names">J.</span></span
            >
            (<span class="NLM_year">2017</span>). Work, Play, and
            Precariousness: An Overview of the Labour Ecosystem of Esports,
            International Journal of Gaming and Computer-Mediated
            Simulations.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0019">
        <span
            ><span class="hlFld-ContribAuthor"
                >Kirkpatrick, <span class="NLM_given-names">G.</span></span
            >
            (<span class="NLM_year">2004</span>).
            _Critical technology: A social theory of personal computing_.
            <span class="NLM_publisher-loc">Aldershot</span>:
            <span class="NLM_publisher-name">Ashgate</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0020">
        <span
            ><span class="hlFld-ContribAuthor"
                >Kirkpatrick, <span class="NLM_given-names">G.</span></span
            >
            (<span class="NLM_year">2016</span>).
            <span class="NLM_article-title"
                >Making games normal: Computer gaming discourse in the
                1980s</span
            >. _New Media and Society_, _18_(8),
            <span class="NLM_fpage">1439</span>–<span class="NLM_lpage"
                >1454</span
            >. doi: <span class="NLM_pub-id">10.1177/1461444814558905</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0021">
        <span
            ><span class="hlFld-ContribAuthor"
                >Kresse, <span class="NLM_given-names">C.</span></span
            >
            (<span class="NLM_year">2016</span>). eSports in 2015 by the
            numbers: Attendance figures, investments and prize money,
            _Esports Marketing Blog_.<span class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0022">
        <span
            ><span class="hlFld-ContribAuthor"
                >Nematzadeh, <span class="NLM_given-names">A.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Ciampaglia, <span class="NLM_given-names">G. L.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Ahn, <span class="NLM_given-names">Y. Y.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Flammini, <span class="NLM_given-names">A.</span></span
            >
            (<span class="NLM_year">2016</span>).
            <i
                >Information overload in group communication: From conversation
                to cacophony in the Twitch chat</i
            >. _arXiv preprint_ arXiv:1610.06497.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0023">
        <span
            ><span class="hlFld-ContribAuthor"
                >Pires, <span class="NLM_given-names">K.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Simon, <span class="NLM_given-names">G.</span></span
            >
            (<span class="NLM_year">2015</span>).
            <span class="NLM_article-title"
                ><i
                    >Youtube live and twitch: A tour of user-generated live
                    streaming systems</i
                ></span
            >.
            <span class="NLM_conf-name"
                >Proceedings of the 6th ACM Multimedia Systems Conference</span
            >, <span class="NLM_conf-loc">Portland, Oregon</span>,
            <span class="NLM_conf-date">18-20 March 2015</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0024">
        <span
            ><span class="hlFld-ContribAuthor">Quantcast</span>. (<span
                class="NLM_year"
                >2016</span
            >). Twitch.tv. Available from
            <a
                class="ext-link"
                href="https://www.quantcast.com/twitch.tv#demographicsCard"
                target="_blank"
                >https://www.quantcast.com/twitch.tv#demographicsCard</a
            >, accessed on 04/11/2016.<span class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0025">
        <span
            ><span class="hlFld-ContribAuthor"
                >Read, <span class="NLM_given-names">J.</span></span
            >
            (<span class="NLM_year">2009</span>).
            <span class="NLM_article-title"
                >A genealogy of homo-economicus: Neoliberalism and the
                production of subjectivity</span
            >. _Foucault Studies_, _6_,
            <span class="NLM_fpage">25</span>–<span class="NLM_lpage">36</span>.
            doi: <span class="NLM_pub-id">10.22439/fs.v0i0.2465</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0026">
        <span
            ><span class="hlFld-ContribAuthor"
                >Ryan, <span class="NLM_given-names">R. M.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Rigby, <span class="NLM_given-names">C. S.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Przybylski, <span class="NLM_given-names">A.</span></span
            >
            (<span class="NLM_year">2006</span>).
            <span class="NLM_article-title"
                >The motivational pull of video games: A self-determination
                theory approach</span
            >. _Motivation and Emotion_, _30_(4),
            <span class="NLM_fpage">347</span>–<span class="NLM_lpage">363</span
            >. doi: <span class="NLM_pub-id">10.1007/s11031-006-9051-8</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0027">
        <span
            ><span class="hlFld-ContribAuthor"
                >Schmidt, <span class="NLM_given-names">C.</span></span
            >
            (<span class="NLM_year">2004</span>).
            <span class="NLM_article-title"
                >The analysis of semi-structured interviews</span
            >. In
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">U.</span> Flick</span
            >,
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">E.</span> von Kardoff</span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                ><span class="NLM_given-names">I.</span> Steinke</span
            >
            (Eds.), _A companion to qualitative research_ (pp.
            <span class="NLM_fpage">253</span>–<span class="NLM_lpage">258</span
            >).
            <span class="NLM_publisher-loc"
                >London, Thousand Oaks, New Delhi</span
            >: <span class="NLM_publisher-name">SAGE Publications</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0028">
        <span
            ><span class="hlFld-ContribAuthor"
                >Seay, <span class="NLM_given-names">A. F.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Jerome, <span class="NLM_given-names">W.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Lee, <span class="NLM_given-names">K. S.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Kraut, <span class="NLM_given-names">R. E.</span></span
            >
            (<span class="NLM_year">2004</span>).
            <span class="NLM_article-title"
                ><i
                    >Project massive: A study of online gaming communities</i
                ></span
            >.
            <span class="NLM_conf-name"
                >CHI'04 extended abstracts on Human factors in computing
                systems</span
            >, <span class="NLM_conf-loc">Vienna</span>,
            <span class="NLM_conf-date">24-29 April, 2004</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0029">
        <span
            ><span class="hlFld-ContribAuthor"
                >Short, <span class="NLM_given-names">J.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Williams, <span class="NLM_given-names">E.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Christie, <span class="NLM_given-names">B.</span></span
            >
            (<span class="NLM_year">1976</span>).
            _The social psychology of telecommunications_.
            <span class="NLM_publisher-loc">London</span>:
            <span class="NLM_publisher-name">John Wiley &amp; Sons</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0030">
        <span
            ><span class="hlFld-ContribAuthor"
                >Sjöblom, <span class="NLM_given-names">M.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Hamari, <span class="NLM_given-names">J.</span></span
            >
            (<span class="NLM_year">2016</span>). Why do people watch others
            play video games? An empirical study on the motivations of Twitch
            users. Retrieved from:
            <a
                class="ext-link"
                href="https://ssrn.com/abstract=2779543"
                target="_blank"
                >https://ssrn.com/abstract=2779543</a
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0031">
        <span
            ><span class="hlFld-ContribAuthor"
                >Standing, <span class="NLM_given-names">G.</span></span
            >
            (<span class="NLM_year">2011</span>).
            _The Precariat: The new dangerous class_.
            <span class="NLM_publisher-loc">London</span>:
            <span class="NLM_publisher-name">A&amp;C Black</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0032">
        <span
            ><span class="hlFld-ContribAuthor"
                >Storey, <span class="NLM_given-names">J.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Salaman, <span class="NLM_given-names">G.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Platman, <span class="NLM_given-names">K.</span></span
            >
            (<span class="NLM_year">2005</span>).
            <span class="NLM_article-title"
                >Living with enterprise in an enterprise economy: Freelance and
                contract workers in the media</span
            >. _Human Relations_, _58_(8),
            <span class="NLM_fpage">1033</span>–<span class="NLM_lpage"
                >1054</span
            >. doi: <span class="NLM_pub-id">10.1177/0018726705058502</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0035">
        <span
            ><span class="hlFld-ContribAuthor"
                >Taylor, <span class="NLM_given-names">T. L.</span></span
            >
            (<span class="NLM_year">2006</span>).
            _Play between worlds: Exploring online game culture_.
            <span class="NLM_publisher-loc">Cambridge, MA</span>:
            <span class="NLM_publisher-name">MIT Press</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0036">
        <span
            ><span class="hlFld-ContribAuthor"
                >Taylor, <span class="NLM_given-names">T. L.</span></span
            >
            (<span class="NLM_year">2012</span>). _Raising the stakes_.
            <span class="NLM_publisher-loc">Cambridge, MA</span>:
            <span class="NLM_publisher-name">MIT Press</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0033">
        <span
            ><span class="hlFld-ContribAuthor"
                >Taylor, <span class="NLM_given-names">N.</span></span
            >
            (<span class="NLM_year">2016a</span>).
            <span class="NLM_article-title"
                >Play to the camera: Video ethnography, spectatorship, and
                e-sports</span
            >.
            <i
                >Convergence: The International Journal of Research Into New
                Media Technologies</i
            >, _22_(2), <span class="NLM_fpage">115</span>–<span
                class="NLM_lpage"
                >130</span
            >. doi: <span class="NLM_pub-id">10.1177/1354856515580282</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0034">
        <span
            ><span class="hlFld-ContribAuthor"
                >Taylor, <span class="NLM_given-names">N.</span></span
            >
            (<span class="NLM_year">2016b</span>).
            <span class="NLM_article-title"
                >Now you’re playing with audience power: The work of watching
                games</span
            >. _Critical Studies in Media Communication_, _33_(4),
            <span class="NLM_fpage">293</span>–<span class="NLM_lpage">307</span
            >. doi: <span class="NLM_pub-id">10.1080/15295036.2016.1215481</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0037">
        <span
            ><span class="hlFld-ContribAuthor"
                >Thompson, <span class="NLM_given-names">J. B.</span></span
            >
            (<span class="NLM_year">1995</span>).
            _The media and modernity: A social theory of the media_.
            <span class="NLM_publisher-loc">Cambridge</span>:
            <span class="NLM_publisher-name">Polity Press</span>.<span
                class="refLink-block"
                >&nbsp;</span
            ></span
        >
    </li>
    <li id="CIT0038">
        <span
            >Twitch. (<span class="NLM_year">2015</span>). Welcome home: The
            2015 retrospective, _Twitch.tv_. Retrieved from
            <a
                class="ext-link"
                href="https://www.twitch.tv/year/2015"
                target="_blank"
                >https://www.twitch.tv/year/2015</a
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0039">
        <span
            ><span class="hlFld-ContribAuthor"
                >Van Dijck, <span class="NLM_given-names">J.</span></span
            >
            (<span class="NLM_year">2013</span>).
            <i
                >The culture of connectivity: A critical history of social
                media</i
            >. <span class="NLM_publisher-loc">Oxford, New York</span>:
            <span class="NLM_publisher-name">Oxford University Press</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0040">
        <span
            ><span class="hlFld-ContribAuthor"
                >Vorderer, <span class="NLM_given-names">P.</span></span
            >,
            <span class="hlFld-ContribAuthor"
                >Klimmt, <span class="NLM_given-names">C.</span></span
            >, &amp;
            <span class="hlFld-ContribAuthor"
                >Ritterfeld, <span class="NLM_given-names">U.</span></span
            >
            (<span class="NLM_year">2004</span>).
            <span class="NLM_article-title"
                >Enjoyment: At the heart of media entertainment</span
            >. _Communication theory_, _14_(4),
            <span class="NLM_fpage">388</span>–<span class="NLM_lpage">408</span
            >. doi:
            <span class="NLM_pub-id">10.1111/j.1468-2885.2004.tb00321.x</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0041">
        <span
            ><span class="hlFld-ContribAuthor"
                >Wajcman, <span class="NLM_given-names">J.</span></span
            >
            (<span class="NLM_year">2015</span>).
            <i
                >Pressed for time: The acceleration of life in digital
                capitalism</i
            >. <span class="NLM_publisher-loc">Chicago</span>:
            <span class="NLM_publisher-name">University of Chicago Press</span
            >.<span class="refLink-block">&nbsp;</span></span
        >
    </li>
    <li id="CIT0042">
        <span
            ><span class="hlFld-ContribAuthor"
                >Weststar, <span class="NLM_given-names">J.</span></span
            >
            (<span class="NLM_year">2015</span>).
            <span class="NLM_article-title"
                >Understanding video game developers as an occupational
                community</span
            >. _Information, Communication and Society_, _18_(10),
            <span class="NLM_fpage">1238</span>–<span class="NLM_lpage"
                >1252</span
            >. doi: <span class="NLM_pub-id">10.1080/1369118X.2015.1036094</span
            ><span class="refLink-block">&nbsp;</span></span
        >
    </li>
</ul>
</div>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="Rise of the Machines: The Future has Lots of Robots, Few Jobs for Humans"
class="paper-story"
data-article-title="Rise of the Machines: The Future has Lots of Robots, Few Jobs for Humans"
>

<h1 class="article-title" id="h_Rise of the Machines: The Future has Lots of Robots, Few Jobs for Humans">Rise of the Machines: The Future has Lots of Robots, Few Jobs for Humans</h1>

<div class="top-meta">Marguerite McNeal, 2015-04-00 13:18:00 AEST. for week 11.</div>

<figure>
<p><img src="https://www.wired.com/wp-content/uploads/2015/04/Martin_Ford_headshot-932x621.jpg"
/></p>
<figcaption>
<p>Martin Ford</p>
</figcaption>
</figure>
<p>The robots haven’t just landed in the workplace—they’re expanding skills, moving up the corporate ladder, showing awesome productivity and retention rates, and increasingly shoving aside their human counterparts. One multi-tasker bot, from Momentum Machines, can make (and flip) a gourmet hamburger in 10 seconds and could soon replace an entire McDonalds crew. A manufacturing device from Universal Robots doesn’t just solder, paint, screw, glue, and grasp—it builds new parts for itself on the fly when they wear out or bust. And just this week, Google won a <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=42&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=google.ASNM.&amp;p=1&amp;OS=AN/google&amp;RS=AN/google" >patent</a>
to start building worker robots with personalities.</p>
<p>As intelligent machines begin their march on labor and become more sophisticated and specialized than first-generation cousins like Roomba or Siri, they have an outspoken champion in their corner: author and entrepreneur Martin Ford. In his new book, <em ><a href="http://www.amazon.com/dp/0465059996/?tag=w050b-20" >Rise of the Robots</a></em >, he argues that AI and robotics will soon overhaul our economy.</p>
<figure>
<img src="https://www.wired.com/wp-content/uploads/2015/04/MTH-Ford-Rise-Robots-289x439.jpg"
/>
<figcaption>
<em>Rise of the Robots</em>
</figcaption>
</figure>
<p>There’s some logic to the thesis, of course, and other economists such as Andrew (<em>The Second Machine Age</em>) McAfee have sided generally with Ford’s outlook. Oxford University researchers have estimated that 47 percent of U.S. jobs could be automated within the next two decades. And if even half that number is closer to the mark, workers are in for a rude awakening.</p>
<p>In Ford’s vision, a full-on worker revolt is on the horizon, followed by a radically new economic state whereby humans will live more productive and entrepreneurial lives, subsisting on guaranteed incomes generated by our amazing machines. (Don’t laugh — even some conservative influencers believe this may be the ultimate means of solving the wealth-inequality dilemma.)</p>
<p>Sound a little nuts? We thought so—we’re human, after all—so we invited Ford to defend his turf.</p>
<h4>Critics say your vision of a jobless future isn’t founded in good research or logic. What makes you so convinced this phenomenon is real?</h4>
<p>I see the advances happening in technology and it’s becoming evident that computers, machines, robots, and algorithms are going to be able to do most of the routine, repetitive types of jobs. That’s the essence of what machine learning is all about. What types of jobs are on some level fundamentally predictable? A lot of different skill levels fall into that category. It’s not just about lower-skilled jobs either. People with college degrees, even professional degrees, people like lawyers are doing things that ultimately are predictable. A lot of those jobs are going to be susceptible over time.</p>
<p>Right now there’s still a lot of debate over it. There are economists who think it’s totally wrong, that problems really stem from things like globalization or the fact that we’ve wiped out unions or haven’t raised the minimum wage. Those are all important, but I tend to believe that technology is a bigger issue, especially as we look to the future.</p>
<p>Eventually I think we’ll get to the point where there’s less debate about whether this is really happening or not. There will be more widespread agreement that it really is a problem and at that point we’ll have to figure out what to do about it.</p>
<h4>Aren’t you relying on some pretty radical and unlikely assumptions?</h4>
<p>People who are very skeptical tend to look at the historical record. It’s true that the economy has always adapted over time. It has created new kinds of jobs. The classic example of that is agriculture. In the 1800s, 80 percent of the U.S. labor force worked on farms. Today it’s 2 percent.
Obviously mechanization didn’t destroy the economy; it made it better off.
Food is now really cheap compared to what it was relative to income, and as a result people have money to spend on other things and they’ve transitioned to jobs in other areas. Skeptics say that will happen again.</p>
<p>The agricultural revolution was about specialized technology that couldn’t be implemented in other industries. You couldn’t take the farm machinery and have it go flip hamburgers. Information technology is totally different.
It’s a broad-based general purpose technology. There isn’t a new place for all these workers to move.</p>
<p>You can imagine lots of new industries—nanotechnology and synthetic biology—but they won’t employ many people. They’ll use lots of technology, rely on big computing centers, and be heavily automated.</p>
<h4>So in the all-automated economy, what will ambitious 20-somethings choose to do with their lives and careers?</h4>
<p>My proposed solution is to have some kind of a guaranteed income that incentivizes education. We don’t want people to get halfway through high school and say, ‘Well if I drop out I’m still going to get the same income as everyone else.’</p>
<p>Then I believe that a guaranteed income would actually result in more entrepreneurship. A lot of people would start businesses just as they do today. The problem with these types of businesses you can start online today is it’s hard to put enough together to generate a middle-class income.</p>
<p>If people had an income floor, and if the incentives were such that on top of that they could do other things and still keep that extra money, without having it all taxed away, then I think a lot of people would pursue those opportunities.</p>
<p>There’s a phenomenon called the <a href="http://www.asse.org/assets/1/7/fall07-feature02.pdf" >Peltzman Effect</a>, based on research from an economist at the University of Chicago who studied auto accidents. He found that when you introduce more safety features like seat belts into cars, the number of fatalities and injuries doesn’t drop. The reason is that people compensate for it. When you have a safety net in place, people will take more risks. That probably is true of the economic arena as well.</p>
<p>People say that having a guaranteed income will turn everyone into a slacker and destroy the economy. I think the opposite might be true, that it might push us toward more entrepreneurship and more risk-taking.</p>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="A Robot-Human Handshake in Space: Touch and Lively Alterity Relations in Social Robotics"
class="paper-story"
data-article-title="A Robot-Human Handshake in Space: Touch and Lively Alterity Relations in Social Robotics"
>

<h1 class="article-title" id="h_A Robot-Human Handshake in Space: Touch and Lively Alterity Relations in Social Robotics">A Robot-Human Handshake in Space: Touch and Lively Alterity Relations in Social Robotics</h1>

<div class="top-meta">Chris Chesher & David Silvera-Tawil, 2020-00-00 00:00:00 AEST. for week 11.</div>

<p>Chesher, C., &amp; Silvera-Tawil, D. (2021). A Robot-Human Handshake in Space: Touch and Lively Alterity Relations in Social Robotics. Culturally Sustainable Social Robotics: Proceedings of Robophilosophy 2020, 335, 86.</p>
<p>Chris CHESHER1 and David SILVERA-TAWIL a Department of Media and Communications, The University of Sydney, Australia bCSIRO Australian e-Health Research Centre, University of New South Wales, Australia</p>
<p>Abstract. In February 2012, Robonaut R2 and Dan Burbank performed the first human-humanoid handshake in space. The handshake welcomed R2 as a crewmember a social agent rather than a thing. In Heidegger's terms, it is experienced not only as present-at-hand or ready-to-hand, but also as a quasi-Dasein. Extending Ihde's concept of alterity relations we argue it is experienced in lively alterity relations, given respect as an other capable of initiating and reacting to contact. R2 is capable not only of executing programs, but of also playing its part in choreographed and improvised collaborative performances within a shared social milieu.</p>
<p>Keywords. Social robotics, human-machine relations, Heidegger, liveness-to-hand,</p>
<p>phenomenology, post-phenomenology, touch</p>
<ol>
<li>Introduction
On February 15, 2012 the humanoid 'Robonaut R2' [1] floats inside the International Space Station, ready to initiate what Commander Dan Burbank claims is &quot;the first human-humanoid handshake in space&quot; [2]. R2 extends its arm towards Burbank who reaches down to grab the outstretched hand. The robot's fingers wrap around the commander's fingers and they shake hands, pausing to have this historic event captured on camera. Ground control cheers. Robonaut's offered the handshake as a kind of gift that established an obligation to reciprocate that Burbank respected [3]. Like other handshakes, this was what Goffman [4] refers to as an 'access ceremony', welcoming the robot to the space station as a fellow crewmember. It marked mutual recognition, establishing solidarity, and synchronising their shared activities from that point forward [5]. It asserted a certain manliness: Burbank reported that it was a firm handshake [6, 7]. This handshake was a socially choreographed action [8] in which the robot took the lead. It seemed to have some of the affectivity of social touch [9]. The contact between human and non-human hands embodied and symbolised the emergence of technologies that initiate active touch [10], going beyond our assumption that technologies are most often tools that are controlled or examined by the hands of users.
In this paper, we consider this encounter between Commander Burbank and R2 as an event that raises philosophical questions about the relationship between people and robots in a shared lifeworld. In particular, how is it possible for these two actants to successfully execute the ritual of the handshake? This suggests that both are capable of active social touch the combination of movement and tactility that helps position each as a legitimate social actor. Does this mean that the robot has (quasi) social agency? Does active social touch from a robot require some form of machine intelligence? What kinds of human-technology relations are established in this interaction? How does the performance of everyday rituals promote the cultural sustainability of social robots in space and back on earth?</li>
</ol>
<p>This paper sits at the intersections between cultural studies [11], media studies [12], science and technology studies [13], and philosophy of technology [14, 15]. The phenomenon of social touch could also be examined as a psychological question [9], and is also the concern of some engineers seeking to model the mediation of affective touch [16, 17]. If social touch is always marked by the gender, class, age and ethnic identity [6], we might ask how Robonaut should be identified. Through an analysis of robotic touch, this paper critically addresses key assumptions underpinning social robotics that a robot can perform as an embodied agent in both physical and social domains. After this introduction, the article is divided into two sections, focusing on each of the participants in the handshake-human and robot.</p>
<p>We construct the narrative of this event through NASA's press releases, biographies, records, videos and still images of missions [7, 18]. In these texts, and also in popular science [19], narratives about robots ask us to imagine future possibilities as much as they report on actual developments. We perform an analysis of these texts in order to develop a reading of the human-technology relations in embodied (quasi) social situations, looking in particular at the role of touch. We situate the handshake in unremitting debates about artificial intelligence and robotics, with controversies about the formation of 'intelligent' behaviour, parasocial interaction and alterity. We argue that both choreography and programming are necessary, but not sufficient to understanding the situated meanings of contact between people and robots.</p>
<ol start="2">
<li>Human Touch: Commander Burbank
NASA's biography of Daniel C. Burbank reveals that he was born on July 27, 1961 in Manchester, Connecticut [20]. After a distinguished career in the Coast Guard, he was selected as an astronaut in April 1996. Burbank was at ease with technology: on two missions to the International Space Station (ISS), he was a mission specialist who helped deliver over three tons of supplies and install key equipment such as solar arrays to prepare the ISS for continuous inhabitation. From 21 November 2011, he became commander of the 30th long-duration mission on the ISS, until he returned to earth on the Soyuz spacecraft on 27 April 2012.</li>
</ol>
<p>As with all humans, Burbank's skin is the largest of all his organs. It gives him the sense of touch, which is the first sense to develop in utero and (arguably) the most important of all human senses [9]. His body is literally covered by a huge network of touch receptors and processing centres the somatosensory system that allow him to perceive temperatu changes, pain and irritation, kinaesthesia, touch and vibration; his muscles, joints and organs are all connected to nerves that constantly send information to his brain. The sense of touch is central for human survival and social interaction. It is believed that people need a daily dose of touch to improve their emotional and physical wellbeing [9]. From the work of Robles-De-La-Torre [21] we know about Ian Waterman, an individual who suffered permanent loss of most of his sense of touch. His tactile loss caused dramatic changes in his life. He could not walk, stand upright or sit up, could not control the movement of his limbs or tell their position. His hands, arms and fingers moved uncontrollably without him even noticing. He would not be able to feel the bed when sleeping or the water when swimming. It took him months, even years to learn to perform some of his basic daily activities by using his eyes to guide every movement.</p>
<p>Touch is classified in terms of its purposive nature. If the agent has control over the exploration process and seeks information by moving or touching an object, this is termed active touch [22]. In contrast, if the skin receptors are activated by an object touching the surface of the body; this is referred to as passive touch. Touch can also be classified as a distal or proximal sense. It is distal if an object activates his touch receptors without direct physical contact, such as the radiation of heat. It is proximal if there is direct contact between the object and the skin. As Cranny-Francis argues, though, these conceptions of touch lack attention to the &quot;intimate politics of our tactile relationships&quot; [6: 4], and imply a problematic stereotypical gendering of the male as active/distant and the female as passive/close.</p>
<p>We often use touch to share our feelings and enhance other forms of non-verbal and verbal communication. In this vein, the interpretation of social touch (or touch that contains social value) is strongly influenced by the context of the interaction along with the identity, cultures, beliefs and emotions of the people who are communicating [23]. The handshake is a special form of touching, distinctive partly because it is a performance of mutual active touch and partly because it is a quasi-universal human convention for meeting, greeting and performing agreements. This convention became prominent in its absence in the COVID-19 pandemic, when handshaking became taboo, for fear that contact would bring contagion. Handshaking has gendered associations, with the powerful heterosexual male subject privileged in this cultural practice. Handshakes vary between cultures [24], and even within them, following choreography but allowing some improvisation and style. In fact, every handshake is a singular, situated intersubjective material event. It is a point of contact between two individuals, eye-to eye, uching and being touched. It is often loaded with affect: joy, camaraderie, anxiety, or even repressed enmity. It is always meaningful and performative, with disavowed connotations of sexuality or infection. It may be judged as weak, insincere, overbearing or cloying. It may be secret, coded to include some and exclude others [25]. It affirms the place of the hand in everyday agency and the human imagination.</p>
<p>The hand is conceptually connected with fundamental ontological questions about the role of technology in everyday experience. Heidegger [14] uses the hand metonymically to distinguish between two different orientations to the world. When people, or what he refers to as Dasein, encounter objects or equipment in the flow of everyday experience, it tends to relate to them within the context of ongoing action, rather than as things to be considered for their technical or abstract properties. Heidegger says these entities in the flow of everyday activity are &quot;ready-to-hand&quot; [14: 99]. A hammer not only invites someone to use it, it also materially transforms the person's physical and experiential relationship with the world. The world becomes a field of possibility for hammering, enabling practices of building, and constituting a creative mode of being-in-the-world. It is only when the hammer malfunctions that it becomes an object with abstract properties that present a problem for inspection and becomes present-at-hand. In this relation, the hammer becomes on hand for objective examination. For Heidegger it is crucial that Dasein is thrown into a world of equipment that is ready to-hand, and only later encountered in theoretical terms as present-at-hand. It is notable that for Heidegger both relations to the world-readiness-to-hand and present-at-hand are associated with the hand, which precedes thought and vision. Where vision has been the dominant metaphor for knowledge in philosophy from Plato to the Enlightenment, in Heidegger's use of this metaphor, the world is primarily manipulable.</p>
<p>In the ISS, many of the phenomenological groundings of being-in-the-world are disturbed, including one's sense of touch. Without the force of gravity, people's experience of their body changes [26]. Hypogravity can distort kinaesthetic and proprioceptive sensations in the vestibular system to disrupt their sense of themselves, their vection (self-movement) [27], and perception of their environment. Similar to Ian Waterman's experience [21], without pressure on their feet astronauts lose the sense of which way is down. Their muscles no longer sense their own weight. People sometimes experience visual orientation illusions and feelings of self-inversion [26]. However, in spite of these changes to his body and his perception, Burbank had the capacity to adapt to being-in-the-off-world. He acclimatised himself enough to fulfil his work esponsibil es, take the routine two hours of exercise each day to maintain fitness and compensate for muscle wastage, and prepare for his encounter with R2.</p>
<p>The handshake with R2 presents something of an ontological paradox in Heidegger's schema, not only because of the disorienting effects of modern technology. In the moments before the handshake Burbank seemed to be examining R2 as something present-at-hand that needed technical attention. However, at the crucial moment, Burbank did not directly control R2, as it offered its hand seemingly autonomously. Burbank seemed not to touch R2 as equipment, but as another Dasein that was more than ready-to-hand. It became what Heidegger would have seen as a very inauthentic manifestation of being-with or Mitsein [14, 28]. This is less of a problem for contemporary thinkers, as many have posited the social agency of non-humans [29]. We would argue that the ontological status of the handshake is not to be taken too heavily. No doubt this handshake is a form of theatre [8], and Burbank was not fooled by R2's mimicry of something living. However, at that moment of contact, the two were brought together, participating as lively social actors in an everyday ceremony. Each reached out with a form of active touch, exploring the other's hand with his or its own. Those witnessing it responded to it as a legitimate handshake. Burbank seemed to relate to R2 as an active embodied social agent. R2 sensed Burbank's hand and closed its fingers to form an intimate and uncanny bond.</p>
<p>Post-phenomenologist Don Ihde [15] makes a related point about technologies that attain the status of &quot;quasi-otherness&quot; [15: 100] in his concept of alterity relations. Robots like R2 operate (somewhat) independently from direct human control. For Ihde, the robot's interior life is not significant for those encountering it. What is important is that the robot has &quot;become the focal centre of attention as a quasi-other to which I may relate&quot; [15: 100]. Like a non-playing character in a video game, the robot might become a competitor or a collaborator in Burbank's engagement with the lifeworld of the space station. However, as embodied interactive agents sharing the same physical and social space, we propose that they met one another in lively alterity relations.</p>
<p>We might add to this by invoking Horton and Wohl's [30] argument that it is commonplace for people to have ongoing social and affective 'para-social' relationships with media personalities, or personae, purely as images on television screens. They stress the manufactured and illusory nature of this form of intimacy. Even as viewers of the video of the handshake, we can begin to form an impression that R2 may have a persona with which we might develop a para-social relationship. This is certainly the case for viewers of the robots R2-D2 and C3PO in the Star Wars movies who are presented as fully formed characters. NASA, no doubt, invoked these meanings in the design and publicising of Robonaut.</p>
<p>Alongside the concept of the parasocial, we might be seen as having an even more equal relationship with our artefacts. Nass and Reeves' argument that people often unconsciously treat media technologies as people or places-could also apply [31, 32]. They propose that there is a direct equivalence between how people relate to artefacts and how they relate to other people [33]. The argument is that people mindlessly apply rules and expectations from social life to computers, such as applying gender or ethnic stereotypes, or being polite [34]. In witnessing the handshake, we could see that Burbank was certainly being polite to R2. However, in observing the video closely it is apparent in his behaviour that Burbank switches between treating Robonaut as a social actor and treating it as equipment. Lively alterity relations are not the same as living social relations, even if the boundary between the two is sometimes ambiguous.</p>
<p>As an aside, we might note that there are many other ways that the astronauts encountered technologies in the ISS. Ihde distinguishes alterity relations from technologies that extend someone's body to assign focal attention into the technology (like driving a car). He calls these embodiment relations (a concept that echoes readiness to-hand). On the other hand, he identifies technologies such as the control panel in the ISS that operate in hermeneutic relations, where the attention is on the device, rather than the world, and through it, we interpret the world as a text. This concept is related to the present-at-hand, but without Heidegger's tendency to diminish this form of relationship. There is a lot of slippage between these modes of human-technology relations. For example, when astronauts piloted the Space Shuttle with a control stick, they were experiencing embodiment relations; but in fact, they were piloting using 'fly by-wire' controls, with the ship's computers handling the control. Astronauts encountered their ship and the world predominantly through screens, read-outs, buttons and displays in the cockpit [35], so it principally operated through hermeneutic relations. The ISS, on the other hand, is not conventionally piloted at all. Computers control its position automatically on the basis of instructions from ground control and an array of sensors. In this case, Ihde would identify another human-te nology relation in play on the space station: background relations. The life support systems in the pressurised cabin operate without the focal attention of its users, and without the need for manual control. They recede into the background to maintain temperature, oxygen levels, position in orbit and so on.</p>
<p>Now that we have established phenomenological experiences of how the astronauts might relate to R2 and their environment, as far as we can imagine them from the evidence, we will shift our focus to Robonaut R2 and its apparent capacities for supervised autonomy, social agency, active touch and lively alterity relations.</p>
<ol start="3">
<li>Robotic Touch: Robonaut R2</li>
</ol>
<p>Almost 200 people from 15 countries have visited the International Space Station,</p>
<p>but the orbiting complex has only had human crew members-until now [18]. Robonaut R2 was created through a partnership established in 2006 between NASA and General Motors [1]. This project followed the original Robonaut, which was developed within NASA, and never made it to space. An operational R2 was launched in the ISS mission STS-133 aboard the space shuttle Discovery in February 2011. NASA's press releases and videos about R2 provide key technical details about R2, and also make anthropomorphic personifications of the humanoid robot. For example, one text reports that the robot &quot;thinks with its stomach&quot; [18], since its computers are not in its head, but in its torso. NASA stresses that the humanoid form allows R2 to fit in spaces designed for humans and allow it to use human tools. They say that R2 will be able to work safely alongside human astronauts as a fellow crewmember, taking on their boring and dangerous tasks. It is a &quot;dexterous&quot; robot with hands and fingers approximating the capabilities of the human hand with 12 degrees of freedom, sensors for touch and position, and fingers that can each exert 2.27kg of grasping force. R2 is apparently gendered male, while its successor R5 (Valkyrie) is female, named after a handmaid in Norse mythology [36]. In order to perceive the world and its own body, and make decisions, R2 has 38 processors and over 350 sensors. As a humanoid upper-torso-like robot, it initially had no legs, but each of its two arms have seven degrees of freedom and a total span of 2.43 metres. It was designed to have the potential to work autonomously in relationships of concern towards the world of equipment in the ISS. In practice, it was reported to have held an airflow sensor without moving and to have cleaned handrails in the ISS [18].</p>
<p>In some ways, R2's genealogy can be traced to the automata of the 18th and 19th century whose technically virtuosic and choreographed lifelike movement fascinated the mechanical computing pioneer Charles Babbage [37]. However, it is different from these machines because its sensors, motors, gearing and programmability allow it to exhibit more complex and random behaviours. NASA proposed that this would allow it to operate flexibly and interactively in an unpredictable environment [38]. A robot is often defined as a machine that senses, thinks and acts [39]. The robot's sensors capture the environment; the computer interprets these inputs and plans the robot's own actions; and its effectors act upon the world. However, this definition only goes so far in explaining the ontological status of a social robot. Sense-think-act effaces the complexity at play that emerges in robots' interactive physical and social performances. For example, when the Softbank robot Pepper uses a program to sense the presence of a human through a video camera, and analyses that person's face with image recognition algorithms, and offers to shake hands only if it 'recognises' him or her [40], it exceeds the capabili of automata because it works with social meanings of offers and rejections. In its embodied interactivity, it transcends the alterity relations of automata to manifest a degree of liveliness.</p>
<p>The claim that a robot can perform active social touch seems to re-open debates over artificial intelligence (AI). Does active touch require the robot to form an intention? Does it need to understand' the social and affective significance of active touch with another? For a long time, debates over 'hard' AI were based on comparing the 'thinking' processes of computers with those of people. Among the classic criticisms of AI is Dreyfus's rejection of the symbolic approach [41, 42]. He drew upon Heidegger's critique of the rationalist tradition and its assumption that thought is symbolic manipulation. Dreyfus's criticisms seemed plausible in the 1970s-90s considering the lack of convincing results in Al research. With his philosophical affiliation with phenomenology, Dreyfus saw this failure as a vindication of his critique of rationalism:</p>
<p>by combining rationalism, representationalism, conceptualism, formalism, and logical atomism into a research program, AI researchers had condemned their enterprise to re-enact a failure [42: 121].</p>
<p>In contrast to symbolic approaches to AI, Dreyfus [41] argues that intelligence should be grounded in something like Dasein's being-in-the-world, and the kind of knowledge that operates in readiness-to-hand. This would mean it would have concern for equipment in its surroundings and the capacity to initiate active touch. Many in the fields of AI and robotics were persuaded that embodiment was essential to simulating intelligence [43]. Dreyfus saw the behaviour-based robotics approach advocated by Rodney Brooks [44] as one step towards this goal, engaging more directly with the world through its sensors and building its actions in the world from the bottom-up. Brooks' experiments with robots such as 'Allen', which avoided touching things in its environment, wandered at random, or headed towards distant things, established a kind of situated lively alterity relations [45]. From very simple principles, its approach had some early successes in invoking liveliness, but it proved difficult to extend it into more complex behaviours [46].</p>
<p>Robotic developers have come to use a mix of techniques to create autonomous operation in robots: frame-by-frame animation, representational programming, behaviour-based techniques and machine learning. One strategy that NASA used with R2 was to create behavioural primitives, such as having the robot reach out and hold an object. The higher-level motor action program GRASP [47] is an abstract routine at the 'planner' level that can perform a grasping action onto anything. It was this routine that programmers invoked when R2 performed the handshake with Commander Burbank, turning an instrumental function into a meaningful social performance.</p>
<p>Lively human-robot touch is therefore more than what the human perceives and what the robot senses. It emerges in the choreographed and improvised action in-between the two through mutual influence. In most cases, it is the human that is more adaptable or more manipulable. Mark Coeckelbergh argues that many technologies already choreograph our movement through their own actions [8]. For example, computer games guide players through environments and the compel them to react to the actions of non playing characters. In a similar way, a robot can use theatrical techniques such as facial expressions, gestures, speech and turn-taking to choreograph our interactions with it. When Robonaut offered its hand to Burbank, according to social protocols, Burbank had to reach down to grasp the robot's hand in order to join the handshake. The robot was programmed, but Burbank's actions were not entirely his own either, as he followed the shared social script of the handshake. This suggests that robots might achieve cultural sustainability by drawing upon the repertoire of conventional choreographic patterns available in culture. However, there need to be mechanisms for choosing which conventional routines should apply to the situation, and sufficiently cultural common ground for this to work reliably. As Chesher [48] argues, human-robot interactions can be governed by metacommunication communication about communication that frames ongoing interaction. In Robonaut's information architecture, these may be handled at the level above the planner level-the &quot;arbitration level&quot; [47], where goal planning, health monitoring and user input take place. However, metacommunication does not need to be handled with such technical means. One of the most successful robots widely used in elderly care is the Paro therapeutic robot, modelled on a baby seal. It invites care in its appearance and its soft materials, and reacts with its body and its eyes to the user's touch to establish lively alterity relations [49].</p>
<p>Another example of a technology that choreographs embodied interaction is the virtual reality application First Steps for Oculus Quest. It features a mini-game that introduces new players to a glowing robot in a large space ship. When one of us first played it, the robot offered its hand, and I was impelled to reach out and shake it. This gave me immediate feedback-I saw my hand join with the robot's, felt haptic pulses in my hand, heard associated sounds, and saw the robot move kinematically towards my body. I was then urged to dance, waving my hands, lowering my body towards the floor, pulling the robot by its arms and releasing its hand to spin it on the dance floor. This interaction felt like a playful, spontaneous and delightful discovery of the robot's affordances, and sensitised me to the embodied experience of the virtual reality set-up. In a similar way, the first time that I came face-to-face with the Geminoid-F robot at UNSW in 2013 I felt a thrill of recognition, as it seemed to make eye contact with me, following my movements. In each of these cases, I would describe the experience of these interactions as lively alterity relations because the other that I encountered initiated situated actions and responded to my own in an apparently shared lifeworld. I was not fooled, but I felt compelled to behave respectfully and self-consciously towards the lively other.</p>
<p>While Robonaut was the first humanoid robot to participate in lively social interactions in space, many researchers on earth have choreographed robots for social touch. For example, Jindai and Watanabe [51] adapted a small robot with two cameras to recognise the 3D position of the human hands that it aims to shake. The robot could then initiate a handshake which subjects found was not only natural in its movement, but &quot;emotionally acceptable&quot; [50: 525]. Designing a robot with powerful motors and heavy materials that shakes hands can present design and engineering challenges that not only afford social touch, but also avoid harming people. Noda et al. [51] wrapped a Robovie robot in malleable tactile sensors that allowed the robot's processor to refer to a &quot;somatosensory map&quot; of its body surface. Using this configuration it was able to participate in social touch interactions, including scenarios such as: &quot;let's shake hands&quot; and &quot;give me a hug&quot; [51: 1102]. Others have developed robots to provide physical and mental support to child and adult patients by facilitating lively interactions with humanoid and pet-like robots, including Paro the seal [52, 53], the humanoid robot KASPAR [54] and the Haptic Creature [17]. In each of these examples, the robots have the ability to sense, interpret and respond to touch using naturalistic choreographed and improvised movement, sound and vibration.</p>
<p>It is apparent that while the connections that we refer to as lively alterity relations between people and robots are not symmetrical, they are relational. That is, robots can perform meaningful proactive and reactive movements that can be experienced in sensation, and in cognitive and affective terms. These interactions are also meaningful for those witnessing lively encounters, such as watching the video of the handshake in the ISS. We might note that liveliness is a form of alterity relation in which there is some experienced directed agency in the other.</p>
<p>Lively alterity relations are established in many other contexts of human-technology relations besides humanoid robotics. The smartphone, with its touchscreen and vibration features experienced in the human hand and body, is a medium of liveliness that attracts attention and gives haptic feedback for touch-screen interaction. The massage chair in airports and shopping centres, with permission, lays its robotic hands onto people's bodies. The computer game, mentioned earlier, inserts the active touch of the player's hand into the older medium of animation. Virtual reality brings the whole body into an animated space of lively alterity. However, the humanoid robot holds a particular fascination, in popular culture, at least. In some ways, this may be a narcissistic mirroring of the self. In other ways it may invoke the seductive or fearful constitution of the other, promising powerful affective relations [26]. To address any of these desires and expectations, designers of culturally sustainable social robots that actively touch will need to combine programming with choreography and a sensitivity to staging lively human-machine interactions.</p>
<h2>References</h2>
<div class="notes-and-refs">
<ul>
<li>[1] Diftler MA, Ahlstrom TD, Ambrose RO, Radford NA, Joyce CA, De La Pena N, et al. Robonaut 2 - Initial activities on-board the ISS. IEEE Aerospace Conference Proceedings. 2012;1-12.</li>
<li>[2] VideoFromSpace. First robot to astronaut handshake on-orbit. YouTube; 2012.</li>
<li>[3] Mauss M. The gift. Forms and functions of exchange in archaic societies. London: Cohen and West; 1966.</li>
<li>[4] Goffman E. Relations in public: Microstudies of the public order. New York: Basic Books; 1971.</li>
<li>[6] Cranny-Francis A. Technology and touch. The biopolitics of emerging technologies. London: Palgrave</li>
<li>[8] Coeckelbergh M. Moved by machines: Performance metaphors and philosophy of technology. New</li>
<li>[11] Slack S, Wise JM. Cultural Studies and communication technology. In: Lievrouw LA, Livingstone S,</li>
<li>[12] Sumner EM, Ramirez A. Media and Communications. In: Allen M, editor. Allen, M The SAGE Encyclopedia of Communication Research Methods.</li>
<li>[15] Ihde D. Technology and the lifeworld. Bloomington: Indiana University Press; 1996.</li>
<li>[16] Silvera-Tawil D, Rye D, Velonaki M. Artificial skin and tactile sensing for socially interactive robots: A</li>
<li>[20] NASA. Astronaut biography: Daniel C. Burbank. [Internet]. Houston, TX: NASA; 2018, Available from: http://www.nasa.gov/astronauts/biographies/daniel-c-burbank.</li>
<li>[5] Schiffrin D. Handwork as ceremony: The case of the handshake. Nonverbal Communication, Interaction, and Gesture: Selections from SEMIOTICA. 2010;237-50. Macmillan UK; 2013.</li>
<li>[7] Wright J. Historic handshake for Robonaut 2 [Internet]. National Aeronautics and Space Administration. 2017. Available from: https://www.nasa.gov/mission_pages/station/main/r2_handshake.html. York: Routledge; 2019.</li>
<li>[9] Field T. Touch. Second Edi. Cambridge MA; 2014.</li>
<li>[10] Scott M. Tactual perception. Australasian Journal of Philosophy. 2001;79(2):149-60.</li>
<li>editors. Handbook of New Media: Social Shaping and Consequences of ICTs. Student Ed. London: Sage; 2006. p. 141-162.</li>
<li>[13] Castañeda C, Suchman L. Robot visions. Social Studies of Science. 2014;44(3):315-41.</li>
<li>[14] Heidegger M, Macquarrie J, Robinson E. Being and time. Oxford: Basil Blackwell; 1962.</li>
<li>review. Robotics and Autonomous Systems. 2015;63(P3):230-43.</li>
<li>[17] Yohanan S, MacLean KE. The role of affective touch in human-robot interaction: Human intent and expectations in touching the Haptic Creature. International Journal of Social Robotics. 2012;4(2):163-80.</li>
<li>[18] National Aeronautics and Space Administration. NASAfacts - Robonaut Facts. 2011.</li>
<li>[19] Bonsor K, Gerbis N. How Robonauts work [Internet]. How stuff works. Available from: https://science.howstuffworks.com/robonaut2.html.</li>
<li>[21] Robles-De-La-Torre G. The Importance of the sense of touch in virtual and real environments. IEEE Multimedia. 2006;13(3):24-30.</li>
<li>[22] Gibson JJ. Psychological Review Observations on Active Touch Psychological Review. 1962;69(6):477-91.</li>
<li>[23] Schiff W, Foulke E. Tactual Perception: A Sourcebook. In Cambridge: Cambridge University Press; 1982.</li>
<li>[24] Ponton D. The pragmatics of the handshake: A politeness index in British and Italian usage. Vestnik Rossijskogo Universiteta Družby Narodov: Seriâ Lingvistika. 2014;0(4):60-75.</li>
<li>[25] Bennington G. Handshake. Derrida today. 2008;1(2):167-84.</li>
<li>[26] White RJ. Weightlessness and the human body. Scientific American. 1998;279(3):58-63.</li>
<li>[27] Gaskill M. Making sense of human senses in space [Internet]. NASA website. 2018. Available from: https://www.nasa.gov/mission_pages/station/research/news/human_senses_in_space.</li>
<li>[28] Coeckelbergh M. Growing moral relations. Growing Moral Relations. Houndsmills: Palgrave Macmillan UK; 2012.</li>
<li>[29] Cerulo KA. Nonhumans in Social Interaction. Annual Review of Sociology. 2009;35(1):531-52.</li>
<li>[30] Horton D, Richard Wohl R. Mass communication and para-social interaction. Psychiatry. 1956;19(3):215-29.</li>
<li>[31] Reeves B, Nass CI. The media equation: How people treat computers, television, and new media like real people and places. Cambridge university press; 1996.</li>
<li>[32] Nass C, Moon Y, Fogg BJ, Reeves B, Dryer DC. Can computer personalities be human personalities? Vol. 43, International Journal of Human - Computer Studies. 1995. p. 223-39.</li>
<li>[33] Reeves B, Nass. CI. The media equation: How people treat computers, television, and new media like real people and places. Cambridge University Press; 1996.</li>
<li>[34] Nass C, Moon Y. Machines and mindlessness: Social responses to computers. Journal of Social Issues. 2000;56(1):81-103.</li>
<li>[35] Lane H. Wings in orbit: Scientific and engineering legacies of the space shuttle [Internet]. NASA website. 2011. Available from: https://www.nasa.gov/mission_pages/station/research/news/human_senses_in_space.</li>
<li>[36] Ackerman E. NASA JSC unveils Valkyrie DRC Robot [Internet]. IEEE Spectrum. 2013. Available from: https://spectrum.ieee.org/automaton/robotics/military-robots/nasa-jsc-unveils-valkyrie-drc-robot.</li>
<li>[37] Schaffer S. OK computer [Internet]. Imaginary futures. 2007 [cited 2020 Jul 9]. Available from: http://www.imaginary futures.net/2007/04/16/ok-computer-by-simon-schaffer.</li>
<li>[38] Abuelsamid S. Robonaut 2 demonstration at Kennedy Space Center. NASA; 2012.</li>
<li>[39] Bekey GA. Autonomous robots: From biological inspiration to implementation and control. The MIT Press; 2005.</li>
<li>[40] Coding Kids. Pepper robot You only shake hands with me [Internet]. 2017. Available from: https://youtu.be/0_hICYW_17Q.</li>
<li>[41] Dreyfus HL. What computers can't do. A critique of artificial reason. Harper and Row. 1972.</li>
<li>[42] Dreyfus H. How representational cognitivism failed and is being replaced by body/world coupling. In: Leidlmair K, editor. After Cognitivism. Dordrecht: Springer; 2009.</li>
<li>[43] Duffy B, Joue G. Intelligent robots: The question of embodiment. Proceedings of Brain-Machine 2000. 2000. p. 20-2.</li>
<li>[44] Brooks RA. Intelligence without representation. Artificial Intelligence. 1991;47(1-3):139-59.</li>
<li>[45] Brooks R. How to build complete creatures rather than isolated cognitive simulators. Artificial Intelligence. 1987;225-239.</li>
<li>[46] Arkin R. Behavior-Based Robotics. Cambridge, MA: MIT Press; 1998.</li>
<li>[47] Badger JM, Yamokoski JD, Wightman BJ. Towards autonomous operation of Robonaut 2. AIAA Infotech at Aerospace Conference and Exhibit 2012. 2012. p. 2-4.</li>
<li>[48] Chesher C. FURO at Robotworld: Human-robot metacommunication and media studies. In Adelaide: Cultural Studies Association of Australia; 2012. p. 1-10.</li>
<li>[49] Jung MM, van der Leij L., Kelders SM. An exploration of the benefits of an animallike robot companion with more advanced touch interaction capabilities for dementia care. Frontiers in ICT. 2017;4(16):1-11.</li>
<li>[50] Jindai M, Watanabe T. A small-size handshake robot system based on a handshake approaching motion model with a voice greeting. In: 2010 IEEE/ASME International Conference on Advanced Intelligent Mechatronics. Montreal, Canada: IEEE; 2010. p. 521-6.</li>
<li>[51] Noda T, Ishiguro H, Miyashita T, Hagita N. Map acquisition and classification of haptic interaction using cross correlation between distributed tactile sensors on the whole body surface. IEEE International Conference on Intelligent Robots and Systems. 2007. p. 1099-105.</li>
<li>[52] Shibata T. An overview of human interactive robots for psychological enrichment. Proceedings of the IEEE. 2004;92(11):1749-58.</li>
<li>[53] Wada K, Shibata T. Living with seal robots - Its sociopsychological and physiological influences on the elderly at a care house. IEEE Transactions on Robotics. 2007;23(5):972-80.</li>
<li>[54] Robins B, Amirabdollahian F, Ji Z, Dautenhahn K. Tactile interaction with a humanoid robot for children with autism: A case study analysis involving user requirements and results of an initial implementation. Proceedings - IEEE International Workshop on Robot and Human Interactive Communication. 2010. p. 704-11.</li>
</ul>
</div>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="City Of Technology: Where The Streets Are Paved With Data"
class="paper-story"
data-article-title="City Of Technology: Where The Streets Are Paved With Data"
>

<h1 class="article-title" id="h_City Of Technology: Where The Streets Are Paved With Data">City Of Technology: Where The Streets Are Paved With Data</h1>

<div class="top-meta">Vincent Mosco, 2019-08-28 00:00:00 AEST. for week 12.</div>

<figure>
<blockquote>
<p>These companies – IBM, Cisco, Siemens, among others – have crafted a seductive pitch. The same technology that fueled the expansion of global business over the last quarter-century can compute away local problems, they say.</p>
</blockquote>
<figcaption>
<p>—Anthony Townsend<sup>1</sup></p>
</figcaption>
<figure>
<h2>TECHNOLOGY: THE NEXT INTERNET</h2>
<p>Most descriptions of smart cities identify several key technical systems that provide their foundation. Among the many ways to describe their configuration, I think it is most useful to view them as comprising the Next Internet, which brings together the Internet of Things (IoT), cloud computing, big data analytics and advanced telecommunications systems.</p>
<h2>The Internet of Things</h2>
<p>The <em>IoT</em> refers to a system that installs sensors and processing devices into everyday physical objects and living organisms, including people. For the city, it means embedding monitoring and data-gathering technology into roads, sidewalks, buildings, streets and their lighting, as well as throughout homes, schools and workplaces. Wherever they are located, these sensors form a network of things that accumulates vast amounts of data and delivers it to cloud computing systems for storage and processing with big data analytics. The result is real-time monitoring of transportation, communication and energy use. Advocates hope the IoT will enable faster response times to everyday problems and major disasters.</p>
<p>One outcome is the development of algorithms or decisionmaking rules that enable autonomous action. Software powers artificial intelligence (AI) systems that use data to create ‘if … then’ rules triggering responses based on changing data. For example, drawing from crime statistics and facial recognition technology, law enforcement has developed algorithms that follow some variation of ‘if you spot a face that looks like this, raise or lower your suspicion level’. Since databases are social constructions that categorise and label with all the subjectivity and prejudice found in society, it is not surprising that algorithms embody racist, sexist and class-based biases. Consequently, algorithms need to be assessed critically and with a keen eye on the social structural conditions that give rise to AI-based decision rules.</p>
<p>The IoT is made possible by advances in the ability to miniaturise scanning devices and provide them with sufficient processing and transmission power to monitor activity, analyse usage and deliver results over digital networks. In one sense, the IoT realises an old vision, once featured in ads for General Electric products, of ‘bringing things to life’, by giving them AI capabilities. These objects – what the philosopher of science Bruno Latour calls actants – in his actor-network theory, can form relationships with other objects and with living things. As one New York City smart city advocate put it:</p>
<blockquote>
<p>can your payment at a parking meter tell the street light that you’re there and accomplish some action? Can we have trash cans interact with other pieces of street furniture that is responsive to what is happening around it?<sup>2</sup></p>
</blockquote>
<p>The Internet that we have known for 30 or so years mainly connects people to other people. The IoT adds a universe of things to the network of networks. There are those who would go as far as to say that the smart city is nothing more than ‘a large-scale example of applying IoT concepts into a practical, socially dynamic application’.<sup>3</sup> At this point, only a tiny fraction of objects, about 1%, are digitally connected in IoT networks in a world where only 40% of the population makes use of the traditional Internet at least once per month. Consequently, as the numbers inevitably climb, there are high expectations for enormous growth, especially among business organisations.</p>
<h2>Cloud Computing</h2>
<p>The brilliance of the original Internet was figuring out how to get a decentralised, distributed world of servers to communicate and connect users through simple, universal software standards. This began to change with the growth of cloud computing, symbolised best by the enormous data centres that have sprung up, seemingly overnight, all over the world. These are huge, windowless buildings housing thousands of digital servers. Before there was an IoT, cloud computing began the process of transitioning to the Next Internet.</p>
<p>The cloud, as it is called, is a system for storing, processing and distributing data, applications, and software using remote computers that provide digital services on demand for a fee. The term ‘cloud’ originated in the diagrams of network engineers responsible for designing telecommunications systems. The nodes or switching points in their diagrams were typically designated by icons that resembled clouds and, before long, distant data storage came to be described as cloud computing. This is distinguished from storing and processing data locally, such as on a personal computer or in a data centre located on the premises of an office. Because of growing data storage and processing requirements, accelerating with the application of IoT devices throughout cities, organisations are increasingly moving their data to distant data centres linked through high-speed telecommunication systems. The transition is not always easy or comfortable for the individuals and organisations contemplating moving to the cloud. Loss of control, including the spectre of making valuable data more easily available to hackers, among other security threats, raise significant commercial and privacy issues that can slow the migration of data to the cloud. More attention to security, including the expansion of blockchain, and perhaps even the adoption of quantum computing, as it emerges from years as little more than a laboratory curiosity, might help address some of these issues. But there is too much uncertainty about both blockchain and quantum to think that they will provide a comprehensive resolution to security concerns any time soon.</p>
<p>It is also uncertain that distant cloud data centres can provide the response times necessary to operate IoT devices properly, particularly when connectivity inevitably grows from the single-digit percentage of objects currently networked. As a result, there are those who believe that smart networks will need to include some processing power located closer to devices, for example, within the sensors of autonomous vehicles. These so-called edge computing systems will be especially important when telecommunications connectivity is spotty. This wrinkle in the cloud does not diminish the importance of data centres and has certainly not yet slowed data migration to the cloud. For example, Apple is so confident that we are only in the early stages of data centre expansion, that between 2017 and 2018, it purchased 7,000 acres of land to build a new generation of data centres.</p>
<p>Cloud computing also comes with a cost to the environment that will only grow as more data centres are built and as climate change reaches into everyday life. Server factories require large tracts of land and depend on massive supplies of water to prevent servers from overheating. Data centres put intense pressure on electrical supply grids and add massively to electronic or e-waste. All of this belies the image of an immaterial cloud. Some cloud companies have been responding with growing reliance on sustainable energy sources, but competitive pressures lead others to choose the least cost and that often means the most environmentally unfriendly alternatives. The rise in popularity of bitcoin and other cryptocurrencies, whose massive data-processing requirements require significant cloud server capacity and acres of data centres, has created some of the ugliest environmental impacts. This reality leaves utilities caught between a critical public and a voracious new sector looking for nearly unlimited power. For utilities to reject the industry’s demands inevitably invites expensive legal battles. As one utility executive put it, ‘If you can afford 100 megawatts, you can afford a lot of attorneys’.<sup>4</sup></p>
<h2>Big Data Analytics</h2>
<p>Data may not be the new oil, as some have suggested, but its value distinctly depends on what can be done with it. Sure, IoT devices accelerate the amount of digital information and cloud data centres expand the capacity to store it. But data becomes genuinely valuable only when it is packaged in a form that enhances the value of existing products and services or makes possible the development of entirely new ones. For this, we turn to the third leg of the Next Internet, big data analytics, which refers to how experts, increasingly with titles like ‘data scientist’, make use of the data gathered by IoT sensors and store and process that in the cloud. Specifically, data analytics involves taking a large and, almost always, quantitative data set, and it examines the specific ways the data does or does not correlate, in order to draw conclusions about current behaviour and attitudes, and to make accurate predictions. It is one thing to gather data on cars travelling down highways or city streets and quite another to process it in a form that leads to adjustments in the timing of traffic lights or in the efficient use of high-occupancy vehicle lanes. It is one thing to put cameras on street lights and quite another to deploy the images gathered so that police can better monitor locations where violent crime is a serious problem. It is relatively easy to collect data on how users surf the Internet, but more difficult to package it for companies who want to improve targeted advertising.</p>
<p>The general aim of big data analytics is to process vast new stores of data and make sense of it all by producing algorithms or rules that specify conclusions to be drawn, or actions to be taken, under specific conditions. Given the limitations of quantitative correlational analysis, especially the absence of historical context, conceptual clarity and subjectivity (qualitative data is ignored or poorly translated into numbers), such analysis is not always accurate. Incidents of big data failures are mounting, on such projects as seasonal flu forecasting and building models for economic development. Privacy concerns are also growing. Almost every IoT device gathers usage information. As a result, it came as no surprise to those who follow big data analytics when a 2018 report noted that ‘smart’ thermometers send data to drug companies so that they can deliver customised messages about their remedies to users.<sup>5</sup> There are also many opportunities to make mischief with data, as we learned most alarmingly from the 2016 U.S. presidential election. Nevertheless, smart city advocates believe that these problems can be managed so that big data analytics can be deployed to provide real-time analyses of city functions to help make municipalities operate more efficiently and effectively.</p>
<p>These three converging technological systems, literally connected through wired and wireless high-speed telecommunications, provide the IT infrastructure for what is anticipated to be the leap to smart cities. The smart city movement is spawning an entire industry comprised of engineers developing technologies and applications, as well as tech-savvy city planners and designers responsible for integrating these into existing or entirely new cities. Reports on the economic prospects for smart city technologies tend to agree that this is an industry about to hit explosive growth. One study concluded that the smart city market will be worth $1.2 trillion by 2019 and $2.75 trillion by 2023.<sup>6</sup> By 2020, forecasts call for 600 smart cities throughout the world.<sup>7</sup></p>
<h1>SMART TRANSPORTATION, SMART ENERGY, SMART COMMUNICATION</h1>
<p>Among smart city applications, increased efficiencies in transportation, energy and communication receive a great deal of attention. Smart city advocates like to talk about cities clogged with unmanageable traffic and demonstrate how, in the words of one, ‘a smart city moves past all that’ with autonomous vehicles, traffic signals that respond to current demand, lanes that change size and direction with congestion patterns, and kerbside parking that is informative and responsive to changing demand.8 Parking garages that identify the number of spaces available and also guide cars to vacant spaces are part of the smart transportation equation. In addition, sensors serve a policing function, with constant surveillance to spot and record traffic violations, thereby enhancing road safety. They also strengthen the public transportation system by enabling flexible scheduling and routing of buses, trains and aeroplanes.</p>
<p>Supporters also focus on the efficient production and distribution of energy resources made possible by Next Internet technologies. As with transportation, much of the benefit is associated with constant surveillance. In the home, this means programmable Wi-Fi thermostats, lighting that is not only energy-efficient (as much LED lighting as possible) but also manageable through a smartphone, and smart metering of energy use. Some cities, mine included, also provide monthly alerts to customers on energy use in their city, their community and on their street, in order to encourage customers to use heating, cooling and lighting more sparingly. Smart street lighting adjusts to environmental changes and monitors street activity. Increasingly, as residents of San Diego and a handful of other cities have come to learn, the ‘eyes on the street’ are embedded in street lighting. Smart buildings, offices and factories operate on the same principles: 24-7 monitoring, data collection and management through algorithms that regularly adjust to changing conditions.</p>
<p>Smart city proponents round out the trio of essential elements by calling for universal access to high-speed communication, particularly through the deployment of 5G telecommunications services. This may take place through private telecommunications carriers or public Wi-Fi systems, such as one pioneered in New York City. The basic idea is that the more communication there is, the better a city is able to understand the needs of its residents and build a smart community. Relatedly, citizens need to have access to information and opportunities to participate in civic affairs. Opinions vary on precisely what participation means, with some believing that online communication helps overcome democratic deficits and with others fearing that an excess of participation may undermine effective decision-making.</p>
<h2>BIG SAVINGS</h2>
<p>Notwithstanding these concerns, there are enormous expectations for cost savings. According to a report produced by ABI Research, the typical smart city government in the United States could save as much as $4.95 billion annually with upgraded smart buildings and street lighting leading the way. Repair and maintenance costs are expected to decline by 30%. Businesses in the smart city will be able to save an additional $14 billion in areas that include smart manufacturing plants, as well as more energy-efficient freight transportation using drones, semi- and fully-autonomous vans and trucks. Finally, smart city advocates expect that citizens can save another $27 billion per year by deploying smart meters and microgrids, and even save on school costs through hybrid systems that make extensive use of online technology. In total, the think-tank expects worldwide savings of $5 trillion yearly by 2022 for the 75 largest smart cities.9 Moreover, looking at the period from 2018 to 2026, the report sees smart cities achieving incremental growth of over 5%, and smart technologies driving more than $20 trillion in additional economic benefits.<sup>10</sup></p>
<p>Shifting from financial to time savings, the technology pioneer Intel produced a report that examined 20 cities across four types of Next Internet applications: mobility, health care, public safety and productivity. It concluded that such things as improved public health and safer streets could save citizens an average of 125 hours per year, thereby adding a little over 5 days to each person’s year.11 Such reports are used to justify big spending on IoT technologies, particularly retrofitting urban infrastructure such as street lighting (increasingly referred to as ‘digital infrastructure beacons’), roads, schools, health care facilities and offices. In a 2018 report by the think-tank IDC, such spending was expected to reach $80 billion worldwide, rising to $135 billion by 2021.<sup>12</sup></p>
<h2>COMMAND AND CONTROL IN THE SMART CITY</h2>
<p>Managing the vast array of urban technology applications that make up smart cities is an enormous challenge. To do so, big technology companies have urged civic officials to build centralised monitoring and decision-making facilities. IBM was the first to succeed, constructing one for Rio de Janeiro that has become the model for many smart cities. Called the Rio Operations Center and resembling a military ‘war room’, it started up at the end of 2010. As is so often the case, a crisis precipitated an opportunity for the authorities to centralise monitoring and control in the region. A massive storm had led to flooding that killed 70 Rio residents and many more outside the city. In the wake of this tragedy, the city’s mayor teamed with IBM to integrate the data-processing and monitoring activities of some 30 municipal and state agencies as well as utilities, in a single structure. The official aim of the Rio Operations Center is to enable the city to run more efficiently especially during emergencies. The Center integrates key departments, such as police and fire, and makes possible centralised monitoring of emergency situations, as well as surveillance of weather, traffic, electricity, trash pickups, recycling, disease outbreaks, gas and water. The facility also contains a ‘crisis room’ that permits the mayor to meet with advisors and make executive decisions when faced with security threats. The Center’s staff of some 70 analysts, all dressed in white jumpsuits, sit before banks of screens. An enormous wall monitor is divided into grids containing live video feeds from surveillance cameras, along with other data. Google satellite and Street View maps are integrated into the system, enabling analysts to overlay additional data and get closeups. The facility has the capacity to locate and identify every public vehicle, such as a city bus, at any time.</p>
<p>Centralisation has its merits, but the Rio Operations Center is notable for its tall gates, tight security and near complete lack of transparency. Data from monitoring devices, including video cameras stationed all over the city, enters the facility and feeds into a centralised decision-making process that has practically no citizen input. The Center was used to monitor protests against the 2014 FIFA World Cup and the 2016 Olympic Games, both held in Brazil. The former mayor of Rio de Janeiro, who has promoted the project on the TED lecture circuit, boasted in a promotional film about these surveillance capabilities: ‘the operations center allows us to have people looking into every corner of the city 24 hours a day, 7 days a week’.<sup>13</sup> A research assessment of the Center raised serious concerns:</p>
<blockquote>
<p>While the use of these systems in Brazil is quite recent, it would appear that smart-city technologies are not being used to solve problems of radical inequality, or systemic poor governance, or compromised urban planning agendas – all of which continue to be the ‘dumbest’ elements of Rio de Janeiro.<sup>14</sup></p>
</blockquote>
<p>The Rio government responded to criticisms with a few modifications (it subsequently built an accessible website). Nevertheless, the first fruit of IBM’s ‘smarter city’ initiative, a $4 billion urban surveillance operation, is still shrouded in controversy. In addition to the concern about surveillance, there are those who worry that the Center is more flashy than functional. According to smart cities expert Anthony Townsend:</p>
<blockquote>
<p>Urban security experts with whom I have spoken are sceptical that it will have any significant impact on law enforcement and technology experts point out that beyond the video streams there has been little investment in new infrastructure to feed realtime data to the Center.<sup>15</sup></p>
</blockquote>
<p>It appears to Townsend that looking smart is often more important to civic officials than actually being smart and that this need to appear smart was driving the mayor and other elected officials ‘into the arms of engineers’.<sup>16</sup></p>
<p>The idea of a centralised command centre for smart city applications has spread to other locales. The German tech company Siemens, which has invested heavily in urban technology, built a City Cockpit for Singapore and bragged that it enables ‘real-time government’:</p>
<blockquote>
<p>Here, state-of-the-art information and communication technology (ICT) enables the mayor and other decision-makers to track and analyze processes in their city in real time. All of the important information flows into a central system that processes the data for convenient display and indicates to what extent specified objectives are being met.<sup>17</sup></p>
</blockquote>
<p>According to the company, the launch of the City Cockpit was followed by 200 groups of visitors from around the world looking to learn about the best ways to integrate the vast stores of data produced by their growing monitoring systems. This step was followed up by another joint Siemens-Singapore project that produced a ‘Digitalization Hub’. Launched in 2017, it centralises the development of smart city applications for the city-state and the entire Southeast Asia region. Like Rio, Singapore has raised alarm bells about surveillance and centralisation. As a result, not all such efforts have succeeded. When, in 2014, technology companies, including Google, convinced the city of Oakland, California to create a centralised facility to coordinate police and other surveillance operations in the eerily named Domain Awareness Center, mass protests led to cancellation of the project.18 Chapter <sup>8</sup> takes a closer look at these concerns. At this point, it is important to understand that the key technical systems providing the foundation for smart cities, primarily the IoT, cloud computing and big data analytics, create significant surveillance opportunities. These provide enticing opportunities for governments interested in deepening control, corporations that want to market technologies, services and data, and hackers looking to make mischief.</p>
<h2>GOOGLE TORONTO AND IT COMES UP NEW YORK</h2>
<p>One of the phrases I began to hear with surprising frequency when I moved to Canada was ‘world-class’. Living in the United States for the first 36 years of my life, it was rare to hear the term used. To speak of New York, Washington, DC or Los Angeles, as world-class would be considered redundant and hence unnecessary. Canadians, I quickly learned, were not satisfied to have the Canadian best. It had to be world-class. For Canadians, references to New York-style anything, the Harvard of the North, or the Paris of North America were far from unusual. This remains especially the case for Toronto where aspirations to world-class stature, which would see it join the ranks of global cities like New York, London and Tokyo, are a regular feature of public discourse. As the saying goes, watch what you wish for. The most recent Toronto–New York entanglement, this time over their similar smart city makeovers, reveals a great deal about the political economy of technology enabled urban areas. The coming of the smart city has brought Toronto and New York together in more ways than one and each provides important insights into the problems and the potential for a smart city future. Both places exemplify the ageing metropolis that is open to urban renewal with smart city technology. Enter Google, which wants to lead the remake in both cities, and, in the process, win control over prime real estate and the data generated by those who use its redevelopment space. The company has been in Manhattan since 2010 when it paid $1.8 billion for a 2.9-million-feet-square building that has served as the company’s headquarters in the city. In 2018 Google expanded across the street by purchasing the iconic Chelsea Market, a 1.2-million-feet-square building for $2.4 billion. According to one Manhattan tech executive,</p>
<blockquote>
<p>The modern tech sector began on the West Coast when it was about developing new technology and programming. It’s now about the implementation and application of technology. And that’s presented an opportunity for New York, the business capital of the world. The talent pool is here.<sup>19</sup></p>
</blockquote>
<p>Shortly after it was revealed that Amazon would locate one half of its second headquarters in New York City (the other is to be built in the Washington, DC suburbs) to house 25,000 employees, Google announced that it would be doubling the size of its New York City staff for a total of 20,000 employees, most of whom will be located in Manhattan. Amazon’s decision to cancel its incentive-laden deal with New York, in the face of massive opposition, leaves Google’s presence in the Big Apple all the more significant.</p>
<p>In addition to making New York the company’s first engineering centre outside of Silicon Valley, Google assisted in the creation of Cornell Tech, a new academic campus in the city focussing on technology and entrepreneurship. In 2015, the company established a new unit called Sidewalk Labs to promote urban redevelopment and it immediately took to developing a free public Wi-Fi system for the city as well as incubating a handful of companies that aim to extend its digital ecosystem in the provision of social services like health care.</p>
<p>At about the same time that Google was expanding in Manhattan, the company set its sights on Toronto, promising to turn a valuable parcel of land in the downtown waterfront, long gone to seed, into a model smart city. Specifically, Sidewalk Labs travelled north and proposed to create a futuristic community of apartments and condos, offices, schools, roads, parks and entertainment venues, all equipped with the latest in Next Internet technology to gather and use data on just about everything. To acknowledge this ‘world-class’ moment, the Google launch in Toronto featured speeches by Canada’s Prime Minister, the premier of Ontario, the mayor of Toronto and the chairman of Alphabet, the parent company of Google. All hailed the project as an opportunity for Toronto to join the ranks of the world’s elite smart cities and provide a model for cities around the globe.</p>
<p>The specific plans for the Toronto project have changed over time and will likely continue to evolve. What is clear is that Sidewalk Labs, with the agreement of Waterfront Toronto, a quasi-governmental body created by the federal, provincial and city governments, and comprised of developers and public figures, received approval to build on land near the city’s downtown and fronting on Lake Ontario. It is, in the New York Times description, ‘the closest thing anyone has seen to a tech company that takes the reins in a major city’. As such, Toronto fulfils the dream of Eric Schmidt, a Google founder and executive chairman of Alphabet, to demonstrate what ‘we could do if someone would just give us a city and put us in charge’.<sup>20</sup> There have also been discussions about developing a much larger adjacent area. In all, the city has about 800 acres of waterfront land available for development. While the focus has been on building a model smart neighbourhood, the goal is to expand on this in Toronto and make Canada’s largest municipality a model for smart cities around the world. In February 2019, Google proposed to collect a share of property taxes and development fees that normally go to the province of Ontario, in return for building its ‘world-class’ smart city.<sup>21</sup> Resisting any restraint on hyperbole, the company proposes to construct what it calls ‘the world’s first neighborhood built from the internet up’.<sup>22</sup> Sidewalk Labs provides examples of what this means:</p>
<ul>
<li>Modular buildings that can shift from housing to retail and back again.</li>
<li>Monitors that track noise and pollution (likely through sensor-equipped traffic lights).</li>
<li>Adaptive traffic lanes and traffic signals.</li>
<li>Self-driving private and public vehicles.</li>
<li>Underground tunnels that accommodate delivery trucks and keep them off the streets (reminiscent of Disney’s original plan for Epcot).</li>
<li>Packages delivered with the aid of drones.</li>
<li>Ride-sharing autonomous taxis (taxibots).</li>
<li>Heated bicycle paths and sidewalks that melt snow.</li>
<li>A carbon-neutral thermal energy grid.</li>
<li>Sensors that monitor and enable the separation of waste from recycling.</li>
<li>A digital infrastructure that provides ubiquitous connectivity for all.</li>
</ul>
<p>Sidewalk Labs also plans to create an innovation centre that will incubate technology companies developing applications for the Toronto neighbourhood.</p>
<p>Toronto’s smart city connection to New York extends to more than a similar corporate blueprint for technology-rich redevelopment. The cities also share the project leadership of a man who opens his book about transforming the Big Apple, Greater Than Ever: New York’s Big Comeback, with the words: ‘I vividly remember my first visit to New York City; it was hate at first sight’. For Daniel L. Doctoroff, the man who would lead Sidewalk Labs in New York and in Toronto, this was more than just a catchy opening. Although not very clear about why, there is little doubt that he really hated New York. All he recalls is a view of high-rise apartment towers and a young boy’s shout from the back seat of the family car: ‘I am never going to live in this city’, followed by a happy return to his suburban Michigan home.<sup>23</sup></p>
<p>One can forgive a 10-year-old for feeling a bit of terror when seeing the city for the first time. Although, frankly, I cannot help but recall how much I loved the city in 1958 when I was 10 and I have continued my deep affection for New York in all the years thereafter. It was a magical place for a working-class kid growing up in Manhattan where everything was just a walk or a 15-cent subway ride away. I loved the diversity that later enabled a teenager to walk to the Cafe Au Go Go in Greenwich Village to hear Richie Havens sing ‘Here Comes the Sun’ on one weekend, then go to a repertory theatre a few blocks away to see a performance of Euripides’s Trojan Women on another weekend, or to Yankee Stadium and Madison Square Garden for the best in sports. I knew, or felt like I knew, practically every museum, bookstore, and Manhattan street. Admittedly, there was dirt, crime, noise, corruption and worse, but I cannot imagine a richer place for a tenement kid to grow up.</p>
<p>I never fully appreciated the contrast between hate for the city and the feeling of interconnected freedom that New Yorkers and those who love the city experience so much of the time, until I heard it described by the novelist Zadie Smith. She wrote on the subject immediately after coming to terms with a terrorist shooting near Stuyvesant High School in Lower Manhattan. Smith speaks of New York’s</p>
<blockquote>
<p>fair weather friends, the kind who celebrate us in our tragic moments but affect to despise us in our everyday mode. The same people who claim to believe that the only meaningful societal bonds are fixed and solid and unbroken – blood, nation, faith – and so can never truly comprehend a city like New York in its everyday mode, in which bonds gather and dissipate with a dizzying fluidity and yet, for the brief duration that they are in place, can display a mighty strength.<sup>24</sup></p>
</blockquote>
<p>I have felt that strength many times over in New York and other big cities. It is what makes cities great and, with or without mediating technologies, it is the ‘dizzying fluidity’ that helps makes them smart.</p>
<p>Foregoing his childhood promise, Doctoroff returned to New York City, albeit reluctantly, but for the same reason millions of other people ‘from away’ come to the Big Apple: to make money. So even though, after graduate school, he and his partner agreed that ‘New York was the last place we expected to end up’, a job offer at Lehman Brothers, then one of the most prestigious investment firms in the world, proved too tempting to pass up. Renting a spacious Gramercy Park apartment down the street from Park Avenue, Doctoroff complained about the tawdry state of the neighbourhood, particularly the prostitutes and drug dealers. Years of investment banking made Doctoroff rich and when Michael Bloomberg was elected Mayor of New York in 2002, not long after the 9/11 attacks, he tapped Doctoroff to become deputy mayor for economic development and rebuilding. The new deputy mayor brought with him many of his associates in the financial industry and, in addition to the job of rebuilding Lower Manhattan, he worked on a plan to reshape New York so that it might win a bid for the 2012 Olympic Games, a dream of his dating back to 1994. Doctoroff held the deputy mayor position until 2008 when Bloomberg engineered a change in the city charter enabling him to eliminate term limits and run for a third term as the city’s mayor. The deputy mayor was rewarded with the position of president of Bloomberg’s business information company, aiming to expand the firm from a lucrative, if small, provider of economic data to subscribers of Bloomberg’s terminals, into a news organisation that served companies worldwide. Doctoroff left Bloomberg in 2015 to become the founding CEO of Sidewalk Labs.</p>
<p>There are conflicting views of the Bloomberg-Doctoroff impact on New York, including the efforts to use information technology to join the ranks of established smart cities. Doctoroff’s book concludes that the city made a ‘big comeback’ and is ‘better than ever’. For Jeremiah Moss, whose popular blog Vanishing New York was turned into a book by that name, the opposite is true: ‘The spirit of the city as we knew it has vanished in the shadow of luxury condo towers, rampant greed and suburbanization’.<sup>25</sup> Moss and others cite changes in zoning that permitted more high-rise luxury housing and the growth of private governance through the increased power of corporate Business Improvement Districts (BIDs). These are areas controlled by local companies that, in return for paying an additional tax levy, are given power over a range of activities from sanitation to culture. In fact, one analyst looks out over the now 75 BIDs and worriedly concludes that they have become the ‘cultural programmers’ of New York City streets, replacing the public art of the city’s diverse communities with business approved and tourist-friendly kitsch.<sup>26</sup> Then there are the public–private partnerships that tend to be public in name only, or only when the partnership fails and the city is left responsible for a mountain of debt. There is a case to be made that New York’s zoning regulations were arcane and needed upgrading. The massive loss of its manufacturing base left the city with areas zoned for industry that would never again be home to manufacturers. However, instead of taking advantage of an opportunity to restructure zoning and related planning tools to promote affordable housing and support small businesses, the city government fell into the laps of big developers who clamoured for high-end/high-return investment.</p>
<p>As a result, skyrocketing housing prices have driven the working class out of Manhattan to the outermost reaches of New York’s other boroughs, or out of the city entirely. At the same time, high rents made it impossible for small and independent retailers to survive and many of these were replaced by stores marked with the names and the merchandise of global brands. Builders of luxury towers receive big tax breaks and the evictions of residents who stand in their way have accelerated. For these reasons, a place once characterised by the diversity of its residents, is increasingly a city for the rich and for tourists. For example, the ‘Little Italy’ neighbourhood in Lower Manhattan, where I spent my youth and which helped generations to enter the American middle class, no longer supports an Italian American community. Although branded Little Italy, with restaurants and shops that sell Italian food and products, hardly any Italians actually live in the neighbourhood anymore. The 2000 census recorded 8.25% of residents claiming Italian ancestry, the same as in the entire City of New York. The 2010 census recorded no one living there who was born in Italy. Today, like many other neighbourhoods in the City, Little Italy most resembles a theme park, similar to those in Disney’s Epcot, a branded commercial replica of what used to be an actual community.</p>
<p>Neither hyper-gentrification nor deepening inequality began with the Bloomberg administration but there is little doubt that these problems accelerated during the city’s ‘comeback’. No less a supporter of the urban creative class than Richard Florida ranks New York City second only to Los Angeles in his New Urban Crisis Index, a measure that combines economic segregation, wage inequality, income inequality and housing unaffordability. Remarkably, much of New York’s major redevelopment under Bloomberg is an extension of the failed bid to host the 2012 Olympic Games. This includes positive developments, like the creation of middle-income housing in the borough of Queens that was earmarked for construction of the Olympic Village. On the other hand, the plans for an Olympic stadium on the far west side of Manhattan became the site of the largest private real estate development in the United States when the city approved the Hudson Yards project containing 28 acres of mainly luxury housing and office space, and the creation of a subway line extension linking the area to the rest of the city. It is hard to justify the development since Manhattan has very little affordable housing and the subway system throughout the city is in the worst condition since the end of the Second World War. Nevertheless, the city is providing private developers with significant tax incentives. In total, according to a 2018 account that unpacked the dense thicket of money flows, taxpayers will have poured $5.6 billion into the development and will receive very little, if anything, in return. Public investment includes $2 billion for a subway extension to provide those living and working in some of the most expensive real estate in the world with convenient public transportation. The city also earmarked $500 million in funds for the most expensive park per acre in New York.<sup>27</sup> Once again it was Daniel Doctoroff, who led the project from its inception in 2004 until he left the Bloomberg government in 2008 to run the mayor’s business information company.</p>
<p>It is striking to compare this Hudson Yards project with one proposed back in 1967 when addressing inequality, supporting pubic services and keeping the working class in Manhattan mattered to those with the power to make a difference. Chelsea Walk, as the earlier proposal was called, would include primarily middle-income housing, as well as units subsidised to make them affordable for poor and working-class residents, along with schools, a park and other civic amenities. Ironically, the project failed to get off the ground because some opponents felt it did not contain enough low-income housing and others wanted to see more job-producing industrial development. Even though the current Hudson Yards development is much larger, it makes no room for middle- and low-income New Yorkers.<sup>28</sup> Moreover, and quite significantly, the Hudson Yards development will collect voluminous amounts of data on how people make use of the space, leading one analyst to refer to the project as the creation of a ‘quantified community’.<sup>29</sup> The main partner is New York University’s Center for Urban Science and Progress (CUSP), a public–private research institute focussing on the relatively new discipline of urban science. The Center has received significant funding from the city, ostensibly in the hope that data gathering and data analysis will benefit future development projects. Critics view the massive surveillance of people, objects and the environment as a prime example of the over-reliance on and fetishisation of data. There is undoubtedly social value in the detailed monitoring of air quality and greenhouse gas emissions. But for private sector participants, it is an opportunity to turn data on social and physical processes at a brand-new luxury development into marketable commodities. In many respects, it foreshadows what Google has in store for the Toronto waterfront.</p>
<p>A related West Side development, the elevated linear park known as the High Line, constructed in 2009 out of an old rail spur and expanded over the years, has attracted widespread praise as a great public space. Having walked the High Line many times, I can easily understand its popularity, particularly for anyone who knew the rough state of the old Meatpacking District it now anchors. However, the park has suffered because of the very zoning changes that were put in place to promote development. Rising above the street, the High Line once felt open and airy, with expansive views of the Hudson River. Now it is more like walking through a tunnel, as high-rise condos and office towers, built to take advantage of the High Line location, block much of what once made the park attractive. It appears that the High Line is serving a similar function as do the communities of artists who move into rundown neighbourhoods and end up advancing gentrification because they provide a cachet attractive to tourists and developers. Eventually, the artists are pushed aside by the very process they once enabled. The High Line offers the cachet to attract not only tourists, but big developers too. Now, their high-rise towers are contributing to the demise of one of the gems of early twenty-first century New York. Contrast this to Paris, where strict zoning has protected the Promenade Plantée, a 3 mile long elevated park created in 1993 from an old viaduct connecting the Bastille to the Bois de Vincennes. I walked both parks in 2018. The High Line was cavernous and downright claustrophobic, with high-rise buildings on both sides; the Promenade Plantée was the same bright garden in the sky it has been for a quarter of a century. Notwithstanding that ‘smart’ is a subjective term, it nevertheless felt obvious to me which city had made the smart choice.</p>
<p>Doctoroff’s Olympic blueprint for New York City contributed significantly to other big development projects, including the construction of Citi Field, home of the New York Mets baseball team in the borough of Queens, on the understanding that it would be used for the 2012 Games. The Olympic bid also led to the redevelopment of Brooklyn’s Williamsburg whose gentrification was subsidised with zoning changes and tax relief justified by the expectation that it would be the location for Olympic aquatic sports. The waterfront park planned to woo the International Olympic Committee was never built. What did go up was luxury housing and, along with it, a 300% increase in neighbourhood property values between 2004 and 2014. It is testimony to the power of Doctoroff that his Olympic dream, which he began to develop in 1994, ultimately had such a profound and, for many New Yorkers, negative impact on the city.</p>
<p>The promise of a genuinely smart city, where cars zip through automated tollbooths and police use instant access to crime and mapping data to anticipate illegal activity, helped to build support for the city’s transformation. So too do the growing number of sewer and air quality sensors, police and traffic cameras, taxi tracking, sound sensors installed on rooftops, sensors that monitor radiation and chemicals, infra-red cameras, as well as garbage cans equipped with Wi-Fi. Moreover, New York is one of nearly 100 cities worldwide that use the ShotSpotter system of microphones located in public places that instantly detect and locate gunshots.</p>
<p>Two of the most important innovations in New York were the development of a concentrated technology research, development and innovation area and the commitment to construct a free, citywide, public Wi-Fi service. Smart cities often include a technology research centre and New York is no exception. It is also no newcomer to this type of activity. In the 1930s, a time when New York was a city of industrial districts, Lower Manhattan featured Radio Row, a centre of electronics businesses that serviced the telecommunications and burgeoning broadcasting companies. AT&amp;T was headquartered in the Radio Row district and Bell Labs was not far away. Ironically, just before Silicon Valley emerged as the world’s information technology capital, Radio Row was torn down to make way for the Twin Towers of the World Trade Center. Two decades later, New York gave birth to a software development district extending from Lower Manhattan up to Madison Square Park. Silicon Alley, as it was called, held out great promise for returning the city to its dominant position in communication and information technology. But the businesses making up the Alley withered in the dotcom bust of 2000, and especially after the city shifted to reconstruction in the wake of the attacks of September 11. Google took a major step towards reviving the industry when it set up an East Coast headquarters in an Art Deco building in Manhattan’s Chelsea neighbourhood and agreed to expand by purchasing the Chelsea Market building across the street.</p>
<p>Of equal or greater significance for smart city advocates is the development of Roosevelt Island, the site of Cornell Tech, which was created in 2011, when it won out over competitors in a Bloomberg government contest to develop a high-tech education, research and innovation centre. Occupying 12 acres on the island, it operates a graduate education programme in technology, and carries out research in partnership with New York-based companies, including Citi Ventures, the venture capital arm of the banking conglomerate Citigroup. Citi Ventures plays a significant role in the new tech district with its own 10,900 feet square facility that brings to the island researchers from university, business, technology and design programmes to work on development projects.</p>
<p>In keeping with a focus on development projects tailored to New York’s elite, it was not until late in the third term of the Bloomberg administration that New York began experimenting with public Wi-Fi. In 2012, it started installing routers at payphone kiosks whose use diminished with the spread of cell phones. The programme expanded in 2014 when Bill de Blasio took office as mayor and a contract was awarded to the company CityBridge to set up Wi-Fi kiosks throughout the city. Doctoroff’s Sidewalk Labs entered the picture when it became a major investor in the project, through a subsidiary firm. It was not until 2016 that the system achieved widespread use and it continues to expand. Although Wi-Fi use is free, Sidewalk Labs benefits in several important ways. The company sells advertising, which appears on large, high-definition screens inside each kiosk. It also gathers data on kiosk patrons, which can be used by the company itself, by any other company in the Alphabet organisation, or sold to third parties. CityBridge’s privacy policy claims that personally identifiable data is not sold, but the American Civil Liberties Union has raised concerns about the vague language. Finally, the system serves as a laboratory and a gateway for expanded smart city systems, such as connected street lighting, smart utility meters, traffic-monitoring networks, connected cameras and the installation of 5G wireless services. Although media coverage of problems with the system has focussed mostly on homeless people downloading pornography, and drug dealers using it to complete deals, there are serious questions about surveillance (including through front facing cameras on the Wi-Fi devices), hacking and the sale of publicly generated data. Critics have also complained about the slow rollout of kiosks, citing specifically the city’s grant of an extension on delivery dates despite the lower than expected funding flowing into city coffers.</p>
<h2>DON’T GOOGLE THIS</h2>
<p>Sidewalk Labs is using its New York experience to expand into Toronto and beyond. This is an important development because it raises significant policy issues that, as the smart city idea continues to spread, should concern every city dweller. Governments are dependent on private sector technologies to make good on smart city promises. That leads municipal and other authorities to develop partnerships with Google, IBM, Cisco, Siemens and other big technology firms supplying Next Internet technologies to make smart cities run and build the command centres to manage them. These public–private partnerships, or P3 arrangements, make it easier to transfer political authority to unelected private entities. ‘Just give us a city and put us in charge’, Eric Schmidt once suggested. Google’s founder, former CEO and the first CEO of Alphabet is beginning to get his wish.</p>
<p>The spectre of private governance over cities did not originate with the smart city concept. In the computer era, the prospect of automated cities that deliver services to customers with the promise of freeing them from municipal bureaucracy is just another manifestation of Bill Gates’s 1996 promise to run the world through ‘friction-free capitalism’.<sup>30</sup> However, it is not simply a matter of handing the keys to the city over to the company making the shiniest offer. When New York City was concerned that citizens might balk at big redevelopment schemes that would raze entire neighbourhoods, the city government expanded the power of a minor agency, the Port Authority of New York and New Jersey, initially charged with handling common harbour issues. Operating at arm’s length from government departments and therefore from public oversight, the Port Authority became the fiefdom of Robert Moses, known to his friends as the Master Builder but dubbed the King of Concrete by those who opposed him. Operating primarily behind closed doors, the organisation enabled Moses to raze entire communities and make the automobile the dominant mode of transportation in New York. Without recourse to oppose such schemes through traditional democratic means, only those citizens who were able to mobilise powerful resistance movements had any chance of success. The most often-cited example is one led by Jane Jacobs that stopped a Moses highway project cutting through Lower Manhattan.</p>
<p>Canada’s version of the Port Authority concept is Waterfront Toronto, a creation of the federal, provincial and municipal governments that serves as the intermediary between the public and the private sectors, in this case, Sidewalk Labs. While it claims representativeness and transparency, the agency’s board of directors contains a ‘who’s who’ of big developers and corporate leaders, along with civic officials. Moreover, following the lead of other such exemplars of the P3 approach, Waterfront Toronto conducts some of its meetings behind closed doors. It is little wonder that with such a ‘public advocate’, as the agency likes to call itself, Google was able to win the right to shape the city’s most valuable real estate before vital issues were settled, including who actually governs the neighbourhood, who owns the mountains of data to be gathered on practically everyone and everything, and what, if any, measures will be deployed to protect privacy, stop hackers and prevent commercial and governmental abuse. Waterfront Toronto was given the authority to select a developer with little public participation and practically no oversight. Moreover, neither the agency nor Sidewalk Labs provided citizens with access to details of their deal. The only public official in a position to actually read the documents was the city council’s representative to Waterfront Toronto. Not even the mayor had access. Like other smart city projects, the plan for Toronto is also very light on details about who is responsible for maintaining the technological apparatus that Sidewalk Labs will install. It is not clear who will oversee and pay for upkeep, updates and prevent abuses of the hardware and software that will give Torontonians a smart waterfront. Moreover, climate change is forecast to have profound effects on the Great Lakes and particularly on cities with highly developed waterfronts. There is little to no preparation in Sidewalk Labs’ plan for the inevitable disruptions to come for Lake Ontario.</p>
<p>What makes this all the more remarkable is that Google, arguably the most substantial information distribution company in the history of the world, cannot see fit to inform the people most affected by its plans about a project that the company hopes will shape the future of the world’s cities. This has raised serious concerns throughout Toronto, including among startups and other companies that might support the project. This is primarily because there is a widespread belief that Google plans to retain control over all data, from design plans to software to data generated by the many uses of the Quayside site. Mark Pavlidis, Chief Technology Officer of the Toronto digital image company Flixel Photos Inc., said he is concerned ‘it wasn’t clear how much access those startups would have to that wealth of data that would be collected through this project’.<sup>31</sup> Benjamin Bergen, Executive Director of the Council of Canadian Innovators, said that his group of more than 100 Canadian companies remained concerned about Sidewalk’s IP ownership requests. ‘There is still no strategy in place to see wealth generation for the Canadian economy’.<sup>32</sup></p>
<p>None of these criticisms matches the attack levelled by one of Canada’s leading technology executives, James Balsillie, founder and former co-CEO of Research in Motion, the company that created the first successful smartphone, the BlackBerry. Having commercialised Canadian intellectual property in 150 countries, Balsillie has some standing when he asserts that</p>
<blockquote>
<p>‘Smart cities’ are the new battlefront for big tech because they serve as the most promising hotbed for additional intangible assets that hold the next trillion dollars to add to their market capitalisations.</p>
</blockquote>
<p>At the heart of his criticism is that Waterfront Toronto violated the first rule in negotiations over smart city development: establish control over intellectual property and data. By leaving this key point unresolved, Balsillie insists, control over both defaults to Sidewalk. His conclusion that ‘Waterfront Toronto executives and board are too dumb to realize they are getting played’, might be too strong or might actually underestimate the complicity of Waterfront Toronto, but it is hard to take issue with the view that the Toronto project is a big data victory for Doctoroff, for Sidewalk Labs and for Google. Years of experience also give credence to the tech executive’s concern about all three levels of the Canadian government fawning over a foreign company ‘whose business model is built exclusively on the principle of mass surveillance’. It is ironic, but also quite significant, that one of the most successful private sector technology leaders in Canadian history has recognised better than most what it means to create a private smart city:</p>
<blockquote>
<p>A privately controlled ‘smart city’ infrastructure &gt; upends traditional models of citizenship because &gt; you cannot opt out of a city or a society that &gt; practises mass surveillance. Foreign corporate &gt; interests tout new technocratic efficiencies while &gt; shrewdly occluding their unprecedented power grab.</p>
</blockquote>
<p>It is rare for business executives to chide even their competitors for promoting ‘a colonizing experiment in surveillance capitalism’, and even rarer for them to criticise the absence of genuine public participation in planning, save for the ‘sham’ of a consultation process run by the company.<sup>33</sup></p>
<p>Also concerned about this apparent Google power grab and frustrated with Sidewalk Labs’ failure to engage the Toronto community on privacy and data control issues, a member of Waterfront Toronto’s Digital Strategy Advisory Panel for the project resigned in protest in October 2018. In her resignation letter, Saadia Muzaffar, the founder of the Toronto group TechGirls Canada, cited the failure of Waterfront Toronto and Sidewalk Labs to communicate its plan to the public. She gave special attention to the danger of embedding surveillance technology throughout critical city infrastructure.<sup>34</sup> Fearing a collapse in support for the project, Google quickly put together plans for a Civic Data Trust that would strip data of identifying characteristics and make it available for free to those seeking to use it for research or for product development. This did little to resolve serious issues that critics have with the company’s data policy. As Bianca Wylie, an advocate of open data and the co-founder of Tech Reset Canada put it: ‘This is a desperate, panicked and rushed move. It’s not a process for a vendor to be leading and framing’.<sup>35</sup> In essence, Google presumes the right to dispose of the data, including location information, gathered on those who use a public space. It believes that allowing the very people from whom it gathers data to use it for free constitutes a concession. Google reserves the right to profit from the data in any of its operations, including cell phones using the company’s apps, by selling it to businesses interested in modelling social behaviour in cities, including advertisers.<sup>36</sup> Moreover, the company makes no commitment to store the data in Ontario or even in Canada.</p>
<p>As a result of its action, Sidewalk Labs lost one of its most valuable advisors when former Ontario Privacy Commissioner Ann Cavoukian resigned as a consultant. One of the world’s foremost authorities on privacy and surveillance, Cavoukian provided important legitimacy to the Google project. However, concerned that the company was not doing enough to keep data gathered at its smart city location anonymised, she resigned. Specifically, Cavoukian stepped down over an issue that is significant for all smart city development projects, especially those that promise to de-identify data or eliminate the ability to match a specific person with the information gathered about their activities. Although Google promised to de-identify data gathered at Quayside, it could not promise that third parties with access to the data would also comply. The only solution is to de-identify data at the source of its collection and Google refuses to do so. Explaining why, in her words, ‘this is unacceptable’, Cavoukian states:</p>
<blockquote>
<p>If personally identifiable data are not de-identified &gt; at source, we will be creating another central &gt; database of personal information (controlled by &gt; whom?), that may be used without data subjects’ consent, that will be exposed to the risks of hacking &gt; and unauthorised access. As we all know, existing &gt; methods of encryption are not infallible and may be &gt; broken, potentially exposing the personal data of &gt; Waterfront Toronto residents! Why take such risks?</p>
</blockquote>
<p>Her disappointment was evident in an interview conducted shortly after announcing her departure: ‘I wanted this to become a smart city of privacy – not a smart city of surveillance’. <sup>37</sup> The Auditor General of Ontario, Bonnie Lysyk, appeared to agree with the critics in her December 2018 annual audit, which concluded that Waterfront Toronto gave Google’s Sidewalk Labs preferential treatment and rushed the approval process with insufficient government oversight. In bureaucratic language, the audit concluded that even before Sidewalk revealed any details, including its plans for privacy and data ownership, governments at every level jumped the gun to support the technology giant.<sup>38</sup></p>
<p>The smart city movement means more than whether or not parking garages will alert drivers to the number of available spaces. It raises fundamental economic, political, social and environmental issues that present challenges to citizens and governments everywhere. The next chapter takes up different ways in which the world’s cities are responding.</p>
<h2>ENDNOTES</h2>
<ol>
<li>Anthony M. Townsend, Smart cities: Big data, civic hackers, and
the quest for a new Utopia, New York, NY: Norton, 2013, p. xiii.
92 The Smart City in a Digital World</li>
<li>Dan Patterson, How New York City plans to become a smart
city leader, TechRepublic, March 1, 2018, https://www.techrepublic.
com/article/how-new-york-city-plans-to-become-a-smart-cityleader/</li>
<li>Saeid Malaki, The connected reality of a smart city, Mass Transit,
December 17, 2018, https://www.masstransitmag.com/technology/
article/12412867/the-connected-reality-of-a-smart-city</li>
<li>Paul Roberts, This is what happens when bitcoin miners take
over your town, Politico, March/April, 2018, https://www.politico.
com/magazine/story/2018/03/09/bitcoin-mining-energy-pricessmalltown-
feature-217230</li>
<li>Sapna Maheshwari, The thermometer tells your temperature,
then tells firms where to advertise, New York Times, October 23,
2018, https://www.nytimes.com/2018/10/23/business/media/feveradvertisements-
medicine-clorox.html</li>
<li>Aaron Hurst, What are the elements of a smart city? Information
Age, August 2, 2018, https://www.information-age.com/elementssmart-
city-123473906/</li>
<li>Teena Maddox, Smart cities: A cheat sheet, TechRepublic, July
16, 2018, https://www.techrepublic.com/article/smart-cities-thesmart-
persons-guide/</li>
<li>Saurabh Hooda, Five technologies that every smart city needs
to cater, BW Smart Cities, July 19, 2018, http://bwsmartcities.
businessworld.in/article/Five-Technologies-that-any-Smart-City-
Needs-to-Cater/19-07-2018-155290/</li>
<li>Nick Ismail, Smart cities could lead to cost savings of $5
trillion: Report suggests, Information Age, December 5, 2017,
https://www.information-age.com/smart-cities-lead-cost-savings-5-
trillion-123469863/</li>
<li>Nick Ismail, Smart city tech could drive millions in
economic growth, Information Age, January 24, 2018, https://
www.information-age.com/smart-city-tech-trillions-economicgrowth-
123470508/</li>
<li>Sandra Vogel, Intel: “Smart cities give every person back
125 hours a year,” Internet of Business, March 14, 2018, https://
City of Technology 93
internetofbusiness.com/intel-smart-cities-give-every-person-back-
125-hours-a-year/</li>
<li>IDC, Investments in technologies enabling smart cities
initiatives are forecast to reach $80 billion in 2018, according to a
new IDC spending guide, February 20, 2018, https://www.idc.com/
getdoc.jsp?containerId=prUS43576718</li>
<li>Anthony M. Townsend, Smart cities: Big data, civic hackers, and
the quest for a new Utopia, New York, NY: Norton, 2013, p. 67.</li>
<li>Cited in Eric Jaffe, 4 lessons from Rio’s ‘flawed’ smart cities
initiative, Medium, May 11, 2016, https://medium.com/sidewalktalk/
4-lessons-from-rios-flawed-smart-cities-initiative-31cbf4e54b72</li>
<li>Anthony M. Townsend, Smart cities: Big data, civic hackers, and
the quest for a new Utopia, New York, NY: Norton, 2013, p. 68.</li>
<li>Anthony M. Townsend, Smart cities: Big data, civic hackers, and
the quest for a new Utopia, New York, NY: Norton, 2013, p. 68.</li>
<li>Bernard Bartsch, Real-time government, Pictures of the future,
Spring 2011, https://www.siemens.com/digitalization/public/pdf/
collective-intelligence-city-dashboard.pdf</li>
<li>Yasha Levine, Surveillance Valley: The secret military history of
the Internet, New York, NY: Public Affairs, 2018, pp. 1–6.</li>
<li>Charles V. Bagli, $2.4 billion deal for Chelsea market enlarges
Google’s New York footprint, New York Times, February 7, 2018,
https://www.nytimes.com/2018/02/07/nyregion/google-chelseamarket-
new-york.html</li>
<li>Emily Badger, Google’s founders wanted to shape a city.
Toronto is their chance, New York Times, October 18, 2017,
https://www.nytimes.com/2017/10/18/upshot/taxibots-sensors-andself-
driving-shuttles-a-glimpse-at-an-internet-city-in-toronto.html</li>
<li>A. J. Dellinger, Sidewalk Labs outlines how it’ll make money
from Toronto, Engadget, February 15, 2019, https://www.engadget.
com/2019/02/15/alphabet-sidewalk-labs-toronto-tax-revenue/</li>
<li>A. J. Dellinger, Sidewalk Labs outlines how it’ll make money
from Toronto, Engadget, February 15, 2019, https://www.engadget.
com/2019/02/15/alphabet-sidewalk-labs-toronto-tax-revenue/
94 The Smart City in a Digital World</li>
<li>Daniel L. Doctoroff, Greater than ever: New York’s big
comeback, New York, NY: Public Affairs, 2017, pp. xi–xii.</li>
<li>Zadie Smith, Under the banner of New York, The New York
Review of Books, November 4, 2017, https://www.nybooks.com/
daily/2017/11/04/under-the-banner-of-new-york/</li>
<li>Jeremiah Moss, Vanishing New York: How a great city lost its
soul, New York, NY: William Morrow, p. 6.</li>
<li>Zachary Small, How paparazzi dogs and rabbit girl conquered
New York City streets, January 6, 2019, https://www.nytimes.
com/2019/01/03/arts/design/gillie-marc-schattner-sydney-australiaart-
paparazzi-dogs.html</li>
<li>Bridget Fisher and Flávia Leite, The cost of New York City’s
Hudson Yards redevelopment project, New York, NY: Schwartz
Center for Economic Policy Analysis, The New School for Social
Research, 2018, https://www.economicpolicyresearch.org/images/docs/
research/political_economy/Cost_of_Hudson_Yards_WP_11.5.18.pdf</li>
<li>See Mark Lamster, The man in the glass house: Philip Johnson,
architect of the modern century, New York, NY: Little, Brown
and Company, 2018 and Katy Cornell, 50 years in the making,
Manhattan West finally takes shape, City Realty, September 6, 2016,
https://www.cityrealty.com/nyc/market-insight/features/the-newskyline/
50-years-making-manhattan-west-finally-takes-shape/5683</li>
<li>Ryan Boysen, Hudson Yards’ smart city initiatives could
provide glimpse of NYC’s future, Bisnow, February 22, 2016,
https://www.bisnow.com/new-york/news/commercial-real-estate/
hudson-yards-smart-city-initiatives-could-provide-glimpse-of-nycsfuture-
56252</li>
<li>Bill Gates, The road ahead, New York, NY: Viking, 1995, p. 182.</li>
<li>Josh O’Kane, Quayside project will benefit Canadian
companies, says former Alphabet chair Eric Schmidt, The Globe
and Mail, September 25, 2018, https://www.theglobeandmail.com/
business/article-quayside-project-will-benefit-canadian-companiessays-
former-alphabet/</li>
<li>Josh O’Kane, Quayside project will benefit Canadian
companies, says former Alphabet chair Eric Schmidt, The Globe
City of Technology 95
and Mail, September 25, 2018, https://www.theglobeandmail.com/
business/article-quayside-project-will-benefit-canadian-companiessays-
former-alphabet/</li>
<li>Jim Balsillie, Sidewalk Toronto has only one beneficiary, and it
is not Toronto, The Globe and Mail, October 5, 2018, https://www.
theglobeandmail.com/opinion/article-sidewalk-toronto-is-not-asmart-
city/</li>
<li>Josh O’Kane, Tech entrepreneur resigns from Waterfront
Toronto advisory board over Sidewalk Labs concerns, The Globe
and Mail, October 4, 2018, https://www.theglobeandmail.com/
business/article-saadia-muzaffar-resigns-from-waterfront-torontoadvisory-
board-over/</li>
<li>Josh O’Kane, Sidewalk Labs to make Toronto Quayside data
publicly available via trust, The Globe and Mail, October 15, 2018,
https://www.theglobeandmail.com/business/article-sidewalk-labs-tomake-
data-publicly-available-via-trust/</li>
<li>Ava Kofman, Google’s Sidewalk Labs plans to package and
sell location data on millions of cellphones, The Intercept, January
28, 2018, https://theintercept.com/2019/01/28/google-alphabetsidewalk-
labs-replica-cellphone-data/</li>
<li>Josh O’Kane, Privacy expert Ann Cavoukian resigns from
Sidewalk Toronto smart-city project: ‘I had no other choice,’ The
Globe and Mail, October 20, 2018, https://www.theglobeandmail.
com/business/article-privacy-expert-ann-cavoukian-resigns-fromsidewalk-
toronto-smart-city/</li>
<li>Josh O’Kane, Ontario auditor-general warns Waterfront
Toronto to slow down project with Google-affiliate Sidewalk
Labs, The Globe and Mail, December 5, 2018, https://www.
theglobeandmail.com/business/article-ontario-auditor-generalwarns-
waterfront-toronto-to-slow-down-project/</li>
</ol>


<p class="dinkus">〰️🤖〰️</p>
</article>
    <article
id="Smart street furniture in Australia: a public service or surveillance and advertising tool?"
class="paper-story"
data-article-title="Smart street furniture in Australia: a public service or surveillance and advertising tool?"
>

<h1 class="article-title" id="h_Smart street furniture in Australia: a public service or surveillance and advertising tool?">Smart street furniture in Australia: a public service or surveillance and advertising tool?</h1>

<div class="top-meta">Justine Humphry, Chris Chesher & Sophia Maalsen, 2021-06-23 06:01:00 AEST. for week 12.</div>

<p>June 23, 2021 6.01am AEST</p>
<h2>Authors</h2>
<h3>Justine Humphry</h3>
<p>Senior Lecturer in Digital Cultures, University of Sydney</p>
<h3>Chris Chesher</h3>
<p>Senior Lecturer in Digital Cultures, University of Sydney</p>
<h3>Sophia Maalsen</h3>
<p>ARC DECRA Fellow and Lecturer in Urbanism, School of Architecture, Design and Planning, University of Sydney</p>
<hr>
<p>Smart street furniture – powered and digitally networked furniture that collects and generates data – is arriving in Australia. It comes in a variety of forms, including benches, kiosks, <a href="https://competition.adesignaward.com/design.php?ID=61809">light poles</a> and bus stops. Early examples in Australia include <a href="https://www.georgesriver.nsw.gov.au/Council/About-Your-Council/Smart-Cities/Smart-ChillOUT-Hubs">ChillOUT Hubs</a> installed by Georges River Council in the Sydney suburbs of Kogarah, Hurstville and Mortdale, and information kiosks and smart light poles in the City of Newcastle as part of its <a href="https://newcastle.nsw.gov.au/smarter-living">Smart City Strategy</a>.</p>
<p>The “smartness” of this street furniture comes from its new data and connectivity capabilities. The idea is that these can generate new products and services, and support real-time planning decisions in cities. Most offer free wi-fi in combination with other functions like advertising, <a href="https://segd.org/what-wayfinding#:%7E:text=Wayfindingrefers%20to%20information%20systems,educational%20campuses%2Cand%20transportationfacilities.">wayfinding</a>, emergency buttons, phone calling and device charging via USB.</p>
<figure class="align-center ">
<img alt="" src="https://images.theconversation.com/files/404954/original/file-20210607-130403-puzf88.jpeg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" srcset="https://images.theconversation.com/files/404954/original/file-20210607-130403-puzf88.jpeg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=763&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/404954/original/file-20210607-130403-puzf88.jpeg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=763&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/404954/original/file-20210607-130403-puzf88.jpeg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=763&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/404954/original/file-20210607-130403-puzf88.jpeg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=959&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/404954/original/file-20210607-130403-puzf88.jpeg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=959&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/404954/original/file-20210607-130403-puzf88.jpeg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=959&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px">
<figcaption>
<span class="caption">A ChillOUT Hub installed in Timothy Reserve, Hurstville, by St Georges River Council.</span>
<span class="attribution"><span class="source">Photo: Chris Chesher</span>, <span class="license">Author provided</span></span>
</figcaption>
</figure>
<h2>Smart, but controversial</h2>
<p>The promise of smart street furniture is that it will enhance public spaces and revitalise ageing infrastructure. By providing vulnerable and disadvantaged citizens with access to free connectivity services it can also bridge digital barriers.</p>
<p>Despite these benefits, some aspects of smart street furniture are controversial. In particular, its data collection and impact on public space have created concerns.</p>
<p>In New York City, the replacement of phone booths by <a href="https://www.link.nyc/">LinkNYC</a> digital kiosks has given rise to protest about <a href="https://nymag.com/intelligencer/2016/03/nyclu-raises-linknyc-privacy-concerns.html">data ownership and sharing</a> and <a href="https://gothamist.com/news/yes-linknyc-kiosks-are-giant-data-harvesting-surveillance-cameras-obviously">surveillance through built-in security cameras</a>. Other sources of tension are the kiosks’ physical footprint, visual impact and use for outdoor advertising with its double-sided 140cm digital displays.</p>
<p>In Australia, Telstra has been fighting a <a href="https://www.smh.com.au/national/telstra-loses-battle-to-install-supersized-phone-booths-across-major-cities-20210416-p57jri.html">long court case</a> against the cities of Sydney, Melbourne and Brisbane over plans to convert its phone booths into smart hubs equipped with digital advertising. Councils objected to these on the basis that they required local planning approval. Telstra argued the hubs were exempt as “<a href="https://www.legislation.gov.au/Details/F2020C00305">low-impact facilities</a>”, but has had to delay installation.</p>
<h2>What can we learn from early adopters overseas?</h2>
<p>We don’t yet understand the public impact and value of smart street furniture, what service model is to be adopted at scale, or what kind of future it offers. To what extent are these facilities offering public services, or are they just enablers of more advertising and surveillance?</p>
<p>Australia can learn from the early examples of smart street furniture in other countries. Our <a href="https://www.sydney.edu.au/arts/our-research/research-areas/literature-art-and-media/smart-publics.html">Smart Publics research project</a> investigated the design, use and governance of InLinkUK kiosks in Glasgow and Strawberry Energy smart benches in London with a <a href="https://www.gla.ac.uk/schools/socialpolitical/research/projects/smartpublics/">research team</a> at the University of Glasgow. (The final report is <a href="https://www.sydney.edu.au/content/dam/corporate/documents/faculty-of-arts-and-social-sciences/research/research-areas/literature-art-and-media/smart-publics-research-report.pdf">here</a>.)</p>
<p>We found the main users were those who were living rough, young people, students and gig workers. Smart furniture enabled these groups to stay digitally connected. They used these facilities to charge their phones and make free calls, which were especially valuable for those who didn’t own phones or lacked the credit to use them. (The InLinkUK kiosks offered free calls to any mobile or landline in the UK.)</p>
<figure class="align-center ">
<img alt="" src="https://images.theconversation.com/files/407366/original/file-20210621-35174-j5yk5g.jpeg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" srcset="https://images.theconversation.com/files/407366/original/file-20210621-35174-j5yk5g.jpeg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=930&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/407366/original/file-20210621-35174-j5yk5g.jpeg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=930&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/407366/original/file-20210621-35174-j5yk5g.jpeg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=930&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/407366/original/file-20210621-35174-j5yk5g.jpeg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=1168&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/407366/original/file-20210621-35174-j5yk5g.jpeg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=1168&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/407366/original/file-20210621-35174-j5yk5g.jpeg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=1168&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px">
<figcaption>
<span class="caption">An InLinkUK kiosk in Glasgow city centre.</span>
<span class="attribution"><span class="source">Photo: Smart Publics researchers</span>, <span class="license">Author provided</span></span>
</figcaption>
</figure>
<h2>Who is funding these facilities?</h2>
<p>Even though kiosks and smart benches could be used for community service information, we found it was commercial advertising that drove private investment in this infrastructure. Advertising revenue paid for the services offered by the InLinkUK kiosks and sponsorship for the Strawberry Energy benches. Advertising agency Primesight was one of the three main partners in InLinkUK (with <a href="https://www.bt.com/">British Telecom</a> and <a href="https://www.intersection.com/success-story/link/">Intersection</a>, the company responsible for LinkNYC).</p>
<p>Because advertising was so prominent in their design, many people were unaware of their other functions. Asked if they’d noticed the InLinks, one person replied:</p>
<blockquote>
<p>“Er no, I haven’t […] what’s it for? Is it to make free calls to anywhere in the UK? […] I just thought it was like an advertising board, I guess!”</p>
</blockquote>
<p>People recognised the wide public value of free wi-fi, device charging and phone calls. But we found the public as a whole didn’t understand the data-collection aspects. The marginalised groups who relied on these services were more exposed to corporate advertising, data collection and surveillance in public spaces.</p>
<p>Councils were also limited in their ability to leverage the benefits that came from the data. The Strawberry Energy benches, for example, collected environmental data such as temperature, noise level and air quality from inbuilt sensors. However, these data weren’t being used to inform planning or policy.</p>
<p>Reliability of the data was another issue. We found inaccuracies when we tested the environmental data.</p>
<figure class="align-center ">
<img alt="" src="https://images.theconversation.com/files/404957/original/file-20210607-121132-1w1293v.jpeg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" srcset="https://images.theconversation.com/files/404957/original/file-20210607-121132-1w1293v.jpeg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=800&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/404957/original/file-20210607-121132-1w1293v.jpeg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=800&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/404957/original/file-20210607-121132-1w1293v.jpeg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=800&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/404957/original/file-20210607-121132-1w1293v.jpeg?ixlib=rb-1.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=1005&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/404957/original/file-20210607-121132-1w1293v.jpeg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=1005&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/404957/original/file-20210607-121132-1w1293v.jpeg?ixlib=rb-1.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=1005&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px">
<figcaption>
<span class="caption">A Strawberry Energy smart bench in Southwark, South London.</span>
<cite><span class="source">Photo: Smart Publics researchers</span>, <span class="license">Author provided</span></cite>
</figcaption>
</figure>
<h2>Where to now in Australia?</h2>
<p>These issues highlight some of the challenges councils encounter when embarking on smart street furniture initiatives with private companies. These include data-sharing contract arrangements as well as the need to upskill council staff to manage new kinds of data capabilities and systems.</p>
<p>The examples we studied in the UK had been rolled out in public-private partnerships. However, some of the models emerging suggest a different kind of civic implementation.</p>
<p>Local governments that have been early adopters of smart furniture in Australia have envisioned it as an extension of council services without added advertising or compromising heritage values. These have typically begun as experimental initiatives funded by <a href="https://www.infrastructure.gov.au/cities/smart-cities/plan/index.aspx">federal</a> and state government grants. The City of Newcastle, for example, is planning to integrate smart city technologies into regular council operations.</p>
<p>Smart street furniture is not going away. If anything, it will become pervasive as technology advances and becomes more integrated into our physical surroundings.</p>
<p>The issues raised by smart street furniture warrant close inspection and further research. It is crucial that governments and private actors are transparent about its use for advertising and data collection. To ensure the benefits of smart street furniture are realised, they need to:</p>
<ul>
<li>emphasise the public value of smart street furniture, including its use for community-based information</li>
<li>collaborate with the public on its design and placement</li>
<li>in the case of councils, take a pro-active approach to access, ownership and stewardship of data</li>
<li>ensure marginalised citizens are not exposed to increased risk of surveillance and data harms.</li>
</ul>


<p class="dinkus">〰️🤖〰️</p>
</article>
    

    <article id="colophon" class="colophon paper-story">
        <h1 class="article-title" data-article-title="Colophon">Colophon</h1>
        <p>some other things at the end</p>
    </article>
</div>

<section class="inside-back-cover"></section>

<section class="back-page"></section>

    </body>
</html>
