---
title: "A Robot-Human Handshake in Space: Touch and Lively Alterity Relations in Social Robotics"
date: "2021-07-26T03:18:00.000Z"
tags: [The_Past_and_Futures_of_Digital_Cultures]
resource_type: core
authors: Chris Chesher & David Silvera-Tawil
source_publish_date: 2020-00-00 00:00:00 AEST
week: 11

# this goes on the index page, and into facebook shares
description:
# This is what twitter will pick up if someone tweets the link to this page
# 110 marker 1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789
twitter-body:
# Twitter and facebook will pick up this image. you can also use it in a post with:
# ![alt text]({{ site.baseurl }}/assets/{{page.featuredimg}})
featuredimg: http://www.uvm.edu/~tstreete/Net_Effect/page2/files/pasted-graphic.jpg
---

Chesher, C., & Silvera-Tawil, D. (2021). A Robot-Human Handshake in Space: Touch and Lively Alterity Relations in Social Robotics. Culturally Sustainable Social Robotics: Proceedings of Robophilosophy 2020, 335, 86.

Chris CHESHER1 and David SILVERA-TAWIL a Department of Media and Communications, The University of Sydney, Australia bCSIRO Australian e-Health Research Centre, University of New South Wales, Australia

Abstract. In February 2012, Robonaut R2 and Dan Burbank performed the first human-humanoid handshake in space. The handshake welcomed R2 as a crewmember a social agent rather than a thing. In Heidegger's terms, it is experienced not only as present-at-hand or ready-to-hand, but also as a quasi-Dasein. Extending Ihde's concept of alterity relations we argue it is experienced in lively alterity relations, given respect as an other capable of initiating and reacting to contact. R2 is capable not only of executing programs, but of also playing its part in choreographed and improvised collaborative performances within a shared social milieu.

Keywords. Social robotics, human-machine relations, Heidegger, liveness-to-hand,

phenomenology, post-phenomenology, touch

1. Introduction
   On February 15, 2012 the humanoid 'Robonaut R2' [1] floats inside the International Space Station, ready to initiate what Commander Dan Burbank claims is "the first human-humanoid handshake in space" [2]. R2 extends its arm towards Burbank who reaches down to grab the outstretched hand. The robot's fingers wrap around the commander's fingers and they shake hands, pausing to have this historic event captured on camera. Ground control cheers. Robonaut's offered the handshake as a kind of gift that established an obligation to reciprocate that Burbank respected [3]. Like other handshakes, this was what Goffman [4] refers to as an 'access ceremony', welcoming the robot to the space station as a fellow crewmember. It marked mutual recognition, establishing solidarity, and synchronising their shared activities from that point forward [5]. It asserted a certain manliness: Burbank reported that it was a firm handshake [6, 7]. This handshake was a socially choreographed action [8] in which the robot took the lead. It seemed to have some of the affectivity of social touch [9]. The contact between human and non-human hands embodied and symbolised the emergence of technologies that initiate active touch [10], going beyond our assumption that technologies are most often tools that are controlled or examined by the hands of users.
   In this paper, we consider this encounter between Commander Burbank and R2 as an event that raises philosophical questions about the relationship between people and robots in a shared lifeworld. In particular, how is it possible for these two actants to successfully execute the ritual of the handshake? This suggests that both are capable of active social touch the combination of movement and tactility that helps position each as a legitimate social actor. Does this mean that the robot has (quasi) social agency? Does active social touch from a robot require some form of machine intelligence? What kinds of human-technology relations are established in this interaction? How does the performance of everyday rituals promote the cultural sustainability of social robots in space and back on earth?

This paper sits at the intersections between cultural studies [11], media studies [12], science and technology studies [13], and philosophy of technology [14, 15]. The phenomenon of social touch could also be examined as a psychological question [9], and is also the concern of some engineers seeking to model the mediation of affective touch [16, 17]. If social touch is always marked by the gender, class, age and ethnic identity [6], we might ask how Robonaut should be identified. Through an analysis of robotic touch, this paper critically addresses key assumptions underpinning social robotics that a robot can perform as an embodied agent in both physical and social domains. After this introduction, the article is divided into two sections, focusing on each of the participants in the handshake-human and robot.

We construct the narrative of this event through NASA's press releases, biographies, records, videos and still images of missions [7, 18]. In these texts, and also in popular science [19], narratives about robots ask us to imagine future possibilities as much as they report on actual developments. We perform an analysis of these texts in order to develop a reading of the human-technology relations in embodied (quasi) social situations, looking in particular at the role of touch. We situate the handshake in unremitting debates about artificial intelligence and robotics, with controversies about the formation of 'intelligent' behaviour, parasocial interaction and alterity. We argue that both choreography and programming are necessary, but not sufficient to understanding the situated meanings of contact between people and robots.

2. Human Touch: Commander Burbank
   NASA's biography of Daniel C. Burbank reveals that he was born on July 27, 1961 in Manchester, Connecticut [20]. After a distinguished career in the Coast Guard, he was selected as an astronaut in April 1996. Burbank was at ease with technology: on two missions to the International Space Station (ISS), he was a mission specialist who helped deliver over three tons of supplies and install key equipment such as solar arrays to prepare the ISS for continuous inhabitation. From 21 November 2011, he became commander of the 30th long-duration mission on the ISS, until he returned to earth on the Soyuz spacecraft on 27 April 2012.

As with all humans, Burbank's skin is the largest of all his organs. It gives him the sense of touch, which is the first sense to develop in utero and (arguably) the most important of all human senses [9]. His body is literally covered by a huge network of touch receptors and processing centres the somatosensory system that allow him to perceive temperatu changes, pain and irritation, kinaesthesia, touch and vibration; his muscles, joints and organs are all connected to nerves that constantly send information to his brain. The sense of touch is central for human survival and social interaction. It is believed that people need a daily dose of touch to improve their emotional and physical wellbeing [9]. From the work of Robles-De-La-Torre [21] we know about Ian Waterman, an individual who suffered permanent loss of most of his sense of touch. His tactile loss caused dramatic changes in his life. He could not walk, stand upright or sit up, could not control the movement of his limbs or tell their position. His hands, arms and fingers moved uncontrollably without him even noticing. He would not be able to feel the bed when sleeping or the water when swimming. It took him months, even years to learn to perform some of his basic daily activities by using his eyes to guide every movement.

Touch is classified in terms of its purposive nature. If the agent has control over the exploration process and seeks information by moving or touching an object, this is termed active touch [22]. In contrast, if the skin receptors are activated by an object touching the surface of the body; this is referred to as passive touch. Touch can also be classified as a distal or proximal sense. It is distal if an object activates his touch receptors without direct physical contact, such as the radiation of heat. It is proximal if there is direct contact between the object and the skin. As Cranny-Francis argues, though, these conceptions of touch lack attention to the "intimate politics of our tactile relationships" [6: 4], and imply a problematic stereotypical gendering of the male as active/distant and the female as passive/close.

We often use touch to share our feelings and enhance other forms of non-verbal and verbal communication. In this vein, the interpretation of social touch (or touch that contains social value) is strongly influenced by the context of the interaction along with the identity, cultures, beliefs and emotions of the people who are communicating [23]. The handshake is a special form of touching, distinctive partly because it is a performance of mutual active touch and partly because it is a quasi-universal human convention for meeting, greeting and performing agreements. This convention became prominent in its absence in the COVID-19 pandemic, when handshaking became taboo, for fear that contact would bring contagion. Handshaking has gendered associations, with the powerful heterosexual male subject privileged in this cultural practice. Handshakes vary between cultures [24], and even within them, following choreography but allowing some improvisation and style. In fact, every handshake is a singular, situated intersubjective material event. It is a point of contact between two individuals, eye-to eye, uching and being touched. It is often loaded with affect: joy, camaraderie, anxiety, or even repressed enmity. It is always meaningful and performative, with disavowed connotations of sexuality or infection. It may be judged as weak, insincere, overbearing or cloying. It may be secret, coded to include some and exclude others [25]. It affirms the place of the hand in everyday agency and the human imagination.

The hand is conceptually connected with fundamental ontological questions about the role of technology in everyday experience. Heidegger [14] uses the hand metonymically to distinguish between two different orientations to the world. When people, or what he refers to as Dasein, encounter objects or equipment in the flow of everyday experience, it tends to relate to them within the context of ongoing action, rather than as things to be considered for their technical or abstract properties. Heidegger says these entities in the flow of everyday activity are "ready-to-hand" [14: 99]. A hammer not only invites someone to use it, it also materially transforms the person's physical and experiential relationship with the world. The world becomes a field of possibility for hammering, enabling practices of building, and constituting a creative mode of being-in-the-world. It is only when the hammer malfunctions that it becomes an object with abstract properties that present a problem for inspection and becomes present-at-hand. In this relation, the hammer becomes on hand for objective examination. For Heidegger it is crucial that Dasein is thrown into a world of equipment that is ready to-hand, and only later encountered in theoretical terms as present-at-hand. It is notable that for Heidegger both relations to the world-readiness-to-hand and present-at-hand are associated with the hand, which precedes thought and vision. Where vision has been the dominant metaphor for knowledge in philosophy from Plato to the Enlightenment, in Heidegger's use of this metaphor, the world is primarily manipulable.

In the ISS, many of the phenomenological groundings of being-in-the-world are disturbed, including one's sense of touch. Without the force of gravity, people's experience of their body changes [26]. Hypogravity can distort kinaesthetic and proprioceptive sensations in the vestibular system to disrupt their sense of themselves, their vection (self-movement) [27], and perception of their environment. Similar to Ian Waterman's experience [21], without pressure on their feet astronauts lose the sense of which way is down. Their muscles no longer sense their own weight. People sometimes experience visual orientation illusions and feelings of self-inversion [26]. However, in spite of these changes to his body and his perception, Burbank had the capacity to adapt to being-in-the-off-world. He acclimatised himself enough to fulfil his work esponsibil es, take the routine two hours of exercise each day to maintain fitness and compensate for muscle wastage, and prepare for his encounter with R2.

The handshake with R2 presents something of an ontological paradox in Heidegger's schema, not only because of the disorienting effects of modern technology. In the moments before the handshake Burbank seemed to be examining R2 as something present-at-hand that needed technical attention. However, at the crucial moment, Burbank did not directly control R2, as it offered its hand seemingly autonomously. Burbank seemed not to touch R2 as equipment, but as another Dasein that was more than ready-to-hand. It became what Heidegger would have seen as a very inauthentic manifestation of being-with or Mitsein [14, 28]. This is less of a problem for contemporary thinkers, as many have posited the social agency of non-humans [29]. We would argue that the ontological status of the handshake is not to be taken too heavily. No doubt this handshake is a form of theatre [8], and Burbank was not fooled by R2's mimicry of something living. However, at that moment of contact, the two were brought together, participating as lively social actors in an everyday ceremony. Each reached out with a form of active touch, exploring the other's hand with his or its own. Those witnessing it responded to it as a legitimate handshake. Burbank seemed to relate to R2 as an active embodied social agent. R2 sensed Burbank's hand and closed its fingers to form an intimate and uncanny bond.

Post-phenomenologist Don Ihde [15] makes a related point about technologies that attain the status of "quasi-otherness" [15: 100] in his concept of alterity relations. Robots like R2 operate (somewhat) independently from direct human control. For Ihde, the robot's interior life is not significant for those encountering it. What is important is that the robot has "become the focal centre of attention as a quasi-other to which I may relate" [15: 100]. Like a non-playing character in a video game, the robot might become a competitor or a collaborator in Burbank's engagement with the lifeworld of the space station. However, as embodied interactive agents sharing the same physical and social space, we propose that they met one another in lively alterity relations.

We might add to this by invoking Horton and Wohl's [30] argument that it is commonplace for people to have ongoing social and affective 'para-social' relationships with media personalities, or personae, purely as images on television screens. They stress the manufactured and illusory nature of this form of intimacy. Even as viewers of the video of the handshake, we can begin to form an impression that R2 may have a persona with which we might develop a para-social relationship. This is certainly the case for viewers of the robots R2-D2 and C3PO in the Star Wars movies who are presented as fully formed characters. NASA, no doubt, invoked these meanings in the design and publicising of Robonaut.

Alongside the concept of the parasocial, we might be seen as having an even more equal relationship with our artefacts. Nass and Reeves' argument that people often unconsciously treat media technologies as people or places-could also apply [31, 32]. They propose that there is a direct equivalence between how people relate to artefacts and how they relate to other people [33]. The argument is that people mindlessly apply rules and expectations from social life to computers, such as applying gender or ethnic stereotypes, or being polite [34]. In witnessing the handshake, we could see that Burbank was certainly being polite to R2. However, in observing the video closely it is apparent in his behaviour that Burbank switches between treating Robonaut as a social actor and treating it as equipment. Lively alterity relations are not the same as living social relations, even if the boundary between the two is sometimes ambiguous.

As an aside, we might note that there are many other ways that the astronauts encountered technologies in the ISS. Ihde distinguishes alterity relations from technologies that extend someone's body to assign focal attention into the technology (like driving a car). He calls these embodiment relations (a concept that echoes readiness to-hand). On the other hand, he identifies technologies such as the control panel in the ISS that operate in hermeneutic relations, where the attention is on the device, rather than the world, and through it, we interpret the world as a text. This concept is related to the present-at-hand, but without Heidegger's tendency to diminish this form of relationship. There is a lot of slippage between these modes of human-technology relations. For example, when astronauts piloted the Space Shuttle with a control stick, they were experiencing embodiment relations; but in fact, they were piloting using 'fly by-wire' controls, with the ship's computers handling the control. Astronauts encountered their ship and the world predominantly through screens, read-outs, buttons and displays in the cockpit [35], so it principally operated through hermeneutic relations. The ISS, on the other hand, is not conventionally piloted at all. Computers control its position automatically on the basis of instructions from ground control and an array of sensors. In this case, Ihde would identify another human-te nology relation in play on the space station: background relations. The life support systems in the pressurised cabin operate without the focal attention of its users, and without the need for manual control. They recede into the background to maintain temperature, oxygen levels, position in orbit and so on.

Now that we have established phenomenological experiences of how the astronauts might relate to R2 and their environment, as far as we can imagine them from the evidence, we will shift our focus to Robonaut R2 and its apparent capacities for supervised autonomy, social agency, active touch and lively alterity relations.

3. Robotic Touch: Robonaut R2

Almost 200 people from 15 countries have visited the International Space Station,

but the orbiting complex has only had human crew members-until now [18]. Robonaut R2 was created through a partnership established in 2006 between NASA and General Motors [1]. This project followed the original Robonaut, which was developed within NASA, and never made it to space. An operational R2 was launched in the ISS mission STS-133 aboard the space shuttle Discovery in February 2011. NASA's press releases and videos about R2 provide key technical details about R2, and also make anthropomorphic personifications of the humanoid robot. For example, one text reports that the robot "thinks with its stomach" [18], since its computers are not in its head, but in its torso. NASA stresses that the humanoid form allows R2 to fit in spaces designed for humans and allow it to use human tools. They say that R2 will be able to work safely alongside human astronauts as a fellow crewmember, taking on their boring and dangerous tasks. It is a "dexterous" robot with hands and fingers approximating the capabilities of the human hand with 12 degrees of freedom, sensors for touch and position, and fingers that can each exert 2.27kg of grasping force. R2 is apparently gendered male, while its successor R5 (Valkyrie) is female, named after a handmaid in Norse mythology [36]. In order to perceive the world and its own body, and make decisions, R2 has 38 processors and over 350 sensors. As a humanoid upper-torso-like robot, it initially had no legs, but each of its two arms have seven degrees of freedom and a total span of 2.43 metres. It was designed to have the potential to work autonomously in relationships of concern towards the world of equipment in the ISS. In practice, it was reported to have held an airflow sensor without moving and to have cleaned handrails in the ISS [18].

In some ways, R2's genealogy can be traced to the automata of the 18th and 19th century whose technically virtuosic and choreographed lifelike movement fascinated the mechanical computing pioneer Charles Babbage [37]. However, it is different from these machines because its sensors, motors, gearing and programmability allow it to exhibit more complex and random behaviours. NASA proposed that this would allow it to operate flexibly and interactively in an unpredictable environment [38]. A robot is often defined as a machine that senses, thinks and acts [39]. The robot's sensors capture the environment; the computer interprets these inputs and plans the robot's own actions; and its effectors act upon the world. However, this definition only goes so far in explaining the ontological status of a social robot. Sense-think-act effaces the complexity at play that emerges in robots' interactive physical and social performances. For example, when the Softbank robot Pepper uses a program to sense the presence of a human through a video camera, and analyses that person's face with image recognition algorithms, and offers to shake hands only if it 'recognises' him or her [40], it exceeds the capabili of automata because it works with social meanings of offers and rejections. In its embodied interactivity, it transcends the alterity relations of automata to manifest a degree of liveliness.

The claim that a robot can perform active social touch seems to re-open debates over artificial intelligence (AI). Does active touch require the robot to form an intention? Does it need to understand' the social and affective significance of active touch with another? For a long time, debates over 'hard' AI were based on comparing the 'thinking' processes of computers with those of people. Among the classic criticisms of AI is Dreyfus's rejection of the symbolic approach [41, 42]. He drew upon Heidegger's critique of the rationalist tradition and its assumption that thought is symbolic manipulation. Dreyfus's criticisms seemed plausible in the 1970s-90s considering the lack of convincing results in Al research. With his philosophical affiliation with phenomenology, Dreyfus saw this failure as a vindication of his critique of rationalism:

by combining rationalism, representationalism, conceptualism, formalism, and logical atomism into a research program, AI researchers had condemned their enterprise to re-enact a failure [42: 121].

In contrast to symbolic approaches to AI, Dreyfus [41] argues that intelligence should be grounded in something like Dasein's being-in-the-world, and the kind of knowledge that operates in readiness-to-hand. This would mean it would have concern for equipment in its surroundings and the capacity to initiate active touch. Many in the fields of AI and robotics were persuaded that embodiment was essential to simulating intelligence [43]. Dreyfus saw the behaviour-based robotics approach advocated by Rodney Brooks [44] as one step towards this goal, engaging more directly with the world through its sensors and building its actions in the world from the bottom-up. Brooks' experiments with robots such as 'Allen', which avoided touching things in its environment, wandered at random, or headed towards distant things, established a kind of situated lively alterity relations [45]. From very simple principles, its approach had some early successes in invoking liveliness, but it proved difficult to extend it into more complex behaviours [46].

Robotic developers have come to use a mix of techniques to create autonomous operation in robots: frame-by-frame animation, representational programming, behaviour-based techniques and machine learning. One strategy that NASA used with R2 was to create behavioural primitives, such as having the robot reach out and hold an object. The higher-level motor action program GRASP [47] is an abstract routine at the 'planner' level that can perform a grasping action onto anything. It was this routine that programmers invoked when R2 performed the handshake with Commander Burbank, turning an instrumental function into a meaningful social performance.

Lively human-robot touch is therefore more than what the human perceives and what the robot senses. It emerges in the choreographed and improvised action in-between the two through mutual influence. In most cases, it is the human that is more adaptable or more manipulable. Mark Coeckelbergh argues that many technologies already choreograph our movement through their own actions [8]. For example, computer games guide players through environments and the compel them to react to the actions of non playing characters. In a similar way, a robot can use theatrical techniques such as facial expressions, gestures, speech and turn-taking to choreograph our interactions with it. When Robonaut offered its hand to Burbank, according to social protocols, Burbank had to reach down to grasp the robot's hand in order to join the handshake. The robot was programmed, but Burbank's actions were not entirely his own either, as he followed the shared social script of the handshake. This suggests that robots might achieve cultural sustainability by drawing upon the repertoire of conventional choreographic patterns available in culture. However, there need to be mechanisms for choosing which conventional routines should apply to the situation, and sufficiently cultural common ground for this to work reliably. As Chesher [48] argues, human-robot interactions can be governed by metacommunication communication about communication that frames ongoing interaction. In Robonaut's information architecture, these may be handled at the level above the planner level-the "arbitration level" [47], where goal planning, health monitoring and user input take place. However, metacommunication does not need to be handled with such technical means. One of the most successful robots widely used in elderly care is the Paro therapeutic robot, modelled on a baby seal. It invites care in its appearance and its soft materials, and reacts with its body and its eyes to the user's touch to establish lively alterity relations [49].

Another example of a technology that choreographs embodied interaction is the virtual reality application First Steps for Oculus Quest. It features a mini-game that introduces new players to a glowing robot in a large space ship. When one of us first played it, the robot offered its hand, and I was impelled to reach out and shake it. This gave me immediate feedback-I saw my hand join with the robot's, felt haptic pulses in my hand, heard associated sounds, and saw the robot move kinematically towards my body. I was then urged to dance, waving my hands, lowering my body towards the floor, pulling the robot by its arms and releasing its hand to spin it on the dance floor. This interaction felt like a playful, spontaneous and delightful discovery of the robot's affordances, and sensitised me to the embodied experience of the virtual reality set-up. In a similar way, the first time that I came face-to-face with the Geminoid-F robot at UNSW in 2013 I felt a thrill of recognition, as it seemed to make eye contact with me, following my movements. In each of these cases, I would describe the experience of these interactions as lively alterity relations because the other that I encountered initiated situated actions and responded to my own in an apparently shared lifeworld. I was not fooled, but I felt compelled to behave respectfully and self-consciously towards the lively other.

While Robonaut was the first humanoid robot to participate in lively social interactions in space, many researchers on earth have choreographed robots for social touch. For example, Jindai and Watanabe [51] adapted a small robot with two cameras to recognise the 3D position of the human hands that it aims to shake. The robot could then initiate a handshake which subjects found was not only natural in its movement, but "emotionally acceptable" [50: 525]. Designing a robot with powerful motors and heavy materials that shakes hands can present design and engineering challenges that not only afford social touch, but also avoid harming people. Noda et al. [51] wrapped a Robovie robot in malleable tactile sensors that allowed the robot's processor to refer to a "somatosensory map" of its body surface. Using this configuration it was able to participate in social touch interactions, including scenarios such as: "let's shake hands" and "give me a hug" [51: 1102]. Others have developed robots to provide physical and mental support to child and adult patients by facilitating lively interactions with humanoid and pet-like robots, including Paro the seal [52, 53], the humanoid robot KASPAR [54] and the Haptic Creature [17]. In each of these examples, the robots have the ability to sense, interpret and respond to touch using naturalistic choreographed and improvised movement, sound and vibration.

It is apparent that while the connections that we refer to as lively alterity relations between people and robots are not symmetrical, they are relational. That is, robots can perform meaningful proactive and reactive movements that can be experienced in sensation, and in cognitive and affective terms. These interactions are also meaningful for those witnessing lively encounters, such as watching the video of the handshake in the ISS. We might note that liveliness is a form of alterity relation in which there is some experienced directed agency in the other.

Lively alterity relations are established in many other contexts of human-technology relations besides humanoid robotics. The smartphone, with its touchscreen and vibration features experienced in the human hand and body, is a medium of liveliness that attracts attention and gives haptic feedback for touch-screen interaction. The massage chair in airports and shopping centres, with permission, lays its robotic hands onto people's bodies. The computer game, mentioned earlier, inserts the active touch of the player's hand into the older medium of animation. Virtual reality brings the whole body into an animated space of lively alterity. However, the humanoid robot holds a particular fascination, in popular culture, at least. In some ways, this may be a narcissistic mirroring of the self. In other ways it may invoke the seductive or fearful constitution of the other, promising powerful affective relations [26]. To address any of these desires and expectations, designers of culturally sustainable social robots that actively touch will need to combine programming with choreography and a sensitivity to staging lively human-machine interactions.

## References

<div class="notes-and-refs">

-   [1] Diftler MA, Ahlstrom TD, Ambrose RO, Radford NA, Joyce CA, De La Pena N, et al. Robonaut 2 - Initial activities on-board the ISS. IEEE Aerospace Conference Proceedings. 2012;1-12.
-   [2] VideoFromSpace. First robot to astronaut handshake on-orbit. YouTube; 2012.
-   [3] Mauss M. The gift. Forms and functions of exchange in archaic societies. London: Cohen and West; 1966.
-   [4] Goffman E. Relations in public: Microstudies of the public order. New York: Basic Books; 1971.
-   [6] Cranny-Francis A. Technology and touch. The biopolitics of emerging technologies. London: Palgrave
-   [8] Coeckelbergh M. Moved by machines: Performance metaphors and philosophy of technology. New
-   [11] Slack S, Wise JM. Cultural Studies and communication technology. In: Lievrouw LA, Livingstone S,
-   [12] Sumner EM, Ramirez A. Media and Communications. In: Allen M, editor. Allen, M The SAGE Encyclopedia of Communication Research Methods.
-   [15] Ihde D. Technology and the lifeworld. Bloomington: Indiana University Press; 1996.
-   [16] Silvera-Tawil D, Rye D, Velonaki M. Artificial skin and tactile sensing for socially interactive robots: A
-   [20] NASA. Astronaut biography: Daniel C. Burbank. [Internet]. Houston, TX: NASA; 2018, Available from: http://www.nasa.gov/astronauts/biographies/daniel-c-burbank.
-   [5] Schiffrin D. Handwork as ceremony: The case of the handshake. Nonverbal Communication, Interaction, and Gesture: Selections from SEMIOTICA. 2010;237-50. Macmillan UK; 2013.
-   [7] Wright J. Historic handshake for Robonaut 2 [Internet]. National Aeronautics and Space Administration. 2017. Available from: https://www.nasa.gov/mission_pages/station/main/r2_handshake.html. York: Routledge; 2019.
-   [9] Field T. Touch. Second Edi. Cambridge MA; 2014.
-   [10] Scott M. Tactual perception. Australasian Journal of Philosophy. 2001;79(2):149-60.
-   editors. Handbook of New Media: Social Shaping and Consequences of ICTs. Student Ed. London: Sage; 2006. p. 141-162.
-   [13] Castañeda C, Suchman L. Robot visions. Social Studies of Science. 2014;44(3):315-41.
-   [14] Heidegger M, Macquarrie J, Robinson E. Being and time. Oxford: Basil Blackwell; 1962.
-   review. Robotics and Autonomous Systems. 2015;63(P3):230-43.
-   [17] Yohanan S, MacLean KE. The role of affective touch in human-robot interaction: Human intent and expectations in touching the Haptic Creature. International Journal of Social Robotics. 2012;4(2):163-80.
-   [18] National Aeronautics and Space Administration. NASAfacts - Robonaut Facts. 2011.
-   [19] Bonsor K, Gerbis N. How Robonauts work [Internet]. How stuff works. Available from: https://science.howstuffworks.com/robonaut2.html.
-   [21] Robles-De-La-Torre G. The Importance of the sense of touch in virtual and real environments. IEEE Multimedia. 2006;13(3):24-30.
-   [22] Gibson JJ. Psychological Review Observations on Active Touch Psychological Review. 1962;69(6):477-91.
-   [23] Schiff W, Foulke E. Tactual Perception: A Sourcebook. In Cambridge: Cambridge University Press; 1982.
-   [24] Ponton D. The pragmatics of the handshake: A politeness index in British and Italian usage. Vestnik Rossijskogo Universiteta Družby Narodov: Seriâ Lingvistika. 2014;0(4):60-75.
-   [25] Bennington G. Handshake. Derrida today. 2008;1(2):167-84.
-   [26] White RJ. Weightlessness and the human body. Scientific American. 1998;279(3):58-63.
-   [27] Gaskill M. Making sense of human senses in space [Internet]. NASA website. 2018. Available from: https://www.nasa.gov/mission_pages/station/research/news/human_senses_in_space.
-   [28] Coeckelbergh M. Growing moral relations. Growing Moral Relations. Houndsmills: Palgrave Macmillan UK; 2012.
-   [29] Cerulo KA. Nonhumans in Social Interaction. Annual Review of Sociology. 2009;35(1):531-52.
-   [30] Horton D, Richard Wohl R. Mass communication and para-social interaction. Psychiatry. 1956;19(3):215-29.
-   [31] Reeves B, Nass CI. The media equation: How people treat computers, television, and new media like real people and places. Cambridge university press; 1996.
-   [32] Nass C, Moon Y, Fogg BJ, Reeves B, Dryer DC. Can computer personalities be human personalities? Vol. 43, International Journal of Human - Computer Studies. 1995. p. 223-39.
-   [33] Reeves B, Nass. CI. The media equation: How people treat computers, television, and new media like real people and places. Cambridge University Press; 1996.
-   [34] Nass C, Moon Y. Machines and mindlessness: Social responses to computers. Journal of Social Issues. 2000;56(1):81-103.
-   [35] Lane H. Wings in orbit: Scientific and engineering legacies of the space shuttle [Internet]. NASA website. 2011. Available from: https://www.nasa.gov/mission_pages/station/research/news/human_senses_in_space.
-   [36] Ackerman E. NASA JSC unveils Valkyrie DRC Robot [Internet]. IEEE Spectrum. 2013. Available from: https://spectrum.ieee.org/automaton/robotics/military-robots/nasa-jsc-unveils-valkyrie-drc-robot.
-   [37] Schaffer S. OK computer [Internet]. Imaginary futures. 2007 [cited 2020 Jul 9]. Available from: http://www.imaginary futures.net/2007/04/16/ok-computer-by-simon-schaffer.
-   [38] Abuelsamid S. Robonaut 2 demonstration at Kennedy Space Center. NASA; 2012.
-   [39] Bekey GA. Autonomous robots: From biological inspiration to implementation and control. The MIT Press; 2005.
-   [40] Coding Kids. Pepper robot You only shake hands with me [Internet]. 2017. Available from: https://youtu.be/0_hICYW_17Q.
-   [41] Dreyfus HL. What computers can't do. A critique of artificial reason. Harper and Row. 1972.
-   [42] Dreyfus H. How representational cognitivism failed and is being replaced by body/world coupling. In: Leidlmair K, editor. After Cognitivism. Dordrecht: Springer; 2009.
-   [43] Duffy B, Joue G. Intelligent robots: The question of embodiment. Proceedings of Brain-Machine 2000. 2000. p. 20-2.
-   [44] Brooks RA. Intelligence without representation. Artificial Intelligence. 1991;47(1-3):139-59.
-   [45] Brooks R. How to build complete creatures rather than isolated cognitive simulators. Artificial Intelligence. 1987;225-239.
-   [46] Arkin R. Behavior-Based Robotics. Cambridge, MA: MIT Press; 1998.
-   [47] Badger JM, Yamokoski JD, Wightman BJ. Towards autonomous operation of Robonaut 2. AIAA Infotech at Aerospace Conference and Exhibit 2012. 2012. p. 2-4.
-   [48] Chesher C. FURO at Robotworld: Human-robot metacommunication and media studies. In Adelaide: Cultural Studies Association of Australia; 2012. p. 1-10.
-   [49] Jung MM, van der Leij L., Kelders SM. An exploration of the benefits of an animallike robot companion with more advanced touch interaction capabilities for dementia care. Frontiers in ICT. 2017;4(16):1-11.
-   [50] Jindai M, Watanabe T. A small-size handshake robot system based on a handshake approaching motion model with a voice greeting. In: 2010 IEEE/ASME International Conference on Advanced Intelligent Mechatronics. Montreal, Canada: IEEE; 2010. p. 521-6.
-   [51] Noda T, Ishiguro H, Miyashita T, Hagita N. Map acquisition and classification of haptic interaction using cross correlation between distributed tactile sensors on the whole body surface. IEEE International Conference on Intelligent Robots and Systems. 2007. p. 1099-105.
-   [52] Shibata T. An overview of human interactive robots for psychological enrichment. Proceedings of the IEEE. 2004;92(11):1749-58.
-   [53] Wada K, Shibata T. Living with seal robots - Its sociopsychological and physiological influences on the elderly at a care house. IEEE Transactions on Robotics. 2007;23(5):972-80.
-   [54] Robins B, Amirabdollahian F, Ji Z, Dautenhahn K. Tactile interaction with a humanoid robot for children with autism: A case study analysis involving user requirements and results of an initial implementation. Proceedings - IEEE International Workshop on Robot and Human Interactive Communication. 2010. p. 704-11.

</div>
